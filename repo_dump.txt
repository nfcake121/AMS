===== FILE: data/examples/request_scandi.json =====
{
  "type": "sofa",
  "style": "scandi",
  "layout": "straight",
  "seat_height_mm": 440,
  "seat_depth_mm": 600,
  "seat_width_range_mm": [500, 700],
  "leg_family": "tapered_cone",
  "armrests": "both",
  "preferences": {
    "leg_thickness_bias": "thin",
    "arm_profile": "rounded_bottom",
    "seat_softness": "medium"
  }
}



===== FILE: data/examples/sofa_ir.json =====
{
  "version": "0.1",
  "id": "sofa_ir_scandi_back_hslats_split_v01",
  "style": "scandi",
  "layout": "straight",
  "seat_count": 2,

  "seat_height_mm": 445,
  "seat_depth_mm": 520,
  "seat_width_mm": 900,

  "legs": {
    "family": "tapered_cone",
    "height_mm": 150,
    "params": { "r_top": 20, "r_bottom": 14 }
  },

  "arms": {
    "type": "both",
    "width_mm": 110,
    "profile": "box"
  },

  "frame": {
    "thickness_mm": 34,
    "back_thickness_mm": 80,
    "back_height_above_seat_mm": 460
  },

  "slats": {
    "enabled": true,
    "count": 16,
    "width_mm": 50,
    "thickness_mm": 12,
    "arc_height_mm": 22,
    "arc_sign": -1,
    "margin_x_mm": 40,
    "margin_y_mm": 55,
    "clearance_mm": 4,
    "mount_mode": "rests_on_plane",
    "mount_offset_mm": 3,
    "rail_inset_mm": 3,
    "rail_inset_y_mm": 18,
    "rail_height_mm": 30,
    "rail_width_mm": 30
  },

  "back_support": {
    "mode": "slats",

    "height_above_seat_mm": 480,
    "thickness_mm": 60,
    "offset_y_mm": 12,

    "margin_x_mm": 30,
    "margin_z_mm": 24,

    "split_center": true,
    "center_post": {
      "enabled": true,
      "thickness_mm": 30,
      "inset_y_mm": 0
    },

    "slats": {
      "orientation": "horizontal",

      "count": 8,
      "width_mm": 70,
      "gap_mm": 42,
      "thickness_mm": 14,

      "arc_height_mm": 0,
      "arc_sign": -1,

      "side_mode": "two_sides",
      "center_gap_mm": 16
    }
  }
}



===== FILE: data/examples/sofa_request.json =====
{
  "request_id": "request_example",
  "user_profile": {
    "style": "modern",
    "color": "gray"
  },
  "dimensions": {
    "width_cm": 2000,
    "depth_cm": 900,
    "height_cm": 800
  }
}



===== FILE: data/examples/user_text.txt =====
I need a modern gray sofa that is about 200cm wide with a chaise on the left.



===== FILE: NER_Parametric_model_1.1.py =====
import torch

print("PyTorch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())

if torch.cuda.is_available():
    print("CUDA version used by torch:", torch.version.cuda)
    print("GPU count:", torch.cuda.device_count())
    print("GPU name 0:", torch.cuda.get_device_name(0))
    print("Compute capability:", torch.cuda.get_device_capability(0))



===== FILE: README.md =====
# AMS

This repository sketches a workflow for turning natural language sofa requests into 3D assets:

1. NER extracts entities from user text.
2. Entities are normalized into a request payload.
3. The request is resolved into an intermediate representation (IR JSON).
4. Blender runner scripts consume the IR JSON to build geometry.
5. The Blender pipeline exports GLB assets.

The new builder subsystem lives in `src/builders/` with Blender and CAD stubs, while pipeline helpers live in `src/pipeline/`.

## How to run the builder

Run the builder and export a GLB using the Python runner (requires Blender installed):

```bash
python -m src.builders.blender.export_blender data/examples/sofa_ir.json out/glb/sofa.glb
```

To point at a custom Blender executable:

```bash
BLENDER_EXE=/path/to/blender python -m src.builders.blender.export_blender data/examples/sofa_ir.json out/glb/sofa.glb
```



===== FILE: repo_dump.txt =====
===== FILE: data/examples/request_scandi.json =====
{
  "type": "sofa",
  "style": "scandi",
  "layout": "straight",
  "seat_height_mm": 440,
  "seat_depth_mm": 600,
  "seat_width_range_mm": [500, 700],
  "leg_family": "tapered_cone",
  "armrests": "both",
  "preferences": {
    "leg_thickness_bias": "thin",
    "arm_profile": "rounded_bottom",
    "seat_softness": "medium"
  }
}



===== FILE: data/examples/sofa_ir.json =====
{
  "version": "0.1",
  "id": "sofa_ir_scandi_baseline_v02",
  "style": "scandi",
  "layout": "straight",
  "seat_count": 2,

  "seat_height_mm": 450,
  "seat_depth_mm": 560,
  "seat_width_mm": 1400,

  "legs": {
    "family": "tapered_cone",
    "height_mm": 160,
    "params": { "r_top": 22, "r_bottom": 14 }
  },

  "arms": {
    "type": "both",
    "width_mm": 120,
    "profile": "box"
  },

  "frame": {
    "thickness_mm": 34,
    "back_thickness_mm": 70,
    "back_height_above_seat_mm": 420
  },

  "slats": {
    "enabled": true,
    "count": 14,
    "width_mm": 55,
    "thickness_mm": 12,
    "arc_height_mm": 18,
    "arc_sign": -1,
    "margin_x_mm": 45,
    "margin_y_mm": 60,
    "clearance_mm": 6,
    "mount_mode": "rests_on_plane",
    "mount_offset_mm": 4,
    "rail_inset_mm": 4,
    "rail_inset_y_mm": 18,
    "rail_height_mm": 30,
    "rail_width_mm": 30
  },

  "back_support": {
    "mode": "slats",
    "height_above_seat_mm": 460,
    "thickness_mm": 45,
    "offset_y_mm": 8,
    "margin_x_mm": 45,
    "margin_z_mm": 25,
    "slats": {
      "count": 7,
      "width_mm": 45,
      "thickness_mm": 14,
      "arc_height_mm": 6,
      "arc_sign": -1
    }
  }
}



===== FILE: data/examples/sofa_request.json =====
{
  "request_id": "request_example",
  "user_profile": {
    "style": "modern",
    "color": "gray"
  },
  "dimensions": {
    "width_cm": 2000,
    "depth_cm": 900,
    "height_cm": 800
  }
}



===== FILE: data/examples/user_text.txt =====
I need a modern gray sofa that is about 200cm wide with a chaise on the left.



===== FILE: NER_Parametric_model_1.1.py =====
import torch

print("PyTorch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())

if torch.cuda.is_available():
    print("CUDA version used by torch:", torch.version.cuda)
    print("GPU count:", torch.cuda.device_count())
    print("GPU name 0:", torch.cuda.get_device_name(0))
    print("Compute capability:", torch.cuda.get_device_capability(0))



===== FILE: README.md =====
# AMS

This repository sketches a workflow for turning natural language sofa requests into 3D assets:

1. NER extracts entities from user text.
2. Entities are normalized into a request payload.
3. The request is resolved into an intermediate representation (IR JSON).
4. Blender runner scripts consume the IR JSON to build geometry.
5. The Blender pipeline exports GLB assets.

The new builder subsystem lives in `src/builders/` with Blender and CAD stubs, while pipeline helpers live in `src/pipeline/`.

## How to run the builder

Run the builder and export a GLB using the Python runner (requires Blender installed):

```bash
python -m src.builders.blender.export_blender data/examples/sofa_ir.json out/glb/sofa.glb
```

To point at a custom Blender executable:

```bash
BLENDER_EXE=/path/to/blender python -m src.builders.blender.export_blender data/examples/sofa_ir.json out/glb/sofa.glb
```



===== FILE: repo_dump.txt =====
===== FILE: data/examples/request_scandi.json =====
{
  "type": "sofa",
  "style": "scandi",
  "layout": "straight",
  "seat_height_mm": 440,
  "seat_depth_mm": 600,
  "seat_width_range_mm": [500, 700],
  "leg_family": "tapered_cone",
  "armrests": "both",
  "preferences": {
    "leg_thickness_bias": "thin",
    "arm_profile": "rounded_bottom",
    "seat_softness": "medium"
  }
}



===== FILE: data/examples/sofa_ir.json =====
{
  "version": "0.1",
  "id": "sofa_ir_scandi_ultra_narrow_v01",
  "style": "scandi",
  "layout": "straight",
  "seat_count": 2,

  "seat_height_mm": 445,
  "seat_depth_mm": 520,
  "seat_width_mm": 900,

  "legs": {
    "family": "tapered_cone",
    "height_mm": 150,
    "params": { "r_top": 20, "r_bottom": 14 }
  },

  "arms": {
    "type": "both",
    "width_mm": 110,
    "profile": "box"
  },

  "frame": {
    "thickness_mm": 34,
    "back_thickness_mm": 80,
    "back_height_above_seat_mm": 460
  },

  "slats": {
    "enabled": true,
    "count": 14,
    "width_mm": 50,
    "thickness_mm": 12,
    "arc_height_mm": 22,
    "arc_sign": -1,
    "margin_x_mm": 40,
    "margin_y_mm": 55,
    "clearance_mm": 4,
    "mount_mode": "rests_on_plane",
    "mount_offset_mm": 3,
    "rail_inset_mm": 3,
    "rail_inset_y_mm": 18,
    "rail_height_mm": 30,
    "rail_width_mm": 30
  },

  "back_support": {
    "mode": "slats",
    "height_above_seat_mm": 480,
    "thickness_mm": 70,
    "offset_y_mm": 12,
    "margin_x_mm": 40,
    "margin_z_mm": 30,
    "slats": {
      "count": 7,
      "width_mm": 38,
      "thickness_mm": 14,
      "arc_height_mm": 8,
      "arc_sign": -1
    }
  }
}



===== FILE: data/examples/sofa_request.json =====
{
  "request_id": "request_example",
  "user_profile": {
    "style": "modern",
    "color": "gray"
  },
  "dimensions": {
    "width_cm": 200,
    "depth_cm": 90,
    "height_cm": 80
  }
}



===== FILE: data/examples/user_text.txt =====
I need a modern gray sofa that is about 200cm wide with a chaise on the left.



===== FILE: NER_Parametric_model_1.1.py =====
import torch

print("PyTorch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())

if torch.cuda.is_available():
    print("CUDA version used by torch:", torch.version.cuda)
    print("GPU count:", torch.cuda.device_count())
    print("GPU name 0:", torch.cuda.get_device_name(0))
    print("Compute capability:", torch.cuda.get_device_capability(0))



===== FILE: README.md =====
# AMS

This repository sketches a workflow for turning natural language sofa requests into 3D assets:

1. NER extracts entities from user text.
2. Entities are normalized into a request payload.
3. The request is resolved into an intermediate representation (IR JSON).
4. Blender runner scripts consume the IR JSON to build geometry.
5. The Blender pipeline exports GLB assets.

The new builder subsystem lives in `src/builders/` with Blender and CAD stubs, while pipeline helpers live in `src/pipeline/`.

## How to run the builder

Run the builder and export a GLB using the Python runner (requires Blender installed):

```bash
python -m src.builders.blender.export_blender data/examples/sofa_ir.json out/glb/sofa.glb
```

To point at a custom Blender executable:

```bash
BLENDER_EXE=/path/to/blender python -m src.builders.blender.export_blender data/examples/sofa_ir.json out/glb/sofa.glb
```



===== FILE: requirements.txt =====
# Minimal dependencies for development; expand as the pipeline grows.



===== FILE: src/__init__.py =====



===== FILE: src/builders/__init__.py =====
"""Builders package for exporting geometry from resolved IR."""

# TODO: expose builder registries when available.



===== FILE: src/builders/blender/__init__.py =====
"""Blender-specific builders and exporters."""

# TODO: register Blender builders when implemented.



===== FILE: src/builders/blender/builder_v01.py =====
"""Generate a geometry plan and anchors for Blender builds."""

from dataclasses import dataclass, field
from typing import Dict, List, Tuple


@dataclass
class Primitive:
    """Represents a basic geometry primitive."""

    name: str
    shape: str
    dimensions_mm: Tuple[float, float, float]
    location_mm: Tuple[float, float, float]
    rotation_deg: Tuple[float, float, float] = (0.0, 0.0, 0.0)
    params: Dict[str, float] = field(default_factory=dict)


@dataclass
class Anchor:
    """Named anchor or empty location."""

    name: str
    location_mm: Tuple[float, float, float]


@dataclass
class BuildPlan:
    """Container for primitives and anchors to build a sofa frame."""

    primitives: List[Primitive] = field(default_factory=list)
    anchors: List[Anchor] = field(default_factory=list)
    metadata: Dict[str, str] = field(default_factory=dict)


def _ir_value(ir: dict, key: str, default: float) -> float:
    """Helper to fetch numeric values from IR with defaults."""
    value = ir.get(key, default)
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _canon_arms_type(value: str) -> str:
    """Normalize arms type to one of: none, left, right, both."""
    if not isinstance(value, str):
        return "none"
    normalized = value.strip().lower()
    if normalized in {"left", "right", "both", "none"}:
        return normalized
    return "none"


def _arms_count(arms_type: str) -> int:
    """Return number of arm blocks for a canonical arms_type."""
    if arms_type == "both":
        return 2
    if arms_type in {"left", "right"}:
        return 1
    return 0


def build_plan_from_ir(ir: dict) -> BuildPlan:
    """Create a sofa-frame geometry plan from resolved IR.

    Coordinate system: X is width (left/right), Y is depth (front/back),
    Z is up. seat_height_mm defines the top of the seat support board.
    """
    seat_width_mm = _ir_value(ir, "seat_width_mm", 600.0)
    seat_depth_mm = _ir_value(ir, "seat_depth_mm", 600.0)
    seat_height_mm = _ir_value(ir, "seat_height_mm", 440.0)
    seat_count = max(1, int(_ir_value(ir, "seat_count", 3)))
    seat_total_width_mm = seat_width_mm * seat_count

    frame = ir.get("frame", {}) if isinstance(ir.get("frame"), dict) else {}
    frame_thickness_mm = _ir_value(frame, "thickness_mm", 35.0)
    back_height_mm = _ir_value(frame, "back_height_above_seat_mm", 420.0)
    back_thickness_mm = _ir_value(frame, "back_thickness_mm", 90.0)

    arms = ir.get("arms", {}) if isinstance(ir.get("arms"), dict) else {}
    arms_type = _canon_arms_type(arms.get("type", "none"))
    arms_width_mm = _ir_value(arms, "width_mm", 120.0)
    arms_total_mm = arms_width_mm * _arms_count(arms_type)
    total_width_mm = seat_total_width_mm + arms_total_mm

    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_height_mm = _ir_value(legs, "height_mm", 160.0)
    legs_family = legs.get("family", "block")

    seat_support_thickness_mm = frame_thickness_mm

    slats = ir.get("slats", {}) if isinstance(ir.get("slats"), dict) else {}
    slats_enabled = bool(slats.get("enabled", False))
    slat_count = max(1, int(_ir_value(slats, "count", 14)))
    slat_width_mm = _ir_value(slats, "width_mm", 55.0)
    slat_thickness_mm = _ir_value(slats, "thickness_mm", 10.0)
    slat_arc_height_mm = _ir_value(slats, "arc_height_mm", 0.0)
    slat_arc_sign = _ir_value(slats, "arc_sign", -1.0)
    slat_margin_x_mm = _ir_value(slats, "margin_x_mm", 40.0)
    slat_margin_y_mm = _ir_value(slats, "margin_y_mm", 60.0)
    slat_clearance_mm = _ir_value(slats, "clearance_mm", 0.0)
    slat_mount_mode = slats.get("mount_mode", "rests_on_plane")
    if not isinstance(slat_mount_mode, str):
        slat_mount_mode = "rests_on_plane"
    slat_mount_mode = slat_mount_mode.strip().lower()
    if slat_mount_mode not in {"rests_on_plane", "centered"}:
        slat_mount_mode = "rests_on_plane"
    slat_mount_offset_mm = _ir_value(slats, "mount_offset_mm", 0.0)
    slat_rail_inset_mm = _ir_value(slats, "rail_inset_mm", 0.0)
    slat_rail_height_mm = _ir_value(slats, "rail_height_mm", frame_thickness_mm)
    slat_rail_width_mm = _ir_value(slats, "rail_width_mm", frame_thickness_mm)
    slat_rail_inset_y_mm = _ir_value(slats, "rail_inset_y_mm", slat_margin_y_mm)

    has_back_support = "back_support" in ir
    back_support = ir.get("back_support", {}) if isinstance(ir.get("back_support"), dict) else {}
    back_support_mode = back_support.get("mode", "panel")
    if not isinstance(back_support_mode, str):
        back_support_mode = "panel"
    back_support_mode = back_support_mode.strip().lower()
    if back_support_mode not in {"panel", "slats", "straps"}:
        back_support_mode = "panel"

    back_height_mm = _ir_value(back_support, "height_above_seat_mm", back_height_mm)
    back_thickness_mm = _ir_value(back_support, "thickness_mm", back_thickness_mm)
    back_offset_y_mm = _ir_value(back_support, "offset_y_mm", 0.0)
    back_margin_x_mm = _ir_value(back_support, "margin_x_mm", 40.0)
    back_margin_z_mm = _ir_value(back_support, "margin_z_mm", 30.0)

    back_slats = back_support.get("slats", {}) if isinstance(back_support.get("slats"), dict) else {}
    back_slat_count = max(1, int(_ir_value(back_slats, "count", 10)))
    back_slat_width_mm = _ir_value(back_slats, "width_mm", 35.0)
    back_slat_thickness_mm = _ir_value(back_slats, "thickness_mm", 10.0)
    back_slat_arc_height_mm = _ir_value(back_slats, "arc_height_mm", 0.0)
    back_slat_arc_sign = _ir_value(back_slats, "arc_sign", -1.0)

    back_straps = back_support.get("straps", {}) if isinstance(back_support.get("straps"), dict) else {}
    back_strap_count = max(1, int(_ir_value(back_straps, "count", 6)))
    back_strap_width_mm = _ir_value(back_straps, "width_mm", 30.0)
    back_strap_thickness_mm = _ir_value(back_straps, "thickness_mm", 6.0)

    # Z placement stack: legs -> base frame -> seat support -> back frame -> arms.
    # Seat support top aligns to seat_height_mm.
    seat_support_top_z = seat_height_mm
    seat_support_center_z = seat_support_top_z - (seat_support_thickness_mm / 2.0)
    base_frame_top_z = seat_support_top_z - seat_support_thickness_mm
    base_frame_center_z = base_frame_top_z - (frame_thickness_mm / 2.0)
    base_frame_bottom_z = base_frame_top_z - frame_thickness_mm
    legs_center_z = base_frame_bottom_z - (legs_height_mm / 2.0)

    plan = BuildPlan(metadata={
        "seat_count": str(seat_count),
        "legs_family": str(legs_family),
        "arms_type": str(arms_type),
        "seat_total_width_mm": str(seat_total_width_mm),
        "total_width_mm": str(total_width_mm),
    })

    # Base frame beams (outer perimeter of total frame).
    front_y = (seat_depth_mm / 2.0) - (frame_thickness_mm / 2.0)
    back_y = -(seat_depth_mm / 2.0) + (frame_thickness_mm / 2.0)
    left_x = -(total_width_mm / 2.0) + (frame_thickness_mm / 2.0)
    right_x = (total_width_mm / 2.0) - (frame_thickness_mm / 2.0)

    plan.primitives.extend(
        [
            Primitive(
                name="beam_front",
                shape="beam",
                dimensions_mm=(total_width_mm, frame_thickness_mm, frame_thickness_mm),
                location_mm=(0.0, front_y, base_frame_center_z),
            ),
            Primitive(
                name="beam_back",
                shape="beam",
                dimensions_mm=(total_width_mm, frame_thickness_mm, frame_thickness_mm),
                location_mm=(0.0, back_y, base_frame_center_z),
            ),
            Primitive(
                name="beam_left",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm, frame_thickness_mm),
                location_mm=(left_x, 0.0, base_frame_center_z),
            ),
            Primitive(
                name="beam_right",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm, frame_thickness_mm),
                location_mm=(right_x, 0.0, base_frame_center_z),
            ),
        ]
    )

    # Cross beams across depth (along Y), evenly spaced along X.
    cross_count = max(2, min(4, seat_count + 1))
    inner_width_mm = max(1.0, total_width_mm - (2.0 * frame_thickness_mm))
    cross_spacing_mm = inner_width_mm / (cross_count + 1)
    for i in range(cross_count):
        x = -(inner_width_mm / 2.0) + cross_spacing_mm * (i + 1)
        plan.primitives.append(
            Primitive(
                name=f"beam_cross_{i + 1}",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm - (2.0 * frame_thickness_mm), frame_thickness_mm),
                location_mm=(x, 0.0, base_frame_center_z),
            )
        )

    # Seat support board (seat area only) on top of base frame.
    if not slats_enabled:
        plan.primitives.append(
            Primitive(
                name="seat_support",
                shape="board",
                dimensions_mm=(seat_total_width_mm, seat_depth_mm, seat_support_thickness_mm),
                location_mm=(0.0, 0.0, seat_support_center_z),
            )
        )

    # Slats (lamellas) across X, running along Y with front/back margins.
    if slats_enabled:
        slat_length_mm = max(1.0, seat_depth_mm - (2.0 * slat_margin_y_mm))
        rail_length_mm = max(1.0, seat_depth_mm - (2.0 * slat_rail_inset_y_mm))
        usable_width_mm = max(1.0, seat_total_width_mm - (2.0 * slat_margin_x_mm))
        if slat_count == 1:
            slat_centers_x = [0.0]
        else:
            span_mm = max(0.0, usable_width_mm - slat_width_mm)
            step_mm = span_mm / (slat_count - 1)
            start_x = -(usable_width_mm / 2.0) + (slat_width_mm / 2.0)
            slat_centers_x = [start_x + (step_mm * i) for i in range(slat_count)]

        # Slats mount to the base frame top plane unless explicitly centered.
        slat_plane_z_mm = base_frame_top_z
        if slat_mount_mode == "centered":
            slat_center_z = seat_support_top_z - (slat_thickness_mm / 2.0) + slat_clearance_mm
        else:
            slat_center_z = (
                slat_plane_z_mm
                + slat_mount_offset_mm
                + slat_clearance_mm
                + (slat_thickness_mm / 2.0)
            )

        min_x = min(slat_centers_x) - (slat_width_mm / 2.0)
        max_x = max(slat_centers_x) + (slat_width_mm / 2.0)
        rail_height_mm = slat_rail_height_mm
        rail_width_mm = slat_rail_width_mm
        rail_depth_mm = rail_length_mm
        rail_top_z = slat_plane_z_mm
        rail_center_z = rail_top_z - (rail_height_mm / 2.0)
        rail_left_x = min_x + (rail_width_mm / 2.0) + slat_rail_inset_mm
        rail_right_x = max_x - (rail_width_mm / 2.0) - slat_rail_inset_mm
        if rail_left_x < rail_right_x:
            plan.primitives.append(
                Primitive(
                    name="rail_left",
                    shape="beam",
                    dimensions_mm=(rail_width_mm, rail_depth_mm, rail_height_mm),
                    location_mm=(rail_left_x, 0.0, rail_center_z),
                )
            )
            plan.primitives.append(
                Primitive(
                    name="rail_right",
                    shape="beam",
                    dimensions_mm=(rail_width_mm, rail_depth_mm, rail_height_mm),
                    location_mm=(rail_right_x, 0.0, rail_center_z),
                )
            )
            plan.anchors.append(
                Anchor(name="rail_left", location_mm=(rail_left_x, 0.0, rail_center_z))
            )
            plan.anchors.append(
                Anchor(name="rail_right", location_mm=(rail_right_x, 0.0, rail_center_z))
            )

        plan.anchors.append(Anchor(name="slat_plane_z", location_mm=(0.0, 0.0, slat_plane_z_mm)))
        plan.anchors.append(Anchor(name="slat_area_center", location_mm=(0.0, 0.0, slat_center_z)))
        for i, x in enumerate(slat_centers_x, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"slat_{i}",
                    shape="slat",
                    dimensions_mm=(slat_width_mm, slat_length_mm, slat_thickness_mm),
                    location_mm=(x, 0.0, slat_center_z),
                    params={
                        "arc_height_mm": slat_arc_height_mm,
                        "arc_sign": slat_arc_sign,
                        "orientation": "horizontal",
                        "mount_mode": slat_mount_mode,
                        "mount_offset_mm": slat_mount_offset_mm,
                        "clearance_mm": slat_clearance_mm,
                    },
                )
            )

    # Back support (panel/slats/straps) at rear edge.
    back_frame_plane_y = -(seat_depth_mm / 2.0)
    back_plane_y = back_frame_plane_y - (back_thickness_mm / 2.0) + back_offset_y_mm
    back_center_z = seat_support_top_z + (back_height_mm / 2.0)
    back_panel_center = (0.0, back_plane_y, back_center_z)

    if not has_back_support:
        # Backward-compatible panel using frame.back_* dimensions.
        plan.primitives.append(
            Primitive(
                name="back_frame",
                shape="board",
                dimensions_mm=(total_width_mm, back_thickness_mm, back_height_mm),
                location_mm=back_panel_center,
            )
        )
    elif back_support_mode == "panel":
        plan.primitives.append(
            Primitive(
                name="back_panel",
                shape="board",
                dimensions_mm=(total_width_mm, back_thickness_mm, back_height_mm),
                location_mm=back_panel_center,
            )
        )
    elif back_support_mode == "slats":
        slat_height_mm = max(1.0, back_height_mm - (2.0 * back_margin_z_mm))
        back_slat_center_z = seat_support_top_z + back_margin_z_mm + (slat_height_mm / 2.0)
        back_slat_plane_y = back_frame_plane_y + back_offset_y_mm
        back_slat_center_y = back_slat_plane_y - (back_slat_thickness_mm / 2.0)
        usable_width_mm = max(1.0, seat_total_width_mm - (2.0 * back_margin_x_mm))
        if back_slat_count == 1:
            slat_centers_x = [0.0]
        else:
            span_mm = max(0.0, usable_width_mm - back_slat_width_mm)
            step_mm = span_mm / (back_slat_count - 1)
            start_x = -(usable_width_mm / 2.0) + (back_slat_width_mm / 2.0)
            slat_centers_x = [start_x + (step_mm * i) for i in range(back_slat_count)]

        plan.anchors.append(Anchor(name="back_slat_plane_y", location_mm=(0.0, back_slat_plane_y, 0.0)))
        plan.anchors.append(Anchor(name="back_slat_center_z", location_mm=(0.0, 0.0, back_slat_center_z)))

        min_x = min(slat_centers_x) - (back_slat_width_mm / 2.0)
        max_x = max(slat_centers_x) + (back_slat_width_mm / 2.0)
        back_rail_inset_mm = _ir_value(back_support, "rail_inset_mm", 0.0)
        back_rail_width_mm = _ir_value(back_support, "rail_width_mm", frame_thickness_mm)
        back_rail_depth_mm = _ir_value(back_support, "rail_depth_mm", back_thickness_mm)
        back_rail_height_mm = _ir_value(back_support, "rail_height_mm", slat_height_mm)
        rail_left_x = min_x + (back_rail_width_mm / 2.0) + back_rail_inset_mm
        rail_right_x = max_x - (back_rail_width_mm / 2.0) - back_rail_inset_mm
        if (
            back_rail_width_mm > 0.0
            and back_rail_depth_mm > 0.0
            and back_rail_height_mm > 0.0
            and rail_left_x < rail_right_x
        ):
            plan.primitives.append(
                Primitive(
                    name="back_rail_left",
                    shape="beam",
                    dimensions_mm=(back_rail_width_mm, back_rail_depth_mm, back_rail_height_mm),
                    location_mm=(rail_left_x, back_slat_center_y, back_slat_center_z),
                )
            )
            plan.primitives.append(
                Primitive(
                    name="back_rail_right",
                    shape="beam",
                    dimensions_mm=(back_rail_width_mm, back_rail_depth_mm, back_rail_height_mm),
                    location_mm=(rail_right_x, back_slat_center_y, back_slat_center_z),
                )
            )
            plan.anchors.append(
                Anchor(name="back_rail_left", location_mm=(rail_left_x, back_slat_center_y, back_slat_center_z))
            )
            plan.anchors.append(
                Anchor(name="back_rail_right", location_mm=(rail_right_x, back_slat_center_y, back_slat_center_z))
            )

        for i, x in enumerate(slat_centers_x, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"back_slat_{i}",
                    shape="slat",
                    dimensions_mm=(back_slat_width_mm, back_slat_thickness_mm, slat_height_mm),
                    location_mm=(x, back_slat_center_y, back_slat_center_z),
                    params={
                        "arc_height_mm": back_slat_arc_height_mm,
                        "arc_sign": back_slat_arc_sign,
                        "orientation": "vertical",
                    },
                )
            )
            plan.anchors.append(
                Anchor(name=f"back_slat_{i}", location_mm=(x, back_slat_center_y, back_slat_center_z))
            )
    elif back_support_mode == "straps":
        strap_center_x = 0.0
        strap_span_z_mm = max(1.0, back_height_mm - (2.0 * back_margin_z_mm))
        if back_strap_count == 1:
            strap_centers_z = [seat_support_top_z + (back_height_mm / 2.0)]
        else:
            step_mm = strap_span_z_mm / (back_strap_count - 1)
            start_z = seat_support_top_z + back_margin_z_mm
            strap_centers_z = [start_z + (step_mm * i) for i in range(back_strap_count)]

        for i, z in enumerate(strap_centers_z, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"back_strap_{i}",
                    shape="board",
                    dimensions_mm=(seat_total_width_mm, back_strap_thickness_mm, back_strap_width_mm),
                    location_mm=(strap_center_x, back_plane_y, z),
                )
            )

    # Simple arm frames as boards when present.
    # Arms sit outside the seat area in X, and their bottoms align to the base frame top.
    arm_height_mm = max(frame_thickness_mm * 2.0, seat_height_mm * 0.65)
    arm_center_z = base_frame_top_z + (arm_height_mm / 2.0)
    if arms_type in {"both", "left"}:
        left_arm_center_x = -(seat_total_width_mm / 2.0) - (arms_width_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="left_arm_frame",
                shape="board",
                dimensions_mm=(arms_width_mm, seat_depth_mm, arm_height_mm),
                location_mm=(left_arm_center_x, 0.0, arm_center_z),
            )
        )
        plan.anchors.append(
            Anchor(name="arm_left_zone", location_mm=(left_arm_center_x, 0.0, seat_height_mm))
        )
    if arms_type in {"both", "right"}:
        right_arm_center_x = (seat_total_width_mm / 2.0) + (arms_width_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="right_arm_frame",
                shape="board",
                dimensions_mm=(arms_width_mm, seat_depth_mm, arm_height_mm),
                location_mm=(right_arm_center_x, 0.0, arm_center_z),
            )
        )
        plan.anchors.append(
            Anchor(name="arm_right_zone", location_mm=(right_arm_center_x, 0.0, seat_height_mm))
        )

    # Leg anchors and leg primitives at corners.
    leg_offset_x = (total_width_mm / 2.0) - (frame_thickness_mm / 2.0)
    leg_offset_y = (seat_depth_mm / 2.0) - (frame_thickness_mm / 2.0)
    leg_points = [
        (-leg_offset_x, -leg_offset_y, legs_center_z),
        (leg_offset_x, -leg_offset_y, legs_center_z),
        (-leg_offset_x, leg_offset_y, legs_center_z),
        (leg_offset_x, leg_offset_y, legs_center_z),
    ]

    for index, point in enumerate(leg_points, start=1):
        plan.anchors.append(Anchor(name=f"leg_point_{index}", location_mm=point))
        plan.primitives.append(
            Primitive(
                name=f"leg_{index}",
                shape=legs_family,
                dimensions_mm=(frame_thickness_mm, frame_thickness_mm, legs_height_mm),
                location_mm=point,
            )
        )

    # Anchors for zones.
    back_bottom_z = seat_support_top_z
    back_top_z = seat_support_top_z + back_height_mm
    back_inner_center = (0.0, back_plane_y, seat_support_top_z + (back_height_mm / 2.0))
    left_back_corner = (-(seat_total_width_mm / 2.0), back_plane_y, back_bottom_z)
    right_back_corner = ((seat_total_width_mm / 2.0), back_plane_y, back_bottom_z)

    plan.anchors.extend(
        [
            Anchor(name="seat_zone", location_mm=(0.0, 0.0, seat_support_center_z)),
            Anchor(name="back_zone", location_mm=back_panel_center),
            Anchor(name="back_bottom_edge_center", location_mm=(0.0, back_plane_y, back_bottom_z)),
            Anchor(name="back_top_edge_center", location_mm=(0.0, back_plane_y, back_top_z)),
            Anchor(name="back_inner_plane_center", location_mm=back_inner_center),
            Anchor(name="left_back_corner", location_mm=left_back_corner),
            Anchor(name="right_back_corner", location_mm=right_back_corner),
        ]
    )

    return plan



===== FILE: src/builders/blender/export_blender.py =====
"""Runner that triggers Blender build from an IR JSON path."""

from __future__ import annotations

import argparse
import os
import subprocess
from pathlib import Path


DEFAULT_GLB_PATH = Path("out/glb/sofa.glb")
DEFAULT_LOG_PATH = Path("out/logs/build.log")
DEFAULT_BLEND_PATH = Path("out/logs/sofa.blend")


def _blender_executable() -> str:
    """Resolve Blender executable path."""
    return os.environ.get("BLENDER_EXE", "blender")


def _run_blender(args: list[str], log_path: Path, env: dict[str, str] | None = None) -> None:
    """Run a Blender command and write output to log."""
    log_path.parent.mkdir(parents=True, exist_ok=True)
    with log_path.open("a", encoding="utf-8") as handle:
        subprocess.run(args, stdout=handle, stderr=subprocess.STDOUT, check=True, env=env)


def run_blender_build(ir_json_path: str, glb_path: str | None = None) -> Path:
    """Run Blender build for the given IR JSON path."""
    ir_path = Path(ir_json_path)
    out_path = Path(glb_path) if glb_path else DEFAULT_GLB_PATH
    blender = _blender_executable()
    blend_path = DEFAULT_BLEND_PATH

    builder_script = Path("tools/blender/run_builder_v01.py")
    export_script = Path("tools/blender/run_export_glb.py")

    builder_env = os.environ.copy()
    builder_env["IR_PATH"] = str(ir_path)
    builder_env["BLEND_PATH"] = str(blend_path)

    _run_blender(
        [
            blender,
            "--background",
            "--python",
            str(builder_script),
            "--",
            str(ir_path),
        ],
        DEFAULT_LOG_PATH,
        env=builder_env,
    )
    if not blend_path.exists() or blend_path.stat().st_size == 0:
        raise RuntimeError(f"Blend file missing or empty: {blend_path.resolve()}")

    export_env = os.environ.copy()
    export_env["GLB_PATH"] = str(out_path)

    _run_blender(
        [
            blender,
            "--background",
            str(blend_path),
            "--python",
            str(export_script),
            "--",
            str(out_path),
        ],
        DEFAULT_LOG_PATH,
        env=export_env,
    )
    if not out_path.exists() or out_path.stat().st_size == 0:
        raise RuntimeError(f"GLB file missing or empty: {out_path.resolve()}")

    return out_path


def main() -> None:
    """CLI entry point."""
    parser = argparse.ArgumentParser(description="Run Blender builder and export GLB.")
    parser.add_argument("ir_json_path", help="Path to resolved IR JSON.")
    parser.add_argument("glb_path", nargs="?", default=str(DEFAULT_GLB_PATH), help="Output GLB path.")
    args = parser.parse_args()

    run_blender_build(args.ir_json_path, args.glb_path)


if __name__ == "__main__":
    main()



===== FILE: src/builders/cad/__init__.py =====
"""CAD-oriented exporters."""

# TODO: register CAD exporters when available.



===== FILE: src/builders/cad/export_step_stub.py =====
"""Placeholder module for STEP export."""

# TODO: implement STEP export once CAD pipeline is defined.

def export_step(resolved_ir, output_path):
    """Export resolved IR to a STEP file."""
    # TODO: translate resolved IR to STEP format.
    return {
        "resolved_ir": resolved_ir,
        "output_path": output_path,
        "exported": False,
    }



===== FILE: src/ner_infer.py =====
from __future__ import annotations

import re
from dataclasses import dataclass
from functools import lru_cache
from typing import Dict, List, Tuple, Optional

import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification


# Простая токенизация, похожая на твою разметку датасета:
# числа, слова, отдельные знаки препинания.
_TOKEN_RE = re.compile(r"\d+(?:[.,]\d+)?|[A-Za-zА-Яа-яЁё]+|[^\w\s]", re.UNICODE)


def basic_tokenize(text: str) -> List[str]:
    return _TOKEN_RE.findall(text)


@dataclass
class NEROutput:
    tokens: List[str]
    tags: List[str]
    entities: Dict[str, List[str]]


@lru_cache(maxsize=4)
def _load(model_dir: str):
    tok = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForTokenClassification.from_pretrained(model_dir)
    model.eval()
    return tok, model


def _bio_to_entities(tokens: List[str], tags: List[str]) -> Dict[str, List[str]]:
    entities: Dict[str, List[str]] = {}
    cur_type: Optional[str] = None
    cur_tokens: List[str] = []

    def flush():
        nonlocal cur_type, cur_tokens
        if cur_type and cur_tokens:
            entities.setdefault(cur_type, []).append(" ".join(cur_tokens))
        cur_type = None
        cur_tokens = []

    for tok, tag in zip(tokens, tags):
        if tag.startswith("B-"):
            flush()
            cur_type = tag[2:]
            cur_tokens = [tok]
        elif tag.startswith("I-") and cur_type == tag[2:]:
            cur_tokens.append(tok)
        else:
            flush()

    flush()
    return entities


def predict(text: str, model_dir: str, max_len: int = 128, device: Optional[str] = None) -> NEROutput:
    tokenizer, model = _load(model_dir)

    words = basic_tokenize(text)

    enc = tokenizer(
        words,
        is_split_into_words=True,
        return_tensors="pt",
        truncation=True,
        max_length=max_len,
    )

    # ВАЖНО: word_ids берём ДО переноса на device и ДО любых преобразований
    if hasattr(enc, "word_ids"):
        word_ids = enc.word_ids(batch_index=0)
    else:
        raise RuntimeError(
            "Tokenizer returned a plain dict without word_ids(). "
            "Ensure you are using a fast tokenizer or keep BatchEncoding object."
        )

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    model.to(device)

    # переносим тензоры, но НЕ затираем enc целиком
    enc_on_device = {k: v.to(device) for k, v in enc.items()}

    with torch.no_grad():
        logits = model(**enc_on_device).logits

    pred_ids = torch.argmax(logits, dim=-1)[0].tolist()
    id2label = model.config.id2label

    word_tags: List[str] = ["O"] * len(words)
    used = set()
    for i, w_id in enumerate(word_ids):
        if w_id is None:
            continue
        if w_id in used:
            continue
        used.add(w_id)
        word_tags[w_id] = id2label[pred_ids[i]]

    entities = _bio_to_entities(words, word_tags)
    return NEROutput(tokens=words, tags=word_tags, entities=entities)




===== FILE: src/pipeline/__init__.py =====
"""Pipeline package for converting NER outputs into buildable IR."""

# TODO: expose high-level pipeline helpers when implementation is ready.



===== FILE: src/pipeline/ner_to_request.py =====
"""Normalize extracted entities into a SofaRequest payload."""

# TODO: define a mapping between NER outputs and SofaRequest fields.
# TODO: validate and normalize entity values (materials, dimensions, styles).

def normalize_entities(entities):
    """Normalize raw NER entities into canonical request fields."""
    # TODO: implement normalization logic once schema is finalized.
    return {
        "raw_entities": entities,
    }


def map_ner_to_request(entities):
    """Map normalized entities into a SofaRequest structure."""
    # TODO: build SofaRequest payload structure from normalized entities.
    return {
        "request": normalize_entities(entities),
    }



===== FILE: src/pipeline/resolve.py =====
"""Wrapper around resolve_sofa for building resolved IR."""

from __future__ import annotations

from typing import Dict

from src.schema import SofaRequest, resolve_sofa


def resolve_request_to_ir(sofa_request: SofaRequest) -> Dict:
    """Resolve a SofaRequest into an intermediate representation."""
    resolved = resolve_sofa(sofa_request)
    return resolved.model_dump()


def resolve_sofa_request(sofa_request: SofaRequest) -> Dict:
    """Backward-compatible wrapper for resolving SofaRequest."""
    return resolve_request_to_ir(sofa_request)



===== FILE: src/schema.py =====
from __future__ import annotations

import re
from enum import Enum
from typing import Any, Dict, Optional, Tuple
from typing_extensions import Literal

from pydantic import BaseModel, Field, field_validator, model_validator


# =========================
# Enums / core types
# =========================

class SofaStyle(str, Enum):
    scandi = "scandi"
    loft = "loft"
    modern = "modern"
    minimal = "minimal"
    classic = "classic"


class SofaLayout(str, Enum):
    straight = "straight"
    corner = "corner"
    u_shape = "u_shape"
    modular = "modular"


class Orientation(str, Enum):
    left = "left"
    right = "right"


class ArmrestType(str, Enum):
    none = "none"
    left = "left"
    right = "right"
    both = "both"


class LegFamily(str, Enum):
    tapered_cone = "tapered_cone"
    tapered_prism = "tapered_prism"
    cylindrical = "cylindrical"
    block = "block"
    hairpin = "hairpin"
    sled = "sled"
    frame = "frame"


class SeatType(str, Enum):
    single = "single"
    cushions = "cushions"


# =========================
# Preferences (level-2)
# =========================

class RawPreferences(BaseModel):
    # thin / medium / thick — можно расширять позже
    leg_thickness_bias: Optional[Literal["thin", "medium", "thick"]] = None
    # box / rounded_bottom / rolled — пока совпадает с ArmsSpec.profile
    arm_profile: Optional[Literal["box", "rounded_bottom", "rolled"]] = None
    # soft / medium / firm — пока влияет только на seat_type
    seat_softness: Optional[Literal["soft", "medium", "firm"]] = None


# =========================
# Aliases / Canonicalization
# =========================

def _canon(s: str) -> str:
    s = s.strip().lower()
    s = s.replace("ё", "е")
    s = s.replace("-", " ")
    s = s.replace("_", " ")
    s = re.sub(r"\s+", " ", s)
    return s


TYPE_ALIASES = {
    "диван": "sofa",
    "софа": "sofa",
    "sofa": "sofa",
}

STYLE_ALIASES = {
    "сканди": "scandi",
    "скандинавский": "scandi",
    "scandi": "scandi",

    "лофт": "loft",
    "loft": "loft",

    "современный": "modern",
    "модерн": "modern",
    "modern": "modern",

    "минимализм": "minimal",
    "минимальный": "minimal",
    "minimal": "minimal",

    "классический": "classic",
    "классика": "classic",
    "classic": "classic",
}

LAYOUT_ALIASES = {
    "прямой": "straight",
    "прямая": "straight",
    "straight": "straight",

    "угловой": "corner",
    "угловая": "corner",
    "corner": "corner",

    "п образный": "u_shape",
    "побразный": "u_shape",
    "u образный": "u_shape",
    "u shape": "u_shape",
    "u_shape": "u_shape",

    "секционный": "modular",
    "модульный": "modular",
    "modular": "modular",
}

LEG_ALIASES = {
    "конусные": "tapered_cone",
    "конус": "tapered_cone",
    "tapered cone": "tapered_cone",
    "tapered_cone": "tapered_cone",

    "пирамида": "tapered_prism",
    "призма": "tapered_prism",
    "скошенная пирамида": "tapered_prism",
    "tapered prism": "tapered_prism",
    "tapered_prism": "tapered_prism",

    "цилиндрические": "cylindrical",
    "цилиндр": "cylindrical",
    "cylindrical": "cylindrical",

    "блочные": "block",
    "кубики": "block",
    "block": "block",

    "hairpin": "hairpin",
    "шпильки": "hairpin",

    "sled": "sled",
    "полозья": "sled",

    "frame": "frame",
    "рамные": "frame",
}


# =========================
# Request model (сырой ввод)
# =========================

class SofaRequest(BaseModel):
    """
    Сырые параметры, извлечённые из текста (NER + нормализация).
    Могут быть неполными — Resolver заполнит дефолты.
    """

    type: Literal["sofa"] = "sofa"

    style: SofaStyle
    layout: SofaLayout
    orientation: Optional[Orientation] = None  # may be None; resolver fills for corner/u_shape

    seat_height_mm: Optional[int] = Field(default=None, ge=250, le=650)
    seat_depth_mm: Optional[int] = Field(default=None, ge=350, le=900)

    seat_width_range_mm: Optional[Tuple[int, int]] = None  # (min,max) mm
    seat_count: Optional[int] = Field(default=None, ge=1, le=8)

    has_chaise: Optional[bool] = None
    armrests: Optional[ArmrestType] = None
    leg_family: Optional[LegFamily] = None
    transformable: Optional[bool] = None

    preferences: Optional[RawPreferences] = None

    # --- Alias validators (before enum parsing) ---

    @field_validator("type", mode="before")
    @classmethod
    def _v_type(cls, v):
        if v is None:
            return v
        return TYPE_ALIASES.get(_canon(str(v)), v)

    @field_validator("style", mode="before")
    @classmethod
    def _v_style(cls, v):
        if v is None:
            return v
        return STYLE_ALIASES.get(_canon(str(v)), v)

    @field_validator("layout", mode="before")
    @classmethod
    def _v_layout(cls, v):
        if v is None:
            return v
        return LAYOUT_ALIASES.get(_canon(str(v)), v)

    @field_validator("leg_family", mode="before")
    @classmethod
    def _v_leg_family(cls, v):
        if v is None:
            return v
        return LEG_ALIASES.get(_canon(str(v)), v)

    # --- Structural validators ---

    @field_validator("seat_width_range_mm")
    @classmethod
    def validate_seat_width_range(cls, v: Optional[Tuple[int, int]]):
        if v is None:
            return None
        a, b = v
        if a <= 0 or b <= 0:
            raise ValueError("seat_width_range_mm values must be > 0")
        if a > b:
            raise ValueError("seat_width_range_mm min must be <= max")
        if a < 350 or b > 1200:
            raise ValueError("seat_width_range_mm out of bounds (350..1200 mm)")
        return v

    @model_validator(mode="after")
    def validate_layout_orientation(self):
        # В Request допускаем отсутствие orientation.
        # Resolver заполнит дефолт, если layout corner/u_shape.
        return self


# =========================
# Resolved specs (Builder input)
# =========================

class LegsSpec(BaseModel):
    family: LegFamily
    height_mm: int = Field(ge=30, le=260)
    params: Dict[str, Any] = Field(default_factory=dict)


class ArmsSpec(BaseModel):
    type: ArmrestType
    width_mm: int = Field(ge=0, le=400)
    profile: Literal["box", "rounded_bottom", "rolled"] = "box"


class FrameSpec(BaseModel):
    thickness_mm: int = Field(ge=20, le=80)
    back_thickness_mm: int = Field(ge=50, le=180)
    back_height_above_seat_mm: int = Field(ge=250, le=700)


class SofaResolved(BaseModel):
    """
    Полная спецификация. Builder обязан уметь собирать любой SofaResolved.
    """

    style: SofaStyle
    layout: SofaLayout
    orientation: Optional[Orientation] = None  # resolved for corner/u_shape

    seat_count: int = Field(ge=1, le=8)

    seat_height_mm: int = Field(ge=250, le=650)
    seat_depth_mm: int = Field(ge=350, le=900)
    seat_width_mm: int = Field(ge=350, le=1200)

    has_chaise: bool
    transformable: bool
    seat_type: SeatType

    legs: LegsSpec
    arms: ArmsSpec
    frame: FrameSpec

    @model_validator(mode="after")
    def sanity(self):
        total_seat_width = self.seat_count * self.seat_width_mm
        if self.arms.type == ArmrestType.both and total_seat_width < 900:
            raise ValueError("Too small sofa for two armrests with given seat_count/seat_width_mm")
        return self


# =========================
# Resolver defaults
# =========================

STYLE_DEFAULTS: Dict[SofaStyle, Dict[str, Any]] = {
    SofaStyle.scandi: dict(
        seat_count=3,
        seat_height_mm=440,
        seat_depth_mm=600,
        seat_width_mm=600,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.cushions,
        legs=dict(family=LegFamily.tapered_cone, height_mm=160, params={"r_top": 22, "r_bottom": 12}),
        arms=dict(type=ArmrestType.both, width_mm=120, profile="box"),
        frame=dict(thickness_mm=35, back_thickness_mm=90, back_height_above_seat_mm=420),
    ),
    SofaStyle.loft: dict(
        seat_count=3,
        seat_height_mm=430,
        seat_depth_mm=620,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.frame, height_mm=120, params={}),
        arms=dict(type=ArmrestType.both, width_mm=140, profile="box"),
        frame=dict(thickness_mm=40, back_thickness_mm=110, back_height_above_seat_mm=420),
    ),
    SofaStyle.modern: dict(
        seat_count=3,
        seat_height_mm=450,
        seat_depth_mm=620,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.block, height_mm=80, params={}),
        arms=dict(type=ArmrestType.both, width_mm=130, profile="rounded_bottom"),
        frame=dict(thickness_mm=40, back_thickness_mm=100, back_height_above_seat_mm=400),
    ),
    SofaStyle.minimal: dict(
        seat_count=3,
        seat_height_mm=430,
        seat_depth_mm=600,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.block, height_mm=40, params={}),
        arms=dict(type=ArmrestType.both, width_mm=110, profile="box"),
        frame=dict(thickness_mm=35, back_thickness_mm=90, back_height_above_seat_mm=380),
    ),
    SofaStyle.classic: dict(
        seat_count=3,
        seat_height_mm=460,
        seat_depth_mm=590,
        seat_width_mm=600,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.cushions,
        legs=dict(family=LegFamily.tapered_prism, height_mm=120, params={"top": [45, 45], "bottom": [30, 30]}),
        arms=dict(type=ArmrestType.both, width_mm=170, profile="rolled"),
        frame=dict(thickness_mm=45, back_thickness_mm=120, back_height_above_seat_mm=480),
    ),
}


# =========================
# Resolver (детерминированный)
# =========================

def resolve_sofa(req: SofaRequest) -> SofaResolved:
    """
    Детерминированно заполняет пропуски и приводит к полной спецификации для Builder.
    """

    defaults = STYLE_DEFAULTS[req.style]

    # 1) Orientation: required for corner/u_shape, but can be missing in Request.
    orientation = req.orientation
    if req.layout in {SofaLayout.corner, SofaLayout.u_shape} and orientation is None:
        orientation = Orientation.left  # system default

    # 2) Seat width: if user gave range — take midpoint; else style default.
    seat_width_mm = defaults["seat_width_mm"]
    if req.seat_width_range_mm is not None:
        a, b = req.seat_width_range_mm
        seat_width_mm = int(round((a + b) / 2))

    # 3) User overrides > defaults
    seat_count = req.seat_count or defaults["seat_count"]
    seat_height_mm = req.seat_height_mm or defaults["seat_height_mm"]
    seat_depth_mm = req.seat_depth_mm or defaults["seat_depth_mm"]

    has_chaise = req.has_chaise if req.has_chaise is not None else defaults["has_chaise"]
    transformable = req.transformable if req.transformable is not None else defaults["transformable"]

    # 4) legs/arms/frame dicts
    legs_dict = dict(defaults["legs"])
    if req.leg_family is not None:
        legs_dict["family"] = req.leg_family

    arms_dict = dict(defaults["arms"])
    if req.armrests is not None:
        arms_dict["type"] = req.armrests
        if req.armrests == ArmrestType.none:
            arms_dict["width_mm"] = 0

    frame_dict = dict(defaults["frame"])

    # 5) Preferences bias (safe, optional)
    if req.preferences is not None:
        prefs = req.preferences

        # leg thickness bias: only applies to families that use radii
        if prefs.leg_thickness_bias in {"thin", "thick"}:
            fam = legs_dict.get("family")
            params = dict(legs_dict.get("params", {}))

            # only for tapered_cone/cylindrical where r_top/r_bottom make sense
            if fam in {LegFamily.tapered_cone, LegFamily.cylindrical}:
                r_top = int(params.get("r_top", 22))
                r_bottom = int(params.get("r_bottom", 12))

                if prefs.leg_thickness_bias == "thin":
                    r_top = max(10, int(round(r_top * 0.8)))
                    r_bottom = max(6, int(round(r_bottom * 0.8)))
                else:  # thick
                    r_top = min(45, int(round(r_top * 1.2)))
                    r_bottom = min(40, int(round(r_bottom * 1.2)))

                params["r_top"] = r_top
                params["r_bottom"] = r_bottom
                legs_dict["params"] = params

        # arm profile preference
        if prefs.arm_profile is not None:
            arms_dict["profile"] = prefs.arm_profile

        # seat softness -> choose cushion seat type for soft/medium
        if prefs.seat_softness in {"soft", "medium"}:
            seat_type = SeatType.cushions
        else:
            seat_type = defaults["seat_type"]
    else:
        seat_type = defaults["seat_type"]

    return SofaResolved(
        style=req.style,
        layout=req.layout,
        orientation=orientation,

        seat_count=seat_count,
        seat_height_mm=seat_height_mm,
        seat_depth_mm=seat_depth_mm,
        seat_width_mm=seat_width_mm,

        has_chaise=has_chaise,
        transformable=transformable,
        seat_type=seat_type,

        legs=LegsSpec(**legs_dict),
        arms=ArmsSpec(**arms_dict),
        frame=FrameSpec(**frame_dict),
    )



===== FILE: tools/blender/batch_debug_run.py =====
"""Batch Blender debug runs for a directory of IR JSON files.

Usage:
  blender --background --python tools/blender/batch_debug_run.py -- <input_dir> <output_dir>
"""

from __future__ import annotations

import csv
import json
import os
import sys
from copy import deepcopy
from pathlib import Path
from typing import Any


REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from tools.blender import debug_run as single_debug_run  # noqa: E402
from tools.blender.debug.autofix import fix_ir  # noqa: E402
from tools.blender.debug.io import ensure_dir, save_json  # noqa: E402
from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
from tools.blender.debug.validators import validate  # noqa: E402
from tools.blender.debug.visualize import apply_debug_visualization  # noqa: E402


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _safe_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def _env_flag(name: str, default: bool = False) -> bool:
    raw = str(os.environ.get(name, "1" if default else "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _env_int(name: str, default: int, min_value: int = 1) -> int:
    raw = os.environ.get(name, str(default))
    try:
        value = int(raw)
    except (TypeError, ValueError):
        value = int(default)
    return max(int(min_value), int(value))


def _resolve_path(path: str) -> Path:
    candidate = Path(path)
    if candidate.is_absolute():
        return candidate
    return Path(REPO_ROOT) / candidate


def _parse_args() -> tuple[Path, Path]:
    args: list[str]
    if "--" in sys.argv:
        idx = sys.argv.index("--")
        args = [str(item).strip() for item in sys.argv[idx + 1 :]]
    else:
        args = [str(item).strip() for item in sys.argv[1:]]

    if len(args) >= 2:
        return _resolve_path(args[0]), _resolve_path(args[1])

    env_in = str(os.environ.get("DEBUG_BATCH_INPUT_DIR", "")).strip()
    env_out = str(os.environ.get("DEBUG_BATCH_OUTPUT_DIR", "")).strip()
    if env_in and env_out:
        return _resolve_path(env_in), _resolve_path(env_out)

    raise RuntimeError(
        "Usage: blender --background --python tools/blender/batch_debug_run.py -- <input_dir> <output_dir>"
    )


def _looks_like_ir(payload: Any) -> bool:
    return isinstance(payload, dict) and any(
        key in payload for key in ("slats", "back_support", "seat_width_mm", "seat_depth_mm")
    )


def _load_ir(path: Path) -> dict[str, Any]:
    with path.open("r", encoding="utf-8") as handle:
        payload = json.load(handle)
    if not _looks_like_ir(payload):
        raise ValueError(f"{path.name}: payload is not an IR JSON object")
    return payload


def _overlap_total(metrics: dict[str, Any], key: str) -> float:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return 0.0
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return 0.0
    return float(_safe_float(entry.get("total_volume", 0.0), 0.0))


def _run_one_ir(
    ir_path: Path,
    *,
    debug_iters: int,
    debug_autofix: bool,
    snapshot_blend_dir: Path | None,
    camera_lens_mm: float,
) -> dict[str, Any]:
    source_ir = _load_ir(ir_path)
    current_ir = deepcopy(source_ir)

    prev_metrics: dict[str, Any] | None = None
    autofix_context: dict[str, Any] = {}
    patches_applied: list[dict[str, Any]] = []

    final_metrics: dict[str, Any] = {}
    final_validation: dict[str, Any] = {"score": 0.0, "problem_count": 0, "problems": []}

    for idx in range(1, debug_iters + 1):
        single_debug_run._build_scene_from_ir(current_ir)
        metrics = collect_scene_metrics()
        validation_payload = validate(current_ir, metrics)

        if debug_autofix and idx < debug_iters:
            problems = validation_payload.get("problems", [])
            if not isinstance(problems, list):
                problems = []
            updated_ir, iteration_patches = fix_ir(
                current_ir,
                problems,
                metrics=metrics,
                validation=validation_payload,
                prev_metrics=prev_metrics,
                context=autofix_context,
            )
            current_ir = updated_ir
            patches_applied.extend(iteration_patches)

        final_metrics = metrics
        final_validation = validation_payload
        prev_metrics = metrics

    top_pair = single_debug_run._top_overlap_offender_pair(final_validation, final_metrics)
    if top_pair and isinstance(final_metrics, dict):
        final_metrics["top_offender_pair"] = top_pair

    if snapshot_blend_dir is not None:
        ensure_dir(str(snapshot_blend_dir))
        blend_path = snapshot_blend_dir / f"{ir_path.stem}.blend"
        apply_debug_visualization(
            validation=final_validation,
            metrics=final_metrics,
            snapshot_blend_path=str(blend_path),
            snapshot_png_path=None,
            camera_lens_mm=float(camera_lens_mm),
        )

    return {
        "ir_path": str(ir_path),
        "ir_out": current_ir,
        "metrics": final_metrics,
        "validation": final_validation,
        "patches_applied": patches_applied,
    }


def _write_summary_csv(path: Path, rows: list[dict[str, Any]]) -> None:
    fieldnames = [
        "file_name",
        "debug_score",
        "problems_count",
        "overlaps_slats_m3",
        "overlaps_back_m3",
        "fixes_applied_count",
    ]
    ensure_dir(str(path.parent))
    with path.open("w", encoding="utf-8", newline="") as handle:
        writer = csv.DictWriter(handle, fieldnames=fieldnames)
        writer.writeheader()
        for row in rows:
            writer.writerow(row)


def main() -> int:
    try:
        import bpy  # type: ignore  # noqa: F401
    except Exception as exc:
        print(f"BATCH_DEBUG_ERROR:bpy unavailable ({exc})", file=sys.stderr)
        return 3

    try:
        input_dir, output_dir = _parse_args()
    except Exception as exc:
        print(f"BATCH_DEBUG_ERROR:{exc}", file=sys.stderr)
        return 2

    if not input_dir.exists() or not input_dir.is_dir():
        print(f"BATCH_DEBUG_ERROR: input_dir not found: {input_dir}", file=sys.stderr)
        return 2

    ensure_dir(str(output_dir))
    debug_iters = _env_int("DEBUG_ITERS", 1, min_value=1)
    debug_autofix = _env_flag("DEBUG_AUTOFIX", default=False)
    camera_lens_mm = float(_safe_float(os.environ.get("DEBUG_SNAPSHOT_LENS_MM", "50"), 50.0))

    snapshot_blend_dir_raw = str(os.environ.get("DEBUG_SNAPSHOT_BLEND_DIR", "")).strip()
    snapshot_blend_dir = _resolve_path(snapshot_blend_dir_raw) if snapshot_blend_dir_raw else None

    ir_files = sorted(input_dir.glob("*.json"))
    if not ir_files:
        print(f"BATCH_DEBUG_FILES:0")
        print(f"BATCH_DEBUG_SUMMARY:{output_dir / 'summary.csv'}")
        return 0

    summary_rows: list[dict[str, Any]] = []
    for ir_path in ir_files:
        print(f"BATCH_DEBUG_RUN:{ir_path.name}")
        try:
            result = _run_one_ir(
                ir_path,
                debug_iters=debug_iters,
                debug_autofix=debug_autofix,
                snapshot_blend_dir=snapshot_blend_dir,
                camera_lens_mm=camera_lens_mm,
            )
            metrics = result.get("metrics", {})
            validation = result.get("validation", {})
            patches_applied = result.get("patches_applied", [])

            out_prefix = output_dir / ir_path.stem
            save_json(str(out_prefix.with_suffix(".validation.json")), validation)
            save_json(str(out_prefix.with_suffix(".metrics.json")), metrics)
            save_json(str(out_prefix.with_suffix(".ir_out.json")), result.get("ir_out", {}))

            summary_rows.append(
                {
                    "file_name": ir_path.name,
                    "debug_score": f"{_safe_float(validation.get('score', 0.0), 0.0):.6f}",
                    "problems_count": int(_safe_int(validation.get("problem_count", 0), 0)),
                    "overlaps_slats_m3": f"{_overlap_total(metrics, 'slats_vs_frame'):.6g}",
                    "overlaps_back_m3": f"{_overlap_total(metrics, 'back_slats_vs_frame'):.6g}",
                    "fixes_applied_count": len(patches_applied) if isinstance(patches_applied, list) else 0,
                }
            )
        except Exception as exc:
            print(f"BATCH_DEBUG_ERROR file={ir_path.name}: {exc}", file=sys.stderr)
            summary_rows.append(
                {
                    "file_name": ir_path.name,
                    "debug_score": "0.000000",
                    "problems_count": -1,
                    "overlaps_slats_m3": "0",
                    "overlaps_back_m3": "0",
                    "fixes_applied_count": 0,
                }
            )

    summary_path = output_dir / "summary.csv"
    _write_summary_csv(summary_path, summary_rows)
    print(f"BATCH_DEBUG_FILES:{len(summary_rows)}")
    print(f"BATCH_DEBUG_SUMMARY:{summary_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())



===== FILE: tools/blender/debug/__init__.py =====
"""Debug tooling for Blender sofa builds."""




===== FILE: tools/blender/debug/autofix.py =====
"""Rule-based IR autofixes for debug validator problems."""

from __future__ import annotations

import json
import math
import os
from copy import deepcopy
from typing import Any


def _as_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _as_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def read_env_float(name: str, default: float) -> float:
    raw = os.getenv(name, str(default))
    try:
        return float(raw)
    except (TypeError, ValueError):
        return float(default)


def bbox_spans_m(bbox_world: Any) -> tuple[float, float, float]:
    if not isinstance(bbox_world, dict):
        return 0.0, 0.0, 0.0

    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return 0.0, 0.0, 0.0
    if len(min_corner) < 3 or len(max_corner) < 3:
        return 0.0, 0.0, 0.0

    sx = max(0.0, _as_float(max_corner[0], 0.0) - _as_float(min_corner[0], 0.0))
    sy = max(0.0, _as_float(max_corner[1], 0.0) - _as_float(min_corner[1], 0.0))
    sz = max(0.0, _as_float(max_corner[2], 0.0) - _as_float(min_corner[2], 0.0))
    return float(sx), float(sy), float(sz)


def bbox_min_span_axis(bbox_world: Any) -> tuple[str, float]:
    sx, sy, sz = bbox_spans_m(bbox_world)
    axis, span = min(
        (("x", sx), ("y", sy), ("z", sz)),
        key=lambda item: float(item[1]),
    )
    return str(axis), float(span)


def _axis_index(axis: str) -> int:
    axis_map = {"x": 0, "y": 1, "z": 2}
    return int(axis_map.get(str(axis).strip().lower(), 0))


def _bbox_center_axis(bbox_world: Any, axis: str) -> float:
    if not isinstance(bbox_world, dict):
        return 0.0
    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return 0.0
    index = _axis_index(axis)
    if len(min_corner) <= index or len(max_corner) <= index:
        return 0.0
    min_value = _as_float(min_corner[index], 0.0)
    max_value = _as_float(max_corner[index], 0.0)
    return float((min_value + max_value) * 0.5)


def _bbox_axis_bounds(bbox_world: Any, axis: str) -> tuple[float, float] | None:
    if not isinstance(bbox_world, dict):
        return None
    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return None
    index = _axis_index(axis)
    if len(min_corner) <= index or len(max_corner) <= index:
        return None
    min_value = _as_float(min_corner[index], 0.0)
    max_value = _as_float(max_corner[index], 0.0)
    if min_value <= max_value:
        return float(min_value), float(max_value)
    return float(max_value), float(min_value)


def _signed_delta_mm(delta_mm: int, direction: int) -> int:
    magnitude = max(1, abs(int(delta_mm)))
    sign = 1 if int(direction) >= 0 else -1
    return int(sign * magnitude)


def _metrics_object_bbox(metrics: dict[str, Any] | None, name: str) -> dict[str, Any] | None:
    if not isinstance(metrics, dict):
        return None
    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return None
    needle = str(name).strip().lower()
    if not needle:
        return None
    for obj in objects:
        if not isinstance(obj, dict):
            continue
        if str(obj.get("name", "")).strip().lower() != needle:
            continue
        bbox_world = obj.get("bbox_world")
        if isinstance(bbox_world, dict):
            return bbox_world
        return None
    return None


def _rail_direction_hint(name: str) -> int | None:
    lowered = str(name).strip().lower()
    if not lowered:
        return None
    if ("back_rail_left" in lowered) or ("rail_left" in lowered):
        return 1
    if ("back_rail_right" in lowered) or ("rail_right" in lowered):
        return -1
    return None


def _resolve_direction(pair: dict[str, Any] | None, axis: str, metrics: dict[str, Any] | None) -> int:
    axis_name = str(axis).strip().lower()
    left_name = str((pair or {}).get("left", ""))
    right_name = str((pair or {}).get("right", ""))
    left_bbox = _metrics_object_bbox(metrics, left_name)
    right_bbox = _metrics_object_bbox(metrics, right_name)
    if left_bbox and right_bbox:
        left_center = _bbox_center_axis(left_bbox, axis_name)
        right_center = _bbox_center_axis(right_bbox, axis_name)
        return 1 if left_center > right_center else -1

    if axis_name == "x":
        rail_hint = _rail_direction_hint(right_name)
        if rail_hint is not None:
            return int(rail_hint)

    overlap_center = _bbox_center_axis((pair or {}).get("bbox_world"), axis_name)
    if axis_name == "x":
        if overlap_center < 0.0:
            return 1
        if overlap_center > 0.0:
            return -1
    return 1 if overlap_center < 0.0 else -1


def mm_from_m(m: float) -> int:
    return int(math.ceil(max(0.0, float(m)) * 1000.0))


def _clamp(value: float, min_value: float | None = None, max_value: float | None = None) -> float:
    result = float(value)
    if min_value is not None:
        result = max(float(min_value), result)
    if max_value is not None:
        result = min(float(max_value), result)
    return result


def _verbose_enabled() -> bool:
    raw = str(os.getenv("DEBUG_AUTOFIX_VERBOSE", "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _vprint(enabled: bool, message: str) -> None:
    if enabled:
        print(message)


def _get_path(root: dict[str, Any], path: str) -> tuple[bool, Any]:
    keys = [k for k in path.split(".") if k]
    if not keys:
        return False, None

    node: Any = root
    for key in keys[:-1]:
        if not isinstance(node, dict):
            return False, None
        node = node.get(key)
        if node is None:
            return False, None

    if not isinstance(node, dict):
        return False, None
    leaf = keys[-1]
    if leaf not in node:
        return False, None
    return True, node.get(leaf)


def _set_path(root: dict[str, Any], path: str, new_value: Any, patches: list[dict[str, Any]]) -> bool:
    keys = [k for k in path.split(".") if k]
    if not keys:
        return False

    node: dict[str, Any] = root
    for key in keys[:-1]:
        next_node = node.get(key)
        if not isinstance(next_node, dict):
            next_node = {}
            node[key] = next_node
        node = next_node

    leaf = keys[-1]
    old_value = node.get(leaf)
    if old_value == new_value:
        return False

    node[leaf] = new_value
    patches.append({"path": path, "old": old_value, "new": new_value})
    return True


def _coerce_numeric(value: float, old_value: Any) -> int | float:
    if isinstance(old_value, bool):
        return int(round(value))
    if isinstance(old_value, int):
        return int(round(value))
    if isinstance(old_value, float):
        return float(value)
    rounded = round(float(value))
    if abs(float(value) - float(rounded)) < 1e-9:
        return int(rounded)
    return float(value)


def _inc_path_clamped(
    ir: dict[str, Any],
    path: str,
    delta: float,
    min_value: float,
    max_value: float,
    patches: list[dict[str, Any]],
) -> tuple[bool, int | float, Any]:
    exists, old_value = _get_path(ir, path)
    base_value = _as_float(old_value, 0.0) if exists else 0.0
    new_numeric = _clamp(base_value + float(delta), min_value=min_value, max_value=max_value)
    new_value = _coerce_numeric(new_numeric, old_value)
    changed = _set_path(ir, path, new_value, patches)
    return changed, new_value, old_value


def _log_pair_context(
    *,
    verbose: bool,
    code: str,
    pair: dict[str, Any] | None,
    axis: str,
    span_m: float,
    delta_mm: int,
    safety_mm: int,
) -> None:
    if not verbose:
        return
    left_name = str((pair or {}).get("left", ""))
    right_name = str((pair or {}).get("right", ""))
    _vprint(
        True,
        (
            f"[autofix] code={code} "
            f"pair={left_name}->{right_name} "
            f"axis={axis} span_m={span_m:.6g} "
            f"delta_mm={delta_mm} safety_mm={safety_mm}"
        ),
    )


def _log_patch_change(
    *,
    verbose: bool,
    code: str,
    path: str,
    old_value: Any,
    new_value: Any,
) -> None:
    if not verbose:
        return
    _vprint(True, f"[autofix] code={code} patch {path}: {old_value} -> {new_value}")


def _normalize_code(code: str) -> str:
    normalized = code.strip().upper()
    aliases = {
        "INTERSECTION_SLATS_FRAME": "OVERLAP_SLATS_FRAME",
        "INTERSECTION_SLATS_ARMS": "OVERLAP_SLATS_ARMS",
    }
    return aliases.get(normalized, normalized)


def _problem_details(problem: dict[str, Any]) -> dict[str, Any]:
    details = problem.get("details", {})
    if isinstance(details, dict):
        return details
    return {}


def _problem_total_volume(problem: dict[str, Any]) -> float:
    details = _problem_details(problem)
    for key in ("total_volume_m3", "volume_m3", "total_volume"):
        if key in details:
            return _as_float(details.get(key), 0.0)
    return 0.0


def _problem_pairs_top(problem: dict[str, Any]) -> list[dict[str, Any]]:
    details = _problem_details(problem)
    pairs = details.get("pairs_top", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def get_top_pair(problem: dict[str, Any]) -> dict[str, Any] | None:
    pairs = _problem_pairs_top(problem)
    if not pairs:
        return None
    return pairs[0]


def _top_pair(problem: dict[str, Any], metrics: dict[str, Any] | None, overlap_key: str) -> dict[str, Any] | None:
    from_problem = get_top_pair(problem)
    if from_problem is not None:
        return from_problem

    pairs = _overlap_pairs(metrics, overlap_key)
    if not pairs:
        return None
    return max(pairs, key=lambda pair: _as_float(pair.get("volume", 0.0), 0.0))


def _safety_mm() -> int:
    return max(0, int(math.ceil(read_env_float("DEBUG_AUTOFIX_SAFETY_MM", 2.0))))


def _delta_from_pair(pair: dict[str, Any] | None, safety_mm: int) -> tuple[str, float, int]:
    if not isinstance(pair, dict):
        return "x", 0.0, 2
    axis, span_m = bbox_min_span_axis(pair.get("bbox_world"))
    if span_m <= 0.0:
        return axis, 0.0, 2
    delta_mm = mm_from_m(span_m) + int(max(0, safety_mm))
    return axis, float(span_m), int(max(1, delta_mm))


def _overlap_total_m3(metrics: dict[str, Any] | None, key: str) -> float | None:
    if not isinstance(metrics, dict):
        return None
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return None
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return None
    return float(_as_float(entry.get("total_volume", 0.0), 0.0))


def is_effective(
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    key: str,
    eps_m3: float | None = None,
) -> bool:
    eps = float(read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8) if eps_m3 is None else eps_m3)
    raw_prev = _overlap_total_m3(prev_metrics, key)
    raw_new = _overlap_total_m3(metrics, key)
    if (raw_prev is None) and (raw_new is None):
        return False
    prev_overlap, new_overlap = _resolved_overlap_pair_m3(prev_metrics, metrics, key)
    if float(new_overlap) <= eps:
        return True
    return (float(prev_overlap) - float(new_overlap)) >= eps


def _format_overlap(value: float | None) -> str:
    if value is None:
        return "n/a"
    return f"{float(value):.6g}"


def _resolved_overlap_pair_m3(
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    key: str,
) -> tuple[float, float]:
    prev_overlap = _overlap_total_m3(prev_metrics, key)
    new_overlap = _overlap_total_m3(metrics, key)
    if prev_overlap is None and new_overlap is None:
        return 0.0, 0.0
    if prev_overlap is None:
        prev_overlap = float(_as_float(new_overlap, 0.0))
    if new_overlap is None:
        new_overlap = float(_as_float(prev_overlap, 0.0))
    return float(prev_overlap), float(new_overlap)


def _log_effect_decision(
    *,
    verbose: bool,
    code: str,
    key: str,
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    eps_m3: float,
) -> tuple[bool, float, float, float]:
    prev_overlap, new_overlap = _resolved_overlap_pair_m3(prev_metrics, metrics, key)
    delta_overlap = float(prev_overlap - new_overlap)
    effective = is_effective(prev_metrics, metrics, key, eps_m3=eps_m3)
    if verbose:
        _vprint(
            True,
            (
                f"[autofix] code={code} overlap_key={key} "
                f"prev_overlap={_format_overlap(prev_overlap)} "
                f"new_overlap={_format_overlap(new_overlap)} "
                f"delta_overlap={delta_overlap:.6g} "
                f"effect_eps_m3={float(eps_m3):.6g} "
                f"effective={effective}"
            ),
        )
    return effective, prev_overlap, new_overlap, delta_overlap


def _overlap_entry(metrics: dict[str, Any] | None, key: str) -> dict[str, Any]:
    if not isinstance(metrics, dict):
        return {}
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return {}
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return {}
    return entry


def _overlap_pairs(metrics: dict[str, Any] | None, key: str) -> list[dict[str, Any]]:
    entry = _overlap_entry(metrics, key)
    pairs = entry.get("pairs", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def _overlap_total(metrics: dict[str, Any] | None, key: str, problem: dict[str, Any]) -> float:
    entry = _overlap_entry(metrics, key)
    total = _as_float(entry.get("total_volume", 0.0), 0.0)
    if total > 0.0:
        return total
    return _problem_total_volume(problem)


def _fix_slats_not_bent(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    slats = ir.get("slats", {})
    if not isinstance(slats, dict):
        slats = {}
        ir["slats"] = slats

    old_arc = _as_float(slats.get("arc_height_mm", 0.0), 0.0)
    new_arc = _clamp(old_arc + 5.0, max_value=60.0)
    _set_path(ir, "slats.arc_height_mm", new_arc, patches)

    if "subdiv_cuts" in slats:
        old_cuts = _as_int(slats.get("subdiv_cuts", 0), 0)
        new_cuts = int(_clamp(float(old_cuts + 8), min_value=0.0, max_value=256.0))
        _set_path(ir, "slats.subdiv_cuts", new_cuts, patches)


def _fix_back_slats_not_bent(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    back_support = ir.get("back_support", {})
    if not isinstance(back_support, dict):
        back_support = {}
        ir["back_support"] = back_support
    slats = back_support.get("slats", {})
    if not isinstance(slats, dict):
        slats = {}
        back_support["slats"] = slats

    old_arc = _as_float(slats.get("arc_height_mm", 0.0), 0.0)
    new_arc = _clamp(old_arc + 3.0, max_value=40.0)
    _set_path(ir, "back_support.slats.arc_height_mm", new_arc, patches)


def _fix_overlap_slats_frame(
    ir: dict[str, Any],
    patches: list[dict[str, Any]],
    metrics: dict[str, Any] | None,
    prev_metrics: dict[str, Any] | None,
    problem: dict[str, Any],
    verbose: bool,
) -> None:
    code = "OVERLAP_SLATS_FRAME"
    overlap_key = "slats_vs_frame"
    pair = _top_pair(problem, metrics, "slats_vs_frame")
    right_name = str((pair or {}).get("right", "")).lower()
    safety_mm = _safety_mm()
    axis, span_m, delta_mm = _delta_from_pair(pair, safety_mm=safety_mm)
    effect_eps_m3 = read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8)
    _log_pair_context(
        verbose=verbose,
        code=code,
        pair=pair,
        axis=axis,
        span_m=span_m,
        delta_mm=delta_mm,
        safety_mm=safety_mm,
    )
    effective, _, _, _ = _log_effect_decision(
        verbose=verbose,
        code=code,
        key=overlap_key,
        prev_metrics=prev_metrics,
        metrics=metrics,
        eps_m3=effect_eps_m3,
    )

    has_mount_offset, _ = _get_path(ir, "slats.mount_offset_mm")
    has_rail_inset, _ = _get_path(ir, "slats.rail_inset_mm")

    clearance_delta = float(max(1, int(math.ceil(float(delta_mm) / 4.0))))
    mount_delta = float(max(1, int(math.ceil(float(delta_mm) / 2.0))))
    rail_inset_delta = float(max(1, int(math.ceil(float(delta_mm) / 2.0))))
    safe_fallback_clearance = float(2 if int(delta_mm) >= 4 else 1)

    Strategy = tuple[str, str, float, float, float, bool]

    def _apply_strategy(strategy: Strategy, step: str) -> bool:
        strategy_name, path, delta, min_value, max_value, require_existing = strategy
        if require_existing:
            exists, _ = _get_path(ir, path)
            if not exists:
                if verbose:
                    _vprint(
                        True,
                        f"[autofix] code={code} skip_strategy={strategy_name} reason=missing_path path={path}",
                    )
                return False
        changed, new_value, old_value = _inc_path_clamped(
            ir,
            path,
            float(delta),
            float(min_value),
            float(max_value),
            patches,
        )
        if changed:
            _log_patch_change(
                verbose=verbose,
                code=code,
                path=path,
                old_value=old_value,
                new_value=new_value,
            )
        if verbose:
            _vprint(
                True,
                f"[autofix] code={code} chosen_strategy={strategy_name} chosen_param={path} step={step}",
            )
        return True

    group = "other"
    if right_name.startswith("rail_") or ("rail_left" in right_name) or ("rail_right" in right_name):
        group = "rail"
    elif right_name.startswith("beam_cross_"):
        group = "beam"

    primary: Strategy
    secondary: Strategy | None = None
    fallback: Strategy = (
        "safe_fallback_clearance",
        "slats.clearance_mm",
        safe_fallback_clearance,
        0.0,
        12.0,
        False,
    )

    if group == "rail":
        if axis == "x":
            primary = ("rail_axis_x_margin_x", "slats.margin_x_mm", float(delta_mm), 0.0, 80.0, False)
            secondary = ("rail_axis_x_rail_inset", "slats.rail_inset_mm", rail_inset_delta, 0.0, 20.0, True)
        elif axis == "y":
            primary = ("rail_axis_y_margin_y", "slats.margin_y_mm", float(delta_mm), 0.0, 120.0, False)
        else:  # axis == "z"
            if has_mount_offset:
                primary = ("rail_axis_z_mount_offset", "slats.mount_offset_mm", mount_delta, 0.0, 80.0, True)
                secondary = ("rail_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
            else:
                primary = ("rail_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)

    elif group == "beam":
        if axis == "y":
            primary = ("beam_axis_y_margin_y", "slats.margin_y_mm", float(delta_mm), 0.0, 120.0, False)
        elif axis == "z":
            if has_mount_offset:
                primary = ("beam_axis_z_mount_offset", "slats.mount_offset_mm", mount_delta, 0.0, 80.0, True)
                secondary = ("beam_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
            else:
                primary = ("beam_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
        else:  # axis == "x"
            primary = ("beam_axis_x_margin_x_fallback", "slats.margin_x_mm", float(delta_mm), 0.0, 80.0, False)

    else:
        primary = ("other_axis_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)

    _apply_strategy(primary, step="primary")
    if effective:
        return

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_primary effective=False")
    secondary_applied = _apply_strategy(secondary, step="secondary") if secondary is not None else False
    if verbose and (secondary is None):
        _vprint(True, f"[autofix] code={code} secondary_strategy=none")
    if not secondary_applied and (secondary is not None) and verbose:
        _vprint(True, f"[autofix] code={code} secondary_strategy_skipped")

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_secondary effective=False fallback=true")
    _apply_strategy(fallback, step="fallback")


def _fix_overlap_back_slats_frame(
    ir: dict[str, Any],
    patches: list[dict[str, Any]],
    metrics: dict[str, Any] | None,
    prev_metrics: dict[str, Any] | None,
    problem: dict[str, Any],
    context: dict[str, Any] | None,
    verbose: bool,
) -> None:
    del context
    code = "OVERLAP_BACK_SLATS_FRAME"
    overlap_key = "back_slats_vs_frame"
    pair = _top_pair(problem, metrics, "back_slats_vs_frame")
    right_name = str((pair or {}).get("right", ""))
    right_name_lower = right_name.lower()
    left_name = str((pair or {}).get("left", ""))
    safety_mm = _safety_mm()
    axis, span_m, delta_mm = _delta_from_pair(pair, safety_mm=safety_mm)
    effect_eps_m3 = read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8)
    left_bbox_world = _metrics_object_bbox(metrics, left_name)
    right_bbox_world = _metrics_object_bbox(metrics, right_name)
    left_center_axis = _bbox_center_axis(left_bbox_world, axis) if left_bbox_world else None
    right_center_axis = _bbox_center_axis(right_bbox_world, axis) if right_bbox_world else None
    overlap_center_axis = _bbox_center_axis((pair or {}).get("bbox_world"), axis)
    slat_bounds = _bbox_axis_bounds(left_bbox_world, axis)
    rail_bounds = _bbox_axis_bounds(right_bbox_world, axis)
    slat_min_axis: float | None = None
    slat_max_axis: float | None = None
    rail_min_axis: float | None = None
    rail_max_axis: float | None = None
    if slat_bounds is not None:
        slat_min_axis, slat_max_axis = slat_bounds
    if rail_bounds is not None:
        rail_min_axis, rail_max_axis = rail_bounds

    push_plus_mm: int | None = None
    push_minus_mm: int | None = None
    rail_side_direction = _rail_direction_hint(right_name_lower)
    if axis in {"y", "z"} and (slat_bounds is not None) and (rail_bounds is not None):
        safety = int(max(0, safety_mm))
        push_plus_mm = int(math.ceil((float(rail_max_axis) - float(slat_min_axis)) * 1000.0)) + safety
        push_minus_mm = int(math.ceil((float(slat_max_axis) - float(rail_min_axis)) * 1000.0)) + safety
        chosen_signed_delta_mm = int(push_plus_mm if push_plus_mm <= push_minus_mm else -push_minus_mm)
        direction = 1 if chosen_signed_delta_mm >= 0 else -1
    else:
        direction = _resolve_direction(pair, axis, metrics)
        if axis == "x" and rail_side_direction is not None:
            direction = int(rail_side_direction)
        chosen_signed_delta_mm = _signed_delta_mm(delta_mm, direction)

    primary_direction = int(direction)
    axis_delta_mm = max(1, abs(int(chosen_signed_delta_mm)))
    left_center_text = "n/a" if left_center_axis is None else f"{float(left_center_axis):.6g}"
    right_center_text = "n/a" if right_center_axis is None else f"{float(right_center_axis):.6g}"
    slat_min_text = "n/a" if slat_min_axis is None else f"{float(slat_min_axis):.6g}"
    slat_max_text = "n/a" if slat_max_axis is None else f"{float(slat_max_axis):.6g}"
    rail_min_text = "n/a" if rail_min_axis is None else f"{float(rail_min_axis):.6g}"
    rail_max_text = "n/a" if rail_max_axis is None else f"{float(rail_max_axis):.6g}"
    push_plus_text = "n/a" if push_plus_mm is None else str(int(push_plus_mm))
    push_minus_text = "n/a" if push_minus_mm is None else str(int(push_minus_mm))
    _log_pair_context(
        verbose=verbose,
        code=code,
        pair=pair,
        axis=axis,
        span_m=span_m,
        delta_mm=axis_delta_mm,
        safety_mm=safety_mm,
    )
    if verbose:
        _vprint(
            True,
            (
                f"[autofix] code={code} pair={left_name}->{right_name} "
                f"axis={axis} dir={int(primary_direction):+d} span_m={span_m:.6g} delta_mm={axis_delta_mm} "
                f"slat_min={slat_min_text} slat_max={slat_max_text} "
                f"rail_min={rail_min_text} rail_max={rail_max_text} "
                f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                f"chosen_signed_delta_mm={int(chosen_signed_delta_mm)} "
                f"left_center={left_center_text} right_center={right_center_text} "
                f"overlap_center={overlap_center_axis:.6g}"
            ),
        )
    effective, _, _, _ = _log_effect_decision(
        verbose=verbose,
        code=code,
        key=overlap_key,
        prev_metrics=prev_metrics,
        metrics=metrics,
        eps_m3=effect_eps_m3,
    )

    Strategy = tuple[str, str, int, float, float, bool, int | None, int | None]

    def _apply_strategy(strategy: Strategy | None, step: str) -> bool:
        if strategy is None:
            return False
        (
            strategy_name,
            path,
            delta_mm_value,
            min_value,
            max_value,
            require_existing,
            forced_direction,
            forced_signed_delta_mm,
        ) = strategy
        direction_used = int(primary_direction if forced_direction is None else forced_direction)
        signed_delta = (
            int(forced_signed_delta_mm)
            if forced_signed_delta_mm is not None
            else _signed_delta_mm(delta_mm_value, direction_used)
        )
        if forced_signed_delta_mm is not None:
            direction_used = 1 if int(signed_delta) >= 0 else -1
        if require_existing:
            exists, _ = _get_path(ir, path)
            if not exists:
                if verbose:
                    _vprint(
                        True,
                        (
                            f"[autofix] code={code} pair={left_name}->{right_name} "
                            f"axis={axis} dir={int(direction_used):+d} span_m={span_m:.6g} delta_mm={delta_mm_value} "
                            f"slat_min={slat_min_text} slat_max={slat_max_text} "
                            f"rail_min={rail_min_text} rail_max={rail_max_text} "
                            f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                            f"chosen_signed_delta_mm={int(signed_delta)} "
                            f"chosen_strategy={strategy_name} param={path} reason=missing_path step={step}"
                        ),
                    )
                return False
        changed, new_value, old_value = _inc_path_clamped(
            ir,
            path,
            float(signed_delta),
            float(min_value),
            float(max_value),
            patches,
        )
        if verbose:
            left_center_text = "n/a" if left_center_axis is None else f"{float(left_center_axis):.6g}"
            right_center_text = "n/a" if right_center_axis is None else f"{float(right_center_axis):.6g}"
            _vprint(
                True,
                (
                    f"[autofix] code={code} pair={left_name}->{right_name} "
                    f"axis={axis} dir={int(direction_used):+d} span_m={span_m:.6g} delta_mm={delta_mm_value} "
                    f"slat_min={slat_min_text} slat_max={slat_max_text} "
                    f"rail_min={rail_min_text} rail_max={rail_max_text} "
                    f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                    f"chosen_signed_delta_mm={int(signed_delta)} chosen_strategy={strategy_name} param={path} "
                    f"old->new={old_value}->{new_value} changed={changed} step={step} "
                    f"left_center={left_center_text} right_center={right_center_text} "
                    f"overlap_center={overlap_center_axis:.6g}"
                ),
            )
        return True

    offset_delta_mm = max(1, int(math.ceil(float(axis_delta_mm) / 2.0)))
    safe_delta_mm = 2 if int(axis_delta_mm) >= 4 else 1
    safe_offset_delta_mm = max(1, int(math.ceil(float(safe_delta_mm) / 2.0)))

    primary: Strategy
    secondary: Strategy | None = None
    fallback: Strategy

    if axis == "y":
        primary = (
            "axis_y_offset_y_primary",
            "back_support.offset_y_mm",
            int(axis_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            int(chosen_signed_delta_mm),
        )
        secondary = (
            "axis_y_margin_z_secondary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            None,
        )
        fallback = (
            "axis_y_offset_y_safe_fallback",
            "back_support.offset_y_mm",
            int(safe_offset_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            None,
        )
    elif axis == "z":
        primary = (
            "axis_z_margin_z_primary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            int(chosen_signed_delta_mm),
        )
        secondary = (
            "axis_z_offset_y_secondary",
            "back_support.offset_y_mm",
            int(offset_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            None,
        )
        fallback = (
            "axis_z_margin_z_safe_fallback",
            "back_support.margin_z_mm",
            int(safe_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            None,
        )
    else:  # axis == "x"
        primary = (
            "axis_x_margin_x_primary",
            "back_support.margin_x_mm",
            int(axis_delta_mm),
            0.0,
            80.0,
            False,
            int(primary_direction),
            None,
        )
        secondary = (
            "axis_x_margin_z_secondary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(primary_direction),
            None,
        )
        fallback = (
            "axis_x_margin_x_safe_fallback",
            "back_support.margin_x_mm",
            int(safe_delta_mm),
            0.0,
            80.0,
            False,
            int(primary_direction),
            None,
        )

    _apply_strategy(primary, step="primary")
    if effective:
        return

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_primary effective=False")
    secondary_applied = _apply_strategy(secondary, step="secondary")
    if verbose and (secondary is None):
        _vprint(True, f"[autofix] code={code} secondary_strategy=none")
    if not secondary_applied and (secondary is not None) and verbose:
        _vprint(True, f"[autofix] code={code} secondary_strategy_skipped")
    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_secondary effective=False fallback=true")
    _apply_strategy(fallback, step="fallback")


def _fix_overlap_slats_arms(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    _inc_path_clamped(ir, "slats.margin_x_mm", 5.0, 0.0, 200.0, patches)


def _resolve_problems(
    problems: list[dict[str, Any]] | None,
    validation: dict[str, Any] | None,
) -> list[dict[str, Any]]:
    if isinstance(problems, list):
        return [item for item in problems if isinstance(item, dict)]
    if isinstance(validation, dict):
        candidate = validation.get("problems", [])
        if isinstance(candidate, list):
            return [item for item in candidate if isinstance(item, dict)]
    return []


def fix_ir(
    ir: dict[str, Any],
    problems: list[dict[str, Any]] | None = None,
    *,
    metrics: dict[str, Any] | None = None,
    validation: dict[str, Any] | None = None,
    prev_metrics: dict[str, Any] | None = None,
    context: dict[str, Any] | None = None,
) -> tuple[dict[str, Any], list[dict[str, Any]]]:
    """Apply MVP debug autofixes and return (new_ir, patches_applied)."""
    patched = deepcopy(ir)
    patches_applied: list[dict[str, Any]] = []
    handled_codes: set[str] = set()
    resolved_problems = _resolve_problems(problems, validation)
    verbose = _verbose_enabled()

    for problem in resolved_problems:
        code = _normalize_code(str(problem.get("code", "")))
        if not code or code in handled_codes:
            continue

        if code == "SLATS_NOT_BENT":
            _fix_slats_not_bent(patched, patches_applied)
            handled_codes.add(code)
            continue

        if code == "BACK_SLATS_NOT_BENT":
            _fix_back_slats_not_bent(patched, patches_applied)
            handled_codes.add(code)
            continue

        if code == "OVERLAP_SLATS_FRAME":
            _fix_overlap_slats_frame(
                patched,
                patches_applied,
                metrics=metrics,
                prev_metrics=prev_metrics,
                problem=problem,
                verbose=verbose,
            )
            handled_codes.add(code)
            continue

        if code == "OVERLAP_BACK_SLATS_FRAME":
            _fix_overlap_back_slats_frame(
                patched,
                patches_applied,
                metrics=metrics,
                prev_metrics=prev_metrics,
                problem=problem,
                context=context,
                verbose=verbose,
            )
            handled_codes.add(code)
            continue

        if code == "OVERLAP_SLATS_ARMS":
            _fix_overlap_slats_arms(patched, patches_applied)
            handled_codes.add(code)

    return patched, patches_applied


if __name__ == "__main__":
    os.environ["DEBUG_AUTOFIX_SAFETY_MM"] = str(_as_int(os.getenv("DEBUG_AUTOFIX_SAFETY_MM", 2), 2))
    os.environ["DEBUG_AUTOFIX_EFFECT_EPS_M3"] = str(read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8))

    ir_base: dict[str, Any] = {
        "slats": {
            "margin_x_mm": 40,
            "margin_y_mm": 55,
            "clearance_mm": 4,
            "mount_offset_mm": 3,
            "rail_inset_mm": 3,
        }
    }

    problem_axis_z = {
        "code": "OVERLAP_SLATS_FRAME",
        "details": {
            "pairs_top": [
                {
                    "left": "slat_1",
                    "right": "rail_left",
                    "volume": 1.0e-4,
                    "bbox_world": {
                        "min": [0.0, 0.0, 0.0],
                        "max": [0.010, 0.008, 0.001],
                    },
                }
            ]
        },
    }
    pair_z = get_top_pair(problem_axis_z)
    axis_z, span_z, delta_z = _delta_from_pair(pair_z, safety_mm=_safety_mm())
    before_margin_x_z = _as_int(ir_base["slats"]["margin_x_mm"], 0)
    before_clearance_z = _as_int(ir_base["slats"]["clearance_mm"], 0)
    before_mount_z = _as_int(ir_base["slats"]["mount_offset_mm"], 0)
    fixed_ir_z, patches_z = fix_ir(
        ir_base,
        problems=[problem_axis_z],
        metrics={"overlaps": {"slats_vs_frame": {"total_volume": 1.0e-3}}},
        prev_metrics=None,
        context=None,
        validation=None,
    )
    after_margin_x_z = _as_int(fixed_ir_z.get("slats", {}).get("margin_x_mm", 0), 0)
    after_clearance_z = _as_int(fixed_ir_z.get("slats", {}).get("clearance_mm", 0), 0)
    after_mount_z = _as_int(fixed_ir_z.get("slats", {}).get("mount_offset_mm", 0), 0)
    primary_path_z = str((patches_z[0] if patches_z else {}).get("path", ""))
    ok_axis_z = bool(
        (axis_z == "z")
        and (primary_path_z in {"slats.clearance_mm", "slats.mount_offset_mm"})
        and (after_margin_x_z == before_margin_x_z)
        and ((after_clearance_z > before_clearance_z) or (after_mount_z > before_mount_z))
    )

    print(f"SELF_TEST_SLATS_RAIL_AXIS_Z axis={axis_z} span_m={span_z:.6g} delta_mm={delta_z}")
    print(
        "SELF_TEST_SLATS_RAIL_AXIS_Z "
        f"margin_x before={before_margin_x_z} after={after_margin_x_z} "
        f"clearance before={before_clearance_z} after={after_clearance_z} "
        f"mount_offset before={before_mount_z} after={after_mount_z}"
    )
    print(f"SELF_TEST_SLATS_RAIL_AXIS_Z primary_patch={primary_path_z} ok={ok_axis_z}")
    print(json.dumps(patches_z, ensure_ascii=False, indent=2))

    problem_axis_x = {
        "code": "OVERLAP_SLATS_FRAME",
        "details": {
            "pairs_top": [
                {
                    "left": "slat_2",
                    "right": "rail_right",
                    "volume": 1.0e-4,
                    "bbox_world": {
                        "min": [0.0, 0.0, 0.0],
                        "max": [0.001, 0.010, 0.020],
                    },
                }
            ]
        },
    }
    pair_x = get_top_pair(problem_axis_x)
    axis_x, span_x, delta_x = _delta_from_pair(pair_x, safety_mm=_safety_mm())
    before_margin_x = _as_int(ir_base["slats"]["margin_x_mm"], 0)
    fixed_ir_x, patches_x = fix_ir(
        ir_base,
        problems=[problem_axis_x],
        metrics={"overlaps": {"slats_vs_frame": {"total_volume": 1.0e-3}}},
        prev_metrics=None,
        context=None,
        validation=None,
    )
    after_margin_x = _as_int(fixed_ir_x.get("slats", {}).get("margin_x_mm", 0), 0)
    primary_path_x = str((patches_x[0] if patches_x else {}).get("path", ""))
    ok_axis_x = bool((axis_x == "x") and (primary_path_x == "slats.margin_x_mm") and (after_margin_x > before_margin_x))

    print(f"SELF_TEST_SLATS_RAIL_AXIS_X axis={axis_x} span_m={span_x:.6g} delta_mm={delta_x}")
    print(f"SELF_TEST_SLATS_RAIL_AXIS_X margin_x before={before_margin_x} after={after_margin_x}")
    print(f"SELF_TEST_SLATS_RAIL_AXIS_X primary_patch={primary_path_x} ok={ok_axis_x}")
    print(json.dumps(patches_x, ensure_ascii=False, indent=2))

    direction_pair_left = {
        "left": "back_slat_1",
        "right": "back_rail_left",
        "bbox_world": {
            "min": [-0.024, 0.10, 0.42],
            "max": [-0.018, 0.14, 0.47],
        },
    }
    direction_pair_right = {
        "left": "back_slat_7",
        "right": "back_rail_right",
        "bbox_world": {
            "min": [0.018, 0.10, 0.42],
            "max": [0.024, 0.14, 0.47],
        },
    }
    direction_left = _resolve_direction(direction_pair_left, "x", metrics=None)
    direction_right = _resolve_direction(direction_pair_right, "x", metrics=None)
    ok_direction_left = bool(direction_left == 1)
    ok_direction_right = bool(direction_right == -1)
    print(
        f"SELF_TEST_BACK_DIRECTION_LEFT axis=x dir={direction_left:+d} "
        f"expected=+1 ok={ok_direction_left}"
    )
    print(
        f"SELF_TEST_BACK_DIRECTION_RIGHT axis=x dir={direction_right:+d} "
        f"expected=-1 ok={ok_direction_right}"
    )



===== FILE: tools/blender/debug/io.py =====
"""JSON I/O helpers for debug runs."""

from __future__ import annotations

import hashlib
import json
import os
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Mapping


def ir_sha256(ir: Mapping[str, Any]) -> str:
    """Return SHA256 of canonical IR JSON."""
    payload = json.dumps(ir, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(payload.encode("utf-8")).hexdigest()


def make_run_id(short_len: int = 8) -> str:
    """Return run id as run_YYYYmmdd_HHMMSS_<shortid>."""
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    short_id = uuid.uuid4().hex[: max(4, int(short_len))]
    return f"run_{timestamp}_{short_id}"


def save_json(path: str | os.PathLike[str], payload: Mapping[str, Any]) -> str:
    """Save JSON payload to path, creating parent directories."""
    output_path = Path(path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    return str(output_path)


def load_json(path: str | os.PathLike[str]) -> dict[str, Any]:
    """Load JSON object from path."""
    data = json.loads(Path(path).read_text(encoding="utf-8"))
    if not isinstance(data, dict):
        raise ValueError(f"Expected JSON object in {path}, got {type(data).__name__}")
    return data


def save_run_log(
    payload: Mapping[str, Any],
    out_dir: str | os.PathLike[str] = "out/logs/runs",
    run_id: str | None = None,
) -> str:
    """Save debug run payload as out/logs/runs/run_<timestamp>_<shortid>.json."""
    resolved_run_id = run_id or make_run_id()
    file_path = Path(out_dir) / f"{resolved_run_id}.json"
    return save_json(file_path, payload)


def load_run_log(path: str | os.PathLike[str]) -> dict[str, Any]:
    """Load a previously saved debug run log."""
    return load_json(path)

def ensure_dir(path: str | os.PathLike[str]) -> str:
    """Create directory if it doesn't exist. Returns normalized string path."""
    p = Path(path)
    p.mkdir(parents=True, exist_ok=True)
    return str(p)
def ensure_parent(path: str | os.PathLike[str]) -> str:
    """Ensure parent directory for a file path exists. Returns normalized string path."""
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    return str(p)
def ensure_dir(path: str | os.PathLike[str]) -> str:
    """Create directory if it doesn't exist. Returns normalized string path."""
    p = Path(path)
    p.mkdir(parents=True, exist_ok=True)
    return str(p)


def make_run_tag(*, run_id: str) -> str:
    """Return a stable tag for artifacts based on run_id."""
    # debug_run ожидает, что run_tag используется в именах файлов: <run_tag>.json / .metrics.json / .ir_in.json ...
    return str(run_id)


def sha256_file(path: str | os.PathLike[str]) -> str:
    """Compute SHA256 hex digest of a file."""
    p = Path(path)
    h = hashlib.sha256()
    with p.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def sha256_json(payload: Mapping[str, Any]) -> str:
    """Compute SHA256 of canonical JSON (stable across key order)."""
    s = json.dumps(payload, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(s.encode("utf-8")).hexdigest()



===== FILE: tools/blender/debug/metrics.py =====
"""Scene metrics collection for Blender debug runs."""

from __future__ import annotations

from datetime import datetime, timezone
from typing import Any, Iterable


GROUP_KEYS = ("slat_", "back_slat_", "arm_", "frame_", "leg_")


def _bbox_from_points(points: Iterable[tuple[float, float, float]]) -> dict[str, list[float]] | None:
    coords = list(points)
    if not coords:
        return None
    xs = [p[0] for p in coords]
    ys = [p[1] for p in coords]
    zs = [p[2] for p in coords]
    return {
        "min": [float(min(xs)), float(min(ys)), float(min(zs))],
        "max": [float(max(xs)), float(max(ys)), float(max(zs))],
    }


def _bbox_union(bboxes: Iterable[dict[str, list[float]] | None]) -> dict[str, list[float]] | None:
    valid = [b for b in bboxes if b]
    if not valid:
        return None
    return {
        "min": [
            float(min(b["min"][0] for b in valid)),
            float(min(b["min"][1] for b in valid)),
            float(min(b["min"][2] for b in valid)),
        ],
        "max": [
            float(max(b["max"][0] for b in valid)),
            float(max(b["max"][1] for b in valid)),
            float(max(b["max"][2] for b in valid)),
        ],
    }


def _bbox_spans(bbox: dict[str, list[float]] | None) -> dict[str, float]:
    if not bbox:
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    return {
        "x": float(max(0.0, bbox["max"][0] - bbox["min"][0])),
        "y": float(max(0.0, bbox["max"][1] - bbox["min"][1])),
        "z": float(max(0.0, bbox["max"][2] - bbox["min"][2])),
    }


def _bbox_overlap(a: dict[str, list[float]] | None, b: dict[str, list[float]] | None) -> tuple[float, dict[str, list[float]] | None]:
    if not a or not b:
        return 0.0, None
    min_corner = [
        max(float(a["min"][0]), float(b["min"][0])),
        max(float(a["min"][1]), float(b["min"][1])),
        max(float(a["min"][2]), float(b["min"][2])),
    ]
    max_corner = [
        min(float(a["max"][0]), float(b["max"][0])),
        min(float(a["max"][1]), float(b["max"][1])),
        min(float(a["max"][2]), float(b["max"][2])),
    ]
    dx = max_corner[0] - min_corner[0]
    dy = max_corner[1] - min_corner[1]
    dz = max_corner[2] - min_corner[2]
    if dx <= 0.0 or dy <= 0.0 or dz <= 0.0:
        return 0.0, None
    return float(dx * dy * dz), {"min": min_corner, "max": max_corner}


def _group_match(name: str, group_key: str) -> bool:
    lower_name = name.lower()
    if group_key == "slat_":
        return lower_name.startswith("slat_")
    if group_key == "back_slat_":
        return lower_name.startswith("back_slat_")
    if group_key == "arm_":
        return (
            lower_name.startswith("arm_")
            or lower_name.startswith("left_arm")
            or lower_name.startswith("right_arm")
            or "_arm_" in lower_name
        )
    if group_key == "frame_":
        return (
            lower_name.startswith("frame_")
            or lower_name.startswith("beam_")
            or lower_name.startswith("rail_")
            or lower_name.startswith("back_rail_")
            or lower_name in {"seat_support", "back_frame", "back_panel"}
        )
    if group_key == "leg_":
        return lower_name.startswith("leg_")
    return False


def _object_base_bbox_world(obj: Any) -> dict[str, list[float]] | None:
    from mathutils import Vector  # type: ignore

    if obj.type == "MESH" and getattr(obj, "data", None) and len(obj.data.vertices) > 0:
        points = []
        for vertex in obj.data.vertices:
            world = obj.matrix_world @ vertex.co
            points.append((float(world.x), float(world.y), float(world.z)))
        return _bbox_from_points(points)

    if hasattr(obj, "bound_box") and obj.bound_box:
        points = []
        for corner in obj.bound_box:
            world = obj.matrix_world @ Vector(corner)
            points.append((float(world.x), float(world.y), float(world.z)))
        return _bbox_from_points(points)

    location = getattr(obj, "location", None)
    if location is None:
        return None
    return {
        "min": [float(location.x), float(location.y), float(location.z)],
        "max": [float(location.x), float(location.y), float(location.z)],
    }


def _mesh_bbox_world(mesh: Any, matrix_world: Any) -> dict[str, list[float]] | None:
    if not mesh or len(mesh.vertices) == 0:
        return None
    points = []
    for vertex in mesh.vertices:
        world = matrix_world @ vertex.co
        points.append((float(world.x), float(world.y), float(world.z)))
    return _bbox_from_points(points)


def _modifier_info(modifier: Any) -> dict[str, Any]:
    payload: dict[str, Any] = {
        "name": str(getattr(modifier, "name", "")),
        "type": str(getattr(modifier, "type", "")),
    }
    if payload["type"] == "SIMPLE_DEFORM":
        payload["deform_method"] = str(getattr(modifier, "deform_method", ""))
        payload["axis"] = str(getattr(modifier, "deform_axis", ""))
        try:
            payload["angle"] = float(getattr(modifier, "angle", 0.0))
        except (TypeError, ValueError):
            payload["angle"] = 0.0
        origin_obj = getattr(modifier, "origin", None)
        payload["origin"] = origin_obj.name if origin_obj is not None else None
    return payload


def _collect_object_metrics(obj: Any, depsgraph: Any) -> dict[str, Any]:
    base_bbox = _object_base_bbox_world(obj)
    eval_bbox = base_bbox
    vertices = 0
    polygons = 0

    if obj.type == "MESH":
        eval_obj = obj.evaluated_get(depsgraph)
        eval_mesh = eval_obj.to_mesh()
        try:
            vertices = int(len(eval_mesh.vertices))
            polygons = int(len(eval_mesh.polygons))
            eval_bbox = _mesh_bbox_world(eval_mesh, eval_obj.matrix_world) or base_bbox
        finally:
            eval_obj.to_mesh_clear()

    base_spans = _bbox_spans(base_bbox)
    eval_spans = _bbox_spans(eval_bbox)
    bbox_delta = {
        "x": float(eval_spans["x"] - base_spans["x"]),
        "y": float(eval_spans["y"] - base_spans["y"]),
        "z": float(eval_spans["z"] - base_spans["z"]),
    }

    return {
        "name": str(obj.name),
        "type": str(obj.type),
        "verts": vertices,
        "polys": polygons,
        "modifiers": [_modifier_info(mod) for mod in obj.modifiers],
        "bbox_world": eval_bbox,
        "bbox_world_base": base_bbox,
        "bbox_spans": eval_spans,
        "bbox_spans_base": base_spans,
        "bbox_delta": bbox_delta,
    }


def _collect_groups(objects: list[dict[str, Any]]) -> dict[str, dict[str, Any]]:
    groups: dict[str, dict[str, Any]] = {}
    for key in GROUP_KEYS:
        members = [obj for obj in objects if _group_match(str(obj.get("name", "")), key)]
        groups[key] = {
            "count": len(members),
            "objects": [str(obj.get("name", "")) for obj in members],
            "bbox_world": _bbox_union(obj.get("bbox_world") for obj in members),
        }
    return groups


def _collect_overlap_pairs(
    left_names: Iterable[str],
    right_names: Iterable[str],
    object_index: dict[str, dict[str, Any]],
) -> dict[str, Any]:
    pairs: list[dict[str, Any]] = []
    total = 0.0
    for left_name in left_names:
        left_bbox = object_index.get(left_name, {}).get("bbox_world")
        if not left_bbox:
            continue
        for right_name in right_names:
            right_bbox = object_index.get(right_name, {}).get("bbox_world")
            if not right_bbox:
                continue
            volume, bbox = _bbox_overlap(left_bbox, right_bbox)
            if volume <= 0.0:
                continue
            total += volume
            pairs.append(
                {
                    "left": left_name,
                    "right": right_name,
                    "volume": float(volume),
                    "bbox_world": bbox,
                }
            )
    return {"total_volume": float(total), "pairs": pairs}


def collect_scene_metrics() -> dict[str, Any]:
    """Collect object-level and group-level Blender scene metrics."""
    import bpy  # type: ignore

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()
    try:
        depsgraph.update()
    except Exception:
        pass

    scene_objects = sorted(bpy.data.objects, key=lambda item: item.name.lower())
    objects = [_collect_object_metrics(obj, depsgraph) for obj in scene_objects]
    groups = _collect_groups(objects)
    object_index = {str(obj.get("name", "")): obj for obj in objects}

    overlaps = {
        "slats_vs_arms": _collect_overlap_pairs(
            groups["slat_"]["objects"],
            groups["arm_"]["objects"],
            object_index,
        ),
        "slats_vs_frame": _collect_overlap_pairs(
            groups["slat_"]["objects"],
            groups["frame_"]["objects"],
            object_index,
        ),
        "back_slats_vs_frame": _collect_overlap_pairs(
            groups["back_slat_"]["objects"],
            groups["frame_"]["objects"],
            object_index,
        ),
    }

    return {
        "timestamp_utc": datetime.now(timezone.utc).isoformat(),
        "units": {"length": "m", "volume": "m3"},
        "object_count": len(objects),
        "objects": objects,
        "groups": groups,
        "overlaps": overlaps,
    }



===== FILE: tools/blender/debug/validators.py =====
"""Validation rules and scoring for Blender debug metrics."""

from __future__ import annotations

import json
import os
import sys
from typing import Any


DEFAULT_OVERLAP_EPS = 1e-8
BEND_MOD_ANGLE_EPS = 1e-6


def _read_env_float(name: str, default: float) -> float:
    raw = os.getenv(name, str(default))
    try:
        return float(raw)
    except (TypeError, ValueError):
        return float(default)


def _read_env_int(name: str, default: int) -> int:
    raw = os.getenv(name, str(default))
    try:
        return int(raw)
    except (TypeError, ValueError):
        return int(default)


BEND_EPS_M = _read_env_float("DEBUG_BEND_EPS_M", 0.002)
CLEARANCE_EPS_M = _read_env_float("DEBUG_CLEARANCE_EPS_M", 0.003)
JOINT_OVERLAP_ALLOWANCE_MM = _read_env_float("DEBUG_JOINT_OVERLAP_ALLOWANCE_MM", 2.0)
MOD_EFFECT_EPS_M = _read_env_float("DEBUG_MOD_EFFECT_EPS_M", 0.001)
MOD_EFFECT_VERTS_EPS = _read_env_int("DEBUG_MOD_EFFECT_VERTS_EPS", 4)


def _as_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _as_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def _looks_like_metrics(payload: Any) -> bool:
    return isinstance(payload, dict) and any(k in payload for k in ("objects", "groups", "overlaps"))


def _looks_like_ir(payload: Any) -> bool:
    return isinstance(payload, dict) and any(k in payload for k in ("slats", "back_support", "seat_width_mm"))


def _normalize_validate_args(first: dict[str, Any], second: dict[str, Any]) -> tuple[dict[str, Any], dict[str, Any]]:
    """Allow both validate(ir, metrics) and legacy validate(metrics, ir)."""
    if _looks_like_metrics(first) and _looks_like_ir(second):
        return second, first
    return first, second


def _objects_by_prefix(metrics: dict[str, Any], prefix: str) -> list[dict[str, Any]]:
    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return []
    lowered = prefix.lower()
    return [
        obj
        for obj in objects
        if isinstance(obj, dict) and str(obj.get("name", "")).lower().startswith(lowered)
    ]


def _mesh_objects_by_prefix(metrics: dict[str, Any], prefix: str) -> list[dict[str, Any]]:
    return [
        obj
        for obj in _objects_by_prefix(metrics, prefix)
        if str(obj.get("type", "")).strip().upper() == "MESH"
    ]


def _bend_mod_summary(obj: dict[str, Any]) -> tuple[bool, float]:
    """Return (has_bend_modifier, max_abs_bend_angle)."""
    max_abs_angle = 0.0
    has_bend_modifier = False
    modifiers = obj.get("modifiers", [])
    if not isinstance(modifiers, list):
        return has_bend_modifier, max_abs_angle
    for modifier in modifiers:
        if not isinstance(modifier, dict):
            continue
        if str(modifier.get("type", "")).upper() != "SIMPLE_DEFORM":
            continue
        if str(modifier.get("deform_method", "")).upper() == "BEND":
            has_bend_modifier = True
            angle = abs(_as_float(modifier.get("angle", 0.0), 0.0))
            if angle > max_abs_angle:
                max_abs_angle = angle
    return has_bend_modifier, float(max_abs_angle)


def _bbox_delta_axis(obj: dict[str, Any], axis: str) -> float:
    bbox_delta = obj.get("bbox_delta", {})
    if not isinstance(bbox_delta, dict):
        return 0.0
    return abs(_as_float(bbox_delta.get(axis, 0.0), 0.0))


def _bbox_delta_abs_xyz(obj: dict[str, Any]) -> dict[str, float]:
    return {
        "x": _bbox_delta_axis(obj, "x"),
        "y": _bbox_delta_axis(obj, "y"),
        "z": _bbox_delta_axis(obj, "z"),
    }


def _bbox_delta_xyz(obj: dict[str, Any]) -> dict[str, float]:
    bbox_delta = obj.get("bbox_delta", {})
    if not isinstance(bbox_delta, dict):
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    return {
        "x": _as_float(bbox_delta.get("x", 0.0), 0.0),
        "y": _as_float(bbox_delta.get("y", 0.0), 0.0),
        "z": _as_float(bbox_delta.get("z", 0.0), 0.0),
    }


def _max_bbox_delta_abs(obj: dict[str, Any]) -> float:
    deltas = _bbox_delta_abs_xyz(obj)
    return max(deltas["x"], deltas["y"], deltas["z"])


def _bent_stats_for_prefix(
    metrics: dict[str, Any],
    prefix: str,
    bend_eps_m: float,
) -> dict[str, Any]:
    diagnostics: list[dict[str, Any]] = []
    count_bent = 0
    for obj in _objects_by_prefix(metrics, prefix):
        bbox_delta = _bbox_delta_xyz(obj)
        deltas = _bbox_delta_abs_xyz(obj)
        max_delta = _max_bbox_delta_abs(obj)
        has_bend_mod, bend_angle = _bend_mod_summary(obj)
        bent = (max_delta >= bend_eps_m) or (has_bend_mod and bend_angle > BEND_MOD_ANGLE_EPS)
        if bent:
            count_bent += 1
        diagnostics.append(
            {
                "name": str(obj.get("name", "")),
                "bbox_delta": bbox_delta,
                "max_delta": float(max_delta),
                "has_bend_mod": bool(has_bend_mod),
                "bend_angle": float(bend_angle),
            }
        )
    top5 = sorted(diagnostics, key=lambda item: float(item.get("max_delta", 0.0)), reverse=True)[:5]
    return {
        "count_total": len(diagnostics),
        "count_bent": int(count_bent),
        "eps_m": float(bend_eps_m),
        "top5": top5,
    }


def _overlap_total(metrics: dict[str, Any], key: str) -> float:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return 0.0
    overlap = overlaps.get(key, {})
    if not isinstance(overlap, dict):
        return 0.0
    return _as_float(overlap.get("total_volume", 0.0), 0.0)


def _group_count(metrics: dict[str, Any], key: str) -> int:
    groups = metrics.get("groups", {})
    if not isinstance(groups, dict):
        return 0
    payload = groups.get(key, {})
    if not isinstance(payload, dict):
        return 0
    return _as_int(payload.get("count", 0), 0)


def _overlap_entry(metrics: dict[str, Any], key: str) -> dict[str, Any]:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return {}
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return {}
    return entry


def _overlap_pairs(metrics: dict[str, Any], key: str) -> list[dict[str, Any]]:
    entry = _overlap_entry(metrics, key)
    pairs = entry.get("pairs", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def _pair_spans(pair: dict[str, Any]) -> dict[str, float]:
    bbox = pair.get("bbox_world", {})
    if not isinstance(bbox, dict):
        return {"x": 0.0, "y": 0.0, "z": 0.0}

    min_corner = bbox.get("min", [])
    max_corner = bbox.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    if len(min_corner) < 3 or len(max_corner) < 3:
        return {"x": 0.0, "y": 0.0, "z": 0.0}

    return {
        "x": max(0.0, _as_float(max_corner[0], 0.0) - _as_float(min_corner[0], 0.0)),
        "y": max(0.0, _as_float(max_corner[1], 0.0) - _as_float(min_corner[1], 0.0)),
        "z": max(0.0, _as_float(max_corner[2], 0.0) - _as_float(min_corner[2], 0.0)),
    }


def _pair_min_span(pair: dict[str, Any]) -> float:
    spans = _pair_spans(pair)
    return min(float(spans["x"]), float(spans["y"]), float(spans["z"]))


def _is_expected_slats_frame_joint_overlap(ir: dict[str, Any], pair: dict[str, Any]) -> bool:
    right_name = str(pair.get("right", "")).strip().lower()
    if not right_name:
        return False

    if right_name.startswith("rail_") or right_name.startswith("beam_cross_"):
        slats = ir.get("slats", {})
        if not isinstance(slats, dict):
            return False
        allowance_mm = (
            _as_float(slats.get("clearance_mm", 0.0), 0.0)
            + _as_float(slats.get("mount_offset_mm", 0.0), 0.0)
            + JOINT_OVERLAP_ALLOWANCE_MM
        )
        allowance_m = max(0.0, allowance_mm / 1000.0)
        return _pair_min_span(pair) <= allowance_m
    return False


def _is_expected_back_slats_frame_joint_overlap(ir: dict[str, Any], pair: dict[str, Any]) -> bool:
    right_name = str(pair.get("right", "")).strip().lower()
    if right_name not in {"back_rail_left", "back_rail_right"}:
        return False

    back_support = ir.get("back_support", {})
    frame = ir.get("frame", {})
    if not isinstance(back_support, dict) or not isinstance(frame, dict):
        return False

    back_depth_mm = _as_float(back_support.get("thickness_mm", 0.0), 0.0)
    frame_depth_mm = _as_float(frame.get("thickness_mm", 0.0), 0.0)
    allowance_mm = max(0.0, back_depth_mm - frame_depth_mm) + JOINT_OVERLAP_ALLOWANCE_MM
    allowance_m = max(0.0, allowance_mm / 1000.0)
    return _pair_min_span(pair) <= allowance_m


def _split_overlap_pairs(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    key: str,
) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
    all_pairs = _overlap_pairs(metrics, key)
    hard_pairs: list[dict[str, Any]] = []
    allowed_joint_pairs: list[dict[str, Any]] = []

    for pair in all_pairs:
        if key == "slats_vs_frame" and _is_expected_slats_frame_joint_overlap(ir, pair):
            allowed_joint_pairs.append(pair)
            continue
        if key == "back_slats_vs_frame" and _is_expected_back_slats_frame_joint_overlap(ir, pair):
            allowed_joint_pairs.append(pair)
            continue
        hard_pairs.append(pair)

    return hard_pairs, allowed_joint_pairs


def _pairs_total_volume(pairs: list[dict[str, Any]]) -> float:
    total = 0.0
    for pair in pairs:
        total += _as_float(pair.get("volume", 0.0), 0.0)
    return float(total)


def _overlap_pairs_top(metrics: dict[str, Any], key: str, limit: int = 10) -> list[dict[str, Any]]:
    pairs = _overlap_pairs(metrics, key)
    return _pairs_top_from_list(pairs, limit=limit)


def _pairs_top_from_list(pairs: list[dict[str, Any]], limit: int = 10) -> list[dict[str, Any]]:
    typed_pairs = [pair for pair in pairs if isinstance(pair, dict)]

    def _pair_volume(pair: dict[str, Any]) -> float:
        return _as_float(pair.get("volume", 0.0), 0.0)

    sorted_pairs = sorted(typed_pairs, key=_pair_volume, reverse=True)[: max(0, int(limit))]
    result: list[dict[str, Any]] = []
    for pair in sorted_pairs:
        result.append(
            {
                "left": str(pair.get("left", "")),
                "right": str(pair.get("right", "")),
                "volume": float(_as_float(pair.get("volume", 0.0), 0.0)),
                "bbox_world": pair.get("bbox_world"),
            }
        )
    return result


def _offenders_from_pairs_top(pairs_top: list[dict[str, Any]]) -> list[dict[str, Any]]:
    names: set[str] = set()
    for pair in pairs_top:
        if not isinstance(pair, dict):
            continue
        left_name = str(pair.get("left", "")).strip()
        right_name = str(pair.get("right", "")).strip()
        if left_name:
            names.add(left_name)
        if right_name:
            names.add(right_name)
    return [{"name": name} for name in sorted(names)]


def _overlap_unique_counts(metrics: dict[str, Any], key: str) -> tuple[int, int]:
    pairs = _overlap_pairs(metrics, key)
    left_names = {str(pair.get("left", "")) for pair in pairs if str(pair.get("left", "")).strip()}
    right_names = {str(pair.get("right", "")) for pair in pairs if str(pair.get("right", "")).strip()}
    return len(left_names), len(right_names)


def _overlap_problem_details(metrics: dict[str, Any], key: str, total_volume: float, overlap_eps: float) -> dict[str, Any]:
    unique_left_count, unique_right_count = _overlap_unique_counts(metrics, key)
    pairs_top = _overlap_pairs_top(metrics, key, limit=10)
    return {
        "total_volume_m3": float(total_volume),
        "eps_m3": float(overlap_eps),
        "pairs_top": pairs_top,
        "offenders": _offenders_from_pairs_top(pairs_top),
        "unique_left_count": int(unique_left_count),
        "unique_right_count": int(unique_right_count),
    }


def _overlap_problem_details_from_pairs(
    metrics: dict[str, Any],
    key: str,
    *,
    overlap_eps: float,
    hard_pairs: list[dict[str, Any]],
    joint_pairs: list[dict[str, Any]],
) -> dict[str, Any]:
    hard_pairs_top = _pairs_top_from_list(hard_pairs, limit=10)
    joint_pairs_top = _pairs_top_from_list(joint_pairs, limit=10)
    offender_pairs_top = hard_pairs_top if hard_pairs_top else joint_pairs_top

    hard_left = {str(pair.get("left", "")) for pair in hard_pairs if str(pair.get("left", "")).strip()}
    hard_right = {str(pair.get("right", "")) for pair in hard_pairs if str(pair.get("right", "")).strip()}

    return {
        "total_volume_m3": float(_overlap_total(metrics, key)),
        "effective_total_volume_m3": float(_pairs_total_volume(hard_pairs)),
        "joint_only_volume_m3": float(_pairs_total_volume(joint_pairs)),
        "eps_m3": float(overlap_eps),
        "pairs_top": hard_pairs_top,
        "joint_pairs_top": joint_pairs_top,
        "offenders": _offenders_from_pairs_top(offender_pairs_top),
        "unique_left_count": int(len(hard_left)),
        "unique_right_count": int(len(hard_right)),
        "joint_pairs_count": int(len(joint_pairs)),
        "joint_allowance_mm": float(JOINT_OVERLAP_ALLOWANCE_MM),
    }


def _group_bbox_world(metrics: dict[str, Any], group_key: str) -> dict[str, Any] | None:
    groups = metrics.get("groups", {})
    if not isinstance(groups, dict):
        return None
    group_payload = groups.get(group_key, {})
    if not isinstance(group_payload, dict):
        return None
    bbox = group_payload.get("bbox_world")
    if not isinstance(bbox, dict):
        return None
    min_corner = bbox.get("min")
    max_corner = bbox.get("max")
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return None
    if len(min_corner) < 3 or len(max_corner) < 3:
        return None
    return bbox


def _z_clearance_between_bboxes(
    first_bbox: dict[str, Any] | None,
    second_bbox: dict[str, Any] | None,
) -> float | None:
    if not first_bbox or not second_bbox:
        return None
    first_min = _as_float(first_bbox.get("min", [0.0, 0.0, 0.0])[2], 0.0)
    first_max = _as_float(first_bbox.get("max", [0.0, 0.0, 0.0])[2], 0.0)
    second_min = _as_float(second_bbox.get("min", [0.0, 0.0, 0.0])[2], 0.0)
    second_max = _as_float(second_bbox.get("max", [0.0, 0.0, 0.0])[2], 0.0)

    if first_max < second_min:
        return float(second_min - first_max)
    if second_max < first_min:
        return float(first_min - second_max)
    return 0.0


def _problem(code: str, severity: int, message: str, details: dict[str, Any]) -> dict[str, Any]:
    return {
        "code": code,
        "severity": int(severity),
        "message": message,
        "details": details,
    }


def _should_check_slats_overlap(ir: dict[str, Any], metrics: dict[str, Any]) -> bool:
    slats = ir.get("slats", {})
    if isinstance(slats, dict) and "enabled" in slats:
        return bool(slats.get("enabled", False))
    return _group_count(metrics, "slat_") > 0


def _should_check_back_slats_overlap(ir: dict[str, Any], metrics: dict[str, Any]) -> bool:
    back_support = ir.get("back_support", {})
    if isinstance(back_support, dict) and "mode" in back_support:
        return str(back_support.get("mode", "")).strip().lower() == "slats"
    return _group_count(metrics, "back_slat_") > 0


def _normalize_modifier_key(key: Any) -> str:
    raw = str(key).strip().upper()
    if not raw:
        return ""
    raw = raw.replace(" ", "")
    if ":" in raw:
        left, right = raw.split(":", 1)
        if right:
            return f"{left}:{right}"
        return left
    return raw


def _expected_modifiers_map(ir: dict[str, Any]) -> dict[str, list[str]]:
    debug_payload = ir.get("debug", {})
    if not isinstance(debug_payload, dict):
        return {}
    expected_payload = debug_payload.get("expect_modifiers", {})
    if not isinstance(expected_payload, dict):
        return {}

    result: dict[str, list[str]] = {}
    for group_key, expected in expected_payload.items():
        if not isinstance(expected, list):
            continue
        normalized: list[str] = []
        for item in expected:
            key = _normalize_modifier_key(item)
            if key and key not in normalized:
                normalized.append(key)
        if normalized:
            result[str(group_key)] = normalized
    return result


def _modifier_key_from_payload(modifier: dict[str, Any]) -> str:
    mod_type = _normalize_modifier_key(modifier.get("type", ""))
    if mod_type != "SIMPLE_DEFORM":
        return mod_type
    deform_method = _normalize_modifier_key(modifier.get("deform_method", ""))
    if deform_method:
        return f"SIMPLE_DEFORM:{deform_method}"
    return "SIMPLE_DEFORM"


def _object_modifier_keys(obj: dict[str, Any]) -> set[str]:
    keys: set[str] = set()
    raw_keys = obj.get("modifier_keys", [])
    if isinstance(raw_keys, list):
        for item in raw_keys:
            key = _normalize_modifier_key(item)
            if key:
                keys.add(key)

    if keys:
        return keys

    modifiers = obj.get("modifiers", [])
    if not isinstance(modifiers, list):
        return keys
    for modifier in modifiers:
        if not isinstance(modifier, dict):
            continue
        key = _modifier_key_from_payload(modifier)
        if key:
            keys.add(key)
    return keys


def _has_expected_modifier(present_keys: set[str], expected_key: str) -> bool:
    normalized_expected = _normalize_modifier_key(expected_key)
    if not normalized_expected:
        return False
    if normalized_expected in present_keys:
        return True

    if ":" in normalized_expected:
        mod_type = normalized_expected.split(":", 1)[0]
        return mod_type in present_keys

    prefix = f"{normalized_expected}:"
    if normalized_expected in present_keys:
        return True
    return any(key.startswith(prefix) for key in present_keys)


def _object_counts(obj: dict[str, Any]) -> tuple[int, int | None, int, int | None]:
    verts = _as_int(obj.get("verts", 0), 0)
    polys = _as_int(obj.get("polys", 0), 0)

    verts_base_raw = obj.get("verts_base")
    verts_base = _as_int(verts_base_raw, 0) if isinstance(verts_base_raw, (int, float)) else None
    polys_base_raw = obj.get("polys_base")
    polys_base = _as_int(polys_base_raw, 0) if isinstance(polys_base_raw, (int, float)) else None
    return verts, verts_base, polys, polys_base


def _verts_delta_abs(obj: dict[str, Any]) -> int | None:
    verts, verts_base, _, _ = _object_counts(obj)
    if verts_base is None:
        return None
    return abs(int(verts - verts_base))


def _modifier_no_effect_for_object(
    obj: dict[str, Any],
    expected_modifier: str,
    *,
    eps_m: float,
    verts_eps: int,
) -> tuple[bool, int, str, float]:
    mod_key = _normalize_modifier_key(expected_modifier)
    mod_type = mod_key.split(":", 1)[0]
    max_delta = _max_bbox_delta_abs(obj)
    verts_delta = _verts_delta_abs(obj)
    has_geom_delta = max_delta >= eps_m
    has_verts_delta = (verts_delta is not None) and (verts_delta > int(verts_eps))

    if mod_key == "SIMPLE_DEFORM:BEND":
        has_bend_mod, bend_angle = _bend_mod_summary(obj)
        if has_geom_delta or (has_bend_mod and bend_angle > BEND_MOD_ANGLE_EPS):
            return False, 0, "", float(bend_angle)
        if bend_angle > BEND_MOD_ANGLE_EPS:
            return False, 0, "", float(bend_angle)
        return True, 2, "bbox_delta too small", float(bend_angle)

    if mod_type == "ARRAY":
        if has_geom_delta or has_verts_delta:
            return False, 0, "", 0.0
        if verts_delta is None:
            return True, 2, "bbox_delta too small", 0.0
        return True, 2, "bbox_delta and verts delta too small", 0.0

    if mod_type == "MIRROR":
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if verts_delta > int(verts_eps):
            return False, 0, "", 0.0
        return True, 2, "verts did not increase versus base mesh", 0.0

    if mod_type == "SOLIDIFY":
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if (max_delta < eps_m) and (verts_delta <= int(verts_eps)):
            return True, 2, "bbox_delta and verts delta too small", 0.0
        return False, 0, "", 0.0

    warn_types = {"BEVEL", "SUBSURF", "WEIGHTED_NORMAL", "BOOLEAN", "SHRINKWRAP", "CURVE", "LATTICE"}
    if mod_type in warn_types:
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if (max_delta < eps_m) and (verts_delta <= int(verts_eps)):
            return True, 1, "bbox_delta and verts delta too small", 0.0
        return False, 0, "", 0.0

    if has_geom_delta or has_verts_delta:
        return False, 0, "", 0.0
    return True, 1, "bbox_delta and verts delta too small", 0.0


def _validate_modifier_expectation_missing(ir: dict[str, Any], metrics: dict[str, Any]) -> list[dict[str, Any]]:
    expected_map = _expected_modifiers_map(ir)
    if not expected_map:
        return []

    problems: list[dict[str, Any]] = []
    for group_key, expected in expected_map.items():
        objects = _mesh_objects_by_prefix(metrics, group_key)
        if not objects:
            continue

        missing_by_object: list[dict[str, Any]] = []
        for obj in objects:
            present_keys = _object_modifier_keys(obj)
            missing = [key for key in expected if not _has_expected_modifier(present_keys, key)]
            if missing:
                missing_by_object.append(
                    {
                        "name": str(obj.get("name", "")),
                        "missing": missing,
                    }
                )

        if not missing_by_object:
            continue

        problems.append(
            _problem(
                code="MOD_EXPECTATION_MISSING",
                severity=2,
                message=f"Expected modifiers are missing for group '{group_key}'.",
                details={
                    "group_key": group_key,
                    "expected": expected,
                    "missing_by_object": missing_by_object,
                    "counts": {
                        "objects": len(objects),
                        "objects_with_missing": len(missing_by_object),
                    },
                },
            )
        )
    return problems


def _validate_modifier_expectation_no_effect(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    *,
    effect_eps_m: float,
    effect_verts_eps: int,
) -> list[dict[str, Any]]:
    expected_map = _expected_modifiers_map(ir)
    if not expected_map:
        return []

    problems: list[dict[str, Any]] = []
    for group_key, expected in expected_map.items():
        objects = _mesh_objects_by_prefix(metrics, group_key)
        for obj in objects:
            present_keys = _object_modifier_keys(obj)
            if not present_keys:
                continue

            for expected_key in expected:
                if not _has_expected_modifier(present_keys, expected_key):
                    continue

                no_effect, severity, reason, bend_angle = _modifier_no_effect_for_object(
                    obj,
                    expected_modifier=expected_key,
                    eps_m=effect_eps_m,
                    verts_eps=effect_verts_eps,
                )
                if not no_effect or severity <= 0:
                    continue

                verts, verts_base, polys, polys_base = _object_counts(obj)
                details: dict[str, Any] = {
                    "group_key": group_key,
                    "name": str(obj.get("name", "")),
                    "modifier": _normalize_modifier_key(expected_key),
                    "reason": reason,
                    "bbox_delta": _bbox_delta_xyz(obj),
                    "verts": int(verts),
                    "verts_base": verts_base,
                    "polys": int(polys),
                    "polys_base": polys_base,
                    "eps_m": float(effect_eps_m),
                    "verts_eps": int(effect_verts_eps),
                }
                if _normalize_modifier_key(expected_key) == "SIMPLE_DEFORM:BEND":
                    details["bend_angle"] = float(bend_angle)

                problems.append(
                    _problem(
                        code="MOD_EXPECTATION_NO_EFFECT",
                        severity=int(severity),
                        message=f"Modifier {_normalize_modifier_key(expected_key)} has no observable effect.",
                        details=details,
                    )
                )
    return problems


def _validate_slats_not_bent(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    bend_eps_m: float,
) -> list[dict[str, Any]]:
    slats = ir.get("slats", {})
    if not isinstance(slats, dict):
        return []
    if not bool(slats.get("enabled", False)):
        return []
    if _as_float(slats.get("arc_height_mm", 0.0), 0.0) <= 0.0:
        return []

    stats = _bent_stats_for_prefix(metrics, "slat_", bend_eps_m=bend_eps_m)
    if int(stats.get("count_bent", 0)) > 0:
        return []

    details = {
        "count_total": int(stats.get("count_total", 0)),
        "count_bent": int(stats.get("count_bent", 0)),
        "eps_m": float(stats.get("eps_m", bend_eps_m)),
        "top5": stats.get("top5", []),
    }
    if int(stats.get("count_total", 0)) == 0:
        details["note"] = "no objects found"

    return [
        _problem(
            code="SLATS_NOT_BENT",
            severity=2,
            message="Seat slats are expected to be bent but bend evidence is missing.",
            details=details,
        )
    ]


def _validate_back_slats_not_bent(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    bend_eps_m: float,
) -> list[dict[str, Any]]:
    back_support = ir.get("back_support", {})
    if not isinstance(back_support, dict):
        return []
    mode = str(back_support.get("mode", "")).strip().lower()
    if mode != "slats":
        return []
    back_slats = back_support.get("slats", {})
    if not isinstance(back_slats, dict):
        return []
    if _as_float(back_slats.get("arc_height_mm", 0.0), 0.0) <= 0.0:
        return []

    stats = _bent_stats_for_prefix(metrics, "back_slat_", bend_eps_m=bend_eps_m)
    if int(stats.get("count_bent", 0)) > 0:
        return []

    details = {
        "count_total": int(stats.get("count_total", 0)),
        "count_bent": int(stats.get("count_bent", 0)),
        "eps_m": float(stats.get("eps_m", bend_eps_m)),
        "top5": stats.get("top5", []),
    }
    if int(stats.get("count_total", 0)) == 0:
        details["note"] = "no objects found"

    return [
        _problem(
            code="BACK_SLATS_NOT_BENT",
            severity=2,
            message="Back slats are expected to be bent but bend evidence is missing.",
            details=details,
        )
    ]


def _validate_overlap_slats_frame(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_slats_overlap(ir, metrics):
        return []

    hard_pairs, joint_pairs = _split_overlap_pairs(ir, metrics, "slats_vs_frame")
    effective_volume = _pairs_total_volume(hard_pairs)
    total_volume = _overlap_total(metrics, "slats_vs_frame")

    if effective_volume <= overlap_eps:
        if total_volume <= overlap_eps or len(joint_pairs) == 0:
            return []
        details = _overlap_problem_details_from_pairs(
            metrics,
            "slats_vs_frame",
            overlap_eps=overlap_eps,
            hard_pairs=hard_pairs,
            joint_pairs=joint_pairs,
        )
        return [
            _problem(
                code="OVERLAP_SLATS_FRAME",
                severity=1,
                message="Seat slats have only expected joint-contact overlaps with frame.",
                details=details,
            )
        ]

    details = _overlap_problem_details_from_pairs(
        metrics,
        "slats_vs_frame",
        overlap_eps=overlap_eps,
        hard_pairs=hard_pairs,
        joint_pairs=joint_pairs,
    )
    if details.get("unique_left_count", 0) == 0:
        unique_left_count, unique_right_count = _overlap_unique_counts(metrics, "slats_vs_frame")
        details["unique_left_count"] = int(unique_left_count)
        details["unique_right_count"] = int(unique_right_count)

    return [
        _problem(
            code="OVERLAP_SLATS_FRAME",
            severity=2,
            message="Seat slats overlap frame geometry.",
            details=details,
        )
    ]


def _validate_overlap_slats_arms(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_slats_overlap(ir, metrics):
        return []
    volume = _overlap_total(metrics, "slats_vs_arms")
    if volume <= overlap_eps:
        return []

    return [
        _problem(
            code="OVERLAP_SLATS_ARMS",
            severity=2,
            message="Seat slats overlap arm geometry.",
            details=_overlap_problem_details(metrics, "slats_vs_arms", volume, overlap_eps),
        )
    ]


def _validate_overlap_back_slats_frame(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_back_slats_overlap(ir, metrics):
        return []

    hard_pairs, joint_pairs = _split_overlap_pairs(ir, metrics, "back_slats_vs_frame")
    effective_volume = _pairs_total_volume(hard_pairs)
    total_volume = _overlap_total(metrics, "back_slats_vs_frame")

    if effective_volume <= overlap_eps:
        if total_volume <= overlap_eps or len(joint_pairs) == 0:
            return []
        details = _overlap_problem_details_from_pairs(
            metrics,
            "back_slats_vs_frame",
            overlap_eps=overlap_eps,
            hard_pairs=hard_pairs,
            joint_pairs=joint_pairs,
        )
        return [
            _problem(
                code="OVERLAP_BACK_SLATS_FRAME",
                severity=1,
                message="Back slats have only expected joint-contact overlaps with frame.",
                details=details,
            )
        ]

    details = _overlap_problem_details_from_pairs(
        metrics,
        "back_slats_vs_frame",
        overlap_eps=overlap_eps,
        hard_pairs=hard_pairs,
        joint_pairs=joint_pairs,
    )
    if details.get("unique_left_count", 0) == 0:
        unique_left_count, unique_right_count = _overlap_unique_counts(metrics, "back_slats_vs_frame")
        details["unique_left_count"] = int(unique_left_count)
        details["unique_right_count"] = int(unique_right_count)

    return [
        _problem(
            code="OVERLAP_BACK_SLATS_FRAME",
            severity=2,
            message="Back slats overlap frame geometry.",
            details=details,
        )
    ]


def _validate_low_clearance_slats_frame(metrics: dict[str, Any], clearance_eps: float) -> list[dict[str, Any]]:
    overlap_volume = _overlap_total(metrics, "slats_vs_frame")
    if overlap_volume > 0.0:
        return []

    slat_bbox = _group_bbox_world(metrics, "slat_")
    frame_bbox = _group_bbox_world(metrics, "frame_")
    min_clearance_z = _z_clearance_between_bboxes(slat_bbox, frame_bbox)
    if min_clearance_z is None:
        return []
    if min_clearance_z >= clearance_eps:
        return []

    return [
        _problem(
            code="LOW_CLEARANCE_SLATS_FRAME",
            severity=1,
            message="Seat slats and frame have very low Z clearance.",
            details={
                "min_clearance_z_m": float(min_clearance_z),
                "eps_m": float(clearance_eps),
            },
        )
    ]


def validate(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    overlap_eps: float = DEFAULT_OVERLAP_EPS,
    bend_delta_eps: float | None = None,
    clearance_eps_m: float | None = None,
) -> dict[str, Any]:
    """Validate IR against metrics and return score payload."""
    ir, metrics = _normalize_validate_args(ir, metrics)
    overlap_eps = float(_read_env_float("DEBUG_OVERLAP_EPS_M3", overlap_eps))
    bent_eps = float(BEND_EPS_M if bend_delta_eps is None else bend_delta_eps)
    clearance_eps = float(CLEARANCE_EPS_M if clearance_eps_m is None else clearance_eps_m)
    mod_effect_eps_m = float(_read_env_float("DEBUG_MOD_EFFECT_EPS_M", MOD_EFFECT_EPS_M))
    mod_effect_verts_eps = int(_read_env_int("DEBUG_MOD_EFFECT_VERTS_EPS", MOD_EFFECT_VERTS_EPS))

    problems: list[dict[str, Any]] = []
    problems.extend(_validate_modifier_expectation_missing(ir, metrics))
    problems.extend(
        _validate_modifier_expectation_no_effect(
            ir,
            metrics,
            effect_eps_m=mod_effect_eps_m,
            effect_verts_eps=mod_effect_verts_eps,
        )
    )
    problems.extend(_validate_slats_not_bent(ir, metrics, bend_eps_m=bent_eps))
    problems.extend(_validate_back_slats_not_bent(ir, metrics, bend_eps_m=bent_eps))
    problems.extend(_validate_overlap_slats_frame(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_overlap_slats_arms(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_overlap_back_slats_frame(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_low_clearance_slats_frame(metrics, clearance_eps=clearance_eps))

    def _severity_weight(severity: int) -> float:
        if severity >= 3:
            return 0.30
        if severity == 2:
            return 0.10
        if severity == 1:
            return 0.02
        return 0.0

    severity_sum = sum(_as_int(problem.get("severity", 0), 0) for problem in problems)
    severity_max = max((_as_int(problem.get("severity", 0), 0) for problem in problems), default=0)
    penalty = min(1.0, sum(_severity_weight(_as_int(problem.get("severity", 0), 0)) for problem in problems))
    score = max(0.0, 1.0 - penalty)

    return {
        "score": float(round(score, 6)),
        "problems": problems,
        "problem_count": len(problems),
        "severity_max": int(severity_max),
        "penalty": float(round(penalty, 6)),
    }


def _load_json_object(path: str) -> dict[str, Any]:
    with open(path, "r", encoding="utf-8") as handle:
        payload = json.load(handle)
    if not isinstance(payload, dict):
        raise ValueError(f"Expected JSON object in {path}, got {type(payload).__name__}")
    return payload


def _resolve_input_path(base_path: str, candidate: str) -> str:
    if not candidate:
        return ""
    if os.path.isabs(candidate):
        return candidate
    return os.path.abspath(os.path.join(os.path.dirname(base_path), candidate))


def _infer_payload_kind(payload: dict[str, Any]) -> tuple[str, str]:
    kind_raw = str(payload.get("kind", "")).strip().lower()
    if kind_raw == "run":
        return "run", "kind_run"
    if kind_raw == "metrics":
        return "metrics", "kind_metrics"

    if (
        "validation" in payload
        or "patches_applied" in payload
        or "ir_in_path" in payload
        or ("metrics" in payload and ("status" in payload or "run_id" in payload))
    ):
        return "run", "heuristic_run"

    if (
        "validation" not in payload
        and "objects" in payload
        and "groups" in payload
        and "overlaps" in payload
    ):
        return "metrics", "heuristic_metrics"

    return "metrics", "heuristic_fallback_metrics"


def _extract_metrics_from_metrics_payload(payload: dict[str, Any]) -> dict[str, Any]:
    nested_metrics = payload.get("metrics")
    if isinstance(nested_metrics, dict) and not _looks_like_metrics(payload):
        return nested_metrics
    return payload


def _extract_ir_from_payload(payload: dict[str, Any]) -> dict[str, Any]:
    embedded_ir = payload.get("ir")
    if isinstance(embedded_ir, dict):
        return embedded_ir
    kind, _ = _infer_payload_kind(payload)
    if kind == "run":
        return {}
    return payload


def load_debug_payload(path: str) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any]]:
    """Load debug input payload and return (ir, metrics, meta)."""
    input_path = os.path.abspath(path)
    payload = _load_json_object(input_path)
    kind, payload_format = _infer_payload_kind(payload)

    meta: dict[str, Any] = {
        "kind": kind,
        "format": payload_format,
        "input_path": input_path,
        "metrics_source": "none",
        "ir_source": "none",
        "metrics_error": None,
    }

    metrics_payload: dict[str, Any] = {}
    ir_payload: dict[str, Any] = {}

    if kind == "run":
        embedded_metrics = payload.get("metrics")
        if isinstance(embedded_metrics, dict):
            metrics_payload = embedded_metrics
            meta["metrics_source"] = "embedded"
        else:
            metrics_path_raw = str(payload.get("metrics_path", "")).strip()
            if metrics_path_raw:
                metrics_path = _resolve_input_path(input_path, metrics_path_raw)
                try:
                    loaded_metrics_payload = _load_json_object(metrics_path)
                    metrics_payload = _extract_metrics_from_metrics_payload(loaded_metrics_payload)
                    meta["metrics_source"] = "metrics_path"
                    meta["metrics_path"] = metrics_path
                except Exception as exc:
                    meta["metrics_error"] = f"failed to load metrics_path: {exc}"
            else:
                meta["metrics_error"] = "run payload has no embedded metrics and no metrics_path"

        env_ir_path = str(os.getenv("DEBUG_IR_JSON", "")).strip()
        if env_ir_path:
            loaded_ir_payload = _load_json_object(env_ir_path)
            ir_payload = _extract_ir_from_payload(loaded_ir_payload)
            meta["ir_source"] = "env_debug_ir_json"
        elif isinstance(payload.get("ir"), dict):
            ir_payload = payload["ir"]
            meta["ir_source"] = "embedded_ir"
        else:
            ir_in_path_raw = str(payload.get("ir_in_path", "")).strip()
            if ir_in_path_raw:
                ir_in_path = _resolve_input_path(input_path, ir_in_path_raw)
                if os.path.exists(ir_in_path):
                    try:
                        ir_payload = _load_json_object(ir_in_path)
                        meta["ir_source"] = "ir_in_path"
                        meta["ir_in_path"] = ir_in_path
                    except Exception:
                        ir_payload = {}
                        meta["ir_source"] = "ir_in_path_unreadable"
    else:
        metrics_payload = _extract_metrics_from_metrics_payload(payload)
        meta["metrics_source"] = "input_file"

        env_ir_path = str(os.getenv("DEBUG_IR_JSON", "")).strip()
        if env_ir_path:
            loaded_ir_payload = _load_json_object(env_ir_path)
            ir_payload = _extract_ir_from_payload(loaded_ir_payload)
            meta["ir_source"] = "env_debug_ir_json"

    return ir_payload, metrics_payload, meta


def _self_check_joint_only_overlap_payload() -> tuple[dict[str, Any], dict[str, Any]]:
    ir_payload: dict[str, Any] = {
        "back_support": {
            "mode": "slats",
            "thickness_mm": 60.0,
        },
        "frame": {
            "thickness_mm": 58.0,
        },
    }
    metrics_payload: dict[str, Any] = {
        "kind": "metrics",
        "groups": {
            "back_slat_": {"count": 1},
            "frame_": {"count": 1},
        },
        "overlaps": {
            "back_slats_vs_frame": {
                "total_volume": 3.2e-5,
                "pairs": [
                    {
                        "left": "back_slat_1",
                        "right": "back_rail_left",
                        "volume": 3.2e-5,
                        "bbox_world": {
                            "min": [0.0, 0.0, 0.0],
                            "max": [0.0015, 0.0010, 0.0040],
                        },
                    }
                ],
            },
            "slats_vs_frame": {"total_volume": 0.0, "pairs": []},
            "slats_vs_arms": {"total_volume": 0.0, "pairs": []},
        },
    }
    return ir_payload, metrics_payload


if __name__ == "__main__":
    input_path = str(os.getenv("DEBUG_INPUT_JSON", "")).strip()
    if not input_path:
        input_path = str(os.getenv("DEBUG_METRICS_JSON", "")).strip()

    if not input_path:
        print("validators: running built-in joint-only overlap self-check", file=sys.stderr)
        ir_payload, metrics_payload = _self_check_joint_only_overlap_payload()
        result = validate(ir_payload, metrics_payload)
        print(json.dumps(result, ensure_ascii=False, indent=2))

        joint_top_found = False
        joint_top_len = 0
        hard_top_len = 0
        offenders_len = 0
        problems = result.get("problems", [])
        if isinstance(problems, list):
            for problem in problems:
                if not isinstance(problem, dict):
                    continue
                code = str(problem.get("code", "")).strip().upper()
                if code != "OVERLAP_BACK_SLATS_FRAME":
                    continue
                details = problem.get("details", {})
                if not isinstance(details, dict):
                    continue
                joint_pairs_top = details.get("joint_pairs_top", [])
                pairs_top = details.get("pairs_top", [])
                offenders = details.get("offenders", [])
                joint_top_found = isinstance(joint_pairs_top, list) and len(joint_pairs_top) > 0
                joint_top_len = len(joint_pairs_top) if isinstance(joint_pairs_top, list) else 0
                hard_top_len = len(pairs_top) if isinstance(pairs_top, list) else 0
                offenders_len = len(offenders) if isinstance(offenders, list) else 0
                break
        print(
            f"validators: self_check joint_pairs_top_found={joint_top_found} "
            f"joint_pairs_top_len={joint_top_len} hard_pairs_top_len={hard_top_len} "
            f"offenders_len={offenders_len}",
            file=sys.stderr,
        )
        raise SystemExit(0)

    try:
        ir_payload, metrics_payload, meta = load_debug_payload(input_path)
    except Exception as exc:
        print(f"validators: failed to load input: {exc}", file=sys.stderr)
        raise SystemExit(2)

    print(
        f"validators: loaded input kind={meta.get('kind')} format={meta.get('format')}",
        file=sys.stderr,
    )

    if meta.get("kind") == "run" and (not _looks_like_metrics(metrics_payload)):
        error_text = str(meta.get("metrics_error") or "run input metrics not found or unreadable")
        print(f"validators: {error_text}", file=sys.stderr)
        raise SystemExit(2)

    result = validate(ir_payload, metrics_payload)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print(
        f"validators: kind={meta.get('kind')} problems={int(result.get('problem_count', 0))}",
        file=sys.stderr,
    )



===== FILE: tools/blender/debug/visualize.py =====
"""Blender-only visualization helpers for debug overlap offenders."""

from __future__ import annotations

import os
from typing import Any


TARGET_GROUPS = ("frame_", "slat_", "back_slat_", "arm_", "leg_")


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _valid_bbox(bbox: Any) -> bool:
    if not isinstance(bbox, dict):
        return False
    min_corner = bbox.get("min")
    max_corner = bbox.get("max")
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return False
    return len(min_corner) >= 3 and len(max_corner) >= 3


def _bbox_union(a: dict[str, list[float]] | None, b: dict[str, list[float]] | None) -> dict[str, list[float]] | None:
    if not a:
        return b
    if not b:
        return a
    return {
        "min": [
            min(_safe_float(a["min"][0]), _safe_float(b["min"][0])),
            min(_safe_float(a["min"][1]), _safe_float(b["min"][1])),
            min(_safe_float(a["min"][2]), _safe_float(b["min"][2])),
        ],
        "max": [
            max(_safe_float(a["max"][0]), _safe_float(b["max"][0])),
            max(_safe_float(a["max"][1]), _safe_float(b["max"][1])),
            max(_safe_float(a["max"][2]), _safe_float(b["max"][2])),
        ],
    }


def _scene_bbox_from_metrics(metrics: dict[str, Any] | None) -> dict[str, list[float]] | None:
    if not isinstance(metrics, dict):
        return None

    groups = metrics.get("groups", {})
    bbox: dict[str, list[float]] | None = None
    if isinstance(groups, dict):
        for group_key in TARGET_GROUPS:
            payload = groups.get(group_key, {})
            if not isinstance(payload, dict):
                continue
            group_bbox = payload.get("bbox_world")
            if _valid_bbox(group_bbox):
                bbox = _bbox_union(bbox, group_bbox)

    if bbox:
        return bbox

    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return None
    for obj in objects:
        if not isinstance(obj, dict):
            continue
        if str(obj.get("type", "")).upper() != "MESH":
            continue
        obj_bbox = obj.get("bbox_world")
        if _valid_bbox(obj_bbox):
            bbox = _bbox_union(bbox, obj_bbox)
    return bbox


def _material(name: str, rgba: tuple[float, float, float, float]) -> Any:
    import bpy  # type: ignore

    mat = bpy.data.materials.get(name)
    if mat is None:
        mat = bpy.data.materials.new(name=name)

    if hasattr(mat, "use_nodes"):
        mat.use_nodes = True
        node_tree = getattr(mat, "node_tree", None)
        if node_tree and node_tree.nodes:
            principled = node_tree.nodes.get("Principled BSDF")
            if principled is not None:
                principled.inputs[0].default_value = rgba
                principled.inputs[7].default_value = 0.35

    if hasattr(mat, "diffuse_color"):
        mat.diffuse_color = rgba
    return mat


def _details(problem: dict[str, Any]) -> dict[str, Any]:
    details = problem.get("details", {})
    if isinstance(details, dict):
        return details
    return {}


def _add_name(target: set[str], value: Any) -> None:
    name = str(value).strip()
    if name:
        target.add(name)


def _names_from_pairs_field(details: dict[str, Any], field_name: str) -> set[str]:
    names: set[str] = set()
    pairs = details.get(field_name, [])
    if not isinstance(pairs, list):
        return names
    for pair in pairs:
        if not isinstance(pair, dict):
            continue
        _add_name(names, pair.get("left", ""))
        _add_name(names, pair.get("right", ""))
    return names


def _names_from_pairs_top(details: dict[str, Any]) -> set[str]:
    return _names_from_pairs_field(details, "pairs_top")


def _names_from_joint_pairs_top(details: dict[str, Any]) -> set[str]:
    return _names_from_pairs_field(details, "joint_pairs_top")


def _names_from_offenders(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    offenders = details.get("offenders")
    if isinstance(offenders, dict):
        _add_name(names, offenders.get("name", ""))
        _add_name(names, offenders.get("left", ""))
        _add_name(names, offenders.get("right", ""))
        return names
    if not isinstance(offenders, list):
        return names
    for item in offenders:
        if isinstance(item, dict):
            _add_name(names, item.get("name", ""))
            _add_name(names, item.get("left", ""))
            _add_name(names, item.get("right", ""))
        else:
            _add_name(names, item)
    return names


def _names_from_top_offender_pair(metrics: dict[str, Any] | None) -> set[str]:
    names: set[str] = set()
    if not isinstance(metrics, dict):
        return names
    pair = metrics.get("top_offender_pair")
    if not isinstance(pair, dict):
        return names
    _add_name(names, pair.get("left", ""))
    _add_name(names, pair.get("right", ""))
    return names


def _names_from_top5(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    top5 = details.get("top5", [])
    if not isinstance(top5, list):
        return names
    for item in top5:
        if not isinstance(item, dict):
            continue
        _add_name(names, item.get("name", ""))
    return names


def _names_from_missing_details(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    missing_by_object = details.get("missing_by_object", [])
    if isinstance(missing_by_object, list):
        for item in missing_by_object:
            if not isinstance(item, dict):
                continue
            _add_name(names, item.get("name", ""))
    elif isinstance(missing_by_object, dict):
        for key in missing_by_object.keys():
            _add_name(names, key)
    return names


def _names_from_no_effect_details(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    _add_name(names, details.get("name", ""))

    by_object = details.get("by_object")
    if isinstance(by_object, list):
        for item in by_object:
            if not isinstance(item, dict):
                continue
            _add_name(names, item.get("name", ""))
    elif isinstance(by_object, dict):
        for key in by_object.keys():
            _add_name(names, key)

    offenders = details.get("offenders")
    if isinstance(offenders, list):
        for item in offenders:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)

    top = details.get("top")
    if isinstance(top, list):
        for item in top:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)

    top5 = details.get("top5")
    if isinstance(top5, list):
        for item in top5:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)
    return names


def _collect_offenders_by_priority(
    validation: dict[str, Any],
    metrics: dict[str, Any] | None = None,
) -> tuple[set[str], set[str], set[str], set[str], set[str], set[str]]:
    red: set[str] = set()
    blue: set[str] = set()
    orange: set[str] = set()
    offender_codes: set[str] = set()
    hard_overlap_offenders: set[str] = set()
    joint_overlap_offenders: set[str] = set()

    problems = validation.get("problems", [])
    if not isinstance(problems, list):
        return red, blue, orange, offender_codes, hard_overlap_offenders, joint_overlap_offenders

    for problem in problems:
        if not isinstance(problem, dict):
            continue
        code = str(problem.get("code", "")).strip().upper()
        details = _details(problem)

        names: set[str] = set()
        if code.startswith("OVERLAP_"):
            hard_names = _names_from_pairs_top(details)
            offender_names = _names_from_offenders(details)
            joint_names = _names_from_joint_pairs_top(details)
            if hard_names:
                names = hard_names
                hard_overlap_offenders.update(hard_names)
            elif offender_names:
                names = offender_names
                if joint_names and not hard_names:
                    joint_overlap_offenders.update(offender_names)
                else:
                    hard_overlap_offenders.update(offender_names)
            elif joint_names:
                names = joint_names
                joint_overlap_offenders.update(joint_names)
            else:
                fallback_names = _names_from_top_offender_pair(metrics)
                if fallback_names:
                    names = fallback_names
                    hard_overlap_offenders.update(fallback_names)
            red.update(names)
        elif code in {"SLATS_NOT_BENT", "BACK_SLATS_NOT_BENT"}:
            names = _names_from_top5(details)
            blue.update(names)
        elif code == "MOD_EXPECTATION_MISSING":
            names = _names_from_missing_details(details)
            blue.update(names)
        elif code == "MOD_EXPECTATION_NO_EFFECT":
            names = _names_from_no_effect_details(details)
            orange.update(names)

        if names:
            offender_codes.add(code)

    return red, blue, orange, offender_codes, hard_overlap_offenders, joint_overlap_offenders


def _look_at_rotation(camera_obj: Any, target_xyz: tuple[float, float, float]) -> None:
    from mathutils import Vector  # type: ignore

    target_vec = Vector((target_xyz[0], target_xyz[1], target_xyz[2]))
    direction = target_vec - camera_obj.location
    if direction.length <= 1e-9:
        return
    camera_obj.rotation_euler = direction.to_track_quat("-Z", "Y").to_euler()


def _ensure_camera_and_light(
    scene_bbox: dict[str, list[float]] | None,
    lens_mm: float = 50.0,
) -> tuple[Any, Any]:
    import bpy  # type: ignore

    center_x = 0.0
    center_y = 0.0
    center_z = 0.0
    extent_x = 2.0
    extent_y = 2.0
    extent_z = 1.5
    if scene_bbox:
        min_corner = scene_bbox["min"]
        max_corner = scene_bbox["max"]
        center_x = 0.5 * (_safe_float(min_corner[0]) + _safe_float(max_corner[0]))
        center_y = 0.5 * (_safe_float(min_corner[1]) + _safe_float(max_corner[1]))
        center_z = 0.5 * (_safe_float(min_corner[2]) + _safe_float(max_corner[2]))
        extent_x = max(0.1, _safe_float(max_corner[0]) - _safe_float(min_corner[0]))
        extent_y = max(0.1, _safe_float(max_corner[1]) - _safe_float(min_corner[1]))
        extent_z = max(0.1, _safe_float(max_corner[2]) - _safe_float(min_corner[2]))

    extent = max(extent_x, extent_y, extent_z)
    cam_distance = max(2.5, extent * 2.4)

    camera_obj = bpy.data.objects.get("DEBUG_CAMERA")
    if camera_obj is None:
        camera_data = bpy.data.cameras.new(name="DEBUG_CAMERA")
        camera_obj = bpy.data.objects.new("DEBUG_CAMERA", camera_data)
        bpy.context.scene.collection.objects.link(camera_obj)
    if getattr(camera_obj, "data", None) is not None:
        camera_obj.data.lens = float(lens_mm)
        camera_obj.data.clip_end = max(200.0, cam_distance * 20.0)

    camera_obj.location.x = center_x + cam_distance
    camera_obj.location.y = center_y - cam_distance
    camera_obj.location.z = center_z + cam_distance * 0.75
    _look_at_rotation(camera_obj, (center_x, center_y, center_z))
    bpy.context.scene.camera = camera_obj

    light_obj = bpy.data.objects.get("DEBUG_LIGHT")
    if light_obj is None:
        light_data = bpy.data.lights.new(name="DEBUG_LIGHT", type="SUN")
        light_obj = bpy.data.objects.new(name="DEBUG_LIGHT", object_data=light_data)
        bpy.context.scene.collection.objects.link(light_obj)
    if getattr(light_obj, "data", None) is not None:
        light_obj.data.energy = 3.0

    light_obj.location.x = center_x + cam_distance * 0.4
    light_obj.location.y = center_y - cam_distance * 0.2
    light_obj.location.z = center_z + cam_distance * 1.2
    _look_at_rotation(light_obj, (center_x, center_y, center_z))
    return camera_obj, light_obj


def apply_debug_visualization(
    validation: dict[str, Any],
    metrics: dict[str, Any] | None = None,
    snapshot_blend_path: str | None = None,
    snapshot_png_path: str | None = None,
    camera_lens_mm: float = 50.0,
) -> dict[str, Any]:
    """Highlight offenders and optionally save .blend and PNG snapshots."""
    try:
        import bpy  # type: ignore
    except Exception:
        return {
            "offender_count": 0,
            "painted_red": 0,
            "painted_gray": 0,
            "snapshot_blend_path": "",
            "snapshot_png_path": "",
            "error": "bpy unavailable",
        }

    (
        red_offenders,
        blue_offenders,
        orange_offenders,
        offender_codes,
        hard_overlap_offenders,
        joint_overlap_offenders,
    ) = _collect_offenders_by_priority(validation, metrics=metrics)
    all_offenders = set(red_offenders) | set(blue_offenders) | set(orange_offenders)

    offender_mat = _material("MAT_DEBUG_OFFENDER", (0.92, 0.16, 0.16, 1.0))
    bent_mat = _material("MAT_DEBUG_BENT", (0.18, 0.42, 0.95, 1.0))
    orange_mat = _material("MAT_DEBUG_ORANGE", (0.95, 0.52, 0.14, 1.0))
    other_mat = _material("MAT_DEBUG_OTHER", (0.58, 0.58, 0.58, 1.0))

    painted_red = 0
    painted_blue = 0
    painted_orange = 0
    painted_gray = 0
    for obj in bpy.data.objects:
        if str(getattr(obj, "type", "")) != "MESH":
            continue
        mesh = getattr(obj, "data", None)
        if mesh is None or not hasattr(mesh, "materials"):
            continue

        if obj.name in red_offenders:
            target_material = offender_mat
            painted_red += 1
        elif obj.name in blue_offenders:
            target_material = bent_mat
            painted_blue += 1
        elif obj.name in orange_offenders:
            target_material = orange_mat
            painted_orange += 1
        else:
            target_material = other_mat
            painted_gray += 1

        if len(mesh.materials) == 0:
            mesh.materials.append(target_material)
        else:
            mesh.materials[0] = target_material

    scene_bbox = _scene_bbox_from_metrics(metrics)
    _ensure_camera_and_light(scene_bbox, lens_mm=camera_lens_mm)

    saved_blend_path = ""
    if snapshot_blend_path:
        blend_path = os.path.abspath(str(snapshot_blend_path).strip())
        if blend_path:
            parent_dir = os.path.dirname(blend_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)
            bpy.ops.wm.save_as_mainfile(filepath=blend_path)
            saved_blend_path = blend_path

    saved_png_path = ""
    if snapshot_png_path:
        png_path = os.path.abspath(str(snapshot_png_path).strip())
        if png_path:
            parent_dir = os.path.dirname(png_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)
            scene = bpy.context.scene
            scene.render.image_settings.file_format = "PNG"
            scene.render.filepath = png_path
            bpy.ops.render.render(write_still=True)
            saved_png_path = png_path

    codes_csv = ",".join(sorted(offender_codes))
    print(f"DEBUG_OFFENDERS_COUNT:{len(all_offenders)}")
    print(f"DEBUG_OFFENDER_CODES:{codes_csv}")

    return {
        "offender_count": len(all_offenders),
        "overlap_offender_count": len(red_offenders),
        "bent_offender_count": len(blue_offenders),
        "mod_offender_count": len(orange_offenders),
        "hard_offender_count": len(hard_overlap_offenders),
        "joint_offender_count": len(joint_overlap_offenders),
        "offender_codes": sorted(offender_codes),
        "painted_red": painted_red,
        "painted_blue": painted_blue,
        "painted_orange": painted_orange,
        "painted_gray": painted_gray,
        "snapshot_blend_path": saved_blend_path,
        "snapshot_png_path": saved_png_path,
    }



===== FILE: tools/blender/debug_run.py =====
"""Blender-level debug run orchestrator for sofa IR.

Usage:
  blender --background --python tools/blender/debug_run.py -- path/to/sofa_ir.json
"""

from __future__ import annotations

import json
import os
import sys
from copy import deepcopy
from typing import Any


REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.builders.blender.builder_v01 import build_plan_from_ir  # noqa: E402
from tools.blender.debug.autofix import fix_ir  # noqa: E402
from tools.blender.debug.io import (  # noqa: E402
    ensure_dir,
    make_run_id,
    make_run_tag,
    save_json,
    sha256_file,
    sha256_json,
)
from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
from tools.blender.debug.validators import validate  # noqa: E402
from tools.blender.run_builder_v01 import (  # noqa: E402
    _clear_scene,
    _create_anchor,
    _create_primitive,
    _ensure_mm_units,
)


def _read_ir_path() -> str:
    """Resolve IR path from argv after '--', then from IR_PATH env."""
    if "--" in sys.argv:
        idx = sys.argv.index("--")
        if len(sys.argv) > idx + 1:
            candidate = str(sys.argv[idx + 1]).strip()
            if candidate:
                return candidate

    env_candidate = str(os.environ.get("IR_PATH", "")).strip()
    if env_candidate:
        return env_candidate

    if len(sys.argv) > 1:
        fallback = str(sys.argv[-1]).strip()
        if fallback and fallback != "--":
            return fallback
    return ""


def _env_int(name: str, default: int, min_value: int = 1) -> int:
    raw = os.environ.get(name, str(default))
    try:
        value = int(raw)
    except (TypeError, ValueError):
        value = int(default)
    return max(int(min_value), value)


def _env_flag(name: str, default: bool = False) -> bool:
    raw = str(os.environ.get(name, "1" if default else "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _resolve_out_dir(path: str) -> str:
    if os.path.isabs(path):
        return path
    return os.path.abspath(os.path.join(REPO_ROOT, path))


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _problem_count(validation: dict[str, Any]) -> int:
    problems = validation.get("problems", [])
    if isinstance(problems, list):
        return len(problems)
    return 0


def _top_overlap_offender_pair(validation: dict[str, Any], metrics: dict[str, Any]) -> dict[str, Any] | None:
    best: dict[str, Any] | None = None
    best_volume = -1.0

    problems = validation.get("problems", [])
    if isinstance(problems, list):
        for problem in problems:
            if not isinstance(problem, dict):
                continue
            code = str(problem.get("code", "")).strip().upper()
            if not code.startswith("OVERLAP_"):
                continue
            details = problem.get("details", {})
            if not isinstance(details, dict):
                continue
            pairs = details.get("pairs_top", [])
            if not isinstance(pairs, list) or len(pairs) == 0:
                pairs = details.get("joint_pairs_top", [])
            if not isinstance(pairs, list):
                continue
            for pair in pairs:
                if not isinstance(pair, dict):
                    continue
                volume = _safe_float(pair.get("volume", 0.0), 0.0)
                if volume > best_volume:
                    best_volume = volume
                    best = {
                        "source": code,
                        "left": str(pair.get("left", "")),
                        "right": str(pair.get("right", "")),
                        "volume": float(volume),
                    }

    if best is not None:
        return best

    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return None

    for overlap_key, payload in overlaps.items():
        if not isinstance(payload, dict):
            continue
        pairs = payload.get("pairs", [])
        if not isinstance(pairs, list):
            continue
        for pair in pairs:
            if not isinstance(pair, dict):
                continue
            volume = _safe_float(pair.get("volume", 0.0), 0.0)
            if volume > best_volume:
                best_volume = volume
                best = {
                    "source": str(overlap_key),
                    "left": str(pair.get("left", "")),
                    "right": str(pair.get("right", "")),
                    "volume": float(volume),
                }
    return best


def _top_fixes_payload(patches_applied: list[dict[str, Any]], limit: int = 5) -> list[dict[str, Any]]:
    payload: list[dict[str, Any]] = []
    for patch in patches_applied[: max(0, int(limit))]:
        if not isinstance(patch, dict):
            continue
        payload.append(
            {
                "path": str(patch.get("path", "")),
                "new": patch.get("new"),
            }
        )
    return payload


def _has_severity_ge3(validation: dict[str, Any]) -> bool:
    problems = validation.get("problems", [])
    if not isinstance(problems, list):
        return False
    for problem in problems:
        if not isinstance(problem, dict):
            continue
        if int(_safe_float(problem.get("severity", 0), 0.0)) >= 3:
            return True
    return False


def _extract_build_counts(metrics: dict[str, Any]) -> dict[str, Any]:
    object_count = 0
    if isinstance(metrics.get("object_count"), int):
        object_count = int(metrics["object_count"])
    elif isinstance(metrics.get("objects"), list):
        object_count = len(metrics["objects"])

    group_counts: dict[str, int] = {}
    top_group_counts = metrics.get("group_counts", {})
    if isinstance(top_group_counts, dict):
        for key, value in top_group_counts.items():
            group_counts[str(key)] = int(_safe_float(value, 0.0))
    else:
        groups = metrics.get("groups", {})
        if isinstance(groups, dict):
            for key, value in groups.items():
                if isinstance(value, dict):
                    group_counts[str(key)] = int(_safe_float(value.get("count", 0), 0.0))

    return {
        "object_count": int(object_count),
        "group_counts": group_counts,
    }


def _build_scene_from_ir(ir: dict[str, Any]) -> dict[str, int]:
    """Build scene from IR using the existing builder primitive functions."""
    import bpy  # type: ignore

    _clear_scene()
    _ensure_mm_units()

    plan = build_plan_from_ir(ir)
    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_params = legs.get("params", {}) if isinstance(legs.get("params"), dict) else None

    for primitive in plan.primitives:
        _create_primitive(primitive, legs_params=legs_params)

    for anchor in plan.anchors:
        _create_anchor(anchor.name, anchor.location_mm)

    bpy.context.view_layer.update()
    return {"primitives": len(plan.primitives), "anchors": len(plan.anchors)}


def main() -> int:
    run_id = make_run_id()
    run_tag = make_run_tag(run_id=run_id)
    out_dir = _resolve_out_dir(os.environ.get("DEBUG_OUT_DIR", "out/logs/runs"))
    ensure_dir(out_dir)

    debug_iters = _env_int("DEBUG_ITERS", 1, min_value=1)
    debug_autofix = _env_flag("DEBUG_AUTOFIX", default=False)
    debug_visualize = _env_flag("DEBUG_VISUALIZE", default=False)

    ir_source_path = ""
    ir_in_path = ""
    ir_out_path = ""
    ir_sha256_in = ""
    ir_sha256_out = ""
    metrics_log_path = ""
    metrics_sha256 = ""
    validation_log_path = ""

    source_ir: dict[str, Any] = {}
    current_ir: dict[str, Any] = {}
    iter_index = 0
    iterations: list[dict[str, Any]] = []
    patches_applied: list[dict[str, Any]] = []

    final_metrics: dict[str, Any] = {}
    final_validation: dict[str, Any] = {
        "score": 0.0,
        "penalty": 1.0,
        "problem_count": 0,
        "problems": [],
    }
    final_build_counts: dict[str, Any] = {"object_count": 0, "group_counts": {}}
    final_top_offender_pair: dict[str, Any] | None = None
    prev_metrics: dict[str, Any] | None = None
    autofix_context: dict[str, Any] = {}

    status = "error"
    error_text: str | None = None
    snapshot_blend_saved = "N/A"
    snapshot_png_saved = "N/A"
    debug_offenders_count = 0
    hard_offenders_count = 0
    joint_offenders_count = 0

    try:
        ir_path = _read_ir_path()
        if not ir_path:
            raise RuntimeError("IR path is required. Pass it after '--' or set IR_PATH.")

        ir_source_path = os.path.abspath(ir_path)
        with open(ir_source_path, "r", encoding="utf-8") as handle:
            loaded_ir = json.load(handle)
        if not isinstance(loaded_ir, dict):
            raise RuntimeError(f"Expected IR JSON object, got {type(loaded_ir).__name__}")

        source_ir = loaded_ir
        current_ir = deepcopy(source_ir)

        ir_in_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_in.json"), source_ir)
        ir_sha256_in = sha256_json(source_ir)

        try:
            import bpy  # type: ignore  # noqa: F401
        except Exception as exc:
            raise RuntimeError("Blender Python runtime is required (module bpy is unavailable).") from exc

        for idx in range(1, debug_iters + 1):
            iter_index = idx
            plan_counts = _build_scene_from_ir(current_ir)
            metrics = collect_scene_metrics()
            validation_payload = validate(current_ir, metrics)
            build_counts = _extract_build_counts(metrics)

            iteration_patches: list[dict[str, Any]] = []
            if debug_autofix and idx < debug_iters:
                problems = validation_payload.get("problems", [])
                if not isinstance(problems, list):
                    problems = []
                updated_ir, iteration_patches = fix_ir(
                    current_ir,
                    problems,
                    metrics=metrics,
                    validation=validation_payload,
                    prev_metrics=prev_metrics,
                    context=autofix_context,
                )
                current_ir = updated_ir
                patches_applied.extend(iteration_patches)

            iterations.append(
                {
                    "iter_index": idx,
                    "plan_counts": plan_counts,
                    "build_counts": build_counts,
                    "validation": validation_payload,
                    "patches_applied": iteration_patches,
                }
            )
            final_metrics = metrics
            final_validation = validation_payload
            final_build_counts = build_counts
            prev_metrics = metrics

        final_top_offender_pair = _top_overlap_offender_pair(final_validation, final_metrics)
        if final_top_offender_pair and isinstance(final_metrics, dict):
            final_metrics["top_offender_pair"] = final_top_offender_pair

        if debug_visualize:
            try:
                from tools.blender.debug.visualize import apply_debug_visualization  # noqa: E402

                vis_payload = apply_debug_visualization(
                    validation=final_validation,
                    metrics=final_metrics,
                    snapshot_blend_path=str(os.environ.get("DEBUG_SNAPSHOT_BLEND", "")).strip() or None,
                    snapshot_png_path=str(os.environ.get("DEBUG_SNAPSHOT_PNG", "")).strip() or None,
                    camera_lens_mm=_safe_float(os.environ.get("DEBUG_SNAPSHOT_LENS_MM", "50"), 50.0),
                )
                debug_offenders_count = int(_safe_float(vis_payload.get("offender_count", 0), 0.0))
                hard_offenders_count = int(_safe_float(vis_payload.get("hard_offender_count", 0), 0.0))
                joint_offenders_count = int(_safe_float(vis_payload.get("joint_offender_count", 0), 0.0))
                snapshot_blend_saved = str(vis_payload.get("snapshot_blend_path", "")).strip() or "N/A"
                snapshot_png_saved = str(vis_payload.get("snapshot_png_path", "")).strip() or "N/A"
            except Exception as exc:
                print(f"DEBUG_VISUALIZE_ERROR:{exc}")

        score = _safe_float(final_validation.get("score", 0.0), 0.0)
        pass_result = score >= 0.95 and (not _has_severity_ge3(final_validation))
        status = "ok" if pass_result else "fail"

    except Exception as exc:
        status = "error"
        error_text = str(exc)

    ir_in_payload = source_ir if isinstance(source_ir, dict) else {}
    if not ir_in_path:
        ir_in_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_in.json"), ir_in_payload)
    if not ir_sha256_in:
        ir_sha256_in = sha256_json(ir_in_payload)

    if not current_ir and isinstance(source_ir, dict):
        current_ir = deepcopy(source_ir)
    ir_out_payload = current_ir if isinstance(current_ir, dict) else {}
    ir_out_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_out.json"), ir_out_payload)
    ir_sha256_out = sha256_json(ir_out_payload)

    metrics_log_payload: dict[str, Any] = {"kind": "metrics"}
    if isinstance(final_metrics, dict):
        metrics_log_payload.update(final_metrics)
    else:
        metrics_log_payload["metrics"] = final_metrics
    metrics_log_path = os.path.abspath(save_json(os.path.join(out_dir, f"{run_tag}.metrics.json"), metrics_log_payload))
    metrics_sha256 = sha256_file(metrics_log_path)
    validation_log_path = os.path.abspath(
        save_json(os.path.join(out_dir, f"{run_tag}.validation.json"), final_validation)
    )

    log_payload: dict[str, Any] = {
        "kind": "run",
        "status": status,
        "error": error_text,
        "run_id": run_id,
        "iter_index": int(iter_index),
        "ir_source_path": ir_source_path,
        "ir_in_path": ir_in_path,
        "ir_out_path": ir_out_path,
        "ir_sha256_in": ir_sha256_in,
        "ir_sha256_out": ir_sha256_out,
        "metrics_path": metrics_log_path,
        "metrics_sha256": metrics_sha256,
        "validation_path": validation_log_path,
        "build_counts": final_build_counts,
        "metrics": final_metrics,
        "validation": final_validation,
        "patches_applied": patches_applied,
        "iterations": iterations,
        "debug_autofix": bool(debug_autofix),
        "debug_iters": int(debug_iters),
        "debug_offenders_count": int(debug_offenders_count),
        "hard_offenders_count": int(hard_offenders_count),
        "joint_offenders_count": int(joint_offenders_count),
    }

    log_path = os.path.abspath(save_json(os.path.join(out_dir, f"{run_tag}.json"), log_payload))

    score = _safe_float(final_validation.get("score", 0.0), 0.0)
    problems = _problem_count(final_validation)
    top_pair = final_top_offender_pair or _top_overlap_offender_pair(final_validation, final_metrics)
    top_fixes = _top_fixes_payload(patches_applied, limit=5)
    ir_in_debug = os.path.abspath(ir_in_path) if ir_in_path else "N/A"
    ir_out_debug = os.path.abspath(ir_out_path) if ir_out_path else "N/A"
    metrics_debug = metrics_log_path if metrics_log_path else "N/A"

    print(f"status: {status}")
    print(f"iterations: {iter_index}")
    if top_pair:
        print(
            "top_offender_pair: "
            f"{top_pair.get('left')} vs {top_pair.get('right')} "
            f"volume_m3={_safe_float(top_pair.get('volume', 0.0), 0.0):.6g} "
            f"source={top_pair.get('source')}"
        )
    else:
        print("top_offender_pair: none")

    print(f"DEBUG_RUN_ID:{run_id}")
    print(f"DEBUG_RUN_LOG:{log_path}")
    print(f"DEBUG_RUN_METRICS:{metrics_debug}")
    print(f"DEBUG_IR_IN:{ir_in_debug}")
    print(f"DEBUG_IR_OUT:{ir_out_debug}")
    print(f"DEBUG_SCORE:{score:.6f}")
    print(f"DEBUG_PROBLEMS:{problems}")
    print(f"DEBUG_TOP_FIXES:{json.dumps(top_fixes, ensure_ascii=False)}")
    print(f"DEBUG_SNAPSHOT_BLEND_SAVED:{snapshot_blend_saved}")
    print(f"DEBUG_SNAPSHOT_PNG_SAVED:{snapshot_png_saved}")
    print(f"DEBUG_OFFENDERS_COUNT:{debug_offenders_count}")
    print(f"DEBUG_HARD_OFFENDERS_COUNT:{hard_offenders_count}")
    print(f"DEBUG_JOINT_OFFENDERS_COUNT:{joint_offenders_count}")

    if status == "error":
        return 3
    if score >= 0.95 and (not _has_severity_ge3(final_validation)):
        return 0
    return 2


if __name__ == "__main__":
    raise SystemExit(main())



===== FILE: tools/blender/DEBUG_USAGE.md =====
# Blender Debug Usage

Optional IR block for modifier expectations:

```json
"debug": {
  "expect_modifiers": {
    "slat_": ["SIMPLE_DEFORM:BEND", "SOLIDIFY", "BEVEL"],
    "back_slat_": ["SIMPLE_DEFORM:BEND"],
    "arm_": ["MIRROR"],
    "frame_": ["BEVEL"],
    "leg_": ["BEVEL"]
  }
}
```

## Color Legend

| Class | Color | Source problem codes |
|---|---|---|
| Overlap offenders | Red | `OVERLAP_*` |
| Missing expected modifiers | Blue | `MOD_EXPECTATION_MISSING` |
| Modifier no-effect offenders | Orange | `MOD_EXPECTATION_NO_EFFECT` |
| Non-offenders / other meshes | Gray | fallback |

Paint priority is fixed: `RED > BLUE > ORANGE > GRAY`.

## Highlight-Only (No Autofix)

```powershell
$env:DEBUG_VISUALIZE="1"
$env:DEBUG_AUTOFIX="0"
$env:DEBUG_ITERS="1"
$env:DEBUG_SNAPSHOT_BLEND="out/snapshots/sofa_highlight_only.blend"
$env:DEBUG_SNAPSHOT_PNG="out/snapshots/sofa_highlight_only.png"
& $env:BLENDER_EXE --background --python tools/blender/debug_run.py -- data/examples/sofa_ir.json
```

## Highlight + Autofix (Iterative)

```powershell
$env:DEBUG_VISUALIZE="1"
$env:DEBUG_AUTOFIX="1"
$env:DEBUG_ITERS="2"
$env:DEBUG_AUTOFIX_VERBOSE="1"
$env:DEBUG_AUTOFIX_SAFETY_MM="3"
$env:DEBUG_SNAPSHOT_BLEND="out/snapshots/sofa_autofix.blend"
$env:DEBUG_SNAPSHOT_PNG="out/snapshots/sofa_autofix.png"
& $env:BLENDER_EXE --background --python tools/blender/debug_run.py -- data/examples/sofa_ir.json
```

Autofix overlap safety margin:
- `DEBUG_AUTOFIX_SAFETY_MM` (default `2`) adds extra millimeters on top of bbox-derived penetration delta.

## Batch Run For Folder Of IR Files

Generates per-IR debug outputs and `summary.csv` with:
- `file_name`
- `debug_score`
- `problems_count`
- `overlaps_slats_m3`
- `overlaps_back_m3`
- `fixes_applied_count`

```powershell
$env:DEBUG_AUTOFIX="1"
$env:DEBUG_ITERS="2"
$env:DEBUG_SNAPSHOT_BLEND_DIR="out/snapshots/batch_blend"
& $env:BLENDER_EXE --background --python tools/blender/batch_debug_run.py -- data/examples out/logs/batch

Get-Item out/logs/batch/summary.csv
```



===== FILE: tools/blender/run_builder_v01.py =====
"""Run builder_v01 inside Blender.

Usage (called by export_blender.py):
blender --background --python tools/blender/run_builder_v01.py -- path/to/sofa_ir.json

This version FIXES slat bending by doing vertex-level bending (bmesh),
instead of relying on SimpleDeform (which can appear "flat" in some pipeline cases).

Env vars:
- IR_PATH: override IR path
- BLEND_PATH: if set, saves .blend to that path
- DEBUG_SLAT=1: adds an extra DEBUG_SLAT
- APPLY_DEBUG_SLAT=1: bakes modifiers for DEBUG_SLAT
- APPLY_ALL_SLATS=1: bakes modifiers for ALL slats (optional)
- DEBUG_JSON=1: writes debug JSON metrics/validation log
"""

import json
import math
import os
import sys
from typing import Optional, Tuple

# --- ensure repo root in sys.path so "src.*" imports work ---
REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.builders.blender import builder_v01 as builder_module  # noqa: E402
from src.builders.blender.builder_v01 import build_plan_from_ir  # noqa: E402


# -------------------------
# small helpers
# -------------------------

def _read_ir_path() -> str:
    """Resolve IR path from env or argv (after '--')."""
    if os.environ.get("IR_PATH"):
        return os.environ["IR_PATH"]

    if "--" in sys.argv:
        i = sys.argv.index("--")
        if len(sys.argv) > i + 1:
            return sys.argv[i + 1]

    # fallback: last arg
    if len(sys.argv) > 1:
        return sys.argv[-1]

    return ""


def _clear_scene() -> None:
    """Start from an empty scene."""
    import bpy  # type: ignore
    bpy.ops.wm.read_factory_settings(use_empty=True)


def _ensure_mm_units() -> None:
    """Configure the scene for millimeter units.

    Blender units: meters. So 1 mm = 0.001 m.
    """
    import bpy  # type: ignore
    scene = bpy.context.scene
    scene.unit_settings.system = "METRIC"
    scene.unit_settings.scale_length = 1.0


def _mm_to_m(v):
    return tuple(float(x) / 1000.0 for x in v)


def _apply_rotation_deg(obj, rotation_deg) -> None:
    if not rotation_deg:
        return
    try:
        rx, ry, rz = rotation_deg
    except (TypeError, ValueError):
        return
    if rx == 0 and ry == 0 and rz == 0:
        return
    obj.rotation_euler = (math.radians(rx), math.radians(ry), math.radians(rz))


def _bake_object_modifiers(obj) -> None:
    """Bake evaluated mesh into obj.data and clear modifiers."""
    import bpy  # type: ignore

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()
    try:
        depsgraph.update()
    except Exception:
        pass

    eval_obj = obj.evaluated_get(depsgraph)
    new_mesh = bpy.data.meshes.new_from_object(
        eval_obj,
        depsgraph=depsgraph,
        preserve_all_data_layers=True,
    )
    obj.data = new_mesh
    obj.modifiers.clear()


# -------------------------
# primitives
# -------------------------

def _create_cube(name, dimensions_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cube_add(size=1.0, location=_mm_to_m(location_mm))
    obj = bpy.context.active_object
    obj.name = name
    obj.dimensions = _mm_to_m(dimensions_mm)
    bpy.context.view_layer.update()
    return obj


def _create_cylinder(name, radius_mm, height_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cylinder_add(
        radius=float(radius_mm) / 1000.0,
        depth=float(height_mm) / 1000.0,
        location=_mm_to_m(location_mm),
    )
    obj = bpy.context.active_object
    obj.name = name
    return obj


def _create_cone(name, r_top_mm, r_bottom_mm, height_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cone_add(
        radius1=float(r_bottom_mm) / 1000.0,
        radius2=float(r_top_mm) / 1000.0,
        depth=float(height_mm) / 1000.0,
        location=_mm_to_m(location_mm),
    )
    obj = bpy.context.active_object
    obj.name = name
    return obj


def _create_anchor(name, location_mm):
    import bpy  # type: ignore
    empty = bpy.data.objects.new(name, None)
    empty.empty_display_type = "PLAIN_AXES"
    empty.location = _mm_to_m(location_mm)
    bpy.context.scene.collection.objects.link(empty)
    return empty


# -------------------------
# slats: mesh + vertex bend
# -------------------------

def _create_slat_mesh(
    name: str,
    width_mm: float,
    length_mm: float,
    location_mm,
    rotation_deg,
    segments_len: int,
    segments_w: int,
    orientation: str,
):
    """Creates a grid plane:
    - horizontal: plane in XY (length along +Y), normal ~ +Z
    - vertical:   plane in XZ (length along +Z), normal ~ +Y (or -Y)
    """
    import bpy  # type: ignore
    import bmesh  # type: ignore

    segments_len = max(1, int(segments_len))
    segments_w = max(1, int(segments_w))

    width_m = float(width_mm) / 1000.0
    length_m = float(length_mm) / 1000.0

    bm = bmesh.new()

    # Start with unit grid in XY centered at origin
    bmesh.ops.create_grid(bm, x_segments=segments_w, y_segments=segments_len, size=1.0)

    # Normalize to target width/length in local space
    if bm.verts:
        xs = [v.co.x for v in bm.verts]
        ys = [v.co.y for v in bm.verts]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        cx = (min_x + max_x) / 2.0
        cy = (min_y + max_y) / 2.0
        ext_x = max_x - min_x
        ext_y = max_y - min_y
        sx = (width_m / ext_x) if ext_x != 0.0 else 1.0
        sy = (length_m / ext_y) if ext_y != 0.0 else 1.0

        for v in bm.verts:
            v.co.x = (v.co.x - cx) * sx
            v.co.y = (v.co.y - cy) * sy
            v.co.z = 0.0

    # If vertical: rotate XY plane into XZ (so length becomes Z)
    if orientation == "vertical":
        from mathutils import Matrix  # type: ignore
        rot_m = Matrix.Rotation(math.radians(90.0), 4, "X")  # Y -> Z
        for v in bm.verts:
            v.co = rot_m @ v.co

    mesh = bpy.data.meshes.new(name)
    bm.to_mesh(mesh)
    bm.free()
    mesh.update()

    for poly in mesh.polygons:
        poly.use_smooth = True

    obj = bpy.data.objects.new(name, mesh)
    obj.location = _mm_to_m(location_mm)
    _apply_rotation_deg(obj, rotation_deg)
    bpy.context.scene.collection.objects.link(obj)
    bpy.context.view_layer.update()
    return obj


def _bend_vertices_arc(
    obj,
    orientation: str,
    length_mm: float,
    arc_height_mm: float,
    arc_sign: float,
) -> Tuple[float, float]:
    """Bend vertices into a circular arc (sagitta).
    Returns (radius_m, angle_rad).
    - horizontal: length along local Y, sag applied to local Z
    - vertical:   length along local Z, sag applied to local Y  (back curvature)
    """
    import bmesh  # type: ignore

    if arc_height_mm <= 0.0 or length_mm <= 0.0:
        return (0.0, 0.0)

    L = float(length_mm) / 1000.0
    h = float(arc_height_mm) / 1000.0
    sign = -1.0 if arc_sign < 0 else 1.0

    # radius from sagitta
    # R = L^2/(8h) + h/2
    R = (L * L) / (8.0 * h) + (h / 2.0)
    if not math.isfinite(R) or R <= 0:
        return (0.0, 0.0)

    angle = L / R
    angle = max(-math.pi, min(math.pi, angle))

    half = L / 2.0

    bm = bmesh.new()
    bm.from_mesh(obj.data)

    for v in bm.verts:
        if orientation == "vertical":
            t = v.co.z  # along length
        else:
            t = v.co.y

        t = max(-half, min(half, t))

        # sag = R - sqrt(R^2 - t^2)
        under = max(0.0, (R * R - t * t))
        sag = R - math.sqrt(under)

        if orientation == "vertical":
            v.co.y += sag * sign
        else:
            v.co.z += sag * sign

    bm.to_mesh(obj.data)
    bm.free()
    obj.data.update()

    return (R, angle)


def _axis_ranges_world(mesh, matrix_world):
    if not mesh or len(mesh.vertices) == 0:
        return None
    xs, ys, zs = [], [], []
    for v in mesh.vertices:
        w = matrix_world @ v.co
        xs.append(w.x)
        ys.append(w.y)
        zs.append(w.z)
    return (min(xs), max(xs)), (min(ys), max(ys)), (min(zs), max(zs))


# -------------------------
# plan primitive creator
# -------------------------

def _create_primitive(p, legs_params=None):
    """Create geometry for a Primitive from builder_v01 plan."""
    import bpy  # type: ignore

    shape = getattr(p, "shape", "cube")
    dims = getattr(p, "dimensions_mm", (100, 100, 100))
    loc = getattr(p, "location_mm", (0, 0, 0))
    rot = getattr(p, "rotation_deg", (0.0, 0.0, 0.0))

    if shape in {"cube", "beam", "board"}:
        obj = _create_cube(p.name, dims, loc)
        _apply_rotation_deg(obj, rot)
        return obj

    if shape == "slat":
        # defaults
        arc_height_mm = 0.0
        arc_sign = -1.0
        orientation = "horizontal"
        subdiv_cuts = 64
        edge_radius_mm = 1.0
        solidify_offset = 1.0

        params = getattr(p, "params", None)
        if isinstance(params, dict):
            try:
                arc_height_mm = float(params.get("arc_height_mm", 0.0))
            except (TypeError, ValueError):
                arc_height_mm = 0.0
            try:
                arc_sign = float(params.get("arc_sign", -1.0))
            except (TypeError, ValueError):
                arc_sign = -1.0
            try:
                orientation = str(params.get("orientation", "horizontal")).strip().lower()
            except (TypeError, ValueError):
                orientation = "horizontal"
            try:
                subdiv_cuts = int(params.get("subdiv_cuts", 64))
            except (TypeError, ValueError):
                subdiv_cuts = 64
            try:
                edge_radius_mm = float(params.get("edge_radius_mm", 1.0))
            except (TypeError, ValueError):
                edge_radius_mm = 1.0
            try:
                solidify_offset = float(params.get("solidify_offset", 1.0))
            except (TypeError, ValueError):
                solidify_offset = 1.0

        if orientation in {"seat"}:
            orientation = "horizontal"
        if orientation not in {"horizontal", "vertical"}:
            orientation = "horizontal"

        arc_sign = -1.0 if arc_sign < 0 else 1.0
        solidify_offset = max(-1.0, min(1.0, solidify_offset))

        # dims mapping
        if orientation == "vertical":
            # width X, thickness Y, length Z  (like your older logic)
            width_mm = float(dims[0])
            thickness_mm = float(dims[1])
            length_mm = float(dims[2])
        else:
            # width X, length Y, thickness Z
            width_mm = float(dims[0])
            length_mm = float(dims[1])
            thickness_mm = float(dims[2])

        # mesh density: must be high along length for nice arc
        subdiv_cuts = max(8, min(200, int(subdiv_cuts)))
        segments_len = max(40, min(240, subdiv_cuts * 2))
        segments_w = 4

        obj = _create_slat_mesh(
            name=p.name,
            width_mm=width_mm,
            length_mm=length_mm,
            location_mm=loc,
            rotation_deg=rot,
            segments_len=segments_len,
            segments_w=segments_w,
            orientation=orientation,
        )

        # do vertex bending (the fix)
        radius_m, angle_rad = (0.0, 0.0)
        if arc_height_mm > 0.0 and length_mm > 0.0:
            radius_m, angle_rad = _bend_vertices_arc(
                obj=obj,
                orientation=orientation,
                length_mm=length_mm,
                arc_height_mm=arc_height_mm,
                arc_sign=arc_sign,
            )

        # solidify thickness (works from normals of the plane)
        if thickness_mm > 0.0:
            solid = obj.modifiers.new(name="Solidify", type="SOLIDIFY")
            solid.thickness = float(thickness_mm) / 1000.0
            solid.offset = solidify_offset
            solid.use_even_offset = True

        # bevel edges
        if edge_radius_mm > 0.0:
            bevel = obj.modifiers.new(name="Bevel", type="BEVEL")
            bevel.width = float(edge_radius_mm) / 1000.0
            bevel.segments = 2
            bevel.limit_method = "ANGLE"
            bevel.angle_limit = math.radians(40.0)
            if hasattr(bevel, "harden_normals"):
                bevel.harden_normals = True

        # normals
        wn = obj.modifiers.new(name="WeightedNormal", type="WEIGHTED_NORMAL")
        wn.keep_sharp = True
        wn.weight = 50
        if hasattr(obj.data, "use_auto_smooth"):
            obj.data.use_auto_smooth = True
        if hasattr(obj.data, "auto_smooth_angle"):
            obj.data.auto_smooth_angle = math.radians(40.0)

        # optional baking
        if os.environ.get("APPLY_ALL_SLATS") == "1":
            _bake_object_modifiers(obj)

        # debug ranges (base/eval)
        if obj.name in {"DEBUG_SLAT", "slat_1"} or os.environ.get("DEBUG_SLAT") == "1":
            bpy.context.view_layer.update()
            depsgraph = bpy.context.evaluated_depsgraph_get()
            eval_obj = obj.evaluated_get(depsgraph)
            eval_mesh = eval_obj.to_mesh()

            base_ranges = _axis_ranges_world(obj.data, obj.matrix_world)
            eval_ranges = _axis_ranges_world(eval_mesh, eval_obj.matrix_world)

            print(
                f"[slat] name={obj.name} orientation={orientation} arc_height_mm={arc_height_mm} "
                f"radius_m={radius_m:.6f} angle_rad={angle_rad:.6f} "
                f"verts={len(obj.data.vertices)} mods={[m.type for m in obj.modifiers]}"
            )
            if base_ranges and eval_ranges:
                base_spans = (
                    base_ranges[0][1] - base_ranges[0][0],
                    base_ranges[1][1] - base_ranges[1][0],
                    base_ranges[2][1] - base_ranges[2][0],
                )
                eval_spans = (
                    eval_ranges[0][1] - eval_ranges[0][0],
                    eval_ranges[1][1] - eval_ranges[1][0],
                    eval_ranges[2][1] - eval_ranges[2][0],
                )
                dx = abs(eval_spans[0] - base_spans[0])
                dy = abs(eval_spans[1] - base_spans[1])
                dz = abs(eval_spans[2] - base_spans[2])
                print(
                    f"SLAT_RANGES_BASE x=({base_ranges[0][0]:.6f},{base_ranges[0][1]:.6f}) "
                    f"y=({base_ranges[1][0]:.6f},{base_ranges[1][1]:.6f}) "
                    f"z=({base_ranges[2][0]:.6f},{base_ranges[2][1]:.6f})"
                )
                print(
                    f"SLAT_RANGES_EVAL x=({eval_ranges[0][0]:.6f},{eval_ranges[0][1]:.6f}) "
                    f"y=({eval_ranges[1][0]:.6f},{eval_ranges[1][1]:.6f}) "
                    f"z=({eval_ranges[2][0]:.6f},{eval_ranges[2][1]:.6f})"
                )
                print(f"SLAT_RANGE_DELTAS dx={dx:.6f} dy={dy:.6f} dz={dz:.6f}")

            eval_obj.to_mesh_clear()

        return obj

    if shape == "cylindrical":
        obj = _create_cylinder(p.name, radius_mm=float(dims[0]) / 2.0, height_mm=float(dims[2]), location_mm=loc)
        _apply_rotation_deg(obj, rot)
        return obj

    if shape == "tapered_cone":
        r_top = None
        r_bottom = None
        if isinstance(legs_params, dict):
            try:
                if legs_params.get("r_top") is not None:
                    r_top = float(legs_params["r_top"])
                if legs_params.get("r_bottom") is not None:
                    r_bottom = float(legs_params["r_bottom"])
            except (TypeError, ValueError):
                r_top = None
                r_bottom = None
        if r_top is None or r_bottom is None:
            r_top = max(6.0, float(dims[0]) * 0.35)
            r_bottom = max(r_top + 2.0, float(dims[0]) * 0.6)
        obj = _create_cone(p.name, r_top_mm=r_top, r_bottom_mm=r_bottom, height_mm=float(dims[2]), location_mm=loc)
        _apply_rotation_deg(obj, rot)
        return obj

    # fallback -> cube
    obj = _create_cube(p.name, dims, loc)
    _apply_rotation_deg(obj, rot)
    return obj


# -------------------------
# main
# -------------------------

def main():
    import bpy  # type: ignore

    ir_path = _read_ir_path()
    if not ir_path:
        raise SystemExit("IR path is required. Pass it after '--' or set IR_PATH env var.")

    print(f"RUN_BUILDER_V01:{__file__}")
    print(f"REPO_ROOT:{REPO_ROOT}")
    print(f"BUILDER_MODULE:{builder_module.__file__}")

    _clear_scene()
    _ensure_mm_units()

    blend_path = os.environ.get("BLEND_PATH", "")
    print(f"IR_PATH:{ir_path}")
    print(f"BLEND_PATH:{blend_path}")

    with open(ir_path, "r", encoding="utf-8") as f:
        ir = json.load(f)

    plan = build_plan_from_ir(ir)
    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_params = legs.get("params", {}) if isinstance(legs.get("params"), dict) else None

    # build primitives
    for prim in plan.primitives:
        _create_primitive(prim, legs_params=legs_params)

    # optional debug slat
    if os.environ.get("DEBUG_SLAT") == "1":
        try:
            debug_slat = _create_primitive(
                builder_module.Primitive(
                    name="DEBUG_SLAT",
                    shape="slat",
                    dimensions_mm=(60.0, 600.0, 12.0),  # width, length, thickness (horizontal)
                    location_mm=(0.0, 900.0, 300.0),
                    rotation_deg=(0.0, 0.0, 0.0),
                    params={
                        "arc_height_mm": 35.0,
                        "arc_sign": -1.0,
                        "orientation": "horizontal",
                        "subdiv_cuts": 64,
                        "edge_radius_mm": 1.0,
                        "solidify_offset": 1.0,
                    },
                ),
                legs_params=legs_params,
            )
            print(f"DEBUG_SLAT_CREATED:{debug_slat.name} verts={len(debug_slat.data.vertices)}")
            if os.environ.get("APPLY_DEBUG_SLAT") == "1":
                _bake_object_modifiers(debug_slat)
                print("DEBUG_SLAT_BAKED:1")
        except Exception as exc:
            print(f"DEBUG_SLAT_CREATED:error={exc}")

    # anchors as empties
    for a in plan.anchors:
        _create_anchor(a.name, a.location_mm)

    object_names = sorted(obj.name for obj in bpy.data.objects)
    print(f"OBJECTS_TOTAL:{len(object_names)} FIRST:{object_names[:10]}")
    slat_count = sum(1 for name in object_names if name.startswith("slat_"))
    beam_count = sum(1 for name in object_names if name.startswith("beam_"))
    rail_count = sum(1 for name in object_names if name.startswith("rail_"))
    print(f"OBJECT_PREFIX_COUNTS slat_={slat_count} beam_={beam_count} rail_={rail_count}")

    if os.environ.get("DEBUG_JSON") == "1":
        try:
            from tools.blender.debug.io import ir_sha256, make_run_id, save_run_log  # noqa: E402
            from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
            from tools.blender.debug.validators import validate  # noqa: E402

            debug_run_id = make_run_id()
            metrics = collect_scene_metrics()
            validation = validate(metrics, ir)
            debug_payload = {
                "run_id": debug_run_id,
                "source": "run_builder_v01",
                "ir_path": os.path.abspath(ir_path),
                "ir_sha256": ir_sha256(ir),
                "build": {
                    "primitives": len(plan.primitives),
                    "anchors": len(plan.anchors),
                },
                "metrics": metrics,
                "validation": validation,
            }
            debug_log_path = save_run_log(
                debug_payload,
                out_dir=os.path.join(REPO_ROOT, "out", "logs", "runs"),
                run_id=debug_run_id,
            )
            print(f"DEBUG_JSON_LOG:{debug_log_path}")
        except Exception as exc:
            print(f"DEBUG_JSON_ERROR:{exc}")

    # optionally save .blend
    if blend_path:
        os.makedirs(os.path.dirname(blend_path), exist_ok=True)
        bpy.ops.wm.save_as_mainfile(filepath=blend_path)

    return {"status": "built", "primitives": len(plan.primitives), "anchors": len(plan.anchors)}


if __name__ == "__main__":
    main()



===== FILE: tools/blender/run_export_glb.py =====
"""Export GLB from Blender scene."""

import os
import sys

import bpy  # type: ignore  # Blender-only


def _read_glb_path() -> str:
    """Resolve GLB path from env or argv."""
    if os.environ.get("GLB_PATH"):
        return os.environ["GLB_PATH"]
    if "--" in sys.argv:
        index = sys.argv.index("--")
        if len(sys.argv) > index + 1:
            return sys.argv[index + 1]
    if len(sys.argv) > 1:
        return sys.argv[-1]
    return "out/glb/sofa.glb"


def _export_apply_kwargs():
    props = bpy.ops.export_scene.gltf.get_rna_type().properties
    if "export_apply" in props:
        return {"export_apply": True}
    if "export_apply_modifiers" in props:
        return {"export_apply_modifiers": True}
    return {}


def _is_exportable_mesh(obj) -> bool:
    if obj.type != "MESH":
        return False
    if obj.name.endswith("_bend_origin"):
        return False
    for col in obj.users_collection:
        if col.name == "_helpers":
            return False
    if obj.hide_get() or obj.hide_viewport or obj.hide_render:
        return False
    if not obj.visible_get():
        return False
    return True


def main():
    """Entry point for Blender execution."""
    glb_path = _read_glb_path()
    glb_path = os.path.abspath(glb_path)
    os.makedirs(os.path.dirname(glb_path), exist_ok=True)

    print(f"RUN_EXPORT_GLB:{__file__}")
    print(f"BLEND_PATH:{bpy.data.filepath}")
    print(f"GLB_PATH:{glb_path}")

    if os.path.exists(glb_path):
        try:
            os.remove(glb_path)
        except OSError as exc:
            print(f"WARNING: failed to remove existing GLB {glb_path}: {exc}")

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()

    helpers = bpy.data.collections.get("_helpers")
    if helpers is not None:
        helpers.hide_viewport = True
        helpers.hide_render = True

    export_objs = [obj for obj in bpy.data.objects if _is_exportable_mesh(obj)]
    tmp_coll = bpy.data.collections.get("_export_tmp")
    if tmp_coll is None:
        tmp_coll = bpy.data.collections.new("_export_tmp")
        bpy.context.scene.collection.children.link(tmp_coll)
    tmp_coll.hide_viewport = False
    tmp_coll.hide_render = False

    tmp_objects = []
    tmp_meshes = []
    for obj in export_objs:
        eval_obj = obj.evaluated_get(depsgraph)
        try:
            mesh = bpy.data.meshes.new_from_object(eval_obj, depsgraph=depsgraph)
            used_new_from_object = True
        except Exception:
            used_new_from_object = False
            mesh_eval = eval_obj.to_mesh()
            mesh = mesh_eval.copy()
            eval_obj.to_mesh_clear()
        tmp = bpy.data.objects.new(obj.name, mesh)
        tmp.matrix_world = obj.matrix_world
        tmp_coll.objects.link(tmp)
        tmp_objects.append(tmp)
        tmp_meshes.append(mesh)

    print(f"EXPORT_MESH_OBJECTS:{len(tmp_objects)}")

    bpy.ops.object.select_all(action="DESELECT")
    for obj in tmp_objects:
        obj.select_set(True)
    if tmp_objects:
        bpy.context.view_layer.objects.active = tmp_objects[0]

    export_kwargs = {
        "filepath": glb_path,
        "export_format": "GLB",
        "use_selection": True,
    }
    export_kwargs.update(_export_apply_kwargs())

    result = bpy.ops.export_scene.gltf(**export_kwargs)
    print(f"GLTF_EXPORT_RESULT:{result}")
    bpy.context.view_layer.update()

    size = os.path.getsize(glb_path) if os.path.exists(glb_path) else 0
    print(f"GLB_SIZE_BYTES:{size}")
    if size <= 0:
        raise SystemExit(2)

    for obj in tmp_objects:
        bpy.data.objects.remove(obj, do_unlink=True)
    for mesh in tmp_meshes:
        if mesh.users == 0:
            bpy.data.meshes.remove(mesh)

    return {
        "status": "exported",
        "path": glb_path,
    }


if __name__ == "__main__":
    main()



===== FILE: tools/blender/slat_lab.py =====
"""Isolated slat deformation lab for Blender 4.4.

Run:
  blender --background --factory-startup --python tools/blender/slat_lab.py -- [options]

Options (after "--"):
  --out_blend <path>   Save .blend (optional)
  --apply              Bake modifiers for variant C
  --arc_mm <float>     Sagitta height in mm (default 35)
  --length_mm <float>  Slat length in mm (default 600)
  --width_mm <float>   Slat width in mm (default 60)
  --thick_mm <float>   Slat thickness in mm (default 12)
  --segments <int>     Grid segments along length (default 80)
"""

from __future__ import annotations

import math
import os
import sys
from dataclasses import dataclass


def _mm_to_m(x_mm: float) -> float:
    return float(x_mm) / 1000.0


def _clamp(v, lo, hi):
    return max(lo, min(hi, v))


@dataclass
class Opts:
    out_blend: str = ""
    apply: bool = False
    arc_mm: float = 35.0
    length_mm: float = 600.0
    width_mm: float = 60.0
    thick_mm: float = 12.0
    segments: int = 80


def _parse_opts(argv: list[str]) -> Opts:
    opts = Opts()

    if "--" in argv:
        args = argv[argv.index("--") + 1 :]
    else:
        args = []

    i = 0
    while i < len(args):
        a = args[i]
        if a == "--apply":
            opts.apply = True
            i += 1
            continue
        if a == "--out_blend" and i + 1 < len(args):
            opts.out_blend = str(args[i + 1])
            i += 2
            continue
        if a == "--arc_mm" and i + 1 < len(args):
            try:
                opts.arc_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--length_mm" and i + 1 < len(args):
            try:
                opts.length_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--width_mm" and i + 1 < len(args):
            try:
                opts.width_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--thick_mm" and i + 1 < len(args):
            try:
                opts.thick_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--segments" and i + 1 < len(args):
            try:
                opts.segments = int(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue

        i += 1

    opts.segments = int(_clamp(opts.segments, 1, 500))
    return opts


def _bend_angle_from_sagitta(length_mm: float, arc_mm: float) -> tuple[float, float]:
    """Return (angle_rad, radius_mm)."""
    if length_mm <= 0.0 or arc_mm <= 0.0:
        return 0.0, 0.0
    arc_mm = min(max(0.0, arc_mm), length_mm / 2.0)
    radius_mm = (length_mm * length_mm) / (8.0 * arc_mm) + (arc_mm / 2.0)
    if radius_mm <= 0.0 or not math.isfinite(radius_mm):
        return 0.0, radius_mm
    angle_rad = length_mm / radius_mm
    angle_rad = max(-math.pi, min(math.pi, angle_rad))
    return angle_rad, radius_mm


def _ensure_child_collection(scene_coll, name: str, hide: bool) -> "bpy.types.Collection":
    import bpy  # type: ignore

    coll = bpy.data.collections.get(name)
    if coll is None:
        coll = bpy.data.collections.new(name)
    if coll.name not in scene_coll.children:
        scene_coll.children.link(coll)
    coll.hide_viewport = bool(hide)
    coll.hide_render = bool(hide)
    return coll


def _move_obj_to_collection(obj, dst_coll) -> None:
    # Ensure object is only linked to dst_coll.
    for c in list(obj.users_collection):
        if c != dst_coll:
            c.objects.unlink(obj)
    if obj not in dst_coll.objects:
        dst_coll.objects.link(obj)


def _create_origin_empty(name: str, location, rotation_euler, helpers_coll):
    import bpy  # type: ignore

    empty = bpy.data.objects.new(name, None)
    empty.empty_display_type = "PLAIN_AXES"
    empty.location = location
    if rotation_euler is not None:
        empty.rotation_euler = rotation_euler
    empty.hide_viewport = True
    empty.hide_render = True
    helpers_coll.objects.link(empty)
    return empty


def _mesh_bbox_world(mesh, matrix_world):
    from mathutils import Vector  # type: ignore

    if not mesh.vertices:
        zero = Vector((0.0, 0.0, 0.0))
        return zero, zero
    min_v = None
    max_v = None
    for v in mesh.vertices:
        co = matrix_world @ v.co
        if min_v is None:
            min_v = co.copy()
            max_v = co.copy()
        else:
            min_v.x = min(min_v.x, co.x)
            min_v.y = min(min_v.y, co.y)
            min_v.z = min(min_v.z, co.z)
            max_v.x = max(max_v.x, co.x)
            max_v.y = max(max_v.y, co.y)
            max_v.z = max(max_v.z, co.z)
    return min_v, max_v


def _print_obj_stats(obj, label: str) -> None:
    mesh = obj.data
    mods = [f"{m.name}:{m.type}" for m in obj.modifiers]
    bb_min, bb_max = _mesh_bbox_world(mesh, obj.matrix_world)
    print(
        f"OBJ {label} name={obj.name} verts={len(mesh.vertices)} polys={len(mesh.polygons)} "
        f"bbox_min=({bb_min.x:.6f},{bb_min.y:.6f},{bb_min.z:.6f}) "
        f"bbox_max=({bb_max.x:.6f},{bb_max.y:.6f},{bb_max.z:.6f}) mods={mods}"
    )


def _print_obj_eval_stats(obj, label: str) -> tuple[float, float]:
    import bpy  # type: ignore

    depsgraph = bpy.context.evaluated_depsgraph_get()
    eval_obj = obj.evaluated_get(depsgraph)
    eval_mesh = eval_obj.to_mesh()
    try:
        bb_min, bb_max = _mesh_bbox_world(eval_mesh, eval_obj.matrix_world)
        mods = [f"{m.name}:{m.type}" for m in obj.modifiers]
        print(
            f"OBJ_EVAL {label} name={obj.name} verts={len(eval_mesh.vertices)} polys={len(eval_mesh.polygons)} "
            f"bbox_min=({bb_min.x:.6f},{bb_min.y:.6f},{bb_min.z:.6f}) "
            f"bbox_max=({bb_max.x:.6f},{bb_max.y:.6f},{bb_max.z:.6f}) mods={mods}"
        )
        return bb_min.z, bb_max.z
    finally:
        eval_obj.to_mesh_clear()


def _create_grid_slat_object(name: str, width_m: float, length_m: float, segments_len: int, segments_w: int):
    import bpy  # type: ignore
    import bmesh  # type: ignore

    bm = bmesh.new()
    bmesh.ops.create_grid(bm, x_segments=segments_w, y_segments=segments_len, size=1.0)

    if bm.verts:
        xs = [v.co.x for v in bm.verts]
        ys = [v.co.y for v in bm.verts]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        cx = (min_x + max_x) / 2.0
        cy = (min_y + max_y) / 2.0
        ext_x = max_x - min_x
        ext_y = max_y - min_y
        sx = (width_m / ext_x) if ext_x != 0.0 else 1.0
        sy = (length_m / ext_y) if ext_y != 0.0 else 1.0
        for v in bm.verts:
            v.co.x = (v.co.x - cx) * sx
            v.co.y = (v.co.y - cy) * sy
            v.co.z = 0.0

    mesh = bpy.data.meshes.new(name)
    bm.to_mesh(mesh)
    bm.free()
    mesh.update()
    for poly in mesh.polygons:
        poly.use_smooth = True

    obj = bpy.data.objects.new(name, mesh)
    return obj


def _add_bend_modifier(obj, origin, axis: str, angle_rad: float) -> None:
    mod = obj.modifiers.new(name="Bend", type="SIMPLE_DEFORM")
    mod.deform_method = "BEND"
    mod.deform_axis = axis
    mod.angle = angle_rad
    mod.origin = origin
    if hasattr(mod, "show_viewport"):
        mod.show_viewport = True
    if hasattr(mod, "show_render"):
        mod.show_render = True
    if hasattr(mod, "show_in_editmode"):
        mod.show_in_editmode = True
    if hasattr(mod, "show_on_cage"):
        mod.show_on_cage = True


def main() -> None:
    import bpy  # type: ignore
    from mathutils import Vector  # type: ignore

    opts = _parse_opts(sys.argv)

    print(f"BLENDER_VERSION:{bpy.app.version_string}")
    print(f"FILEPATH:{bpy.data.filepath}")
    print(
        "OPTS "
        f"out_blend={opts.out_blend!r} apply={opts.apply} arc_mm={opts.arc_mm} "
        f"length_mm={opts.length_mm} width_mm={opts.width_mm} thick_mm={opts.thick_mm} segments={opts.segments}"
    )

    bpy.ops.wm.read_factory_settings(use_empty=True)
    scene = bpy.context.scene

    lab_coll = _ensure_child_collection(scene.collection, "_lab", hide=False)
    helpers_coll = _ensure_child_collection(scene.collection, "_helpers", hide=True)

    width_m = _mm_to_m(opts.width_mm)
    length_m = _mm_to_m(opts.length_mm)
    thick_m = _mm_to_m(opts.thick_mm)

    # Use negative angle to bend "upwards" in +Z for axis=Y in typical orientation.
    angle_rad, radius_mm = _bend_angle_from_sagitta(opts.length_mm, opts.arc_mm)
    bend_angle = -angle_rad
    print(f"BEND_CALC arc_mm={opts.arc_mm} length_mm={opts.length_mm} radius_mm={radius_mm} angle_rad={bend_angle}")

    # Layout: three objects spaced in X.
    base_z = 0.30
    loc_a = Vector((-0.45, 0.0, base_z))
    loc_b = Vector((0.00, 0.0, base_z))
    loc_c = Vector((0.45, 0.0, base_z))

    # A) SLAT_CUBE
    bpy.ops.mesh.primitive_cube_add(size=1.0, location=loc_a)
    obj_a = bpy.context.active_object
    obj_a.name = "SLAT_CUBE"
    obj_a.dimensions = (width_m, length_m, thick_m)
    _move_obj_to_collection(obj_a, lab_coll)
    origin_a = _create_origin_empty("SLAT_CUBE_ORIGIN", obj_a.location.copy(), obj_a.rotation_euler, helpers_coll)
    _add_bend_modifier(obj_a, origin_a, axis="Y", angle_rad=bend_angle)

    # B) SLAT_GRID
    obj_b = _create_grid_slat_object("SLAT_GRID", width_m=width_m, length_m=length_m, segments_len=opts.segments, segments_w=2)
    obj_b.location = loc_b
    lab_coll.objects.link(obj_b)
    mod_solid_b = obj_b.modifiers.new(name="Solidify", type="SOLIDIFY")
    mod_solid_b.thickness = thick_m
    mod_solid_b.offset = 0.0
    mod_solid_b.use_even_offset = True
    origin_b = _create_origin_empty(
        "SLAT_GRID_ORIGIN",
        obj_b.matrix_world @ Vector((0.0, -length_m / 2.0, 0.0)),
        obj_b.rotation_euler,
        helpers_coll,
    )
    _add_bend_modifier(obj_b, origin_b, axis="Y", angle_rad=bend_angle)

    # C) SLAT_GRID_APPLIED
    obj_c = obj_b.copy()
    obj_c.data = obj_b.data.copy()
    obj_c.name = "SLAT_GRID_APPLIED"
    obj_c.location = loc_c
    lab_coll.objects.link(obj_c)
    # Replace bend origin to avoid sharing the same empty.
    for m in obj_c.modifiers:
        if m.type == "SIMPLE_DEFORM":
            origin_c = _create_origin_empty(
                "SLAT_GRID_APPLIED_ORIGIN",
                obj_c.matrix_world @ Vector((0.0, -length_m / 2.0, 0.0)),
                obj_c.rotation_euler,
                helpers_coll,
            )
            m.origin = origin_c

    bpy.context.view_layer.update()

    # Logs: base mesh stats.
    _print_obj_stats(obj_a, label="BASE")
    _print_obj_stats(obj_b, label="BASE")
    _print_obj_stats(obj_c, label="BASE")

    # Logs: evaluated stats (show modifier effect).
    _print_obj_eval_stats(obj_a, label="EVAL")
    b_base_minz, b_base_maxz = _mesh_bbox_world(obj_b.data, obj_b.matrix_world)
    b_eval_minz, b_eval_maxz = _print_obj_eval_stats(obj_b, label="EVAL")
    print(f"Z_RANGE SLAT_GRID base=({b_base_minz.z:.6f},{b_base_maxz.z:.6f}) eval=({b_eval_minz:.6f},{b_eval_maxz:.6f})")

    c_base_minz, c_base_maxz = _mesh_bbox_world(obj_c.data, obj_c.matrix_world)
    c_eval_minz, c_eval_maxz = _print_obj_eval_stats(obj_c, label="EVAL")
    print(
        f"Z_RANGE SLAT_GRID_APPLIED base=({c_base_minz.z:.6f},{c_base_maxz.z:.6f}) "
        f"eval=({c_eval_minz:.6f},{c_eval_maxz:.6f})"
    )

    if opts.apply:
        depsgraph = bpy.context.evaluated_depsgraph_get()
        eval_obj = obj_c.evaluated_get(depsgraph)
        new_mesh = bpy.data.meshes.new_from_object(eval_obj, depsgraph=depsgraph)
        old_mesh = obj_c.data
        obj_c.data = new_mesh
        obj_c.modifiers.clear()
        if old_mesh.users == 0:
            bpy.data.meshes.remove(old_mesh)
        bpy.context.view_layer.update()
        _print_obj_stats(obj_c, label="APPLIED")

    if opts.out_blend:
        out_blend = os.path.abspath(opts.out_blend)
        out_dir = os.path.dirname(out_blend)
        if out_dir:
            os.makedirs(out_dir, exist_ok=True)
        bpy.ops.wm.save_as_mainfile(filepath=out_blend)
        print(f"SAVED_BLEND:{out_blend}")


if __name__ == "__main__":
    main()



===== FILE: tools/dump_debug.ps1 =====
param(
  [int]$MaxFileSizeKB = 500,
  [string]$OutDump = "repo_dump_debug.txt",
  [string]$OutIndex = "repo_dump_debug_index.txt"
)

$ErrorActionPreference = "Stop"
$root = (Resolve-Path ".").Path

# Список файлов debug-системы (поддерживаемый минимум)
$paths = @(
  "tools/blender/debug_run.py",
  "tools/blender/batch_debug_run.py",
  "tools/blender/DEBUG_USAGE.md",

  "tools/blender/debug/__init__.py",
  "tools/blender/debug/io.py",
  "tools/blender/debug/metrics.py",
  "tools/blender/debug/validators.py",
  "tools/blender/debug/visualize.py",
  "tools/blender/debug/autofix.py",

  # опционально, но часто нужно рядом
  "tools/blender/run_builder_v01.py",
  "tools/blender/run_export_glb.py",
  "tools/blender/slat_lab.py"
)

# нормализация
$files = @()
foreach ($p in $paths) {
  $abs = Join-Path $root $p
  if (Test-Path $abs) { $files += (Get-Item $abs) }
}

# индекс
$idx = @()
$i = 1
foreach ($f in $files) {
  $sizeKB = [math]::Round(($f.Length / 1KB), 2)
  $note = ""
  if ($sizeKB -gt $MaxFileSizeKB) { $note = "skipped_content_over_limit" }

  $idx += [pscustomobject]@{
    id = $i
    path = (Resolve-Path $f.FullName).Path.Substring($root.Length + 1) -replace "\\","/"
    size_kb = $sizeKB
    note = $note
  }
  $i++
}

$idx | ConvertTo-Json -Depth 6 | Set-Content -Encoding UTF8 $OutIndex

# дамп (в один текстовый файл)
$sb = New-Object System.Text.StringBuilder
$null = $sb.AppendLine("=== DEBUG DUMP (filtered) ===")
$null = $sb.AppendLine("root: $root")
$null = $sb.AppendLine("max_file_size_kb: $MaxFileSizeKB")
$null = $sb.AppendLine("generated_at: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')")
$null = $sb.AppendLine("")

foreach ($item in $idx) {
  $rel = $item.path -replace "/","\"
  $abs = Join-Path $root $rel

  $null = $sb.AppendLine("----- FILE: $($item.path) ($($item.size_kb) KB) -----")

  if ($item.note -eq "skipped_content_over_limit") {
    $null = $sb.AppendLine("[SKIPPED CONTENT: file is larger than MaxFileSizeKB]")
    $null = $sb.AppendLine("")
    continue
  }

  try {
    $content = Get-Content -Raw -Encoding UTF8 $abs
    $null = $sb.AppendLine($content)
  } catch {
    $null = $sb.AppendLine("[FAILED TO READ FILE AS UTF8] $($_.Exception.Message)")
  }

  $null = $sb.AppendLine("")
}

$sb.ToString() | Set-Content -Encoding UTF8 $OutDump

Write-Host "Wrote $OutDump"
Write-Host "Wrote $OutIndex (rows=$($idx.Count))"



===== FILE: tools/dump_repo.ps1 =====
<#
Usage:
  powershell -ExecutionPolicy Bypass -File tools/dump_repo.ps1

Creates in repository root:
  - repo_dump.txt
  - repo_dump_index.txt

Key excluded directories (any level):
  .git, __pycache__, .venv, venv, out, models, data/cache,
  .mypy_cache, .pytest_cache, .ruff_cache, node_modules,
  dist, build, .next, .idea, .vscode, .vs, logs, tmp, temp, .cache
#>

Set-StrictMode -Version Latest
$ErrorActionPreference = 'Stop'

$script:MaxFileSizeBytes = 2MB
$script:IncludedExtensions = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@('.py', '.ps1', '.md', '.txt', '.json', '.yml', '.yaml', '.toml', '.ini') | ForEach-Object {
    [void]$script:IncludedExtensions.Add($_)
}

$script:IncludedExactNames = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@('requirements.txt', 'pyproject.toml', 'README.md') | ForEach-Object {
    [void]$script:IncludedExactNames.Add($_)
}

$script:ExcludedDirNames = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@(
    '.git', '__pycache__', '.venv', 'venv', 'out', 'models',
    '.mypy_cache', '.pytest_cache', '.ruff_cache', 'node_modules',
    'dist', 'build', '.next', '.idea', '.vscode', '.vs',
    'logs', 'tmp', 'temp', '.cache'
) | ForEach-Object {
    [void]$script:ExcludedDirNames.Add($_)
}

$script:Utf8NoBom = New-Object System.Text.UTF8Encoding($false)

function Resolve-RepoRoot {
    param(
        [string]$StartPath = (Get-Location).Path
    )

    $startItem = Get-Item -LiteralPath $StartPath -Force -ErrorAction SilentlyContinue
    if ($null -eq $startItem) {
        return (Get-Location).Path
    }

    $initialDir = if ($startItem.PSIsContainer) {
        $startItem.FullName
    } else {
        Split-Path -LiteralPath $startItem.FullName -Parent
    }
    $currentPath = $initialDir

    while ($true) {
        if (Test-Path -LiteralPath (Join-Path -Path $currentPath -ChildPath '.git')) {
            return $currentPath
        }

        $parent = [System.IO.Directory]::GetParent($currentPath)
        if ($null -eq $parent) {
            return $initialDir
        }

        $currentPath = $parent.FullName
    }
}

function Get-RelativePath {
    param(
        [Parameter(Mandatory = $true)][string]$BasePath,
        [Parameter(Mandatory = $true)][string]$Path
    )

    $baseResolved = [System.IO.Path]::GetFullPath((Resolve-Path -LiteralPath $BasePath -ErrorAction Stop).Path).TrimEnd('\', '/')
    $pathResolved = [System.IO.Path]::GetFullPath((Resolve-Path -LiteralPath $Path -ErrorAction Stop).Path)

    if ($pathResolved.Equals($baseResolved, [System.StringComparison]::OrdinalIgnoreCase)) {
        return '.'
    }

    $basePrefix = $baseResolved + '\'
    if ($pathResolved.StartsWith($basePrefix, [System.StringComparison]::OrdinalIgnoreCase)) {
        return ($pathResolved.Substring($basePrefix.Length) -replace '\\', '/')
    }

    $baseUriText = 'file:///' + (($baseResolved -replace '\\', '/').TrimStart('/')) + '/'
    $pathUriText = 'file:///' + (($pathResolved -replace '\\', '/').TrimStart('/'))
    $baseUri = New-Object System.Uri($baseUriText)
    $pathUri = New-Object System.Uri($pathUriText)
    $relative = [System.Uri]::UnescapeDataString($baseUri.MakeRelativeUri($pathUri).ToString())
    return ($relative -replace '\\', '/')
}

function Is-ExcludedDir {
    param(
        [Parameter(Mandatory = $true)][string]$RepoRoot,
        [Parameter(Mandatory = $true)][string]$DirPath
    )

    $relative = Get-RelativePath -BasePath $RepoRoot -Path $DirPath
    if ($relative -eq '.') {
        return $false
    }

    $parts = @($relative -split '/' | Where-Object { $_ -ne '' })

    foreach ($part in $parts) {
        if ($script:ExcludedDirNames.Contains($part)) {
            return $true
        }
    }

    for ($i = 0; $i -lt ($parts.Count - 1); $i++) {
        if ($parts[$i].Equals('data', [System.StringComparison]::OrdinalIgnoreCase) -and
            $parts[$i + 1].Equals('cache', [System.StringComparison]::OrdinalIgnoreCase)) {
            return $true
        }
    }

    return $false
}

function Is-IncludedFile {
    param(
        [Parameter(Mandatory = $true)][System.IO.FileInfo]$File
    )

    if ($script:IncludedExactNames.Contains($File.Name)) {
        return $true
    }

    if ($script:IncludedExtensions.Contains($File.Extension)) {
        return $true
    }

    return $false
}

function Is-BinaryFile {
    param(
        [Parameter(Mandatory = $true)][string]$Path
    )

    try {
        $stream = [System.IO.File]::Open($Path, [System.IO.FileMode]::Open, [System.IO.FileAccess]::Read, [System.IO.FileShare]::ReadWrite)
        try {
            $buffer = New-Object byte[] 4096
            $bytesRead = $stream.Read($buffer, 0, $buffer.Length)
            for ($i = 0; $i -lt $bytesRead; $i++) {
                if ($buffer[$i] -eq 0) {
                    return $true
                }
            }
            return $false
        } finally {
            $stream.Dispose()
        }
    } catch {
        return $true
    }
}

function Write-Dump {
    param(
        [Parameter(Mandatory = $true)][array]$Entries,
        [Parameter(Mandatory = $true)][string]$DumpPath
    )

    $includedEntries = @($Entries | Where-Object { $_.Included } | Sort-Object RelativePath)

    $filesFound = $Entries.Count
    $filesWritten = @($Entries | Where-Object { $_.Status -eq 'OK' }).Count
    $filesSkippedLarge = @($Entries | Where-Object { $_.Status -eq 'SKIP_LARGE' }).Count
    $filesSkippedBinary = @($Entries | Where-Object { $_.Status -eq 'SKIP_BINARY' }).Count

    $renderDump = {
        param([long]$OutputBytesValue)

        $sb = New-Object System.Text.StringBuilder

        for ($i = 0; $i -lt $includedEntries.Count; $i++) {
            $entry = $includedEntries[$i]

            if ($i -gt 0) {
                [void]$sb.Append("`r`n`r`n`r`n")
            }

            [void]$sb.Append('===== FILE: ').Append($entry.RelativePath).Append(" =====`r`n")

            if ($entry.Status -eq 'OK') {
                if ($null -ne $entry.Content) {
                    [void]$sb.Append($entry.Content)
                }
            } elseif ($entry.Status -eq 'SKIP_LARGE') {
                [void]$sb.Append('[SKIP: file too large ').Append($entry.SizeBytes).Append(' bytes]')
            } elseif ($entry.Status -eq 'SKIP_BINARY') {
                [void]$sb.Append('[SKIP: unreadable or binary]')
            }
        }

        if ($includedEntries.Count -gt 0) {
            [void]$sb.Append("`r`n`r`n")
        }

        [void]$sb.Append("===== SUMMARY =====`r`n")
        [void]$sb.Append('files_found=').Append($filesFound).Append("`r`n")
        [void]$sb.Append('files_written=').Append($filesWritten).Append("`r`n")
        [void]$sb.Append('files_skipped_large=').Append($filesSkippedLarge).Append("`r`n")
        [void]$sb.Append('files_skipped_binary=').Append($filesSkippedBinary).Append("`r`n")
        [void]$sb.Append('output_bytes=').Append($OutputBytesValue)

        return $sb.ToString()
    }

    $outputBytes = 0L
    $content = ''

    for ($i = 0; $i -lt 8; $i++) {
        $content = & $renderDump $outputBytes
        $calculated = $script:Utf8NoBom.GetByteCount($content)
        if ($calculated -eq $outputBytes) {
            break
        }
        $outputBytes = $calculated
    }

    $content = & $renderDump $outputBytes
    [System.IO.File]::WriteAllText($DumpPath, $content, $script:Utf8NoBom)

    return (Get-Item -LiteralPath $DumpPath -ErrorAction Stop).Length
}

function Write-Index {
    param(
        [Parameter(Mandatory = $true)][array]$Entries,
        [Parameter(Mandatory = $true)][string]$IndexPath
    )

    $sb = New-Object System.Text.StringBuilder
    [void]$sb.Append("path`tsize_bytes`tstatus`r`n")

    foreach ($entry in $Entries) {
        [void]$sb.Append($entry.RelativePath).Append("`t").Append($entry.SizeBytes).Append("`t").Append($entry.Status).Append("`r`n")
    }

    [System.IO.File]::WriteAllText($IndexPath, $sb.ToString(), $script:Utf8NoBom)

    return ($Entries.Count + 1)
}

$repoRoot = Resolve-RepoRoot
$dumpPath = Join-Path -Path $repoRoot -ChildPath 'repo_dump.txt'
$indexPath = Join-Path -Path $repoRoot -ChildPath 'repo_dump_index.txt'

$allFiles = New-Object System.Collections.Generic.List[System.IO.FileInfo]
$stack = New-Object 'System.Collections.Generic.Stack[string]'
$stack.Push($repoRoot)

while ($stack.Count -gt 0) {
    $currentDir = $stack.Pop()

    try {
        $children = Get-ChildItem -LiteralPath $currentDir -Force -ErrorAction Stop
    } catch {
        continue
    }

    foreach ($child in $children) {
        if ($child.PSIsContainer) {
            if (($child.Attributes -band [System.IO.FileAttributes]::ReparsePoint) -ne 0) {
                continue
            }

            if (Is-ExcludedDir -RepoRoot $repoRoot -DirPath $child.FullName) {
                continue
            }

            $stack.Push($child.FullName)
            continue
        }

        $allFiles.Add([System.IO.FileInfo]$child)
    }
}

$entries = @(
    foreach ($file in ($allFiles | Sort-Object { Get-RelativePath -BasePath $repoRoot -Path $_.FullName })) {
        $relativePath = Get-RelativePath -BasePath $repoRoot -Path $file.FullName
        $included = Is-IncludedFile -File $file
        $status = 'SKIP_EXT'
        $content = $null

        if ($included) {
            if ($file.Length -gt $script:MaxFileSizeBytes) {
                $status = 'SKIP_LARGE'
            } elseif (Is-BinaryFile -Path $file.FullName) {
                $status = 'SKIP_BINARY'
            } else {
                try {
                    $content = [System.IO.File]::ReadAllText($file.FullName)
                    $status = 'OK'
                } catch {
                    $status = 'SKIP_BINARY'
                    $content = $null
                }
            }
        }

        [pscustomobject]@{
            RelativePath = $relativePath
            SizeBytes = [long]$file.Length
            Status = $status
            Included = $included
            Content = $content
        }
    }
)

$dumpBytes = Write-Dump -Entries $entries -DumpPath $dumpPath
$indexRows = Write-Index -Entries $entries -IndexPath $indexPath

Write-Output ("Wrote repo_dump.txt (bytes={0})" -f $dumpBytes)
Write-Output ("Wrote repo_dump_index.txt (rows={0})" -f $indexRows)



===== FILE: tools/generate_sofa_ner_dataset.py =====
import json
import random
import re
from pathlib import Path

# ----------------------------
# Config
# ----------------------------

TAGS = [
    "TYPE", "STYLE", "LAYOUT", "ORIENTATION",
    "SEAT_HEIGHT_MM", "SEAT_DEPTH_MM", "SEAT_WIDTH_RANGE_MM",
    "SEAT_COUNT", "HAS_CHAISE", "ARMRESTS", "LEG_FAMILY", "TRANSFORMABLE"
]

RANDOM_SEED = 42

# ----------------------------
# Lexicons
# ----------------------------

TYPE_WORDS = ["диван", "софа"]

STYLE_WORDS = {
    "scandi": ["сканди", "скандинавский", "scandi"],
    "loft": ["лофт", "industrial", "индастриал"],
    "modern": ["модерн", "современный", "modern"],
    "minimal": ["минимализм", "минималистичный", "minimal"],
    "classic": ["классика", "классический", "classic"],
}

LAYOUT_WORDS = {
    "straight": ["прямой", "прямолинейный", "обычный"],
    "corner": ["угловой", "Г-образный", "l-образный"],
    "u_shape": ["п-образный", "u-образный"],
    "modular": ["модульный", "секции", "модули"],
}

ORIENTATION_WORDS = {
    "left": ["левый", "слева", "левосторонний"],
    "right": ["правый", "справа", "правосторонний"],
}

LEG_FAMILY_WORDS = {
    "tapered_cone": ["конусные ножки", "конусообразные ножки", "tapered_cone"],
    "tapered_prism": ["призматические ножки", "скошенная пирамида", "tapered_prism"],
    "cylindrical": ["цилиндрические ножки", "круглые ножки", "cylindrical"],
    "block": ["блочные ножки", "квадратные ножки", "block"],
    "hairpin": ["hairpin", "шпильки", "ножки-шпильки"],
    "sled": ["салазки", "sled", "полозья"],
    "frame": ["рамные ножки", "металлическая рама", "frame"],
}

ARMREST_WORDS = {
    "none": ["без подлокотников", "подлокотники не нужны", "no armrests"],
    "both": ["с подлокотниками", "два подлокотника", "с двух сторон"],
    "left": ["подлокотник слева", "левый подлокотник"],
    "right": ["подлокотник справа", "правый подлокотник"],
}

CHAISE_WORDS_TRUE = ["с оттоманкой", "с шезлонгом", "с канапе", "с удлинением"]
CHAISE_WORDS_FALSE = ["без оттоманки", "без шезлонга", "без удлинения"]

TRANSFORM_TRUE = ["раскладной", "трансформер", "с механизмом раскладывания"]
TRANSFORM_FALSE = ["не раскладной", "без механизма", "стационарный"]

# ----------------------------
# Helpers
# ----------------------------

def tokenize_ru(text: str):
    # токенизация как у тебя в примерах (слова/числа/знаки)
    # разделяем числа, точки, запятые
    tokens = re.findall(r"\d+|[A-Za-zА-Яа-яЁё]+|[^\w\s]", text, flags=re.UNICODE)
    return tokens

def tag_span(tokens, start_idx, end_idx, label):
    # end_idx exclusive
    tags = ["O"] * len(tokens)
    tags[start_idx] = f"B-{label}"
    for i in range(start_idx + 1, end_idx):
        tags[i] = f"I-{label}"
    return tags

def merge_tags(base_tags, span_tags):
    # span_tags has O except labeled region; overlay onto base_tags
    out = base_tags[:]
    for i, t in enumerate(span_tags):
        if t != "O":
            out[i] = t
    return out

def mm_or_cm_value(mm_value: int):
    # иногда пишем в мм, иногда в см
    if random.random() < 0.65:
        # см
        cm = round(mm_value / 10)
        return cm, "см"
    return mm_value, "мм"

def format_dim_phrase(kind: str, mm_value: int):
    # kind: высота сиденья / глубина сиденья
    val, unit = mm_or_cm_value(mm_value)
    # варианты формулировок
    templates = [
        f"{kind} {val} {unit}",
        f"{kind} — {val}{unit}",
        f"{kind}: {val} {unit}",
        f"{kind} примерно {val} {unit}",
    ]
    return random.choice(templates)

def format_width_range(min_mm: int, max_mm: int):
    min_val, unit1 = mm_or_cm_value(min_mm)
    # чтобы не было несостыковки единиц в одном диапазоне, делаем одинаковую единицу
    if unit1 == "см":
        max_val = round(max_mm / 10)
        unit = "см"
    else:
        max_val = max_mm
        unit = "мм"
    templates = [
        f"ширина посадки {min_val}–{max_val} {unit}",
        f"ширина сиденья от {min_val} до {max_val} {unit}",
        f"посадочное место {min_val}-{max_val} {unit} по ширине",
    ]
    return random.choice(templates)

def pick_style():
    key = random.choice(list(STYLE_WORDS.keys()))
    return key, random.choice(STYLE_WORDS[key])

def pick_layout():
    key = random.choice(list(LAYOUT_WORDS.keys()))
    return key, random.choice(LAYOUT_WORDS[key])

def pick_orientation():
    key = random.choice(list(ORIENTATION_WORDS.keys()))
    return key, random.choice(ORIENTATION_WORDS[key])

def pick_legs():
    key = random.choice(list(LEG_FAMILY_WORDS.keys()))
    return key, random.choice(LEG_FAMILY_WORDS[key])

def pick_armrests():
    key = random.choice(list(ARMREST_WORDS.keys()))
    return key, random.choice(ARMREST_WORDS[key])

def maybe(include_prob=0.7):
    return random.random() < include_prob

# ----------------------------
# Sample generator
# ----------------------------

def generate_one():
    # Core choices
    type_word = random.choice(TYPE_WORDS)

    style_key, style_word = pick_style()
    layout_key, layout_word = pick_layout()

    # Orientation only for corner/u_shape sometimes mentioned
    orientation_key = None
    orientation_word = None
    if layout_key in ("corner", "u_shape") and maybe(0.85):
        orientation_key, orientation_word = pick_orientation()

    # Dimensions
    seat_height = random.randint(380, 500)   # mm typical
    seat_depth = random.randint(520, 700)    # mm typical

    w_min = random.randint(450, 650)
    w_max = random.randint(max(w_min + 50, 520), min(w_min + 300, 900))

    # Seat count
    seat_count = random.choice([2, 3, 4, 5])

    # Options
    has_chaise = random.random() < 0.35
    leg_key, leg_word = pick_legs()
    arm_key, arm_word = pick_armrests()
    transformable = random.random() < 0.25

    # Text templates (shuffled clauses)
    clauses = []

    # intro
    intro_templates = [
        f"Мне нужен {type_word}",
        f"Хочу {type_word}",
        f"Подберите {type_word}",
        f"Нужен {type_word} для гостиной",
    ]
    clauses.append(random.choice(intro_templates))

    # style + layout
    style_layout_templates = [
        f"в стиле {style_word}",
        f"{style_word} стиль",
        f"стиль {style_word}",
    ]
    clauses.append(random.choice(style_layout_templates))

    layout_templates = [
        f"{layout_word}",
        f"компоновка {layout_word}",
        f"формат {layout_word}",
    ]
    clauses.append(random.choice(layout_templates))

    # orientation clause
    if orientation_word:
        orientation_templates = [
            f"угол {orientation_word}",
            f"ориентация {orientation_word}",
            f"{orientation_word} угол",
        ]
        clauses.append(random.choice(orientation_templates))

    # seat count
    if maybe(0.75):
        seat_templates = [
            f"на {seat_count} места",
            f"{seat_count}-местный",
            f"количество мест {seat_count}",
        ]
        clauses.append(random.choice(seat_templates))

    # dimensions
    if maybe(0.8):
        clauses.append(format_dim_phrase("высота сиденья", seat_height))
    if maybe(0.8):
        clauses.append(format_dim_phrase("глубина сиденья", seat_depth))
    if maybe(0.7):
        clauses.append(format_width_range(w_min, w_max))

    # legs
    if maybe(0.75):
        legs_templates = [
            f"ножки {leg_word}",
            f"с ножками: {leg_word}",
            f"тип ножек {leg_word}",
        ]
        clauses.append(random.choice(legs_templates))

    # armrests
    if maybe(0.75):
        clauses.append(arm_word)

    # chaise
    if maybe(0.65):
        clauses.append(random.choice(CHAISE_WORDS_TRUE if has_chaise else CHAISE_WORDS_FALSE))

    # transformable
    if maybe(0.6):
        clauses.append(random.choice(TRANSFORM_TRUE if transformable else TRANSFORM_FALSE))

    # Shuffle clauses and join
    random.shuffle(clauses)
    text = ", ".join(clauses) + "."

    tokens = tokenize_ru(text)
    tags = ["O"] * len(tokens)

    # Labeling helper to find token spans of inserted phrases
    def label_phrase(phrase: str, label: str):
        nonlocal tags
        phrase_tokens = tokenize_ru(phrase)
        # find first occurrence
        for i in range(len(tokens) - len(phrase_tokens) + 1):
            if tokens[i:i+len(phrase_tokens)] == phrase_tokens:
                span = tag_span(tokens, i, i+len(phrase_tokens), label)
                tags = merge_tags(tags, span)
                return True
        return False

    # TYPE
    label_phrase(type_word, "TYPE")

    # STYLE (label only the style word/phrase)
    label_phrase(style_word, "STYLE")

    # LAYOUT
    # label the main layout_word if present
    label_phrase(layout_word, "LAYOUT")

    # ORIENTATION
    if orientation_word:
        label_phrase(orientation_word, "ORIENTATION")

    # SEAT_COUNT: label the number token only (simpler and consistent)
    # locate seat_count as token
    for i, tok in enumerate(tokens):
        if tok == str(seat_count):
            tags[i] = "B-SEAT_COUNT"
            break

    # SEAT_HEIGHT_MM / SEAT_DEPTH_MM: label the numeric+unit region where possible
    # we label [число][единица] (e.g. "44", "см")
    def label_number_unit(mm_kind_label: str):
        nonlocal tags
        # look for pattern: number then unit token
        for i in range(len(tokens) - 1):
            if tokens[i].isdigit() and tokens[i+1] in ("см", "мм"):
                # Heuristic: check previous token context in window
                window = " ".join(tokens[max(0, i-4):i])
                if mm_kind_label == "SEAT_HEIGHT_MM" and ("высота" in window and "сиденья" in window):
                    tags[i] = f"B-{mm_kind_label}"
                    tags[i+1] = f"I-{mm_kind_label}"
                    return
                if mm_kind_label == "SEAT_DEPTH_MM" and ("глубина" in window and "сиденья" in window):
                    tags[i] = f"B-{mm_kind_label}"
                    tags[i+1] = f"I-{mm_kind_label}"
                    return

    label_number_unit("SEAT_HEIGHT_MM")
    label_number_unit("SEAT_DEPTH_MM")

    # SEAT_WIDTH_RANGE_MM: label the min–max + unit
    # patterns: number, "–"/"-", number, unit  OR  "от", number, "до", number, unit
    def label_width_range():
        nonlocal tags
        # pattern 1: N – N unit
        for i in range(len(tokens) - 3):
            if tokens[i].isdigit() and tokens[i+1] in ("–", "-") and tokens[i+2].isdigit() and tokens[i+3] in ("см", "мм"):
                tags[i] = "B-SEAT_WIDTH_RANGE_MM"
                tags[i+1] = "I-SEAT_WIDTH_RANGE_MM"
                tags[i+2] = "I-SEAT_WIDTH_RANGE_MM"
                tags[i+3] = "I-SEAT_WIDTH_RANGE_MM"
                return
        # pattern 2: от N до N unit
        for i in range(len(tokens) - 4):
            if tokens[i].lower() == "от" and tokens[i+1].isdigit() and tokens[i+2].lower() == "до" and tokens[i+3].isdigit() and tokens[i+4] in ("см", "мм"):
                tags[i] = "B-SEAT_WIDTH_RANGE_MM"
                for j in range(i+1, i+5):
                    tags[j] = "I-SEAT_WIDTH_RANGE_MM"
                return

    label_width_range()

    # HAS_CHAISE: label whole phrase (simple)
    chaise_phrase = random.choice(CHAISE_WORDS_TRUE if has_chaise else CHAISE_WORDS_FALSE)
    # but note: we used random choice when building clauses; we must find which one ended up in text
    for ph in CHAISE_WORDS_TRUE + CHAISE_WORDS_FALSE:
        if ph in text:
            label_phrase(ph, "HAS_CHAISE")
            break

    # ARMRESTS: label phrase
    for ph in sum(ARMREST_WORDS.values(), []):
        if ph in text:
            label_phrase(ph, "ARMRESTS")
            break

    # LEG_FAMILY: label phrase
    for ph in sum(LEG_FAMILY_WORDS.values(), []):
        if ph in text:
            label_phrase(ph, "LEG_FAMILY")
            break

    # TRANSFORMABLE: label phrase
    for ph in TRANSFORM_TRUE + TRANSFORM_FALSE:
        if ph in text:
            label_phrase(ph, "TRANSFORMABLE")
            break

    return {"tokens": tokens, "tags": tags}


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--n", type=int, default=20000, help="number of samples")
    parser.add_argument("--out", type=str, default="data/sofa_ner_train.jsonl")
    args = parser.parse_args()

    random.seed(RANDOM_SEED)

    out_path = Path(args.out)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with out_path.open("w", encoding="utf-8") as f:
        for _ in range(args.n):
            sample = generate_one()
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")

    print(f"✅ Wrote {args.n} samples to: {out_path.resolve()}")


if __name__ == "__main__":
    main()



===== FILE: tools/inspect_blend.py =====
# tools/inspect_blend.py
# Usage:
#   blender --background out/logs/sofa.blend --python C:\Users\Gigabyte\AMS\tools\inspect_blend.py

print("INSPECT_BLEND_START")

import bpy  # type: ignore


def axis_ranges_world(mesh, matrix_world):
    if not mesh or not getattr(mesh, "vertices", None):
        return None
    if len(mesh.vertices) == 0:
        return None

    xs = []
    ys = []
    zs = []
    for v in mesh.vertices:
        w = matrix_world @ v.co
        xs.append(w.x)
        ys.append(w.y)
        zs.append(w.z)

    return (
        (min(xs), max(xs)),
        (min(ys), max(ys)),
        (min(zs), max(zs)),
    )


def axis_spans(ranges):
    return (
        ranges[0][1] - ranges[0][0],
        ranges[1][1] - ranges[1][0],
        ranges[2][1] - ranges[2][0],
    )


def fmt_axis(ranges):
    return (
        f"x=({ranges[0][0]:.6f},{ranges[0][1]:.6f}) "
        f"y=({ranges[1][0]:.6f},{ranges[1][1]:.6f}) "
        f"z=({ranges[2][0]:.6f},{ranges[2][1]:.6f})"
    )


def mesh_counts(mesh):
    if not mesh:
        return (0, 0)
    verts = len(mesh.vertices) if getattr(mesh, "vertices", None) is not None else 0
    polys = len(mesh.polygons) if getattr(mesh, "polygons", None) is not None else 0
    return (verts, polys)


def fmt_modifiers(obj):
    if len(obj.modifiers) == 0:
        return "[]"

    rows = []
    for mod in obj.modifiers:
        show_viewport = bool(getattr(mod, "show_viewport", False))
        show_render = bool(getattr(mod, "show_render", False))
        show_in_editmode = bool(getattr(mod, "show_in_editmode", False))
        show_on_cage = bool(getattr(mod, "show_on_cage", False))
        rows.append(
            f"{mod.name}:{mod.type} "
            f"viewport={int(show_viewport)} render={int(show_render)} "
            f"edit={int(show_in_editmode)} cage={int(show_on_cage)}"
        )
    return "[" + ", ".join(rows) + "]"


def print_bend_modifiers(obj):
    for mod in obj.modifiers:
        if mod.type == "SIMPLE_DEFORM" and getattr(mod, "deform_method", "") == "BEND":
            origin = mod.origin.name if getattr(mod, "origin", None) else "None"
            print(f"BEND axis={mod.deform_axis} angle={float(mod.angle):.6f} origin={origin}")


def main():
    print("FILE:", bpy.data.filepath)
    print("BLENDER_VERSION:", bpy.app.version_string)
    print("Objects:", len(bpy.data.objects))

    depsgraph = bpy.context.evaluated_depsgraph_get()

    slats = [
        o
        for o in bpy.data.objects
        if o.type == "MESH" and ("slat" in o.name.lower() or o.name == "DEBUG_SLAT")
    ]
    slats = sorted(slats, key=lambda x: x.name)

    print("Slat-like:", len(slats))
    print("--- SLATS DUMP (first 60) ---")

    for obj in slats[:60]:
        eval_obj = obj.evaluated_get(depsgraph)
        eval_mesh = None
        base_verts, base_polys = mesh_counts(obj.data)
        try:
            eval_mesh = eval_obj.to_mesh()
            base_ranges = axis_ranges_world(obj.data, obj.matrix_world)
            eval_ranges = axis_ranges_world(eval_mesh, eval_obj.matrix_world)
        finally:
            if eval_mesh is not None:
                eval_obj.to_mesh_clear()

        print(f"\n- {obj.name}")
        print(f"BASE_MESH verts={base_verts} polys={base_polys}")
        print(f"MODIFIERS {fmt_modifiers(obj)}")
        print_bend_modifiers(obj)

        if base_ranges is None or eval_ranges is None:
            print("AXIS_RANGES_BASE x=(nan,nan) y=(nan,nan) z=(nan,nan)")
            print("AXIS_RANGES_EVAL x=(nan,nan) y=(nan,nan) z=(nan,nan)")
            print("RANGE_DELTAS dx=nan dy=nan dz=nan")
            print("BEND_EFFECT=NO")
            continue

        base_spans = axis_spans(base_ranges)
        eval_spans = axis_spans(eval_ranges)
        dx = abs(eval_spans[0] - base_spans[0])
        dy = abs(eval_spans[1] - base_spans[1])
        dz = abs(eval_spans[2] - base_spans[2])
        bend_effect = "OK" if max(dx, dy, dz) > 1e-5 else "NO"

        print(f"AXIS_RANGES_BASE {fmt_axis(base_ranges)}")
        print(f"AXIS_RANGES_EVAL {fmt_axis(eval_ranges)}")
        print(f"RANGE_DELTAS dx={dx:.6f} dy={dy:.6f} dz={dz:.6f}")
        print(f"BEND_EFFECT={bend_effect}")

    print("\nINSPECT_BLEND_DONE")


if __name__ == "__main__":
    main()



===== FILE: tools/ner_to_schema_demo.py =====
import sys
import re
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(ROOT))

from src.ner_infer import predict
from src.schema import SofaRequest, resolve_sofa

MODEL_DIR = "models/sofa_ner_rubert"


def parse_length_to_mm(s: str) -> int:
    t = s.lower().replace(",", ".")
    m = re.search(r"(\d+(?:\.\d+)?)", t)
    if not m:
        raise ValueError(f"Cannot parse length: {s}")
    value = float(m.group(1))

    if "мм" in t:
        mm = value
    elif "см" in t:
        mm = value * 10
    elif "м" in t:
        mm = value * 1000
    else:
        mm = value  # по умолчанию считаем мм

    return int(round(mm))


def parse_int(s: str) -> int:
    m = re.search(r"\d+", s)
    if not m:
        raise ValueError(f"Cannot parse int: {s}")
    return int(m.group(0))


def normalize_entities(entities: dict) -> dict:
    data: dict = {}

    # простые строковые
    for key in ["type", "style", "layout", "orientation", "leg_family", "armrests"]:
        K = key.upper()
        if K in entities and entities[K]:
            data[key] = entities[K][0].strip()

    # числовые
    if "SEAT_HEIGHT_MM" in entities and entities["SEAT_HEIGHT_MM"]:
        data["seat_height_mm"] = parse_length_to_mm(entities["SEAT_HEIGHT_MM"][0])

    if "SEAT_DEPTH_MM" in entities and entities["SEAT_DEPTH_MM"]:
        data["seat_depth_mm"] = parse_length_to_mm(entities["SEAT_DEPTH_MM"][0])

    if "SEAT_COUNT" in entities and entities["SEAT_COUNT"]:
        data["seat_count"] = parse_int(entities["SEAT_COUNT"][0])

    if "SEAT_WIDTH_RANGE_MM" in entities and entities["SEAT_WIDTH_RANGE_MM"]:
        joined = " ".join(entities["SEAT_WIDTH_RANGE_MM"])
        nums = [int(x) for x in re.findall(r"\d+", joined)]
        if len(nums) >= 2:
            data["seat_width_range_mm"] = (nums[0], nums[1])

    if "TRANSFORMABLE" in entities and entities["TRANSFORMABLE"]:
        t = " ".join(entities["TRANSFORMABLE"]).lower()
        data["transformable"] = not ("без" in t or "нет" in t)

    return data


def main():
    text = (
        "Мне нужен скандинавский угловой диван, "
        "высота сиденья 44 см, глубина 60 см, "
        "на 3 места, без механизма, ножки конусные."
    )

    print("\n=== USER TEXT ===")
    print(text)

    out = predict(text, MODEL_DIR, max_len=128)

    print("\n=== TOKENS ===")
    print(out.tokens)

    print("\n=== TAGS ===")
    print(out.tags)

    print("\n=== NER ENTITIES ===")
    for k, v in out.entities.items():
        print(f"{k}: {v}")

    params = normalize_entities(out.entities)
    print("\n=== NORMALIZED PARAMS ===")
    print(params)

    # 1) validate + aliases (Request)
    req = SofaRequest(**params)

    # 2) deterministic resolve (IR for Builder)
    resolved = resolve_sofa(req)

    print("\n=== SOFA RESOLVED (IR) ===")
    # красиво JSON-ом
    print(resolved.model_dump_json(indent=2, ensure_ascii=False))

    # если нужен dict:
    # print(resolved.model_dump())


if __name__ == "__main__":
    main()



===== FILE: tools/predict_sofa_ner.py =====



===== FILE: tools/train_sofa_ner.py =====
from __future__ import annotations
import json
import random
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    DataCollatorForTokenClassification,
    TrainingArguments,
    Trainer,
)
from seqeval.metrics import f1_score, precision_score, recall_score, classification_report


# ----------------------------
# Config
# ----------------------------
RANDOM_SEED = 42

# стабильная, хорошая стартовая RU-модель для NER
DEFAULT_MODEL_NAME = "DeepPavlov/rubert-base-cased"


def read_jsonl(path: str) -> List[Dict]:
    items = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            items.append(json.loads(line))
    return items


def build_label_list(items: List[Dict]) -> List[str]:
    # собираем список всех тегов, чтобы label2id/id2label были стабильны
    labels = set()
    for it in items:
        for t in it["tags"]:
            labels.add(t)
    # важно: O первым
    labels = sorted(labels)
    if "O" in labels:
        labels.remove("O")
    return ["O"] + labels


def split_items(items: List[Dict], train_ratio=0.9) -> Tuple[List[Dict], List[Dict]]:
    random.shuffle(items)
    n_train = int(len(items) * train_ratio)
    return items[:n_train], items[n_train:]


def align_labels_with_tokens(tokenizer, tokens: List[str], tags: List[str], label2id: Dict[str, int], max_length: int):
    # токенизация по словам + alignment
    enc = tokenizer(
        tokens,
        is_split_into_words=True,
        truncation=True,
        max_length=max_length,
    )
    word_ids = enc.word_ids()
    label_ids = []
    prev_word_id = None

    for word_id in word_ids:
        if word_id is None:
            label_ids.append(-100)
        elif word_id != prev_word_id:
            label_ids.append(label2id[tags[word_id]])
        else:
            # если токен является продолжением слова:
            # B-XXX -> I-XXX, иначе остаётся как есть
            tag = tags[word_id]
            if tag.startswith("B-"):
                tag = "I-" + tag[2:]
                tag = tag if tag in label2id else tags[word_id]
            label_ids.append(label2id[tag])
        prev_word_id = word_id

    enc["labels"] = label_ids
    return enc


def compute_metrics_builder(id2label: Dict[int, str]):
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)

        true_labels = []
        true_preds = []

        for pred_row, label_row in zip(preds, labels):
            seq_true = []
            seq_pred = []
            for p, l in zip(pred_row, label_row):
                if l == -100:
                    continue
                seq_true.append(id2label[int(l)])
                seq_pred.append(id2label[int(p)])
            true_labels.append(seq_true)
            true_preds.append(seq_pred)

        return {
            "precision": precision_score(true_labels, true_preds),
            "recall": recall_score(true_labels, true_preds),
            "f1": f1_score(true_labels, true_preds),
        }
    return compute_metrics


def main():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, default="data/sofa_ner_train.jsonl")
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL_NAME)
    parser.add_argument("--out", type=str, default="models/sofa_ner_rubert")
    parser.add_argument("--max_len", type=int, default=192)
    parser.add_argument("--epochs", type=int, default=5)
    parser.add_argument("--batch", type=int, default=16)
    parser.add_argument("--lr", type=float, default=3e-5)
    args = parser.parse_args()

    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)

    items = read_jsonl(args.data)
    if not items:
        raise RuntimeError("Dataset is empty")

    labels = build_label_list(items)
    label2id = {l: i for i, l in enumerate(labels)}
    id2label = {i: l for l, i in label2id.items()}

    train_items, val_items = split_items(items, train_ratio=0.9)

    tokenizer = AutoTokenizer.from_pretrained(args.model)

    def to_features(item):
        return align_labels_with_tokens(
            tokenizer,
            item["tokens"],
            item["tags"],
            label2id=label2id,
            max_length=args.max_len,
        )

    train_ds = Dataset.from_list(train_items).map(to_features, remove_columns=["tokens", "tags"])
    val_ds = Dataset.from_list(val_items).map(to_features, remove_columns=["tokens", "tags"])

    model = AutoModelForTokenClassification.from_pretrained(
        args.model,
        num_labels=len(labels),
        id2label=id2label,
        label2id=label2id,
    )

    collator = DataCollatorForTokenClassification(tokenizer)

    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    training_args = TrainingArguments(
    output_dir=str(out_dir),
    eval_strategy="epoch",
    save_strategy="epoch",
        learning_rate=args.lr,
        per_device_train_batch_size=args.batch,
        per_device_eval_batch_size=args.batch,
        num_train_epochs=args.epochs,
        weight_decay=0.01,
        logging_steps=100,
        report_to="none",
        fp16=True,  # на RTX 5070 обычно ок
        seed=RANDOM_SEED,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        tokenizer=tokenizer,
        data_collator=collator,
        compute_metrics=compute_metrics_builder(id2label),
    )

    trainer.train()

    # финальная оценка + отчёт
    preds = trainer.predict(val_ds)
    logits, labels_ids = preds.predictions, preds.label_ids
    preds_ids = np.argmax(logits, axis=-1)

    true_labels = []
    true_preds = []
    for pr, lb in zip(preds_ids, labels_ids):
        seq_true = []
        seq_pred = []
        for p, l in zip(pr, lb):
            if l == -100:
                continue
            seq_true.append(id2label[int(l)])
            seq_pred.append(id2label[int(p)])
        true_labels.append(seq_true)
        true_preds.append(seq_pred)

    print("\n=== SeqEval report (VAL) ===")
    print(classification_report(true_labels, true_preds))

    # сохраняем модель
    trainer.save_model(str(out_dir))
    tokenizer.save_pretrained(str(out_dir))
    print(f"\n✅ Saved model to: {out_dir.resolve()}")


if __name__ == "__main__":
    main()



===== FILE: tools/validate_schema.py =====
# tools/validate_schema.py
import json
import sys
from pathlib import Path

from pydantic import ValidationError

ROOT = Path(__file__).resolve().parents[1]  # AMS/
sys.path.insert(0, str(ROOT))

from src.schema import SofaRequest, resolve_sofa  # noqa: E402


def main():
    path = ROOT / "data" / "examples" / "request_scandi.json"
    raw = json.loads(path.read_text(encoding="utf-8"))

    print("INPUT JSON:")
    print(json.dumps(raw, ensure_ascii=False, indent=2))

    try:
        req = SofaRequest.model_validate(raw)
        print("\nSofaRequest OK ✅")
        print(req.model_dump())

        resolved = resolve_sofa(req)
        print("\nSofaResolved OK ✅")
        print(json.dumps(resolved.model_dump(), ensure_ascii=False, indent=2))

    except ValidationError as e:
        print("\nVALIDATION ERROR ❌")
        print(e)


if __name__ == "__main__":
    main()


===== SUMMARY =====
files_found=41
files_written=39
files_skipped_large=0
files_skipped_binary=0
output_bytes=273103


===== FILE: repo_dump_index.txt =====
path	size_bytes	status
.gitignore	558	SKIP_EXT
data/examples/request_scandi.json	346	OK
data/examples/sofa_ir.json	1257	OK
data/examples/sofa_request.json	202	OK
data/examples/user_text.txt	79	OK
data/sofa_ner_train.jsonl	17226902	SKIP_EXT
NER_Parametric_model_1.1.py	390	OK
README.md	916	OK
requirements.txt	71	OK
src/__init__.py	0	OK
src/builders/__init__.py	118	OK
src/builders/blender/__init__.py	103	OK
src/builders/blender/builder_v01.py	21956	OK
src/builders/blender/export_blender.py	2773	OK
src/builders/cad/__init__.py	81	OK
src/builders/cad/export_step_stub.py	372	OK
src/ner_infer.py	3301	OK
src/pipeline/__init__.py	146	OK
src/pipeline/ner_to_request.py	696	OK
src/pipeline/resolve.py	554	OK
src/schema.py	14427	OK
tools/blender/batch_debug_run.py	9660	OK
tools/blender/debug/__init__.py	48	OK
tools/blender/debug/autofix.py	40519	OK
tools/blender/debug/io.py	3502	OK
tools/blender/debug/metrics.py	9595	OK
tools/blender/debug/validators.py	44522	OK
tools/blender/debug/visualize.py	16172	OK
tools/blender/debug_run.py	17024	OK
tools/blender/DEBUG_USAGE.md	2091	OK
tools/blender/run_builder_v01.py	20905	OK
tools/blender/run_export_glb.py	3863	OK
tools/blender/slat_lab.py	12374	OK
tools/dump_debug.ps1	2486	OK
tools/dump_repo.ps1	10484	OK
tools/generate_sofa_ner_dataset.py	14299	OK
tools/inspect_blend.py	4265	OK
tools/ner_to_schema_demo.py	3293	OK
tools/predict_sofa_ner.py	0	OK
tools/train_sofa_ner.py	7132	OK
tools/validate_schema.py	922	OK



===== FILE: requirements.txt =====
# Minimal dependencies for development; expand as the pipeline grows.



===== FILE: src/__init__.py =====



===== FILE: src/builders/__init__.py =====
"""Builders package for exporting geometry from resolved IR."""

# TODO: expose builder registries when available.



===== FILE: src/builders/blender/__init__.py =====
"""Blender-specific builders and exporters."""

# TODO: register Blender builders when implemented.



===== FILE: src/builders/blender/builder_v01.py =====
"""Generate a geometry plan and anchors for Blender builds."""

from dataclasses import dataclass, field
from typing import Dict, List, Tuple


@dataclass
class Primitive:
    """Represents a basic geometry primitive."""

    name: str
    shape: str
    dimensions_mm: Tuple[float, float, float]
    location_mm: Tuple[float, float, float]
    rotation_deg: Tuple[float, float, float] = (0.0, 0.0, 0.0)
    params: Dict[str, float] = field(default_factory=dict)


@dataclass
class Anchor:
    """Named anchor or empty location."""

    name: str
    location_mm: Tuple[float, float, float]


@dataclass
class BuildPlan:
    """Container for primitives and anchors to build a sofa frame."""

    primitives: List[Primitive] = field(default_factory=list)
    anchors: List[Anchor] = field(default_factory=list)
    metadata: Dict[str, str] = field(default_factory=dict)


def _ir_value(ir: dict, key: str, default: float) -> float:
    """Helper to fetch numeric values from IR with defaults."""
    value = ir.get(key, default)
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _canon_arms_type(value: str) -> str:
    """Normalize arms type to one of: none, left, right, both."""
    if not isinstance(value, str):
        return "none"
    normalized = value.strip().lower()
    if normalized in {"left", "right", "both", "none"}:
        return normalized
    return "none"


def _arms_count(arms_type: str) -> int:
    """Return number of arm blocks for a canonical arms_type."""
    if arms_type == "both":
        return 2
    if arms_type in {"left", "right"}:
        return 1
    return 0


def _clamp(value: float, min_value: float, max_value: float) -> float:
    return max(min_value, min(max_value, float(value)))


def _primitive_bbox_world(primitive: Primitive) -> Dict[str, Tuple[float, float, float]]:
    """Axis-aligned bbox for a primitive in world coordinates (plan space)."""
    dx, dy, dz = primitive.dimensions_mm
    cx, cy, cz = primitive.location_mm
    half_x = float(dx) / 2.0
    half_y = float(dy) / 2.0
    half_z = float(dz) / 2.0
    return {
        "min": (cx - half_x, cy - half_y, cz - half_z),
        "max": (cx + half_x, cy + half_y, cz + half_z),
    }


def build_plan_from_ir(ir: dict) -> BuildPlan:
    """Create a sofa-frame geometry plan from resolved IR.

    Coordinate system: X is width (left/right), Y is depth (front/back),
    Z is up. seat_height_mm defines the top of the seat support board.
    """
    seat_width_mm = _ir_value(ir, "seat_width_mm", 600.0)
    seat_depth_mm = _ir_value(ir, "seat_depth_mm", 600.0)
    seat_height_mm = _ir_value(ir, "seat_height_mm", 440.0)
    seat_count = max(1, int(_ir_value(ir, "seat_count", 3)))
    seat_total_width_mm = seat_width_mm * seat_count

    frame = ir.get("frame", {}) if isinstance(ir.get("frame"), dict) else {}
    frame_thickness_mm = _ir_value(frame, "thickness_mm", 35.0)
    back_height_mm = _ir_value(frame, "back_height_above_seat_mm", 420.0)
    back_thickness_mm = _ir_value(frame, "back_thickness_mm", 90.0)

    arms = ir.get("arms", {}) if isinstance(ir.get("arms"), dict) else {}
    arms_type = _canon_arms_type(arms.get("type", "none"))
    arms_width_mm = _ir_value(arms, "width_mm", 120.0)
    arms_total_mm = arms_width_mm * _arms_count(arms_type)
    total_width_mm = seat_total_width_mm + arms_total_mm

    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_height_mm = _ir_value(legs, "height_mm", 160.0)
    legs_family = legs.get("family", "block")

    seat_support_thickness_mm = frame_thickness_mm

    slats = ir.get("slats", {}) if isinstance(ir.get("slats"), dict) else {}
    slats_enabled = bool(slats.get("enabled", False))
    slat_count = max(1, int(_ir_value(slats, "count", 14)))
    slat_width_mm = _ir_value(slats, "width_mm", 55.0)
    slat_thickness_mm = _ir_value(slats, "thickness_mm", 10.0)
    slat_arc_height_mm = _ir_value(slats, "arc_height_mm", 0.0)
    slat_arc_sign = _ir_value(slats, "arc_sign", -1.0)
    slat_margin_x_mm = _ir_value(slats, "margin_x_mm", 40.0)
    slat_margin_y_mm = _ir_value(slats, "margin_y_mm", 60.0)
    slat_clearance_mm = _ir_value(slats, "clearance_mm", 0.0)
    slat_mount_mode = slats.get("mount_mode", "rests_on_plane")
    if not isinstance(slat_mount_mode, str):
        slat_mount_mode = "rests_on_plane"
    slat_mount_mode = slat_mount_mode.strip().lower()
    if slat_mount_mode not in {"rests_on_plane", "centered"}:
        slat_mount_mode = "rests_on_plane"
    slat_mount_offset_mm = _ir_value(slats, "mount_offset_mm", 0.0)
    slat_rail_inset_mm = _ir_value(slats, "rail_inset_mm", 0.0)
    slat_rail_height_mm = _ir_value(slats, "rail_height_mm", frame_thickness_mm)
    slat_rail_width_mm = _ir_value(slats, "rail_width_mm", frame_thickness_mm)
    slat_rail_inset_y_mm = _ir_value(slats, "rail_inset_y_mm", slat_margin_y_mm)

    has_back_support = "back_support" in ir
    back_support = ir.get("back_support", {}) if isinstance(ir.get("back_support"), dict) else {}
    back_support_mode = back_support.get("mode", "panel")
    if not isinstance(back_support_mode, str):
        back_support_mode = "panel"
    back_support_mode = back_support_mode.strip().lower()
    if back_support_mode not in {"panel", "slats", "straps"}:
        back_support_mode = "panel"

    back_height_mm = _ir_value(back_support, "height_above_seat_mm", back_height_mm)
    back_thickness_mm = _ir_value(back_support, "thickness_mm", back_thickness_mm)
    back_offset_y_mm = _ir_value(back_support, "offset_y_mm", 0.0)
    back_margin_x_mm = _ir_value(back_support, "margin_x_mm", 40.0)
    back_margin_z_mm = _ir_value(back_support, "margin_z_mm", 30.0)
    back_rail_inset_mm = _ir_value(back_support, "rail_inset_mm", 0.0)
    back_rail_width_mm = _ir_value(back_support, "rail_width_mm", frame_thickness_mm)
    back_rail_depth_mm = _ir_value(back_support, "rail_depth_mm", frame_thickness_mm)
    back_rail_height_mm = _ir_value(back_support, "rail_height_mm", back_rail_width_mm)

    back_slats = back_support.get("slats", {}) if isinstance(back_support.get("slats"), dict) else {}
    back_slat_count = max(1, int(_ir_value(back_slats, "count", 10)))
    back_slat_width_mm = _ir_value(back_slats, "width_mm", 35.0)
    back_slat_thickness_mm = _ir_value(back_slats, "thickness_mm", 10.0)
    back_slat_arc_height_mm = _ir_value(back_slats, "arc_height_mm", 0.0)
    back_slat_arc_sign = _ir_value(back_slats, "arc_sign", -1.0)

    back_straps = back_support.get("straps", {}) if isinstance(back_support.get("straps"), dict) else {}
    back_strap_count = max(1, int(_ir_value(back_straps, "count", 6)))
    back_strap_width_mm = _ir_value(back_straps, "width_mm", 30.0)
    back_strap_thickness_mm = _ir_value(back_straps, "thickness_mm", 6.0)

    # Z placement stack: legs -> base frame -> seat support -> back frame -> arms.
    # Seat support top aligns to seat_height_mm.
    seat_support_top_z = seat_height_mm
    seat_support_center_z = seat_support_top_z - (seat_support_thickness_mm / 2.0)
    base_frame_top_z = seat_support_top_z - seat_support_thickness_mm
    base_frame_center_z = base_frame_top_z - (frame_thickness_mm / 2.0)
    base_frame_bottom_z = base_frame_top_z - frame_thickness_mm
    legs_center_z = base_frame_bottom_z - (legs_height_mm / 2.0)

    plan = BuildPlan(metadata={
        "seat_count": str(seat_count),
        "legs_family": str(legs_family),
        "arms_type": str(arms_type),
        "seat_total_width_mm": str(seat_total_width_mm),
        "total_width_mm": str(total_width_mm),
    })

    # Base frame beams (outer perimeter of total frame).
    front_y = (seat_depth_mm / 2.0) - (frame_thickness_mm / 2.0)
    back_y = -(seat_depth_mm / 2.0) + (frame_thickness_mm / 2.0)
    left_x = -(total_width_mm / 2.0) + (frame_thickness_mm / 2.0)
    right_x = (total_width_mm / 2.0) - (frame_thickness_mm / 2.0)

    plan.primitives.extend(
        [
            Primitive(
                name="beam_front",
                shape="beam",
                dimensions_mm=(total_width_mm, frame_thickness_mm, frame_thickness_mm),
                location_mm=(0.0, front_y, base_frame_center_z),
            ),
            Primitive(
                name="beam_back",
                shape="beam",
                dimensions_mm=(total_width_mm, frame_thickness_mm, frame_thickness_mm),
                location_mm=(0.0, back_y, base_frame_center_z),
            ),
            Primitive(
                name="beam_left",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm, frame_thickness_mm),
                location_mm=(left_x, 0.0, base_frame_center_z),
            ),
            Primitive(
                name="beam_right",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm, frame_thickness_mm),
                location_mm=(right_x, 0.0, base_frame_center_z),
            ),
        ]
    )

    # Cross beams across depth (along Y), evenly spaced along X.
    cross_count = max(2, min(4, seat_count + 1))
    inner_width_mm = max(1.0, total_width_mm - (2.0 * frame_thickness_mm))
    cross_spacing_mm = inner_width_mm / (cross_count + 1)
    for i in range(cross_count):
        x = -(inner_width_mm / 2.0) + cross_spacing_mm * (i + 1)
        plan.primitives.append(
            Primitive(
                name=f"beam_cross_{i + 1}",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm - (2.0 * frame_thickness_mm), frame_thickness_mm),
                location_mm=(x, 0.0, base_frame_center_z),
            )
        )

    # Seat support board (seat area only) on top of base frame.
    if not slats_enabled:
        plan.primitives.append(
            Primitive(
                name="seat_support",
                shape="board",
                dimensions_mm=(seat_total_width_mm, seat_depth_mm, seat_support_thickness_mm),
                location_mm=(0.0, 0.0, seat_support_center_z),
            )
        )

    # Slats (lamellas) across X, running along Y with front/back margins.
    if slats_enabled:
        slat_length_mm = max(1.0, seat_depth_mm - (2.0 * slat_margin_y_mm))
        rail_length_mm = max(1.0, seat_depth_mm - (2.0 * slat_rail_inset_y_mm))
        usable_width_mm = max(1.0, seat_total_width_mm - (2.0 * slat_margin_x_mm))
        if slat_count == 1:
            slat_centers_x = [0.0]
        else:
            span_mm = max(0.0, usable_width_mm - slat_width_mm)
            step_mm = span_mm / (slat_count - 1)
            start_x = -(usable_width_mm / 2.0) + (slat_width_mm / 2.0)
            slat_centers_x = [start_x + (step_mm * i) for i in range(slat_count)]

        # Slats mount to the base frame top plane unless explicitly centered.
        slat_plane_z_mm = base_frame_top_z
        if slat_mount_mode == "centered":
            slat_center_z = seat_support_top_z - (slat_thickness_mm / 2.0) + slat_clearance_mm
        else:
            slat_center_z = (
                slat_plane_z_mm
                + slat_mount_offset_mm
                + slat_clearance_mm
                + (slat_thickness_mm / 2.0)
            )

        min_x = min(slat_centers_x) - (slat_width_mm / 2.0)
        max_x = max(slat_centers_x) + (slat_width_mm / 2.0)
        rail_height_mm = slat_rail_height_mm
        rail_width_mm = slat_rail_width_mm
        rail_depth_mm = rail_length_mm
        rail_top_z = slat_plane_z_mm
        rail_center_z = rail_top_z - (rail_height_mm / 2.0)
        rail_left_x = min_x + (rail_width_mm / 2.0) + slat_rail_inset_mm
        rail_right_x = max_x - (rail_width_mm / 2.0) - slat_rail_inset_mm
        if rail_left_x < rail_right_x:
            plan.primitives.append(
                Primitive(
                    name="rail_left",
                    shape="beam",
                    dimensions_mm=(rail_width_mm, rail_depth_mm, rail_height_mm),
                    location_mm=(rail_left_x, 0.0, rail_center_z),
                )
            )
            plan.primitives.append(
                Primitive(
                    name="rail_right",
                    shape="beam",
                    dimensions_mm=(rail_width_mm, rail_depth_mm, rail_height_mm),
                    location_mm=(rail_right_x, 0.0, rail_center_z),
                )
            )
            plan.anchors.append(
                Anchor(name="rail_left", location_mm=(rail_left_x, 0.0, rail_center_z))
            )
            plan.anchors.append(
                Anchor(name="rail_right", location_mm=(rail_right_x, 0.0, rail_center_z))
            )

        plan.anchors.append(Anchor(name="slat_plane_z", location_mm=(0.0, 0.0, slat_plane_z_mm)))
        plan.anchors.append(Anchor(name="slat_area_center", location_mm=(0.0, 0.0, slat_center_z)))
        for i, x in enumerate(slat_centers_x, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"slat_{i}",
                    shape="slat",
                    dimensions_mm=(slat_width_mm, slat_length_mm, slat_thickness_mm),
                    location_mm=(x, 0.0, slat_center_z),
                    params={
                        "arc_height_mm": slat_arc_height_mm,
                        "arc_sign": slat_arc_sign,
                        "orientation": "horizontal",
                        "mount_mode": slat_mount_mode,
                        "mount_offset_mm": slat_mount_offset_mm,
                        "clearance_mm": slat_clearance_mm,
                    },
                )
            )

    # Back support uses a frame tied directly to the rear seat rail.
    back_offset_y_micro_mm = _clamp(back_offset_y_mm, -10.0, 10.0)
    seat_back_rail_center_y = back_y
    seat_back_rail_outer_face_y = seat_back_rail_center_y - (frame_thickness_mm / 2.0)
    y_back_seat = seat_back_rail_outer_face_y
    seat_rear_rail_center = (0.0, seat_back_rail_center_y, base_frame_center_z)
    seat_rear_rail_top_z = base_frame_top_z

    back_rail_width_mm = max(1.0, back_rail_width_mm)
    back_rail_depth_mm = max(1.0, back_rail_depth_mm)
    back_rail_height_mm = max(1.0, back_rail_height_mm)
    back_frame_member_mm = max(1.0, back_thickness_mm)

    back_gap_base_mm = 1.5
    back_gap_mm = _clamp(back_gap_base_mm + back_offset_y_micro_mm, 0.0, 12.0)
    back_frame_plane_y = y_back_seat - back_gap_mm
    back_frame_base_z = seat_rear_rail_top_z
    back_frame_top_z = max(back_frame_base_z + 1.0, seat_support_top_z + back_height_mm)
    back_frame_height_mm = back_frame_top_z - back_frame_base_z
    back_frame_center_y = back_frame_plane_y - (back_rail_depth_mm / 2.0)
    back_frame_origin = (0.0, back_frame_plane_y, back_frame_base_z)
    back_center_z = back_frame_base_z + (back_frame_height_mm / 2.0)
    back_panel_center = (0.0, back_frame_center_y, back_center_z)
    rail_left_x = -(seat_total_width_mm / 2.0) + (back_rail_width_mm / 2.0)
    rail_right_x = (seat_total_width_mm / 2.0) - (back_rail_width_mm / 2.0)

    back_frame_debug_primitives: List[Primitive] = []
    back_slat_debug_primitives: List[Primitive] = []
    back_slats_bbox_inner_text = "n/a"

    if has_back_support:
        back_upright_center_z = back_frame_base_z + (back_frame_height_mm / 2.0)

        back_rail_left = Primitive(
            name="back_rail_left",
            shape="beam",
            dimensions_mm=(back_rail_width_mm, back_rail_depth_mm, back_frame_height_mm),
            location_mm=(rail_left_x, back_frame_center_y, back_upright_center_z),
        )
        back_rail_right = Primitive(
            name="back_rail_right",
            shape="beam",
            dimensions_mm=(back_rail_width_mm, back_rail_depth_mm, back_frame_height_mm),
            location_mm=(rail_right_x, back_frame_center_y, back_upright_center_z),
        )
        plan.primitives.extend([back_rail_left, back_rail_right])
        back_frame_debug_primitives.extend([back_rail_left, back_rail_right])
        plan.anchors.extend(
            [
                Anchor(name="back_rail_left", location_mm=back_rail_left.location_mm),
                Anchor(name="back_rail_right", location_mm=back_rail_right.location_mm),
            ]
        )

    if not has_back_support:
        # Backward-compatible panel using frame.back_* dimensions.
        legacy_back_plane_y = seat_back_rail_outer_face_y - (back_thickness_mm / 2.0) + back_offset_y_mm
        legacy_back_center_z = seat_support_top_z + (back_height_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="back_frame",
                shape="board",
                dimensions_mm=(total_width_mm, back_thickness_mm, back_height_mm),
                location_mm=(0.0, legacy_back_plane_y, legacy_back_center_z),
            )
        )
    elif back_support_mode == "panel":
        plan.primitives.append(
            Primitive(
                name="back_panel",
                shape="board",
                dimensions_mm=(seat_total_width_mm, back_frame_member_mm, back_frame_height_mm),
                location_mm=back_panel_center,
            )
        )
    elif back_support_mode == "slats":
        inset_x_mm = max(3.0, back_rail_inset_mm)
        inset_z_mm = max(3.0, back_rail_inset_mm)

        frame_inner_min_x = rail_left_x + (back_rail_width_mm / 2.0)
        frame_inner_max_x = rail_right_x - (back_rail_width_mm / 2.0)
        slat_min_x_raw = frame_inner_min_x + inset_x_mm
        slat_max_x_raw = frame_inner_max_x - inset_x_mm
        inner_min_x = min(slat_min_x_raw, slat_max_x_raw)
        inner_max_x = max(slat_min_x_raw, slat_max_x_raw)

        frame_inner_width_mm = max(1.0, (rail_right_x - rail_left_x) - back_rail_width_mm)
        bottom_rail_center_z = back_frame_base_z + (back_rail_height_mm / 2.0)
        top_rail_center_z = back_frame_top_z - (back_rail_height_mm / 2.0)
        back_rail_bottom = Primitive(
            name="back_rail_bottom",
            shape="beam",
            dimensions_mm=(frame_inner_width_mm, back_rail_depth_mm, back_rail_height_mm),
            location_mm=(0.0, back_frame_center_y, bottom_rail_center_z),
        )
        back_rail_top = Primitive(
            name="back_rail_top",
            shape="beam",
            dimensions_mm=(frame_inner_width_mm, back_rail_depth_mm, back_rail_height_mm),
            location_mm=(0.0, back_frame_center_y, top_rail_center_z),
        )
        plan.primitives.extend([back_rail_bottom, back_rail_top])
        back_frame_debug_primitives.extend([back_rail_bottom, back_rail_top])
        plan.anchors.append(Anchor(name="back_rail_bottom", location_mm=back_rail_bottom.location_mm))
        plan.anchors.append(Anchor(name="back_rail_top", location_mm=back_rail_top.location_mm))

        inner_bottom_z = (bottom_rail_center_z + (back_rail_height_mm / 2.0)) + inset_z_mm
        inner_top_z = (top_rail_center_z - (back_rail_height_mm / 2.0)) - inset_z_mm
        if inner_bottom_z > inner_top_z:
            inner_bottom_z, inner_top_z = inner_top_z, inner_bottom_z

        usable_width_mm = max(1.0, inner_max_x - inner_min_x)
        slat_height_mm = max(1.0, inner_top_z - inner_bottom_z)
        back_slat_center_z = inner_bottom_z + (slat_height_mm / 2.0)
        y_slat_inset_max = max(0.0, ((back_rail_depth_mm - back_slat_thickness_mm) / 2.0) - 0.5)
        y_slat_inset_mm = min(2.0, y_slat_inset_max)
        back_slat_center_y = back_frame_center_y - y_slat_inset_mm
        back_slat_plane_y = back_slat_center_y + (back_slat_thickness_mm / 2.0)
        back_slats_bbox_inner_text = (
            f"min=({inner_min_x:.3f},{inner_bottom_z:.3f}) "
            f"max=({inner_max_x:.3f},{inner_top_z:.3f}) y={back_slat_center_y:.3f}"
        )

        if back_slat_count == 1:
            slat_centers_x = [0.5 * (inner_min_x + inner_max_x)]
        else:
            span_mm = max(0.0, usable_width_mm - back_slat_width_mm)
            step_mm = span_mm / (back_slat_count - 1)
            start_x = inner_min_x + (back_slat_width_mm / 2.0)
            slat_centers_x = [start_x + (step_mm * i) for i in range(back_slat_count)]

        plan.anchors.append(Anchor(name="back_slat_plane_y", location_mm=(0.0, back_slat_plane_y, 0.0)))
        plan.anchors.append(Anchor(name="back_slat_center_z", location_mm=(0.0, 0.0, back_slat_center_z)))
        plan.anchors.append(
            Anchor(name="back_frame_inner_rect_min", location_mm=(inner_min_x, back_frame_center_y, inner_bottom_z))
        )
        plan.anchors.append(
            Anchor(name="back_frame_inner_rect_max", location_mm=(inner_max_x, back_frame_center_y, inner_top_z))
        )

        for i, x in enumerate(slat_centers_x, start=1):
            back_slat = Primitive(
                name=f"back_slat_{i}",
                shape="slat",
                dimensions_mm=(back_slat_width_mm, back_slat_thickness_mm, slat_height_mm),
                location_mm=(x, back_slat_center_y, back_slat_center_z),
                params={
                    "arc_height_mm": back_slat_arc_height_mm,
                    "arc_sign": back_slat_arc_sign,
                    "orientation": "vertical",
                },
            )
            plan.primitives.append(back_slat)
            if i <= 2:
                back_slat_debug_primitives.append(back_slat)
            plan.anchors.append(
                Anchor(name=f"back_slat_{i}", location_mm=(x, back_slat_center_y, back_slat_center_z))
            )
    elif back_support_mode == "straps":
        strap_center_x = 0.0
        strap_span_z_mm = max(1.0, (back_frame_height_mm - back_frame_member_mm) - (2.0 * back_margin_z_mm))
        if back_strap_count == 1:
            strap_centers_z = [back_frame_base_z + ((back_frame_height_mm - back_frame_member_mm) / 2.0)]
        else:
            step_mm = strap_span_z_mm / (back_strap_count - 1)
            start_z = back_frame_base_z + back_margin_z_mm
            strap_centers_z = [start_z + (step_mm * i) for i in range(back_strap_count)]

        for i, z in enumerate(strap_centers_z, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"back_strap_{i}",
                    shape="board",
                    dimensions_mm=(seat_total_width_mm, back_strap_thickness_mm, back_strap_width_mm),
                    location_mm=(strap_center_x, back_frame_center_y, z),
                )
            )

    if has_back_support:
        print(f"BACK_ANCHOR y_back_seat={y_back_seat:.3f}")
        print(f"BACK_FRAME y={back_frame_center_y:.3f} plane_y={back_frame_plane_y:.3f} gap_mm={back_gap_mm:.3f}")
        print(f"BACK_SLATS bbox_inner={back_slats_bbox_inner_text}")
        print(f"[builder_v01] back_frame back_frame_origin={back_frame_origin}")
        for primitive in back_frame_debug_primitives:
            bbox = _primitive_bbox_world(primitive)
            print(
                "[builder_v01] back_frame "
                f"{primitive.name} bbox_world.min={bbox['min']} bbox_world.max={bbox['max']}"
            )
        for primitive in back_slat_debug_primitives:
            bbox = _primitive_bbox_world(primitive)
            print(
                "[builder_v01] back_frame "
                f"{primitive.name} bbox_world.min={bbox['min']} bbox_world.max={bbox['max']}"
            )

    # Simple arm frames as boards when present.
    # Arms sit outside the seat area in X, and their bottoms align to the base frame top.
    arm_height_mm = max(frame_thickness_mm * 2.0, seat_height_mm * 0.65)
    arm_center_z = base_frame_top_z + (arm_height_mm / 2.0)
    if arms_type in {"both", "left"}:
        left_arm_center_x = -(seat_total_width_mm / 2.0) - (arms_width_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="left_arm_frame",
                shape="board",
                dimensions_mm=(arms_width_mm, seat_depth_mm, arm_height_mm),
                location_mm=(left_arm_center_x, 0.0, arm_center_z),
            )
        )
        plan.anchors.append(
            Anchor(name="arm_left_zone", location_mm=(left_arm_center_x, 0.0, seat_height_mm))
        )
    if arms_type in {"both", "right"}:
        right_arm_center_x = (seat_total_width_mm / 2.0) + (arms_width_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="right_arm_frame",
                shape="board",
                dimensions_mm=(arms_width_mm, seat_depth_mm, arm_height_mm),
                location_mm=(right_arm_center_x, 0.0, arm_center_z),
            )
        )
        plan.anchors.append(
            Anchor(name="arm_right_zone", location_mm=(right_arm_center_x, 0.0, seat_height_mm))
        )

    # Leg anchors and leg primitives at corners.
    leg_offset_x = (total_width_mm / 2.0) - (frame_thickness_mm / 2.0)
    leg_offset_y = (seat_depth_mm / 2.0) - (frame_thickness_mm / 2.0)
    leg_points = [
        (-leg_offset_x, -leg_offset_y, legs_center_z),
        (leg_offset_x, -leg_offset_y, legs_center_z),
        (-leg_offset_x, leg_offset_y, legs_center_z),
        (leg_offset_x, leg_offset_y, legs_center_z),
    ]

    for index, point in enumerate(leg_points, start=1):
        plan.anchors.append(Anchor(name=f"leg_point_{index}", location_mm=point))
        plan.primitives.append(
            Primitive(
                name=f"leg_{index}",
                shape=legs_family,
                dimensions_mm=(frame_thickness_mm, frame_thickness_mm, legs_height_mm),
                location_mm=point,
            )
        )

    # Anchors for zones.
    if has_back_support:
        back_anchor_y = back_frame_center_y
        back_bottom_z = back_frame_base_z
        back_top_z = back_frame_top_z
        back_inner_center = (0.0, back_frame_center_y, back_center_z)
    else:
        back_anchor_y = seat_back_rail_outer_face_y - (back_thickness_mm / 2.0) + back_offset_y_mm
        back_bottom_z = seat_support_top_z
        back_top_z = seat_support_top_z + back_height_mm
        back_inner_center = (0.0, back_anchor_y, seat_support_top_z + (back_height_mm / 2.0))
    left_back_corner = (-(seat_total_width_mm / 2.0), back_anchor_y, back_bottom_z)
    right_back_corner = ((seat_total_width_mm / 2.0), back_anchor_y, back_bottom_z)

    plan.anchors.extend(
        [
            Anchor(name="seat_zone", location_mm=(0.0, 0.0, seat_support_center_z)),
            Anchor(name="back_zone", location_mm=back_panel_center),
            Anchor(name="seat_rear_rail", location_mm=seat_rear_rail_center),
            Anchor(
                name="seat_back_rail_center_y",
                location_mm=(0.0, seat_back_rail_center_y, base_frame_center_z),
            ),
            Anchor(
                name="seat_back_rail_outer_face_y",
                location_mm=(0.0, seat_back_rail_outer_face_y, base_frame_center_z),
            ),
            Anchor(name="y_back_seat", location_mm=(0.0, y_back_seat, base_frame_center_z)),
            Anchor(name="seat_back_plane", location_mm=(0.0, seat_back_rail_outer_face_y, back_bottom_z)),
            Anchor(name="back_frame_origin", location_mm=back_frame_origin),
            Anchor(name="back_bottom_edge_center", location_mm=(0.0, back_anchor_y, back_bottom_z)),
            Anchor(name="back_top_edge_center", location_mm=(0.0, back_anchor_y, back_top_z)),
            Anchor(name="back_inner_plane_center", location_mm=back_inner_center),
            Anchor(name="left_back_corner", location_mm=left_back_corner),
            Anchor(name="right_back_corner", location_mm=right_back_corner),
        ]
    )

    return plan



===== FILE: src/builders/blender/export_blender.py =====
"""Runner that triggers Blender build from an IR JSON path."""

from __future__ import annotations

import argparse
import os
import subprocess
from pathlib import Path


DEFAULT_GLB_PATH = Path("out/glb/sofa.glb")
DEFAULT_LOG_PATH = Path("out/logs/build.log")
DEFAULT_BLEND_PATH = Path("out/logs/sofa.blend")


def _blender_executable() -> str:
    """Resolve Blender executable path."""
    return os.environ.get("BLENDER_EXE", "blender")


def _run_blender(args: list[str], log_path: Path, env: dict[str, str] | None = None) -> None:
    """Run a Blender command and write output to log."""
    log_path.parent.mkdir(parents=True, exist_ok=True)
    with log_path.open("a", encoding="utf-8") as handle:
        subprocess.run(args, stdout=handle, stderr=subprocess.STDOUT, check=True, env=env)


def run_blender_build(ir_json_path: str, glb_path: str | None = None) -> Path:
    """Run Blender build for the given IR JSON path."""
    ir_path = Path(ir_json_path)
    out_path = Path(glb_path) if glb_path else DEFAULT_GLB_PATH
    blender = _blender_executable()
    blend_path = DEFAULT_BLEND_PATH

    builder_script = Path("tools/blender/run_builder_v01.py")
    export_script = Path("tools/blender/run_export_glb.py")

    builder_env = os.environ.copy()
    builder_env["IR_PATH"] = str(ir_path)
    builder_env["BLEND_PATH"] = str(blend_path)

    _run_blender(
        [
            blender,
            "--background",
            "--python",
            str(builder_script),
            "--",
            str(ir_path),
        ],
        DEFAULT_LOG_PATH,
        env=builder_env,
    )
    if not blend_path.exists() or blend_path.stat().st_size == 0:
        raise RuntimeError(f"Blend file missing or empty: {blend_path.resolve()}")

    export_env = os.environ.copy()
    export_env["GLB_PATH"] = str(out_path)

    _run_blender(
        [
            blender,
            "--background",
            str(blend_path),
            "--python",
            str(export_script),
            "--",
            str(out_path),
        ],
        DEFAULT_LOG_PATH,
        env=export_env,
    )
    if not out_path.exists() or out_path.stat().st_size == 0:
        raise RuntimeError(f"GLB file missing or empty: {out_path.resolve()}")

    return out_path


def main() -> None:
    """CLI entry point."""
    parser = argparse.ArgumentParser(description="Run Blender builder and export GLB.")
    parser.add_argument("ir_json_path", help="Path to resolved IR JSON.")
    parser.add_argument("glb_path", nargs="?", default=str(DEFAULT_GLB_PATH), help="Output GLB path.")
    args = parser.parse_args()

    run_blender_build(args.ir_json_path, args.glb_path)


if __name__ == "__main__":
    main()



===== FILE: src/builders/cad/__init__.py =====
"""CAD-oriented exporters."""

# TODO: register CAD exporters when available.



===== FILE: src/builders/cad/export_step_stub.py =====
"""Placeholder module for STEP export."""

# TODO: implement STEP export once CAD pipeline is defined.

def export_step(resolved_ir, output_path):
    """Export resolved IR to a STEP file."""
    # TODO: translate resolved IR to STEP format.
    return {
        "resolved_ir": resolved_ir,
        "output_path": output_path,
        "exported": False,
    }



===== FILE: src/ner_infer.py =====
from __future__ import annotations

import re
from dataclasses import dataclass
from functools import lru_cache
from typing import Dict, List, Tuple, Optional

import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification


# Простая токенизация, похожая на твою разметку датасета:
# числа, слова, отдельные знаки препинания.
_TOKEN_RE = re.compile(r"\d+(?:[.,]\d+)?|[A-Za-zА-Яа-яЁё]+|[^\w\s]", re.UNICODE)


def basic_tokenize(text: str) -> List[str]:
    return _TOKEN_RE.findall(text)


@dataclass
class NEROutput:
    tokens: List[str]
    tags: List[str]
    entities: Dict[str, List[str]]


@lru_cache(maxsize=4)
def _load(model_dir: str):
    tok = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForTokenClassification.from_pretrained(model_dir)
    model.eval()
    return tok, model


def _bio_to_entities(tokens: List[str], tags: List[str]) -> Dict[str, List[str]]:
    entities: Dict[str, List[str]] = {}
    cur_type: Optional[str] = None
    cur_tokens: List[str] = []

    def flush():
        nonlocal cur_type, cur_tokens
        if cur_type and cur_tokens:
            entities.setdefault(cur_type, []).append(" ".join(cur_tokens))
        cur_type = None
        cur_tokens = []

    for tok, tag in zip(tokens, tags):
        if tag.startswith("B-"):
            flush()
            cur_type = tag[2:]
            cur_tokens = [tok]
        elif tag.startswith("I-") and cur_type == tag[2:]:
            cur_tokens.append(tok)
        else:
            flush()

    flush()
    return entities


def predict(text: str, model_dir: str, max_len: int = 128, device: Optional[str] = None) -> NEROutput:
    tokenizer, model = _load(model_dir)

    words = basic_tokenize(text)

    enc = tokenizer(
        words,
        is_split_into_words=True,
        return_tensors="pt",
        truncation=True,
        max_length=max_len,
    )

    # ВАЖНО: word_ids берём ДО переноса на device и ДО любых преобразований
    if hasattr(enc, "word_ids"):
        word_ids = enc.word_ids(batch_index=0)
    else:
        raise RuntimeError(
            "Tokenizer returned a plain dict without word_ids(). "
            "Ensure you are using a fast tokenizer or keep BatchEncoding object."
        )

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    model.to(device)

    # переносим тензоры, но НЕ затираем enc целиком
    enc_on_device = {k: v.to(device) for k, v in enc.items()}

    with torch.no_grad():
        logits = model(**enc_on_device).logits

    pred_ids = torch.argmax(logits, dim=-1)[0].tolist()
    id2label = model.config.id2label

    word_tags: List[str] = ["O"] * len(words)
    used = set()
    for i, w_id in enumerate(word_ids):
        if w_id is None:
            continue
        if w_id in used:
            continue
        used.add(w_id)
        word_tags[w_id] = id2label[pred_ids[i]]

    entities = _bio_to_entities(words, word_tags)
    return NEROutput(tokens=words, tags=word_tags, entities=entities)




===== FILE: src/pipeline/__init__.py =====
"""Pipeline package for converting NER outputs into buildable IR."""

# TODO: expose high-level pipeline helpers when implementation is ready.



===== FILE: src/pipeline/ner_to_request.py =====
"""Normalize extracted entities into a SofaRequest payload."""

# TODO: define a mapping between NER outputs and SofaRequest fields.
# TODO: validate and normalize entity values (materials, dimensions, styles).

def normalize_entities(entities):
    """Normalize raw NER entities into canonical request fields."""
    # TODO: implement normalization logic once schema is finalized.
    return {
        "raw_entities": entities,
    }


def map_ner_to_request(entities):
    """Map normalized entities into a SofaRequest structure."""
    # TODO: build SofaRequest payload structure from normalized entities.
    return {
        "request": normalize_entities(entities),
    }



===== FILE: src/pipeline/resolve.py =====
"""Wrapper around resolve_sofa for building resolved IR."""

from __future__ import annotations

from typing import Dict

from src.schema import SofaRequest, resolve_sofa


def resolve_request_to_ir(sofa_request: SofaRequest) -> Dict:
    """Resolve a SofaRequest into an intermediate representation."""
    resolved = resolve_sofa(sofa_request)
    return resolved.model_dump()


def resolve_sofa_request(sofa_request: SofaRequest) -> Dict:
    """Backward-compatible wrapper for resolving SofaRequest."""
    return resolve_request_to_ir(sofa_request)



===== FILE: src/schema.py =====
from __future__ import annotations

import re
from enum import Enum
from typing import Any, Dict, Optional, Tuple
from typing_extensions import Literal

from pydantic import BaseModel, Field, field_validator, model_validator


# =========================
# Enums / core types
# =========================

class SofaStyle(str, Enum):
    scandi = "scandi"
    loft = "loft"
    modern = "modern"
    minimal = "minimal"
    classic = "classic"


class SofaLayout(str, Enum):
    straight = "straight"
    corner = "corner"
    u_shape = "u_shape"
    modular = "modular"


class Orientation(str, Enum):
    left = "left"
    right = "right"


class ArmrestType(str, Enum):
    none = "none"
    left = "left"
    right = "right"
    both = "both"


class LegFamily(str, Enum):
    tapered_cone = "tapered_cone"
    tapered_prism = "tapered_prism"
    cylindrical = "cylindrical"
    block = "block"
    hairpin = "hairpin"
    sled = "sled"
    frame = "frame"


class SeatType(str, Enum):
    single = "single"
    cushions = "cushions"


# =========================
# Preferences (level-2)
# =========================

class RawPreferences(BaseModel):
    # thin / medium / thick — можно расширять позже
    leg_thickness_bias: Optional[Literal["thin", "medium", "thick"]] = None
    # box / rounded_bottom / rolled — пока совпадает с ArmsSpec.profile
    arm_profile: Optional[Literal["box", "rounded_bottom", "rolled"]] = None
    # soft / medium / firm — пока влияет только на seat_type
    seat_softness: Optional[Literal["soft", "medium", "firm"]] = None


# =========================
# Aliases / Canonicalization
# =========================

def _canon(s: str) -> str:
    s = s.strip().lower()
    s = s.replace("ё", "е")
    s = s.replace("-", " ")
    s = s.replace("_", " ")
    s = re.sub(r"\s+", " ", s)
    return s


TYPE_ALIASES = {
    "диван": "sofa",
    "софа": "sofa",
    "sofa": "sofa",
}

STYLE_ALIASES = {
    "сканди": "scandi",
    "скандинавский": "scandi",
    "scandi": "scandi",

    "лофт": "loft",
    "loft": "loft",

    "современный": "modern",
    "модерн": "modern",
    "modern": "modern",

    "минимализм": "minimal",
    "минимальный": "minimal",
    "minimal": "minimal",

    "классический": "classic",
    "классика": "classic",
    "classic": "classic",
}

LAYOUT_ALIASES = {
    "прямой": "straight",
    "прямая": "straight",
    "straight": "straight",

    "угловой": "corner",
    "угловая": "corner",
    "corner": "corner",

    "п образный": "u_shape",
    "побразный": "u_shape",
    "u образный": "u_shape",
    "u shape": "u_shape",
    "u_shape": "u_shape",

    "секционный": "modular",
    "модульный": "modular",
    "modular": "modular",
}

LEG_ALIASES = {
    "конусные": "tapered_cone",
    "конус": "tapered_cone",
    "tapered cone": "tapered_cone",
    "tapered_cone": "tapered_cone",

    "пирамида": "tapered_prism",
    "призма": "tapered_prism",
    "скошенная пирамида": "tapered_prism",
    "tapered prism": "tapered_prism",
    "tapered_prism": "tapered_prism",

    "цилиндрические": "cylindrical",
    "цилиндр": "cylindrical",
    "cylindrical": "cylindrical",

    "блочные": "block",
    "кубики": "block",
    "block": "block",

    "hairpin": "hairpin",
    "шпильки": "hairpin",

    "sled": "sled",
    "полозья": "sled",

    "frame": "frame",
    "рамные": "frame",
}


# =========================
# Request model (сырой ввод)
# =========================

class SofaRequest(BaseModel):
    """
    Сырые параметры, извлечённые из текста (NER + нормализация).
    Могут быть неполными — Resolver заполнит дефолты.
    """

    type: Literal["sofa"] = "sofa"

    style: SofaStyle
    layout: SofaLayout
    orientation: Optional[Orientation] = None  # may be None; resolver fills for corner/u_shape

    seat_height_mm: Optional[int] = Field(default=None, ge=250, le=650)
    seat_depth_mm: Optional[int] = Field(default=None, ge=350, le=900)

    seat_width_range_mm: Optional[Tuple[int, int]] = None  # (min,max) mm
    seat_count: Optional[int] = Field(default=None, ge=1, le=8)

    has_chaise: Optional[bool] = None
    armrests: Optional[ArmrestType] = None
    leg_family: Optional[LegFamily] = None
    transformable: Optional[bool] = None

    preferences: Optional[RawPreferences] = None

    # --- Alias validators (before enum parsing) ---

    @field_validator("type", mode="before")
    @classmethod
    def _v_type(cls, v):
        if v is None:
            return v
        return TYPE_ALIASES.get(_canon(str(v)), v)

    @field_validator("style", mode="before")
    @classmethod
    def _v_style(cls, v):
        if v is None:
            return v
        return STYLE_ALIASES.get(_canon(str(v)), v)

    @field_validator("layout", mode="before")
    @classmethod
    def _v_layout(cls, v):
        if v is None:
            return v
        return LAYOUT_ALIASES.get(_canon(str(v)), v)

    @field_validator("leg_family", mode="before")
    @classmethod
    def _v_leg_family(cls, v):
        if v is None:
            return v
        return LEG_ALIASES.get(_canon(str(v)), v)

    # --- Structural validators ---

    @field_validator("seat_width_range_mm")
    @classmethod
    def validate_seat_width_range(cls, v: Optional[Tuple[int, int]]):
        if v is None:
            return None
        a, b = v
        if a <= 0 or b <= 0:
            raise ValueError("seat_width_range_mm values must be > 0")
        if a > b:
            raise ValueError("seat_width_range_mm min must be <= max")
        if a < 350 or b > 1200:
            raise ValueError("seat_width_range_mm out of bounds (350..1200 mm)")
        return v

    @model_validator(mode="after")
    def validate_layout_orientation(self):
        # В Request допускаем отсутствие orientation.
        # Resolver заполнит дефолт, если layout corner/u_shape.
        return self


# =========================
# Resolved specs (Builder input)
# =========================

class LegsSpec(BaseModel):
    family: LegFamily
    height_mm: int = Field(ge=30, le=260)
    params: Dict[str, Any] = Field(default_factory=dict)


class ArmsSpec(BaseModel):
    type: ArmrestType
    width_mm: int = Field(ge=0, le=400)
    profile: Literal["box", "rounded_bottom", "rolled"] = "box"


class FrameSpec(BaseModel):
    thickness_mm: int = Field(ge=20, le=80)
    back_thickness_mm: int = Field(ge=50, le=180)
    back_height_above_seat_mm: int = Field(ge=250, le=700)


class SofaResolved(BaseModel):
    """
    Полная спецификация. Builder обязан уметь собирать любой SofaResolved.
    """

    style: SofaStyle
    layout: SofaLayout
    orientation: Optional[Orientation] = None  # resolved for corner/u_shape

    seat_count: int = Field(ge=1, le=8)

    seat_height_mm: int = Field(ge=250, le=650)
    seat_depth_mm: int = Field(ge=350, le=900)
    seat_width_mm: int = Field(ge=350, le=1200)

    has_chaise: bool
    transformable: bool
    seat_type: SeatType

    legs: LegsSpec
    arms: ArmsSpec
    frame: FrameSpec

    @model_validator(mode="after")
    def sanity(self):
        total_seat_width = self.seat_count * self.seat_width_mm
        if self.arms.type == ArmrestType.both and total_seat_width < 900:
            raise ValueError("Too small sofa for two armrests with given seat_count/seat_width_mm")
        return self


# =========================
# Resolver defaults
# =========================

STYLE_DEFAULTS: Dict[SofaStyle, Dict[str, Any]] = {
    SofaStyle.scandi: dict(
        seat_count=3,
        seat_height_mm=440,
        seat_depth_mm=600,
        seat_width_mm=600,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.cushions,
        legs=dict(family=LegFamily.tapered_cone, height_mm=160, params={"r_top": 22, "r_bottom": 12}),
        arms=dict(type=ArmrestType.both, width_mm=120, profile="box"),
        frame=dict(thickness_mm=35, back_thickness_mm=90, back_height_above_seat_mm=420),
    ),
    SofaStyle.loft: dict(
        seat_count=3,
        seat_height_mm=430,
        seat_depth_mm=620,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.frame, height_mm=120, params={}),
        arms=dict(type=ArmrestType.both, width_mm=140, profile="box"),
        frame=dict(thickness_mm=40, back_thickness_mm=110, back_height_above_seat_mm=420),
    ),
    SofaStyle.modern: dict(
        seat_count=3,
        seat_height_mm=450,
        seat_depth_mm=620,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.block, height_mm=80, params={}),
        arms=dict(type=ArmrestType.both, width_mm=130, profile="rounded_bottom"),
        frame=dict(thickness_mm=40, back_thickness_mm=100, back_height_above_seat_mm=400),
    ),
    SofaStyle.minimal: dict(
        seat_count=3,
        seat_height_mm=430,
        seat_depth_mm=600,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.block, height_mm=40, params={}),
        arms=dict(type=ArmrestType.both, width_mm=110, profile="box"),
        frame=dict(thickness_mm=35, back_thickness_mm=90, back_height_above_seat_mm=380),
    ),
    SofaStyle.classic: dict(
        seat_count=3,
        seat_height_mm=460,
        seat_depth_mm=590,
        seat_width_mm=600,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.cushions,
        legs=dict(family=LegFamily.tapered_prism, height_mm=120, params={"top": [45, 45], "bottom": [30, 30]}),
        arms=dict(type=ArmrestType.both, width_mm=170, profile="rolled"),
        frame=dict(thickness_mm=45, back_thickness_mm=120, back_height_above_seat_mm=480),
    ),
}


# =========================
# Resolver (детерминированный)
# =========================

def resolve_sofa(req: SofaRequest) -> SofaResolved:
    """
    Детерминированно заполняет пропуски и приводит к полной спецификации для Builder.
    """

    defaults = STYLE_DEFAULTS[req.style]

    # 1) Orientation: required for corner/u_shape, but can be missing in Request.
    orientation = req.orientation
    if req.layout in {SofaLayout.corner, SofaLayout.u_shape} and orientation is None:
        orientation = Orientation.left  # system default

    # 2) Seat width: if user gave range — take midpoint; else style default.
    seat_width_mm = defaults["seat_width_mm"]
    if req.seat_width_range_mm is not None:
        a, b = req.seat_width_range_mm
        seat_width_mm = int(round((a + b) / 2))

    # 3) User overrides > defaults
    seat_count = req.seat_count or defaults["seat_count"]
    seat_height_mm = req.seat_height_mm or defaults["seat_height_mm"]
    seat_depth_mm = req.seat_depth_mm or defaults["seat_depth_mm"]

    has_chaise = req.has_chaise if req.has_chaise is not None else defaults["has_chaise"]
    transformable = req.transformable if req.transformable is not None else defaults["transformable"]

    # 4) legs/arms/frame dicts
    legs_dict = dict(defaults["legs"])
    if req.leg_family is not None:
        legs_dict["family"] = req.leg_family

    arms_dict = dict(defaults["arms"])
    if req.armrests is not None:
        arms_dict["type"] = req.armrests
        if req.armrests == ArmrestType.none:
            arms_dict["width_mm"] = 0

    frame_dict = dict(defaults["frame"])

    # 5) Preferences bias (safe, optional)
    if req.preferences is not None:
        prefs = req.preferences

        # leg thickness bias: only applies to families that use radii
        if prefs.leg_thickness_bias in {"thin", "thick"}:
            fam = legs_dict.get("family")
            params = dict(legs_dict.get("params", {}))

            # only for tapered_cone/cylindrical where r_top/r_bottom make sense
            if fam in {LegFamily.tapered_cone, LegFamily.cylindrical}:
                r_top = int(params.get("r_top", 22))
                r_bottom = int(params.get("r_bottom", 12))

                if prefs.leg_thickness_bias == "thin":
                    r_top = max(10, int(round(r_top * 0.8)))
                    r_bottom = max(6, int(round(r_bottom * 0.8)))
                else:  # thick
                    r_top = min(45, int(round(r_top * 1.2)))
                    r_bottom = min(40, int(round(r_bottom * 1.2)))

                params["r_top"] = r_top
                params["r_bottom"] = r_bottom
                legs_dict["params"] = params

        # arm profile preference
        if prefs.arm_profile is not None:
            arms_dict["profile"] = prefs.arm_profile

        # seat softness -> choose cushion seat type for soft/medium
        if prefs.seat_softness in {"soft", "medium"}:
            seat_type = SeatType.cushions
        else:
            seat_type = defaults["seat_type"]
    else:
        seat_type = defaults["seat_type"]

    return SofaResolved(
        style=req.style,
        layout=req.layout,
        orientation=orientation,

        seat_count=seat_count,
        seat_height_mm=seat_height_mm,
        seat_depth_mm=seat_depth_mm,
        seat_width_mm=seat_width_mm,

        has_chaise=has_chaise,
        transformable=transformable,
        seat_type=seat_type,

        legs=LegsSpec(**legs_dict),
        arms=ArmsSpec(**arms_dict),
        frame=FrameSpec(**frame_dict),
    )



===== FILE: tools/blender/batch_debug_run.py =====
"""Batch Blender debug runs for a directory of IR JSON files.

Usage:
  blender --background --python tools/blender/batch_debug_run.py -- <input_dir> <output_dir>
"""

from __future__ import annotations

import csv
import json
import os
import sys
from copy import deepcopy
from pathlib import Path
from typing import Any


REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from tools.blender import debug_run as single_debug_run  # noqa: E402
from tools.blender.debug.autofix import fix_ir  # noqa: E402
from tools.blender.debug.io import ensure_dir, save_json  # noqa: E402
from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
from tools.blender.debug.validators import validate  # noqa: E402
from tools.blender.debug.visualize import apply_debug_visualization  # noqa: E402


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _safe_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def _env_flag(name: str, default: bool = False) -> bool:
    raw = str(os.environ.get(name, "1" if default else "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _env_int(name: str, default: int, min_value: int = 1) -> int:
    raw = os.environ.get(name, str(default))
    try:
        value = int(raw)
    except (TypeError, ValueError):
        value = int(default)
    return max(int(min_value), int(value))


def _resolve_path(path: str) -> Path:
    candidate = Path(path)
    if candidate.is_absolute():
        return candidate
    return Path(REPO_ROOT) / candidate


def _parse_args() -> tuple[Path, Path]:
    args: list[str]
    if "--" in sys.argv:
        idx = sys.argv.index("--")
        args = [str(item).strip() for item in sys.argv[idx + 1 :]]
    else:
        args = [str(item).strip() for item in sys.argv[1:]]

    if len(args) >= 2:
        return _resolve_path(args[0]), _resolve_path(args[1])

    env_in = str(os.environ.get("DEBUG_BATCH_INPUT_DIR", "")).strip()
    env_out = str(os.environ.get("DEBUG_BATCH_OUTPUT_DIR", "")).strip()
    if env_in and env_out:
        return _resolve_path(env_in), _resolve_path(env_out)

    raise RuntimeError(
        "Usage: blender --background --python tools/blender/batch_debug_run.py -- <input_dir> <output_dir>"
    )


def _looks_like_ir(payload: Any) -> bool:
    return isinstance(payload, dict) and any(
        key in payload for key in ("slats", "back_support", "seat_width_mm", "seat_depth_mm")
    )


def _load_ir(path: Path) -> dict[str, Any]:
    with path.open("r", encoding="utf-8") as handle:
        payload = json.load(handle)
    if not _looks_like_ir(payload):
        raise ValueError(f"{path.name}: payload is not an IR JSON object")
    return payload


def _overlap_total(metrics: dict[str, Any], key: str) -> float:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return 0.0
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return 0.0
    return float(_safe_float(entry.get("total_volume", 0.0), 0.0))


def _run_one_ir(
    ir_path: Path,
    *,
    debug_iters: int,
    debug_autofix: bool,
    snapshot_blend_dir: Path | None,
    camera_lens_mm: float,
) -> dict[str, Any]:
    source_ir = _load_ir(ir_path)
    current_ir = deepcopy(source_ir)

    prev_metrics: dict[str, Any] | None = None
    autofix_context: dict[str, Any] = {}
    patches_applied: list[dict[str, Any]] = []

    final_metrics: dict[str, Any] = {}
    final_validation: dict[str, Any] = {"score": 0.0, "problem_count": 0, "problems": []}

    for idx in range(1, debug_iters + 1):
        single_debug_run._build_scene_from_ir(current_ir)
        metrics = collect_scene_metrics()
        validation_payload = validate(current_ir, metrics)

        if debug_autofix and idx < debug_iters:
            problems = validation_payload.get("problems", [])
            if not isinstance(problems, list):
                problems = []
            updated_ir, iteration_patches = fix_ir(
                current_ir,
                problems,
                metrics=metrics,
                validation=validation_payload,
                prev_metrics=prev_metrics,
                context=autofix_context,
            )
            current_ir = updated_ir
            patches_applied.extend(iteration_patches)

        final_metrics = metrics
        final_validation = validation_payload
        prev_metrics = metrics

    top_pair = single_debug_run._top_overlap_offender_pair(final_validation, final_metrics)
    if top_pair and isinstance(final_metrics, dict):
        final_metrics["top_offender_pair"] = top_pair

    if snapshot_blend_dir is not None:
        ensure_dir(str(snapshot_blend_dir))
        blend_path = snapshot_blend_dir / f"{ir_path.stem}.blend"
        apply_debug_visualization(
            validation=final_validation,
            metrics=final_metrics,
            snapshot_blend_path=str(blend_path),
            snapshot_png_path=None,
            camera_lens_mm=float(camera_lens_mm),
        )

    return {
        "ir_path": str(ir_path),
        "ir_out": current_ir,
        "metrics": final_metrics,
        "validation": final_validation,
        "patches_applied": patches_applied,
    }


def _write_summary_csv(path: Path, rows: list[dict[str, Any]]) -> None:
    fieldnames = [
        "file_name",
        "debug_score",
        "problems_count",
        "overlaps_slats_m3",
        "overlaps_back_m3",
        "fixes_applied_count",
    ]
    ensure_dir(str(path.parent))
    with path.open("w", encoding="utf-8", newline="") as handle:
        writer = csv.DictWriter(handle, fieldnames=fieldnames)
        writer.writeheader()
        for row in rows:
            writer.writerow(row)


def main() -> int:
    try:
        import bpy  # type: ignore  # noqa: F401
    except Exception as exc:
        print(f"BATCH_DEBUG_ERROR:bpy unavailable ({exc})", file=sys.stderr)
        return 3

    try:
        input_dir, output_dir = _parse_args()
    except Exception as exc:
        print(f"BATCH_DEBUG_ERROR:{exc}", file=sys.stderr)
        return 2

    if not input_dir.exists() or not input_dir.is_dir():
        print(f"BATCH_DEBUG_ERROR: input_dir not found: {input_dir}", file=sys.stderr)
        return 2

    ensure_dir(str(output_dir))
    debug_iters = _env_int("DEBUG_ITERS", 1, min_value=1)
    debug_autofix = _env_flag("DEBUG_AUTOFIX", default=False)
    camera_lens_mm = float(_safe_float(os.environ.get("DEBUG_SNAPSHOT_LENS_MM", "50"), 50.0))

    snapshot_blend_dir_raw = str(os.environ.get("DEBUG_SNAPSHOT_BLEND_DIR", "")).strip()
    snapshot_blend_dir = _resolve_path(snapshot_blend_dir_raw) if snapshot_blend_dir_raw else None

    ir_files = sorted(input_dir.glob("*.json"))
    if not ir_files:
        print(f"BATCH_DEBUG_FILES:0")
        print(f"BATCH_DEBUG_SUMMARY:{output_dir / 'summary.csv'}")
        return 0

    summary_rows: list[dict[str, Any]] = []
    for ir_path in ir_files:
        print(f"BATCH_DEBUG_RUN:{ir_path.name}")
        try:
            result = _run_one_ir(
                ir_path,
                debug_iters=debug_iters,
                debug_autofix=debug_autofix,
                snapshot_blend_dir=snapshot_blend_dir,
                camera_lens_mm=camera_lens_mm,
            )
            metrics = result.get("metrics", {})
            validation = result.get("validation", {})
            patches_applied = result.get("patches_applied", [])

            out_prefix = output_dir / ir_path.stem
            save_json(str(out_prefix.with_suffix(".validation.json")), validation)
            save_json(str(out_prefix.with_suffix(".metrics.json")), metrics)
            save_json(str(out_prefix.with_suffix(".ir_out.json")), result.get("ir_out", {}))

            summary_rows.append(
                {
                    "file_name": ir_path.name,
                    "debug_score": f"{_safe_float(validation.get('score', 0.0), 0.0):.6f}",
                    "problems_count": int(_safe_int(validation.get("problem_count", 0), 0)),
                    "overlaps_slats_m3": f"{_overlap_total(metrics, 'slats_vs_frame'):.6g}",
                    "overlaps_back_m3": f"{_overlap_total(metrics, 'back_slats_vs_frame'):.6g}",
                    "fixes_applied_count": len(patches_applied) if isinstance(patches_applied, list) else 0,
                }
            )
        except Exception as exc:
            print(f"BATCH_DEBUG_ERROR file={ir_path.name}: {exc}", file=sys.stderr)
            summary_rows.append(
                {
                    "file_name": ir_path.name,
                    "debug_score": "0.000000",
                    "problems_count": -1,
                    "overlaps_slats_m3": "0",
                    "overlaps_back_m3": "0",
                    "fixes_applied_count": 0,
                }
            )

    summary_path = output_dir / "summary.csv"
    _write_summary_csv(summary_path, summary_rows)
    print(f"BATCH_DEBUG_FILES:{len(summary_rows)}")
    print(f"BATCH_DEBUG_SUMMARY:{summary_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())



===== FILE: tools/blender/debug/__init__.py =====
"""Debug tooling for Blender sofa builds."""




===== FILE: tools/blender/debug/autofix.py =====
"""Rule-based IR autofixes for debug validator problems."""

from __future__ import annotations

import json
import math
import os
from copy import deepcopy
from typing import Any


def _as_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _as_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def read_env_float(name: str, default: float) -> float:
    raw = os.getenv(name, str(default))
    try:
        return float(raw)
    except (TypeError, ValueError):
        return float(default)


def bbox_spans_m(bbox_world: Any) -> tuple[float, float, float]:
    if not isinstance(bbox_world, dict):
        return 0.0, 0.0, 0.0

    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return 0.0, 0.0, 0.0
    if len(min_corner) < 3 or len(max_corner) < 3:
        return 0.0, 0.0, 0.0

    sx = max(0.0, _as_float(max_corner[0], 0.0) - _as_float(min_corner[0], 0.0))
    sy = max(0.0, _as_float(max_corner[1], 0.0) - _as_float(min_corner[1], 0.0))
    sz = max(0.0, _as_float(max_corner[2], 0.0) - _as_float(min_corner[2], 0.0))
    return float(sx), float(sy), float(sz)


def bbox_min_span_axis(bbox_world: Any) -> tuple[str, float]:
    sx, sy, sz = bbox_spans_m(bbox_world)
    axis, span = min(
        (("x", sx), ("y", sy), ("z", sz)),
        key=lambda item: float(item[1]),
    )
    return str(axis), float(span)


def _axis_index(axis: str) -> int:
    axis_map = {"x": 0, "y": 1, "z": 2}
    return int(axis_map.get(str(axis).strip().lower(), 0))


def _bbox_center_axis(bbox_world: Any, axis: str) -> float:
    if not isinstance(bbox_world, dict):
        return 0.0
    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return 0.0
    index = _axis_index(axis)
    if len(min_corner) <= index or len(max_corner) <= index:
        return 0.0
    min_value = _as_float(min_corner[index], 0.0)
    max_value = _as_float(max_corner[index], 0.0)
    return float((min_value + max_value) * 0.5)


def _bbox_axis_bounds(bbox_world: Any, axis: str) -> tuple[float, float] | None:
    if not isinstance(bbox_world, dict):
        return None
    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return None
    index = _axis_index(axis)
    if len(min_corner) <= index or len(max_corner) <= index:
        return None
    min_value = _as_float(min_corner[index], 0.0)
    max_value = _as_float(max_corner[index], 0.0)
    if min_value <= max_value:
        return float(min_value), float(max_value)
    return float(max_value), float(min_value)


def _signed_delta_mm(delta_mm: int, direction: int) -> int:
    magnitude = max(1, abs(int(delta_mm)))
    sign = 1 if int(direction) >= 0 else -1
    return int(sign * magnitude)


def _metrics_object_bbox(metrics: dict[str, Any] | None, name: str) -> dict[str, Any] | None:
    if not isinstance(metrics, dict):
        return None
    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return None
    needle = str(name).strip().lower()
    if not needle:
        return None
    for obj in objects:
        if not isinstance(obj, dict):
            continue
        if str(obj.get("name", "")).strip().lower() != needle:
            continue
        bbox_world = obj.get("bbox_world")
        if isinstance(bbox_world, dict):
            return bbox_world
        return None
    return None


def _rail_direction_hint(name: str) -> int | None:
    lowered = str(name).strip().lower()
    if not lowered:
        return None
    if ("back_rail_left" in lowered) or ("rail_left" in lowered):
        return 1
    if ("back_rail_right" in lowered) or ("rail_right" in lowered):
        return -1
    return None


def _resolve_direction(pair: dict[str, Any] | None, axis: str, metrics: dict[str, Any] | None) -> int:
    axis_name = str(axis).strip().lower()
    left_name = str((pair or {}).get("left", ""))
    right_name = str((pair or {}).get("right", ""))
    left_bbox = _metrics_object_bbox(metrics, left_name)
    right_bbox = _metrics_object_bbox(metrics, right_name)
    if left_bbox and right_bbox:
        left_center = _bbox_center_axis(left_bbox, axis_name)
        right_center = _bbox_center_axis(right_bbox, axis_name)
        return 1 if left_center > right_center else -1

    if axis_name == "x":
        rail_hint = _rail_direction_hint(right_name)
        if rail_hint is not None:
            return int(rail_hint)

    overlap_center = _bbox_center_axis((pair or {}).get("bbox_world"), axis_name)
    if axis_name == "x":
        if overlap_center < 0.0:
            return 1
        if overlap_center > 0.0:
            return -1
    return 1 if overlap_center < 0.0 else -1


def mm_from_m(m: float) -> int:
    return int(math.ceil(max(0.0, float(m)) * 1000.0))


def _clamp(value: float, min_value: float | None = None, max_value: float | None = None) -> float:
    result = float(value)
    if min_value is not None:
        result = max(float(min_value), result)
    if max_value is not None:
        result = min(float(max_value), result)
    return result


def _verbose_enabled() -> bool:
    raw = str(os.getenv("DEBUG_AUTOFIX_VERBOSE", "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _vprint(enabled: bool, message: str) -> None:
    if enabled:
        print(message)


def _get_path(root: dict[str, Any], path: str) -> tuple[bool, Any]:
    keys = [k for k in path.split(".") if k]
    if not keys:
        return False, None

    node: Any = root
    for key in keys[:-1]:
        if not isinstance(node, dict):
            return False, None
        node = node.get(key)
        if node is None:
            return False, None

    if not isinstance(node, dict):
        return False, None
    leaf = keys[-1]
    if leaf not in node:
        return False, None
    return True, node.get(leaf)


def _set_path(root: dict[str, Any], path: str, new_value: Any, patches: list[dict[str, Any]]) -> bool:
    keys = [k for k in path.split(".") if k]
    if not keys:
        return False

    node: dict[str, Any] = root
    for key in keys[:-1]:
        next_node = node.get(key)
        if not isinstance(next_node, dict):
            next_node = {}
            node[key] = next_node
        node = next_node

    leaf = keys[-1]
    old_value = node.get(leaf)
    if old_value == new_value:
        return False

    node[leaf] = new_value
    patches.append({"path": path, "old": old_value, "new": new_value})
    return True


def _coerce_numeric(value: float, old_value: Any) -> int | float:
    if isinstance(old_value, bool):
        return int(round(value))
    if isinstance(old_value, int):
        return int(round(value))
    if isinstance(old_value, float):
        return float(value)
    rounded = round(float(value))
    if abs(float(value) - float(rounded)) < 1e-9:
        return int(rounded)
    return float(value)


def _inc_path_clamped(
    ir: dict[str, Any],
    path: str,
    delta: float,
    min_value: float,
    max_value: float,
    patches: list[dict[str, Any]],
) -> tuple[bool, int | float, Any]:
    exists, old_value = _get_path(ir, path)
    base_value = _as_float(old_value, 0.0) if exists else 0.0
    new_numeric = _clamp(base_value + float(delta), min_value=min_value, max_value=max_value)
    new_value = _coerce_numeric(new_numeric, old_value)
    changed = _set_path(ir, path, new_value, patches)
    return changed, new_value, old_value


def _log_pair_context(
    *,
    verbose: bool,
    code: str,
    pair: dict[str, Any] | None,
    axis: str,
    span_m: float,
    delta_mm: int,
    safety_mm: int,
) -> None:
    if not verbose:
        return
    left_name = str((pair or {}).get("left", ""))
    right_name = str((pair or {}).get("right", ""))
    _vprint(
        True,
        (
            f"[autofix] code={code} "
            f"pair={left_name}->{right_name} "
            f"axis={axis} span_m={span_m:.6g} "
            f"delta_mm={delta_mm} safety_mm={safety_mm}"
        ),
    )


def _log_patch_change(
    *,
    verbose: bool,
    code: str,
    path: str,
    old_value: Any,
    new_value: Any,
) -> None:
    if not verbose:
        return
    _vprint(True, f"[autofix] code={code} patch {path}: {old_value} -> {new_value}")


def _normalize_code(code: str) -> str:
    normalized = code.strip().upper()
    aliases = {
        "INTERSECTION_SLATS_FRAME": "OVERLAP_SLATS_FRAME",
        "INTERSECTION_SLATS_ARMS": "OVERLAP_SLATS_ARMS",
    }
    return aliases.get(normalized, normalized)


def _problem_details(problem: dict[str, Any]) -> dict[str, Any]:
    details = problem.get("details", {})
    if isinstance(details, dict):
        return details
    return {}


def _problem_total_volume(problem: dict[str, Any]) -> float:
    details = _problem_details(problem)
    for key in ("total_volume_m3", "volume_m3", "total_volume"):
        if key in details:
            return _as_float(details.get(key), 0.0)
    return 0.0


def _problem_pairs_top(problem: dict[str, Any]) -> list[dict[str, Any]]:
    details = _problem_details(problem)
    pairs = details.get("pairs_top", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def get_top_pair(problem: dict[str, Any]) -> dict[str, Any] | None:
    pairs = _problem_pairs_top(problem)
    if not pairs:
        return None
    return pairs[0]


def _top_pair(problem: dict[str, Any], metrics: dict[str, Any] | None, overlap_key: str) -> dict[str, Any] | None:
    from_problem = get_top_pair(problem)
    if from_problem is not None:
        return from_problem

    pairs = _overlap_pairs(metrics, overlap_key)
    if not pairs:
        return None
    return max(pairs, key=lambda pair: _as_float(pair.get("volume", 0.0), 0.0))


def _safety_mm() -> int:
    return max(0, int(math.ceil(read_env_float("DEBUG_AUTOFIX_SAFETY_MM", 2.0))))


def _delta_from_pair(pair: dict[str, Any] | None, safety_mm: int) -> tuple[str, float, int]:
    if not isinstance(pair, dict):
        return "x", 0.0, 2
    axis, span_m = bbox_min_span_axis(pair.get("bbox_world"))
    if span_m <= 0.0:
        return axis, 0.0, 2
    delta_mm = mm_from_m(span_m) + int(max(0, safety_mm))
    return axis, float(span_m), int(max(1, delta_mm))


def _overlap_total_m3(metrics: dict[str, Any] | None, key: str) -> float | None:
    if not isinstance(metrics, dict):
        return None
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return None
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return None
    return float(_as_float(entry.get("total_volume", 0.0), 0.0))


def is_effective(
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    key: str,
    eps_m3: float | None = None,
) -> bool:
    eps = float(read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8) if eps_m3 is None else eps_m3)
    raw_prev = _overlap_total_m3(prev_metrics, key)
    raw_new = _overlap_total_m3(metrics, key)
    if (raw_prev is None) and (raw_new is None):
        return False
    prev_overlap, new_overlap = _resolved_overlap_pair_m3(prev_metrics, metrics, key)
    if float(new_overlap) <= eps:
        return True
    return (float(prev_overlap) - float(new_overlap)) >= eps


def _format_overlap(value: float | None) -> str:
    if value is None:
        return "n/a"
    return f"{float(value):.6g}"


def _resolved_overlap_pair_m3(
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    key: str,
) -> tuple[float, float]:
    prev_overlap = _overlap_total_m3(prev_metrics, key)
    new_overlap = _overlap_total_m3(metrics, key)
    if prev_overlap is None and new_overlap is None:
        return 0.0, 0.0
    if prev_overlap is None:
        prev_overlap = float(_as_float(new_overlap, 0.0))
    if new_overlap is None:
        new_overlap = float(_as_float(prev_overlap, 0.0))
    return float(prev_overlap), float(new_overlap)


def _log_effect_decision(
    *,
    verbose: bool,
    code: str,
    key: str,
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    eps_m3: float,
) -> tuple[bool, float, float, float]:
    prev_overlap, new_overlap = _resolved_overlap_pair_m3(prev_metrics, metrics, key)
    delta_overlap = float(prev_overlap - new_overlap)
    effective = is_effective(prev_metrics, metrics, key, eps_m3=eps_m3)
    if verbose:
        _vprint(
            True,
            (
                f"[autofix] code={code} overlap_key={key} "
                f"prev_overlap={_format_overlap(prev_overlap)} "
                f"new_overlap={_format_overlap(new_overlap)} "
                f"delta_overlap={delta_overlap:.6g} "
                f"effect_eps_m3={float(eps_m3):.6g} "
                f"effective={effective}"
            ),
        )
    return effective, prev_overlap, new_overlap, delta_overlap


def _overlap_entry(metrics: dict[str, Any] | None, key: str) -> dict[str, Any]:
    if not isinstance(metrics, dict):
        return {}
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return {}
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return {}
    return entry


def _overlap_pairs(metrics: dict[str, Any] | None, key: str) -> list[dict[str, Any]]:
    entry = _overlap_entry(metrics, key)
    pairs = entry.get("pairs", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def _overlap_total(metrics: dict[str, Any] | None, key: str, problem: dict[str, Any]) -> float:
    entry = _overlap_entry(metrics, key)
    total = _as_float(entry.get("total_volume", 0.0), 0.0)
    if total > 0.0:
        return total
    return _problem_total_volume(problem)


def _fix_slats_not_bent(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    slats = ir.get("slats", {})
    if not isinstance(slats, dict):
        slats = {}
        ir["slats"] = slats

    old_arc = _as_float(slats.get("arc_height_mm", 0.0), 0.0)
    new_arc = _clamp(old_arc + 5.0, max_value=60.0)
    _set_path(ir, "slats.arc_height_mm", new_arc, patches)

    if "subdiv_cuts" in slats:
        old_cuts = _as_int(slats.get("subdiv_cuts", 0), 0)
        new_cuts = int(_clamp(float(old_cuts + 8), min_value=0.0, max_value=256.0))
        _set_path(ir, "slats.subdiv_cuts", new_cuts, patches)


def _fix_back_slats_not_bent(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    back_support = ir.get("back_support", {})
    if not isinstance(back_support, dict):
        back_support = {}
        ir["back_support"] = back_support
    slats = back_support.get("slats", {})
    if not isinstance(slats, dict):
        slats = {}
        back_support["slats"] = slats

    old_arc = _as_float(slats.get("arc_height_mm", 0.0), 0.0)
    new_arc = _clamp(old_arc + 3.0, max_value=40.0)
    _set_path(ir, "back_support.slats.arc_height_mm", new_arc, patches)


def _fix_overlap_slats_frame(
    ir: dict[str, Any],
    patches: list[dict[str, Any]],
    metrics: dict[str, Any] | None,
    prev_metrics: dict[str, Any] | None,
    problem: dict[str, Any],
    verbose: bool,
) -> None:
    code = "OVERLAP_SLATS_FRAME"
    overlap_key = "slats_vs_frame"
    pair = _top_pair(problem, metrics, "slats_vs_frame")
    right_name = str((pair or {}).get("right", "")).lower()
    safety_mm = _safety_mm()
    axis, span_m, delta_mm = _delta_from_pair(pair, safety_mm=safety_mm)
    effect_eps_m3 = read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8)
    _log_pair_context(
        verbose=verbose,
        code=code,
        pair=pair,
        axis=axis,
        span_m=span_m,
        delta_mm=delta_mm,
        safety_mm=safety_mm,
    )
    effective, _, _, _ = _log_effect_decision(
        verbose=verbose,
        code=code,
        key=overlap_key,
        prev_metrics=prev_metrics,
        metrics=metrics,
        eps_m3=effect_eps_m3,
    )

    has_mount_offset, _ = _get_path(ir, "slats.mount_offset_mm")
    has_rail_inset, _ = _get_path(ir, "slats.rail_inset_mm")

    clearance_delta = float(max(1, int(math.ceil(float(delta_mm) / 4.0))))
    mount_delta = float(max(1, int(math.ceil(float(delta_mm) / 2.0))))
    rail_inset_delta = float(max(1, int(math.ceil(float(delta_mm) / 2.0))))
    safe_fallback_clearance = float(2 if int(delta_mm) >= 4 else 1)

    Strategy = tuple[str, str, float, float, float, bool]

    def _apply_strategy(strategy: Strategy, step: str) -> bool:
        strategy_name, path, delta, min_value, max_value, require_existing = strategy
        if require_existing:
            exists, _ = _get_path(ir, path)
            if not exists:
                if verbose:
                    _vprint(
                        True,
                        f"[autofix] code={code} skip_strategy={strategy_name} reason=missing_path path={path}",
                    )
                return False
        changed, new_value, old_value = _inc_path_clamped(
            ir,
            path,
            float(delta),
            float(min_value),
            float(max_value),
            patches,
        )
        if changed:
            _log_patch_change(
                verbose=verbose,
                code=code,
                path=path,
                old_value=old_value,
                new_value=new_value,
            )
        if verbose:
            _vprint(
                True,
                f"[autofix] code={code} chosen_strategy={strategy_name} chosen_param={path} step={step}",
            )
        return True

    group = "other"
    if right_name.startswith("rail_") or ("rail_left" in right_name) or ("rail_right" in right_name):
        group = "rail"
    elif right_name.startswith("beam_cross_"):
        group = "beam"

    primary: Strategy
    secondary: Strategy | None = None
    fallback: Strategy = (
        "safe_fallback_clearance",
        "slats.clearance_mm",
        safe_fallback_clearance,
        0.0,
        12.0,
        False,
    )

    if group == "rail":
        if axis == "x":
            primary = ("rail_axis_x_margin_x", "slats.margin_x_mm", float(delta_mm), 0.0, 80.0, False)
            secondary = ("rail_axis_x_rail_inset", "slats.rail_inset_mm", rail_inset_delta, 0.0, 20.0, True)
        elif axis == "y":
            primary = ("rail_axis_y_margin_y", "slats.margin_y_mm", float(delta_mm), 0.0, 120.0, False)
        else:  # axis == "z"
            if has_mount_offset:
                primary = ("rail_axis_z_mount_offset", "slats.mount_offset_mm", mount_delta, 0.0, 80.0, True)
                secondary = ("rail_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
            else:
                primary = ("rail_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)

    elif group == "beam":
        if axis == "y":
            primary = ("beam_axis_y_margin_y", "slats.margin_y_mm", float(delta_mm), 0.0, 120.0, False)
        elif axis == "z":
            if has_mount_offset:
                primary = ("beam_axis_z_mount_offset", "slats.mount_offset_mm", mount_delta, 0.0, 80.0, True)
                secondary = ("beam_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
            else:
                primary = ("beam_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
        else:  # axis == "x"
            primary = ("beam_axis_x_margin_x_fallback", "slats.margin_x_mm", float(delta_mm), 0.0, 80.0, False)

    else:
        primary = ("other_axis_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)

    _apply_strategy(primary, step="primary")
    if effective:
        return

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_primary effective=False")
    secondary_applied = _apply_strategy(secondary, step="secondary") if secondary is not None else False
    if verbose and (secondary is None):
        _vprint(True, f"[autofix] code={code} secondary_strategy=none")
    if not secondary_applied and (secondary is not None) and verbose:
        _vprint(True, f"[autofix] code={code} secondary_strategy_skipped")

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_secondary effective=False fallback=true")
    _apply_strategy(fallback, step="fallback")


def _fix_overlap_back_slats_frame(
    ir: dict[str, Any],
    patches: list[dict[str, Any]],
    metrics: dict[str, Any] | None,
    prev_metrics: dict[str, Any] | None,
    problem: dict[str, Any],
    context: dict[str, Any] | None,
    verbose: bool,
) -> None:
    del context
    code = "OVERLAP_BACK_SLATS_FRAME"
    overlap_key = "back_slats_vs_frame"
    pair = _top_pair(problem, metrics, "back_slats_vs_frame")
    right_name = str((pair or {}).get("right", ""))
    right_name_lower = right_name.lower()
    left_name = str((pair or {}).get("left", ""))
    safety_mm = _safety_mm()
    axis, span_m, delta_mm = _delta_from_pair(pair, safety_mm=safety_mm)
    effect_eps_m3 = read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8)
    left_bbox_world = _metrics_object_bbox(metrics, left_name)
    right_bbox_world = _metrics_object_bbox(metrics, right_name)
    left_center_axis = _bbox_center_axis(left_bbox_world, axis) if left_bbox_world else None
    right_center_axis = _bbox_center_axis(right_bbox_world, axis) if right_bbox_world else None
    overlap_center_axis = _bbox_center_axis((pair or {}).get("bbox_world"), axis)
    slat_bounds = _bbox_axis_bounds(left_bbox_world, axis)
    rail_bounds = _bbox_axis_bounds(right_bbox_world, axis)
    slat_min_axis: float | None = None
    slat_max_axis: float | None = None
    rail_min_axis: float | None = None
    rail_max_axis: float | None = None
    if slat_bounds is not None:
        slat_min_axis, slat_max_axis = slat_bounds
    if rail_bounds is not None:
        rail_min_axis, rail_max_axis = rail_bounds

    push_plus_mm: int | None = None
    push_minus_mm: int | None = None
    rail_side_direction = _rail_direction_hint(right_name_lower)
    if axis in {"y", "z"} and (slat_bounds is not None) and (rail_bounds is not None):
        safety = int(max(0, safety_mm))
        push_plus_mm = int(math.ceil((float(rail_max_axis) - float(slat_min_axis)) * 1000.0)) + safety
        push_minus_mm = int(math.ceil((float(slat_max_axis) - float(rail_min_axis)) * 1000.0)) + safety
        chosen_signed_delta_mm = int(push_plus_mm if push_plus_mm <= push_minus_mm else -push_minus_mm)
        direction = 1 if chosen_signed_delta_mm >= 0 else -1
    else:
        direction = _resolve_direction(pair, axis, metrics)
        if axis == "x" and rail_side_direction is not None:
            direction = int(rail_side_direction)
        chosen_signed_delta_mm = _signed_delta_mm(delta_mm, direction)

    primary_direction = int(direction)
    axis_delta_mm = max(1, abs(int(chosen_signed_delta_mm)))
    left_center_text = "n/a" if left_center_axis is None else f"{float(left_center_axis):.6g}"
    right_center_text = "n/a" if right_center_axis is None else f"{float(right_center_axis):.6g}"
    slat_min_text = "n/a" if slat_min_axis is None else f"{float(slat_min_axis):.6g}"
    slat_max_text = "n/a" if slat_max_axis is None else f"{float(slat_max_axis):.6g}"
    rail_min_text = "n/a" if rail_min_axis is None else f"{float(rail_min_axis):.6g}"
    rail_max_text = "n/a" if rail_max_axis is None else f"{float(rail_max_axis):.6g}"
    push_plus_text = "n/a" if push_plus_mm is None else str(int(push_plus_mm))
    push_minus_text = "n/a" if push_minus_mm is None else str(int(push_minus_mm))
    _log_pair_context(
        verbose=verbose,
        code=code,
        pair=pair,
        axis=axis,
        span_m=span_m,
        delta_mm=axis_delta_mm,
        safety_mm=safety_mm,
    )
    if verbose:
        _vprint(
            True,
            (
                f"[autofix] code={code} pair={left_name}->{right_name} "
                f"axis={axis} dir={int(primary_direction):+d} span_m={span_m:.6g} delta_mm={axis_delta_mm} "
                f"slat_min={slat_min_text} slat_max={slat_max_text} "
                f"rail_min={rail_min_text} rail_max={rail_max_text} "
                f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                f"chosen_signed_delta_mm={int(chosen_signed_delta_mm)} "
                f"left_center={left_center_text} right_center={right_center_text} "
                f"overlap_center={overlap_center_axis:.6g}"
            ),
        )
    effective, _, _, _ = _log_effect_decision(
        verbose=verbose,
        code=code,
        key=overlap_key,
        prev_metrics=prev_metrics,
        metrics=metrics,
        eps_m3=effect_eps_m3,
    )

    Strategy = tuple[str, str, int, float, float, bool, int | None, int | None]

    def _apply_strategy(strategy: Strategy | None, step: str) -> bool:
        if strategy is None:
            return False
        (
            strategy_name,
            path,
            delta_mm_value,
            min_value,
            max_value,
            require_existing,
            forced_direction,
            forced_signed_delta_mm,
        ) = strategy
        direction_used = int(primary_direction if forced_direction is None else forced_direction)
        signed_delta = (
            int(forced_signed_delta_mm)
            if forced_signed_delta_mm is not None
            else _signed_delta_mm(delta_mm_value, direction_used)
        )
        if forced_signed_delta_mm is not None:
            direction_used = 1 if int(signed_delta) >= 0 else -1
        if require_existing:
            exists, _ = _get_path(ir, path)
            if not exists:
                if verbose:
                    _vprint(
                        True,
                        (
                            f"[autofix] code={code} pair={left_name}->{right_name} "
                            f"axis={axis} dir={int(direction_used):+d} span_m={span_m:.6g} delta_mm={delta_mm_value} "
                            f"slat_min={slat_min_text} slat_max={slat_max_text} "
                            f"rail_min={rail_min_text} rail_max={rail_max_text} "
                            f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                            f"chosen_signed_delta_mm={int(signed_delta)} "
                            f"chosen_strategy={strategy_name} param={path} reason=missing_path step={step}"
                        ),
                    )
                return False
        changed, new_value, old_value = _inc_path_clamped(
            ir,
            path,
            float(signed_delta),
            float(min_value),
            float(max_value),
            patches,
        )
        if verbose:
            left_center_text = "n/a" if left_center_axis is None else f"{float(left_center_axis):.6g}"
            right_center_text = "n/a" if right_center_axis is None else f"{float(right_center_axis):.6g}"
            _vprint(
                True,
                (
                    f"[autofix] code={code} pair={left_name}->{right_name} "
                    f"axis={axis} dir={int(direction_used):+d} span_m={span_m:.6g} delta_mm={delta_mm_value} "
                    f"slat_min={slat_min_text} slat_max={slat_max_text} "
                    f"rail_min={rail_min_text} rail_max={rail_max_text} "
                    f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                    f"chosen_signed_delta_mm={int(signed_delta)} chosen_strategy={strategy_name} param={path} "
                    f"old->new={old_value}->{new_value} changed={changed} step={step} "
                    f"left_center={left_center_text} right_center={right_center_text} "
                    f"overlap_center={overlap_center_axis:.6g}"
                ),
            )
        return True

    offset_delta_mm = max(1, int(math.ceil(float(axis_delta_mm) / 2.0)))
    safe_delta_mm = 2 if int(axis_delta_mm) >= 4 else 1
    safe_offset_delta_mm = max(1, int(math.ceil(float(safe_delta_mm) / 2.0)))

    primary: Strategy
    secondary: Strategy | None = None
    fallback: Strategy

    if axis == "y":
        primary = (
            "axis_y_offset_y_primary",
            "back_support.offset_y_mm",
            int(axis_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            int(chosen_signed_delta_mm),
        )
        secondary = (
            "axis_y_margin_z_secondary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            None,
        )
        fallback = (
            "axis_y_offset_y_safe_fallback",
            "back_support.offset_y_mm",
            int(safe_offset_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            None,
        )
    elif axis == "z":
        primary = (
            "axis_z_margin_z_primary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            int(chosen_signed_delta_mm),
        )
        secondary = (
            "axis_z_offset_y_secondary",
            "back_support.offset_y_mm",
            int(offset_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            None,
        )
        fallback = (
            "axis_z_margin_z_safe_fallback",
            "back_support.margin_z_mm",
            int(safe_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            None,
        )
    else:  # axis == "x"
        primary = (
            "axis_x_margin_x_primary",
            "back_support.margin_x_mm",
            int(axis_delta_mm),
            0.0,
            80.0,
            False,
            int(primary_direction),
            None,
        )
        secondary = (
            "axis_x_margin_z_secondary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(primary_direction),
            None,
        )
        fallback = (
            "axis_x_margin_x_safe_fallback",
            "back_support.margin_x_mm",
            int(safe_delta_mm),
            0.0,
            80.0,
            False,
            int(primary_direction),
            None,
        )

    _apply_strategy(primary, step="primary")
    if effective:
        return

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_primary effective=False")
    secondary_applied = _apply_strategy(secondary, step="secondary")
    if verbose and (secondary is None):
        _vprint(True, f"[autofix] code={code} secondary_strategy=none")
    if not secondary_applied and (secondary is not None) and verbose:
        _vprint(True, f"[autofix] code={code} secondary_strategy_skipped")
    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_secondary effective=False fallback=true")
    _apply_strategy(fallback, step="fallback")


def _fix_overlap_slats_arms(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    _inc_path_clamped(ir, "slats.margin_x_mm", 5.0, 0.0, 200.0, patches)


def _resolve_problems(
    problems: list[dict[str, Any]] | None,
    validation: dict[str, Any] | None,
) -> list[dict[str, Any]]:
    if isinstance(problems, list):
        return [item for item in problems if isinstance(item, dict)]
    if isinstance(validation, dict):
        candidate = validation.get("problems", [])
        if isinstance(candidate, list):
            return [item for item in candidate if isinstance(item, dict)]
    return []


def fix_ir(
    ir: dict[str, Any],
    problems: list[dict[str, Any]] | None = None,
    *,
    metrics: dict[str, Any] | None = None,
    validation: dict[str, Any] | None = None,
    prev_metrics: dict[str, Any] | None = None,
    context: dict[str, Any] | None = None,
) -> tuple[dict[str, Any], list[dict[str, Any]]]:
    """Apply MVP debug autofixes and return (new_ir, patches_applied)."""
    patched = deepcopy(ir)
    patches_applied: list[dict[str, Any]] = []
    handled_codes: set[str] = set()
    resolved_problems = _resolve_problems(problems, validation)
    verbose = _verbose_enabled()

    for problem in resolved_problems:
        code = _normalize_code(str(problem.get("code", "")))
        if not code or code in handled_codes:
            continue

        if code == "SLATS_NOT_BENT":
            _fix_slats_not_bent(patched, patches_applied)
            handled_codes.add(code)
            continue

        if code == "BACK_SLATS_NOT_BENT":
            _fix_back_slats_not_bent(patched, patches_applied)
            handled_codes.add(code)
            continue

        if code == "OVERLAP_SLATS_FRAME":
            _fix_overlap_slats_frame(
                patched,
                patches_applied,
                metrics=metrics,
                prev_metrics=prev_metrics,
                problem=problem,
                verbose=verbose,
            )
            handled_codes.add(code)
            continue

        if code == "OVERLAP_BACK_SLATS_FRAME":
            _fix_overlap_back_slats_frame(
                patched,
                patches_applied,
                metrics=metrics,
                prev_metrics=prev_metrics,
                problem=problem,
                context=context,
                verbose=verbose,
            )
            handled_codes.add(code)
            continue

        if code == "OVERLAP_SLATS_ARMS":
            _fix_overlap_slats_arms(patched, patches_applied)
            handled_codes.add(code)

    return patched, patches_applied


if __name__ == "__main__":
    os.environ["DEBUG_AUTOFIX_SAFETY_MM"] = str(_as_int(os.getenv("DEBUG_AUTOFIX_SAFETY_MM", 2), 2))
    os.environ["DEBUG_AUTOFIX_EFFECT_EPS_M3"] = str(read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8))

    ir_base: dict[str, Any] = {
        "slats": {
            "margin_x_mm": 40,
            "margin_y_mm": 55,
            "clearance_mm": 4,
            "mount_offset_mm": 3,
            "rail_inset_mm": 3,
        }
    }

    problem_axis_z = {
        "code": "OVERLAP_SLATS_FRAME",
        "details": {
            "pairs_top": [
                {
                    "left": "slat_1",
                    "right": "rail_left",
                    "volume": 1.0e-4,
                    "bbox_world": {
                        "min": [0.0, 0.0, 0.0],
                        "max": [0.010, 0.008, 0.001],
                    },
                }
            ]
        },
    }
    pair_z = get_top_pair(problem_axis_z)
    axis_z, span_z, delta_z = _delta_from_pair(pair_z, safety_mm=_safety_mm())
    before_margin_x_z = _as_int(ir_base["slats"]["margin_x_mm"], 0)
    before_clearance_z = _as_int(ir_base["slats"]["clearance_mm"], 0)
    before_mount_z = _as_int(ir_base["slats"]["mount_offset_mm"], 0)
    fixed_ir_z, patches_z = fix_ir(
        ir_base,
        problems=[problem_axis_z],
        metrics={"overlaps": {"slats_vs_frame": {"total_volume": 1.0e-3}}},
        prev_metrics=None,
        context=None,
        validation=None,
    )
    after_margin_x_z = _as_int(fixed_ir_z.get("slats", {}).get("margin_x_mm", 0), 0)
    after_clearance_z = _as_int(fixed_ir_z.get("slats", {}).get("clearance_mm", 0), 0)
    after_mount_z = _as_int(fixed_ir_z.get("slats", {}).get("mount_offset_mm", 0), 0)
    primary_path_z = str((patches_z[0] if patches_z else {}).get("path", ""))
    ok_axis_z = bool(
        (axis_z == "z")
        and (primary_path_z in {"slats.clearance_mm", "slats.mount_offset_mm"})
        and (after_margin_x_z == before_margin_x_z)
        and ((after_clearance_z > before_clearance_z) or (after_mount_z > before_mount_z))
    )

    print(f"SELF_TEST_SLATS_RAIL_AXIS_Z axis={axis_z} span_m={span_z:.6g} delta_mm={delta_z}")
    print(
        "SELF_TEST_SLATS_RAIL_AXIS_Z "
        f"margin_x before={before_margin_x_z} after={after_margin_x_z} "
        f"clearance before={before_clearance_z} after={after_clearance_z} "
        f"mount_offset before={before_mount_z} after={after_mount_z}"
    )
    print(f"SELF_TEST_SLATS_RAIL_AXIS_Z primary_patch={primary_path_z} ok={ok_axis_z}")
    print(json.dumps(patches_z, ensure_ascii=False, indent=2))

    problem_axis_x = {
        "code": "OVERLAP_SLATS_FRAME",
        "details": {
            "pairs_top": [
                {
                    "left": "slat_2",
                    "right": "rail_right",
                    "volume": 1.0e-4,
                    "bbox_world": {
                        "min": [0.0, 0.0, 0.0],
                        "max": [0.001, 0.010, 0.020],
                    },
                }
            ]
        },
    }
    pair_x = get_top_pair(problem_axis_x)
    axis_x, span_x, delta_x = _delta_from_pair(pair_x, safety_mm=_safety_mm())
    before_margin_x = _as_int(ir_base["slats"]["margin_x_mm"], 0)
    fixed_ir_x, patches_x = fix_ir(
        ir_base,
        problems=[problem_axis_x],
        metrics={"overlaps": {"slats_vs_frame": {"total_volume": 1.0e-3}}},
        prev_metrics=None,
        context=None,
        validation=None,
    )
    after_margin_x = _as_int(fixed_ir_x.get("slats", {}).get("margin_x_mm", 0), 0)
    primary_path_x = str((patches_x[0] if patches_x else {}).get("path", ""))
    ok_axis_x = bool((axis_x == "x") and (primary_path_x == "slats.margin_x_mm") and (after_margin_x > before_margin_x))

    print(f"SELF_TEST_SLATS_RAIL_AXIS_X axis={axis_x} span_m={span_x:.6g} delta_mm={delta_x}")
    print(f"SELF_TEST_SLATS_RAIL_AXIS_X margin_x before={before_margin_x} after={after_margin_x}")
    print(f"SELF_TEST_SLATS_RAIL_AXIS_X primary_patch={primary_path_x} ok={ok_axis_x}")
    print(json.dumps(patches_x, ensure_ascii=False, indent=2))

    direction_pair_left = {
        "left": "back_slat_1",
        "right": "back_rail_left",
        "bbox_world": {
            "min": [-0.024, 0.10, 0.42],
            "max": [-0.018, 0.14, 0.47],
        },
    }
    direction_pair_right = {
        "left": "back_slat_7",
        "right": "back_rail_right",
        "bbox_world": {
            "min": [0.018, 0.10, 0.42],
            "max": [0.024, 0.14, 0.47],
        },
    }
    direction_left = _resolve_direction(direction_pair_left, "x", metrics=None)
    direction_right = _resolve_direction(direction_pair_right, "x", metrics=None)
    ok_direction_left = bool(direction_left == 1)
    ok_direction_right = bool(direction_right == -1)
    print(
        f"SELF_TEST_BACK_DIRECTION_LEFT axis=x dir={direction_left:+d} "
        f"expected=+1 ok={ok_direction_left}"
    )
    print(
        f"SELF_TEST_BACK_DIRECTION_RIGHT axis=x dir={direction_right:+d} "
        f"expected=-1 ok={ok_direction_right}"
    )



===== FILE: tools/blender/debug/io.py =====
"""JSON I/O helpers for debug runs."""

from __future__ import annotations

import hashlib
import json
import os
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Mapping


def ir_sha256(ir: Mapping[str, Any]) -> str:
    """Return SHA256 of canonical IR JSON."""
    payload = json.dumps(ir, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(payload.encode("utf-8")).hexdigest()


def make_run_id(short_len: int = 8) -> str:
    """Return run id as run_YYYYmmdd_HHMMSS_<shortid>."""
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    short_id = uuid.uuid4().hex[: max(4, int(short_len))]
    return f"run_{timestamp}_{short_id}"


def save_json(path: str | os.PathLike[str], payload: Mapping[str, Any]) -> str:
    """Save JSON payload to path, creating parent directories."""
    output_path = Path(path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    return str(output_path)


def load_json(path: str | os.PathLike[str]) -> dict[str, Any]:
    """Load JSON object from path."""
    data = json.loads(Path(path).read_text(encoding="utf-8"))
    if not isinstance(data, dict):
        raise ValueError(f"Expected JSON object in {path}, got {type(data).__name__}")
    return data


def save_run_log(
    payload: Mapping[str, Any],
    out_dir: str | os.PathLike[str] = "out/logs/runs",
    run_id: str | None = None,
) -> str:
    """Save debug run payload as out/logs/runs/run_<timestamp>_<shortid>.json."""
    resolved_run_id = run_id or make_run_id()
    file_path = Path(out_dir) / f"{resolved_run_id}.json"
    return save_json(file_path, payload)


def load_run_log(path: str | os.PathLike[str]) -> dict[str, Any]:
    """Load a previously saved debug run log."""
    return load_json(path)

def ensure_dir(path: str | os.PathLike[str]) -> str:
    """Create directory if it doesn't exist. Returns normalized string path."""
    p = Path(path)
    p.mkdir(parents=True, exist_ok=True)
    return str(p)
def ensure_parent(path: str | os.PathLike[str]) -> str:
    """Ensure parent directory for a file path exists. Returns normalized string path."""
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    return str(p)
def ensure_dir(path: str | os.PathLike[str]) -> str:
    """Create directory if it doesn't exist. Returns normalized string path."""
    p = Path(path)
    p.mkdir(parents=True, exist_ok=True)
    return str(p)


def make_run_tag(*, run_id: str) -> str:
    """Return a stable tag for artifacts based on run_id."""
    # debug_run ожидает, что run_tag используется в именах файлов: <run_tag>.json / .metrics.json / .ir_in.json ...
    return str(run_id)


def sha256_file(path: str | os.PathLike[str]) -> str:
    """Compute SHA256 hex digest of a file."""
    p = Path(path)
    h = hashlib.sha256()
    with p.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def sha256_json(payload: Mapping[str, Any]) -> str:
    """Compute SHA256 of canonical JSON (stable across key order)."""
    s = json.dumps(payload, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(s.encode("utf-8")).hexdigest()



===== FILE: tools/blender/debug/metrics.py =====
"""Scene metrics collection for Blender debug runs."""

from __future__ import annotations

from datetime import datetime, timezone
from typing import Any, Iterable


GROUP_KEYS = ("slat_", "back_slat_", "arm_", "frame_", "leg_")


def _bbox_from_points(points: Iterable[tuple[float, float, float]]) -> dict[str, list[float]] | None:
    coords = list(points)
    if not coords:
        return None
    xs = [p[0] for p in coords]
    ys = [p[1] for p in coords]
    zs = [p[2] for p in coords]
    return {
        "min": [float(min(xs)), float(min(ys)), float(min(zs))],
        "max": [float(max(xs)), float(max(ys)), float(max(zs))],
    }


def _bbox_union(bboxes: Iterable[dict[str, list[float]] | None]) -> dict[str, list[float]] | None:
    valid = [b for b in bboxes if b]
    if not valid:
        return None
    return {
        "min": [
            float(min(b["min"][0] for b in valid)),
            float(min(b["min"][1] for b in valid)),
            float(min(b["min"][2] for b in valid)),
        ],
        "max": [
            float(max(b["max"][0] for b in valid)),
            float(max(b["max"][1] for b in valid)),
            float(max(b["max"][2] for b in valid)),
        ],
    }


def _bbox_spans(bbox: dict[str, list[float]] | None) -> dict[str, float]:
    if not bbox:
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    return {
        "x": float(max(0.0, bbox["max"][0] - bbox["min"][0])),
        "y": float(max(0.0, bbox["max"][1] - bbox["min"][1])),
        "z": float(max(0.0, bbox["max"][2] - bbox["min"][2])),
    }


def _bbox_overlap(a: dict[str, list[float]] | None, b: dict[str, list[float]] | None) -> tuple[float, dict[str, list[float]] | None]:
    if not a or not b:
        return 0.0, None
    min_corner = [
        max(float(a["min"][0]), float(b["min"][0])),
        max(float(a["min"][1]), float(b["min"][1])),
        max(float(a["min"][2]), float(b["min"][2])),
    ]
    max_corner = [
        min(float(a["max"][0]), float(b["max"][0])),
        min(float(a["max"][1]), float(b["max"][1])),
        min(float(a["max"][2]), float(b["max"][2])),
    ]
    dx = max_corner[0] - min_corner[0]
    dy = max_corner[1] - min_corner[1]
    dz = max_corner[2] - min_corner[2]
    if dx <= 0.0 or dy <= 0.0 or dz <= 0.0:
        return 0.0, None
    return float(dx * dy * dz), {"min": min_corner, "max": max_corner}


def _group_match(name: str, group_key: str) -> bool:
    lower_name = name.lower()
    if group_key == "slat_":
        return lower_name.startswith("slat_")
    if group_key == "back_slat_":
        return lower_name.startswith("back_slat_")
    if group_key == "arm_":
        return (
            lower_name.startswith("arm_")
            or lower_name.startswith("left_arm")
            or lower_name.startswith("right_arm")
            or "_arm_" in lower_name
        )
    if group_key == "frame_":
        return (
            lower_name.startswith("frame_")
            or lower_name.startswith("beam_")
            or lower_name.startswith("rail_")
            or lower_name.startswith("back_rail_")
            or lower_name in {"seat_support", "back_frame", "back_panel"}
        )
    if group_key == "leg_":
        return lower_name.startswith("leg_")
    return False


def _object_base_bbox_world(obj: Any) -> dict[str, list[float]] | None:
    from mathutils import Vector  # type: ignore

    if obj.type == "MESH" and getattr(obj, "data", None) and len(obj.data.vertices) > 0:
        points = []
        for vertex in obj.data.vertices:
            world = obj.matrix_world @ vertex.co
            points.append((float(world.x), float(world.y), float(world.z)))
        return _bbox_from_points(points)

    if hasattr(obj, "bound_box") and obj.bound_box:
        points = []
        for corner in obj.bound_box:
            world = obj.matrix_world @ Vector(corner)
            points.append((float(world.x), float(world.y), float(world.z)))
        return _bbox_from_points(points)

    location = getattr(obj, "location", None)
    if location is None:
        return None
    return {
        "min": [float(location.x), float(location.y), float(location.z)],
        "max": [float(location.x), float(location.y), float(location.z)],
    }


def _mesh_bbox_world(mesh: Any, matrix_world: Any) -> dict[str, list[float]] | None:
    if not mesh or len(mesh.vertices) == 0:
        return None
    points = []
    for vertex in mesh.vertices:
        world = matrix_world @ vertex.co
        points.append((float(world.x), float(world.y), float(world.z)))
    return _bbox_from_points(points)


def _modifier_info(modifier: Any) -> dict[str, Any]:
    payload: dict[str, Any] = {
        "name": str(getattr(modifier, "name", "")),
        "type": str(getattr(modifier, "type", "")),
    }
    if payload["type"] == "SIMPLE_DEFORM":
        payload["deform_method"] = str(getattr(modifier, "deform_method", ""))
        payload["axis"] = str(getattr(modifier, "deform_axis", ""))
        try:
            payload["angle"] = float(getattr(modifier, "angle", 0.0))
        except (TypeError, ValueError):
            payload["angle"] = 0.0
        origin_obj = getattr(modifier, "origin", None)
        payload["origin"] = origin_obj.name if origin_obj is not None else None
    return payload


def _collect_object_metrics(obj: Any, depsgraph: Any) -> dict[str, Any]:
    base_bbox = _object_base_bbox_world(obj)
    eval_bbox = base_bbox
    vertices = 0
    polygons = 0

    if obj.type == "MESH":
        eval_obj = obj.evaluated_get(depsgraph)
        eval_mesh = eval_obj.to_mesh()
        try:
            vertices = int(len(eval_mesh.vertices))
            polygons = int(len(eval_mesh.polygons))
            eval_bbox = _mesh_bbox_world(eval_mesh, eval_obj.matrix_world) or base_bbox
        finally:
            eval_obj.to_mesh_clear()

    base_spans = _bbox_spans(base_bbox)
    eval_spans = _bbox_spans(eval_bbox)
    bbox_delta = {
        "x": float(eval_spans["x"] - base_spans["x"]),
        "y": float(eval_spans["y"] - base_spans["y"]),
        "z": float(eval_spans["z"] - base_spans["z"]),
    }

    return {
        "name": str(obj.name),
        "type": str(obj.type),
        "verts": vertices,
        "polys": polygons,
        "modifiers": [_modifier_info(mod) for mod in obj.modifiers],
        "bbox_world": eval_bbox,
        "bbox_world_base": base_bbox,
        "bbox_spans": eval_spans,
        "bbox_spans_base": base_spans,
        "bbox_delta": bbox_delta,
    }


def _collect_groups(objects: list[dict[str, Any]]) -> dict[str, dict[str, Any]]:
    groups: dict[str, dict[str, Any]] = {}
    for key in GROUP_KEYS:
        members = [obj for obj in objects if _group_match(str(obj.get("name", "")), key)]
        groups[key] = {
            "count": len(members),
            "objects": [str(obj.get("name", "")) for obj in members],
            "bbox_world": _bbox_union(obj.get("bbox_world") for obj in members),
        }
    return groups


def _collect_overlap_pairs(
    left_names: Iterable[str],
    right_names: Iterable[str],
    object_index: dict[str, dict[str, Any]],
) -> dict[str, Any]:
    pairs: list[dict[str, Any]] = []
    total = 0.0
    for left_name in left_names:
        left_bbox = object_index.get(left_name, {}).get("bbox_world")
        if not left_bbox:
            continue
        for right_name in right_names:
            right_bbox = object_index.get(right_name, {}).get("bbox_world")
            if not right_bbox:
                continue
            volume, bbox = _bbox_overlap(left_bbox, right_bbox)
            if volume <= 0.0:
                continue
            total += volume
            pairs.append(
                {
                    "left": left_name,
                    "right": right_name,
                    "volume": float(volume),
                    "bbox_world": bbox,
                }
            )
    return {"total_volume": float(total), "pairs": pairs}


def collect_scene_metrics() -> dict[str, Any]:
    """Collect object-level and group-level Blender scene metrics."""
    import bpy  # type: ignore

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()
    try:
        depsgraph.update()
    except Exception:
        pass

    scene_objects = sorted(bpy.data.objects, key=lambda item: item.name.lower())
    objects = [_collect_object_metrics(obj, depsgraph) for obj in scene_objects]
    groups = _collect_groups(objects)
    object_index = {str(obj.get("name", "")): obj for obj in objects}

    overlaps = {
        "slats_vs_arms": _collect_overlap_pairs(
            groups["slat_"]["objects"],
            groups["arm_"]["objects"],
            object_index,
        ),
        "slats_vs_frame": _collect_overlap_pairs(
            groups["slat_"]["objects"],
            groups["frame_"]["objects"],
            object_index,
        ),
        "back_slats_vs_frame": _collect_overlap_pairs(
            groups["back_slat_"]["objects"],
            groups["frame_"]["objects"],
            object_index,
        ),
    }

    return {
        "timestamp_utc": datetime.now(timezone.utc).isoformat(),
        "units": {"length": "m", "volume": "m3"},
        "object_count": len(objects),
        "objects": objects,
        "groups": groups,
        "overlaps": overlaps,
    }



===== FILE: tools/blender/debug/validators.py =====
"""Validation rules and scoring for Blender debug metrics."""

from __future__ import annotations

import json
import os
import sys
from typing import Any


DEFAULT_OVERLAP_EPS = 1e-8
BEND_MOD_ANGLE_EPS = 1e-6


def _read_env_float(name: str, default: float) -> float:
    raw = os.getenv(name, str(default))
    try:
        return float(raw)
    except (TypeError, ValueError):
        return float(default)


def _read_env_int(name: str, default: int) -> int:
    raw = os.getenv(name, str(default))
    try:
        return int(raw)
    except (TypeError, ValueError):
        return int(default)


BEND_EPS_M = _read_env_float("DEBUG_BEND_EPS_M", 0.002)
CLEARANCE_EPS_M = _read_env_float("DEBUG_CLEARANCE_EPS_M", 0.003)
JOINT_OVERLAP_ALLOWANCE_MM = _read_env_float("DEBUG_JOINT_OVERLAP_ALLOWANCE_MM", 2.0)
MOD_EFFECT_EPS_M = _read_env_float("DEBUG_MOD_EFFECT_EPS_M", 0.001)
MOD_EFFECT_VERTS_EPS = _read_env_int("DEBUG_MOD_EFFECT_VERTS_EPS", 4)


def _as_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _as_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def _looks_like_metrics(payload: Any) -> bool:
    return isinstance(payload, dict) and any(k in payload for k in ("objects", "groups", "overlaps"))


def _looks_like_ir(payload: Any) -> bool:
    return isinstance(payload, dict) and any(k in payload for k in ("slats", "back_support", "seat_width_mm"))


def _normalize_validate_args(first: dict[str, Any], second: dict[str, Any]) -> tuple[dict[str, Any], dict[str, Any]]:
    """Allow both validate(ir, metrics) and legacy validate(metrics, ir)."""
    if _looks_like_metrics(first) and _looks_like_ir(second):
        return second, first
    return first, second


def _objects_by_prefix(metrics: dict[str, Any], prefix: str) -> list[dict[str, Any]]:
    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return []
    lowered = prefix.lower()
    return [
        obj
        for obj in objects
        if isinstance(obj, dict) and str(obj.get("name", "")).lower().startswith(lowered)
    ]


def _mesh_objects_by_prefix(metrics: dict[str, Any], prefix: str) -> list[dict[str, Any]]:
    return [
        obj
        for obj in _objects_by_prefix(metrics, prefix)
        if str(obj.get("type", "")).strip().upper() == "MESH"
    ]


def _bend_mod_summary(obj: dict[str, Any]) -> tuple[bool, float]:
    """Return (has_bend_modifier, max_abs_bend_angle)."""
    max_abs_angle = 0.0
    has_bend_modifier = False
    modifiers = obj.get("modifiers", [])
    if not isinstance(modifiers, list):
        return has_bend_modifier, max_abs_angle
    for modifier in modifiers:
        if not isinstance(modifier, dict):
            continue
        if str(modifier.get("type", "")).upper() != "SIMPLE_DEFORM":
            continue
        if str(modifier.get("deform_method", "")).upper() == "BEND":
            has_bend_modifier = True
            angle = abs(_as_float(modifier.get("angle", 0.0), 0.0))
            if angle > max_abs_angle:
                max_abs_angle = angle
    return has_bend_modifier, float(max_abs_angle)


def _bbox_delta_axis(obj: dict[str, Any], axis: str) -> float:
    bbox_delta = obj.get("bbox_delta", {})
    if not isinstance(bbox_delta, dict):
        return 0.0
    return abs(_as_float(bbox_delta.get(axis, 0.0), 0.0))


def _bbox_delta_abs_xyz(obj: dict[str, Any]) -> dict[str, float]:
    return {
        "x": _bbox_delta_axis(obj, "x"),
        "y": _bbox_delta_axis(obj, "y"),
        "z": _bbox_delta_axis(obj, "z"),
    }


def _bbox_delta_xyz(obj: dict[str, Any]) -> dict[str, float]:
    bbox_delta = obj.get("bbox_delta", {})
    if not isinstance(bbox_delta, dict):
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    return {
        "x": _as_float(bbox_delta.get("x", 0.0), 0.0),
        "y": _as_float(bbox_delta.get("y", 0.0), 0.0),
        "z": _as_float(bbox_delta.get("z", 0.0), 0.0),
    }


def _max_bbox_delta_abs(obj: dict[str, Any]) -> float:
    deltas = _bbox_delta_abs_xyz(obj)
    return max(deltas["x"], deltas["y"], deltas["z"])


def _bent_stats_for_prefix(
    metrics: dict[str, Any],
    prefix: str,
    bend_eps_m: float,
) -> dict[str, Any]:
    diagnostics: list[dict[str, Any]] = []
    count_bent = 0
    for obj in _objects_by_prefix(metrics, prefix):
        bbox_delta = _bbox_delta_xyz(obj)
        deltas = _bbox_delta_abs_xyz(obj)
        max_delta = _max_bbox_delta_abs(obj)
        has_bend_mod, bend_angle = _bend_mod_summary(obj)
        bent = (max_delta >= bend_eps_m) or (has_bend_mod and bend_angle > BEND_MOD_ANGLE_EPS)
        if bent:
            count_bent += 1
        diagnostics.append(
            {
                "name": str(obj.get("name", "")),
                "bbox_delta": bbox_delta,
                "max_delta": float(max_delta),
                "has_bend_mod": bool(has_bend_mod),
                "bend_angle": float(bend_angle),
            }
        )
    top5 = sorted(diagnostics, key=lambda item: float(item.get("max_delta", 0.0)), reverse=True)[:5]
    return {
        "count_total": len(diagnostics),
        "count_bent": int(count_bent),
        "eps_m": float(bend_eps_m),
        "top5": top5,
    }


def _overlap_total(metrics: dict[str, Any], key: str) -> float:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return 0.0
    overlap = overlaps.get(key, {})
    if not isinstance(overlap, dict):
        return 0.0
    return _as_float(overlap.get("total_volume", 0.0), 0.0)


def _group_count(metrics: dict[str, Any], key: str) -> int:
    groups = metrics.get("groups", {})
    if not isinstance(groups, dict):
        return 0
    payload = groups.get(key, {})
    if not isinstance(payload, dict):
        return 0
    return _as_int(payload.get("count", 0), 0)


def _overlap_entry(metrics: dict[str, Any], key: str) -> dict[str, Any]:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return {}
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return {}
    return entry


def _overlap_pairs(metrics: dict[str, Any], key: str) -> list[dict[str, Any]]:
    entry = _overlap_entry(metrics, key)
    pairs = entry.get("pairs", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def _pair_spans(pair: dict[str, Any]) -> dict[str, float]:
    bbox = pair.get("bbox_world", {})
    if not isinstance(bbox, dict):
        return {"x": 0.0, "y": 0.0, "z": 0.0}

    min_corner = bbox.get("min", [])
    max_corner = bbox.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    if len(min_corner) < 3 or len(max_corner) < 3:
        return {"x": 0.0, "y": 0.0, "z": 0.0}

    return {
        "x": max(0.0, _as_float(max_corner[0], 0.0) - _as_float(min_corner[0], 0.0)),
        "y": max(0.0, _as_float(max_corner[1], 0.0) - _as_float(min_corner[1], 0.0)),
        "z": max(0.0, _as_float(max_corner[2], 0.0) - _as_float(min_corner[2], 0.0)),
    }


def _pair_min_span(pair: dict[str, Any]) -> float:
    spans = _pair_spans(pair)
    return min(float(spans["x"]), float(spans["y"]), float(spans["z"]))


def _is_expected_slats_frame_joint_overlap(ir: dict[str, Any], pair: dict[str, Any]) -> bool:
    right_name = str(pair.get("right", "")).strip().lower()
    if not right_name:
        return False

    if right_name.startswith("rail_") or right_name.startswith("beam_cross_"):
        slats = ir.get("slats", {})
        if not isinstance(slats, dict):
            return False
        allowance_mm = (
            _as_float(slats.get("clearance_mm", 0.0), 0.0)
            + _as_float(slats.get("mount_offset_mm", 0.0), 0.0)
            + JOINT_OVERLAP_ALLOWANCE_MM
        )
        allowance_m = max(0.0, allowance_mm / 1000.0)
        return _pair_min_span(pair) <= allowance_m
    return False


def _is_expected_back_slats_frame_joint_overlap(ir: dict[str, Any], pair: dict[str, Any]) -> bool:
    right_name = str(pair.get("right", "")).strip().lower()
    if right_name not in {"back_rail_left", "back_rail_right"}:
        return False

    back_support = ir.get("back_support", {})
    frame = ir.get("frame", {})
    if not isinstance(back_support, dict) or not isinstance(frame, dict):
        return False

    back_depth_mm = _as_float(back_support.get("thickness_mm", 0.0), 0.0)
    frame_depth_mm = _as_float(frame.get("thickness_mm", 0.0), 0.0)
    allowance_mm = max(0.0, back_depth_mm - frame_depth_mm) + JOINT_OVERLAP_ALLOWANCE_MM
    allowance_m = max(0.0, allowance_mm / 1000.0)
    return _pair_min_span(pair) <= allowance_m


def _split_overlap_pairs(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    key: str,
) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
    all_pairs = _overlap_pairs(metrics, key)
    hard_pairs: list[dict[str, Any]] = []
    allowed_joint_pairs: list[dict[str, Any]] = []

    for pair in all_pairs:
        if key == "slats_vs_frame" and _is_expected_slats_frame_joint_overlap(ir, pair):
            allowed_joint_pairs.append(pair)
            continue
        if key == "back_slats_vs_frame" and _is_expected_back_slats_frame_joint_overlap(ir, pair):
            allowed_joint_pairs.append(pair)
            continue
        hard_pairs.append(pair)

    return hard_pairs, allowed_joint_pairs


def _pairs_total_volume(pairs: list[dict[str, Any]]) -> float:
    total = 0.0
    for pair in pairs:
        total += _as_float(pair.get("volume", 0.0), 0.0)
    return float(total)


def _overlap_pairs_top(metrics: dict[str, Any], key: str, limit: int = 10) -> list[dict[str, Any]]:
    pairs = _overlap_pairs(metrics, key)
    return _pairs_top_from_list(pairs, limit=limit)


def _pairs_top_from_list(pairs: list[dict[str, Any]], limit: int = 10) -> list[dict[str, Any]]:
    typed_pairs = [pair for pair in pairs if isinstance(pair, dict)]

    def _pair_volume(pair: dict[str, Any]) -> float:
        return _as_float(pair.get("volume", 0.0), 0.0)

    sorted_pairs = sorted(typed_pairs, key=_pair_volume, reverse=True)[: max(0, int(limit))]
    result: list[dict[str, Any]] = []
    for pair in sorted_pairs:
        result.append(
            {
                "left": str(pair.get("left", "")),
                "right": str(pair.get("right", "")),
                "volume": float(_as_float(pair.get("volume", 0.0), 0.0)),
                "bbox_world": pair.get("bbox_world"),
            }
        )
    return result


def _offenders_from_pairs_top(pairs_top: list[dict[str, Any]]) -> list[dict[str, Any]]:
    names: set[str] = set()
    for pair in pairs_top:
        if not isinstance(pair, dict):
            continue
        left_name = str(pair.get("left", "")).strip()
        right_name = str(pair.get("right", "")).strip()
        if left_name:
            names.add(left_name)
        if right_name:
            names.add(right_name)
    return [{"name": name} for name in sorted(names)]


def _overlap_unique_counts(metrics: dict[str, Any], key: str) -> tuple[int, int]:
    pairs = _overlap_pairs(metrics, key)
    left_names = {str(pair.get("left", "")) for pair in pairs if str(pair.get("left", "")).strip()}
    right_names = {str(pair.get("right", "")) for pair in pairs if str(pair.get("right", "")).strip()}
    return len(left_names), len(right_names)


def _overlap_problem_details(metrics: dict[str, Any], key: str, total_volume: float, overlap_eps: float) -> dict[str, Any]:
    unique_left_count, unique_right_count = _overlap_unique_counts(metrics, key)
    pairs_top = _overlap_pairs_top(metrics, key, limit=10)
    return {
        "total_volume_m3": float(total_volume),
        "eps_m3": float(overlap_eps),
        "pairs_top": pairs_top,
        "offenders": _offenders_from_pairs_top(pairs_top),
        "unique_left_count": int(unique_left_count),
        "unique_right_count": int(unique_right_count),
    }


def _overlap_problem_details_from_pairs(
    metrics: dict[str, Any],
    key: str,
    *,
    overlap_eps: float,
    hard_pairs: list[dict[str, Any]],
    joint_pairs: list[dict[str, Any]],
) -> dict[str, Any]:
    hard_pairs_top = _pairs_top_from_list(hard_pairs, limit=10)
    joint_pairs_top = _pairs_top_from_list(joint_pairs, limit=10)
    offender_pairs_top = hard_pairs_top if hard_pairs_top else joint_pairs_top

    hard_left = {str(pair.get("left", "")) for pair in hard_pairs if str(pair.get("left", "")).strip()}
    hard_right = {str(pair.get("right", "")) for pair in hard_pairs if str(pair.get("right", "")).strip()}

    return {
        "total_volume_m3": float(_overlap_total(metrics, key)),
        "effective_total_volume_m3": float(_pairs_total_volume(hard_pairs)),
        "joint_only_volume_m3": float(_pairs_total_volume(joint_pairs)),
        "eps_m3": float(overlap_eps),
        "pairs_top": hard_pairs_top,
        "joint_pairs_top": joint_pairs_top,
        "offenders": _offenders_from_pairs_top(offender_pairs_top),
        "unique_left_count": int(len(hard_left)),
        "unique_right_count": int(len(hard_right)),
        "joint_pairs_count": int(len(joint_pairs)),
        "joint_allowance_mm": float(JOINT_OVERLAP_ALLOWANCE_MM),
    }


def _group_bbox_world(metrics: dict[str, Any], group_key: str) -> dict[str, Any] | None:
    groups = metrics.get("groups", {})
    if not isinstance(groups, dict):
        return None
    group_payload = groups.get(group_key, {})
    if not isinstance(group_payload, dict):
        return None
    bbox = group_payload.get("bbox_world")
    if not isinstance(bbox, dict):
        return None
    min_corner = bbox.get("min")
    max_corner = bbox.get("max")
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return None
    if len(min_corner) < 3 or len(max_corner) < 3:
        return None
    return bbox


def _z_clearance_between_bboxes(
    first_bbox: dict[str, Any] | None,
    second_bbox: dict[str, Any] | None,
) -> float | None:
    if not first_bbox or not second_bbox:
        return None
    first_min = _as_float(first_bbox.get("min", [0.0, 0.0, 0.0])[2], 0.0)
    first_max = _as_float(first_bbox.get("max", [0.0, 0.0, 0.0])[2], 0.0)
    second_min = _as_float(second_bbox.get("min", [0.0, 0.0, 0.0])[2], 0.0)
    second_max = _as_float(second_bbox.get("max", [0.0, 0.0, 0.0])[2], 0.0)

    if first_max < second_min:
        return float(second_min - first_max)
    if second_max < first_min:
        return float(first_min - second_max)
    return 0.0


def _problem(code: str, severity: int, message: str, details: dict[str, Any]) -> dict[str, Any]:
    return {
        "code": code,
        "severity": int(severity),
        "message": message,
        "details": details,
    }


def _should_check_slats_overlap(ir: dict[str, Any], metrics: dict[str, Any]) -> bool:
    slats = ir.get("slats", {})
    if isinstance(slats, dict) and "enabled" in slats:
        return bool(slats.get("enabled", False))
    return _group_count(metrics, "slat_") > 0


def _should_check_back_slats_overlap(ir: dict[str, Any], metrics: dict[str, Any]) -> bool:
    back_support = ir.get("back_support", {})
    if isinstance(back_support, dict) and "mode" in back_support:
        return str(back_support.get("mode", "")).strip().lower() == "slats"
    return _group_count(metrics, "back_slat_") > 0


def _normalize_modifier_key(key: Any) -> str:
    raw = str(key).strip().upper()
    if not raw:
        return ""
    raw = raw.replace(" ", "")
    if ":" in raw:
        left, right = raw.split(":", 1)
        if right:
            return f"{left}:{right}"
        return left
    return raw


def _expected_modifiers_map(ir: dict[str, Any]) -> dict[str, list[str]]:
    debug_payload = ir.get("debug", {})
    if not isinstance(debug_payload, dict):
        return {}
    expected_payload = debug_payload.get("expect_modifiers", {})
    if not isinstance(expected_payload, dict):
        return {}

    result: dict[str, list[str]] = {}
    for group_key, expected in expected_payload.items():
        if not isinstance(expected, list):
            continue
        normalized: list[str] = []
        for item in expected:
            key = _normalize_modifier_key(item)
            if key and key not in normalized:
                normalized.append(key)
        if normalized:
            result[str(group_key)] = normalized
    return result


def _modifier_key_from_payload(modifier: dict[str, Any]) -> str:
    mod_type = _normalize_modifier_key(modifier.get("type", ""))
    if mod_type != "SIMPLE_DEFORM":
        return mod_type
    deform_method = _normalize_modifier_key(modifier.get("deform_method", ""))
    if deform_method:
        return f"SIMPLE_DEFORM:{deform_method}"
    return "SIMPLE_DEFORM"


def _object_modifier_keys(obj: dict[str, Any]) -> set[str]:
    keys: set[str] = set()
    raw_keys = obj.get("modifier_keys", [])
    if isinstance(raw_keys, list):
        for item in raw_keys:
            key = _normalize_modifier_key(item)
            if key:
                keys.add(key)

    if keys:
        return keys

    modifiers = obj.get("modifiers", [])
    if not isinstance(modifiers, list):
        return keys
    for modifier in modifiers:
        if not isinstance(modifier, dict):
            continue
        key = _modifier_key_from_payload(modifier)
        if key:
            keys.add(key)
    return keys


def _has_expected_modifier(present_keys: set[str], expected_key: str) -> bool:
    normalized_expected = _normalize_modifier_key(expected_key)
    if not normalized_expected:
        return False
    if normalized_expected in present_keys:
        return True

    if ":" in normalized_expected:
        mod_type = normalized_expected.split(":", 1)[0]
        return mod_type in present_keys

    prefix = f"{normalized_expected}:"
    if normalized_expected in present_keys:
        return True
    return any(key.startswith(prefix) for key in present_keys)


def _object_counts(obj: dict[str, Any]) -> tuple[int, int | None, int, int | None]:
    verts = _as_int(obj.get("verts", 0), 0)
    polys = _as_int(obj.get("polys", 0), 0)

    verts_base_raw = obj.get("verts_base")
    verts_base = _as_int(verts_base_raw, 0) if isinstance(verts_base_raw, (int, float)) else None
    polys_base_raw = obj.get("polys_base")
    polys_base = _as_int(polys_base_raw, 0) if isinstance(polys_base_raw, (int, float)) else None
    return verts, verts_base, polys, polys_base


def _verts_delta_abs(obj: dict[str, Any]) -> int | None:
    verts, verts_base, _, _ = _object_counts(obj)
    if verts_base is None:
        return None
    return abs(int(verts - verts_base))


def _modifier_no_effect_for_object(
    obj: dict[str, Any],
    expected_modifier: str,
    *,
    eps_m: float,
    verts_eps: int,
) -> tuple[bool, int, str, float]:
    mod_key = _normalize_modifier_key(expected_modifier)
    mod_type = mod_key.split(":", 1)[0]
    max_delta = _max_bbox_delta_abs(obj)
    verts_delta = _verts_delta_abs(obj)
    has_geom_delta = max_delta >= eps_m
    has_verts_delta = (verts_delta is not None) and (verts_delta > int(verts_eps))

    if mod_key == "SIMPLE_DEFORM:BEND":
        has_bend_mod, bend_angle = _bend_mod_summary(obj)
        if has_geom_delta or (has_bend_mod and bend_angle > BEND_MOD_ANGLE_EPS):
            return False, 0, "", float(bend_angle)
        if bend_angle > BEND_MOD_ANGLE_EPS:
            return False, 0, "", float(bend_angle)
        return True, 2, "bbox_delta too small", float(bend_angle)

    if mod_type == "ARRAY":
        if has_geom_delta or has_verts_delta:
            return False, 0, "", 0.0
        if verts_delta is None:
            return True, 2, "bbox_delta too small", 0.0
        return True, 2, "bbox_delta and verts delta too small", 0.0

    if mod_type == "MIRROR":
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if verts_delta > int(verts_eps):
            return False, 0, "", 0.0
        return True, 2, "verts did not increase versus base mesh", 0.0

    if mod_type == "SOLIDIFY":
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if (max_delta < eps_m) and (verts_delta <= int(verts_eps)):
            return True, 2, "bbox_delta and verts delta too small", 0.0
        return False, 0, "", 0.0

    warn_types = {"BEVEL", "SUBSURF", "WEIGHTED_NORMAL", "BOOLEAN", "SHRINKWRAP", "CURVE", "LATTICE"}
    if mod_type in warn_types:
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if (max_delta < eps_m) and (verts_delta <= int(verts_eps)):
            return True, 1, "bbox_delta and verts delta too small", 0.0
        return False, 0, "", 0.0

    if has_geom_delta or has_verts_delta:
        return False, 0, "", 0.0
    return True, 1, "bbox_delta and verts delta too small", 0.0


def _validate_modifier_expectation_missing(ir: dict[str, Any], metrics: dict[str, Any]) -> list[dict[str, Any]]:
    expected_map = _expected_modifiers_map(ir)
    if not expected_map:
        return []

    problems: list[dict[str, Any]] = []
    for group_key, expected in expected_map.items():
        objects = _mesh_objects_by_prefix(metrics, group_key)
        if not objects:
            continue

        missing_by_object: list[dict[str, Any]] = []
        for obj in objects:
            present_keys = _object_modifier_keys(obj)
            missing = [key for key in expected if not _has_expected_modifier(present_keys, key)]
            if missing:
                missing_by_object.append(
                    {
                        "name": str(obj.get("name", "")),
                        "missing": missing,
                    }
                )

        if not missing_by_object:
            continue

        problems.append(
            _problem(
                code="MOD_EXPECTATION_MISSING",
                severity=2,
                message=f"Expected modifiers are missing for group '{group_key}'.",
                details={
                    "group_key": group_key,
                    "expected": expected,
                    "missing_by_object": missing_by_object,
                    "counts": {
                        "objects": len(objects),
                        "objects_with_missing": len(missing_by_object),
                    },
                },
            )
        )
    return problems


def _validate_modifier_expectation_no_effect(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    *,
    effect_eps_m: float,
    effect_verts_eps: int,
) -> list[dict[str, Any]]:
    expected_map = _expected_modifiers_map(ir)
    if not expected_map:
        return []

    problems: list[dict[str, Any]] = []
    for group_key, expected in expected_map.items():
        objects = _mesh_objects_by_prefix(metrics, group_key)
        for obj in objects:
            present_keys = _object_modifier_keys(obj)
            if not present_keys:
                continue

            for expected_key in expected:
                if not _has_expected_modifier(present_keys, expected_key):
                    continue

                no_effect, severity, reason, bend_angle = _modifier_no_effect_for_object(
                    obj,
                    expected_modifier=expected_key,
                    eps_m=effect_eps_m,
                    verts_eps=effect_verts_eps,
                )
                if not no_effect or severity <= 0:
                    continue

                verts, verts_base, polys, polys_base = _object_counts(obj)
                details: dict[str, Any] = {
                    "group_key": group_key,
                    "name": str(obj.get("name", "")),
                    "modifier": _normalize_modifier_key(expected_key),
                    "reason": reason,
                    "bbox_delta": _bbox_delta_xyz(obj),
                    "verts": int(verts),
                    "verts_base": verts_base,
                    "polys": int(polys),
                    "polys_base": polys_base,
                    "eps_m": float(effect_eps_m),
                    "verts_eps": int(effect_verts_eps),
                }
                if _normalize_modifier_key(expected_key) == "SIMPLE_DEFORM:BEND":
                    details["bend_angle"] = float(bend_angle)

                problems.append(
                    _problem(
                        code="MOD_EXPECTATION_NO_EFFECT",
                        severity=int(severity),
                        message=f"Modifier {_normalize_modifier_key(expected_key)} has no observable effect.",
                        details=details,
                    )
                )
    return problems


def _validate_slats_not_bent(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    bend_eps_m: float,
) -> list[dict[str, Any]]:
    slats = ir.get("slats", {})
    if not isinstance(slats, dict):
        return []
    if not bool(slats.get("enabled", False)):
        return []
    if _as_float(slats.get("arc_height_mm", 0.0), 0.0) <= 0.0:
        return []

    stats = _bent_stats_for_prefix(metrics, "slat_", bend_eps_m=bend_eps_m)
    if int(stats.get("count_bent", 0)) > 0:
        return []

    details = {
        "count_total": int(stats.get("count_total", 0)),
        "count_bent": int(stats.get("count_bent", 0)),
        "eps_m": float(stats.get("eps_m", bend_eps_m)),
        "top5": stats.get("top5", []),
    }
    if int(stats.get("count_total", 0)) == 0:
        details["note"] = "no objects found"

    return [
        _problem(
            code="SLATS_NOT_BENT",
            severity=2,
            message="Seat slats are expected to be bent but bend evidence is missing.",
            details=details,
        )
    ]


def _validate_back_slats_not_bent(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    bend_eps_m: float,
) -> list[dict[str, Any]]:
    back_support = ir.get("back_support", {})
    if not isinstance(back_support, dict):
        return []
    mode = str(back_support.get("mode", "")).strip().lower()
    if mode != "slats":
        return []
    back_slats = back_support.get("slats", {})
    if not isinstance(back_slats, dict):
        return []
    if _as_float(back_slats.get("arc_height_mm", 0.0), 0.0) <= 0.0:
        return []

    stats = _bent_stats_for_prefix(metrics, "back_slat_", bend_eps_m=bend_eps_m)
    if int(stats.get("count_bent", 0)) > 0:
        return []

    details = {
        "count_total": int(stats.get("count_total", 0)),
        "count_bent": int(stats.get("count_bent", 0)),
        "eps_m": float(stats.get("eps_m", bend_eps_m)),
        "top5": stats.get("top5", []),
    }
    if int(stats.get("count_total", 0)) == 0:
        details["note"] = "no objects found"

    return [
        _problem(
            code="BACK_SLATS_NOT_BENT",
            severity=2,
            message="Back slats are expected to be bent but bend evidence is missing.",
            details=details,
        )
    ]


def _validate_overlap_slats_frame(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_slats_overlap(ir, metrics):
        return []

    hard_pairs, joint_pairs = _split_overlap_pairs(ir, metrics, "slats_vs_frame")
    effective_volume = _pairs_total_volume(hard_pairs)
    total_volume = _overlap_total(metrics, "slats_vs_frame")

    if effective_volume <= overlap_eps:
        if total_volume <= overlap_eps or len(joint_pairs) == 0:
            return []
        details = _overlap_problem_details_from_pairs(
            metrics,
            "slats_vs_frame",
            overlap_eps=overlap_eps,
            hard_pairs=hard_pairs,
            joint_pairs=joint_pairs,
        )
        return [
            _problem(
                code="OVERLAP_SLATS_FRAME",
                severity=1,
                message="Seat slats have only expected joint-contact overlaps with frame.",
                details=details,
            )
        ]

    details = _overlap_problem_details_from_pairs(
        metrics,
        "slats_vs_frame",
        overlap_eps=overlap_eps,
        hard_pairs=hard_pairs,
        joint_pairs=joint_pairs,
    )
    if details.get("unique_left_count", 0) == 0:
        unique_left_count, unique_right_count = _overlap_unique_counts(metrics, "slats_vs_frame")
        details["unique_left_count"] = int(unique_left_count)
        details["unique_right_count"] = int(unique_right_count)

    return [
        _problem(
            code="OVERLAP_SLATS_FRAME",
            severity=2,
            message="Seat slats overlap frame geometry.",
            details=details,
        )
    ]


def _validate_overlap_slats_arms(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_slats_overlap(ir, metrics):
        return []
    volume = _overlap_total(metrics, "slats_vs_arms")
    if volume <= overlap_eps:
        return []

    return [
        _problem(
            code="OVERLAP_SLATS_ARMS",
            severity=2,
            message="Seat slats overlap arm geometry.",
            details=_overlap_problem_details(metrics, "slats_vs_arms", volume, overlap_eps),
        )
    ]


def _validate_overlap_back_slats_frame(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_back_slats_overlap(ir, metrics):
        return []

    hard_pairs, joint_pairs = _split_overlap_pairs(ir, metrics, "back_slats_vs_frame")
    effective_volume = _pairs_total_volume(hard_pairs)
    total_volume = _overlap_total(metrics, "back_slats_vs_frame")

    if effective_volume <= overlap_eps:
        if total_volume <= overlap_eps or len(joint_pairs) == 0:
            return []
        details = _overlap_problem_details_from_pairs(
            metrics,
            "back_slats_vs_frame",
            overlap_eps=overlap_eps,
            hard_pairs=hard_pairs,
            joint_pairs=joint_pairs,
        )
        return [
            _problem(
                code="OVERLAP_BACK_SLATS_FRAME",
                severity=1,
                message="Back slats have only expected joint-contact overlaps with frame.",
                details=details,
            )
        ]

    details = _overlap_problem_details_from_pairs(
        metrics,
        "back_slats_vs_frame",
        overlap_eps=overlap_eps,
        hard_pairs=hard_pairs,
        joint_pairs=joint_pairs,
    )
    if details.get("unique_left_count", 0) == 0:
        unique_left_count, unique_right_count = _overlap_unique_counts(metrics, "back_slats_vs_frame")
        details["unique_left_count"] = int(unique_left_count)
        details["unique_right_count"] = int(unique_right_count)

    return [
        _problem(
            code="OVERLAP_BACK_SLATS_FRAME",
            severity=2,
            message="Back slats overlap frame geometry.",
            details=details,
        )
    ]


def _validate_low_clearance_slats_frame(metrics: dict[str, Any], clearance_eps: float) -> list[dict[str, Any]]:
    overlap_volume = _overlap_total(metrics, "slats_vs_frame")
    if overlap_volume > 0.0:
        return []

    slat_bbox = _group_bbox_world(metrics, "slat_")
    frame_bbox = _group_bbox_world(metrics, "frame_")
    min_clearance_z = _z_clearance_between_bboxes(slat_bbox, frame_bbox)
    if min_clearance_z is None:
        return []
    if min_clearance_z >= clearance_eps:
        return []

    return [
        _problem(
            code="LOW_CLEARANCE_SLATS_FRAME",
            severity=1,
            message="Seat slats and frame have very low Z clearance.",
            details={
                "min_clearance_z_m": float(min_clearance_z),
                "eps_m": float(clearance_eps),
            },
        )
    ]


def validate(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    overlap_eps: float = DEFAULT_OVERLAP_EPS,
    bend_delta_eps: float | None = None,
    clearance_eps_m: float | None = None,
) -> dict[str, Any]:
    """Validate IR against metrics and return score payload."""
    ir, metrics = _normalize_validate_args(ir, metrics)
    overlap_eps = float(_read_env_float("DEBUG_OVERLAP_EPS_M3", overlap_eps))
    bent_eps = float(BEND_EPS_M if bend_delta_eps is None else bend_delta_eps)
    clearance_eps = float(CLEARANCE_EPS_M if clearance_eps_m is None else clearance_eps_m)
    mod_effect_eps_m = float(_read_env_float("DEBUG_MOD_EFFECT_EPS_M", MOD_EFFECT_EPS_M))
    mod_effect_verts_eps = int(_read_env_int("DEBUG_MOD_EFFECT_VERTS_EPS", MOD_EFFECT_VERTS_EPS))

    problems: list[dict[str, Any]] = []
    problems.extend(_validate_modifier_expectation_missing(ir, metrics))
    problems.extend(
        _validate_modifier_expectation_no_effect(
            ir,
            metrics,
            effect_eps_m=mod_effect_eps_m,
            effect_verts_eps=mod_effect_verts_eps,
        )
    )
    problems.extend(_validate_slats_not_bent(ir, metrics, bend_eps_m=bent_eps))
    problems.extend(_validate_back_slats_not_bent(ir, metrics, bend_eps_m=bent_eps))
    problems.extend(_validate_overlap_slats_frame(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_overlap_slats_arms(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_overlap_back_slats_frame(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_low_clearance_slats_frame(metrics, clearance_eps=clearance_eps))

    def _severity_weight(severity: int) -> float:
        if severity >= 3:
            return 0.30
        if severity == 2:
            return 0.10
        if severity == 1:
            return 0.02
        return 0.0

    severity_sum = sum(_as_int(problem.get("severity", 0), 0) for problem in problems)
    severity_max = max((_as_int(problem.get("severity", 0), 0) for problem in problems), default=0)
    penalty = min(1.0, sum(_severity_weight(_as_int(problem.get("severity", 0), 0)) for problem in problems))
    score = max(0.0, 1.0 - penalty)

    return {
        "score": float(round(score, 6)),
        "problems": problems,
        "problem_count": len(problems),
        "severity_max": int(severity_max),
        "penalty": float(round(penalty, 6)),
    }


def _load_json_object(path: str) -> dict[str, Any]:
    with open(path, "r", encoding="utf-8") as handle:
        payload = json.load(handle)
    if not isinstance(payload, dict):
        raise ValueError(f"Expected JSON object in {path}, got {type(payload).__name__}")
    return payload


def _resolve_input_path(base_path: str, candidate: str) -> str:
    if not candidate:
        return ""
    if os.path.isabs(candidate):
        return candidate
    return os.path.abspath(os.path.join(os.path.dirname(base_path), candidate))


def _infer_payload_kind(payload: dict[str, Any]) -> tuple[str, str]:
    kind_raw = str(payload.get("kind", "")).strip().lower()
    if kind_raw == "run":
        return "run", "kind_run"
    if kind_raw == "metrics":
        return "metrics", "kind_metrics"

    if (
        "validation" in payload
        or "patches_applied" in payload
        or "ir_in_path" in payload
        or ("metrics" in payload and ("status" in payload or "run_id" in payload))
    ):
        return "run", "heuristic_run"

    if (
        "validation" not in payload
        and "objects" in payload
        and "groups" in payload
        and "overlaps" in payload
    ):
        return "metrics", "heuristic_metrics"

    return "metrics", "heuristic_fallback_metrics"


def _extract_metrics_from_metrics_payload(payload: dict[str, Any]) -> dict[str, Any]:
    nested_metrics = payload.get("metrics")
    if isinstance(nested_metrics, dict) and not _looks_like_metrics(payload):
        return nested_metrics
    return payload


def _extract_ir_from_payload(payload: dict[str, Any]) -> dict[str, Any]:
    embedded_ir = payload.get("ir")
    if isinstance(embedded_ir, dict):
        return embedded_ir
    kind, _ = _infer_payload_kind(payload)
    if kind == "run":
        return {}
    return payload


def load_debug_payload(path: str) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any]]:
    """Load debug input payload and return (ir, metrics, meta)."""
    input_path = os.path.abspath(path)
    payload = _load_json_object(input_path)
    kind, payload_format = _infer_payload_kind(payload)

    meta: dict[str, Any] = {
        "kind": kind,
        "format": payload_format,
        "input_path": input_path,
        "metrics_source": "none",
        "ir_source": "none",
        "metrics_error": None,
    }

    metrics_payload: dict[str, Any] = {}
    ir_payload: dict[str, Any] = {}

    if kind == "run":
        embedded_metrics = payload.get("metrics")
        if isinstance(embedded_metrics, dict):
            metrics_payload = embedded_metrics
            meta["metrics_source"] = "embedded"
        else:
            metrics_path_raw = str(payload.get("metrics_path", "")).strip()
            if metrics_path_raw:
                metrics_path = _resolve_input_path(input_path, metrics_path_raw)
                try:
                    loaded_metrics_payload = _load_json_object(metrics_path)
                    metrics_payload = _extract_metrics_from_metrics_payload(loaded_metrics_payload)
                    meta["metrics_source"] = "metrics_path"
                    meta["metrics_path"] = metrics_path
                except Exception as exc:
                    meta["metrics_error"] = f"failed to load metrics_path: {exc}"
            else:
                meta["metrics_error"] = "run payload has no embedded metrics and no metrics_path"

        env_ir_path = str(os.getenv("DEBUG_IR_JSON", "")).strip()
        if env_ir_path:
            loaded_ir_payload = _load_json_object(env_ir_path)
            ir_payload = _extract_ir_from_payload(loaded_ir_payload)
            meta["ir_source"] = "env_debug_ir_json"
        elif isinstance(payload.get("ir"), dict):
            ir_payload = payload["ir"]
            meta["ir_source"] = "embedded_ir"
        else:
            ir_in_path_raw = str(payload.get("ir_in_path", "")).strip()
            if ir_in_path_raw:
                ir_in_path = _resolve_input_path(input_path, ir_in_path_raw)
                if os.path.exists(ir_in_path):
                    try:
                        ir_payload = _load_json_object(ir_in_path)
                        meta["ir_source"] = "ir_in_path"
                        meta["ir_in_path"] = ir_in_path
                    except Exception:
                        ir_payload = {}
                        meta["ir_source"] = "ir_in_path_unreadable"
    else:
        metrics_payload = _extract_metrics_from_metrics_payload(payload)
        meta["metrics_source"] = "input_file"

        env_ir_path = str(os.getenv("DEBUG_IR_JSON", "")).strip()
        if env_ir_path:
            loaded_ir_payload = _load_json_object(env_ir_path)
            ir_payload = _extract_ir_from_payload(loaded_ir_payload)
            meta["ir_source"] = "env_debug_ir_json"

    return ir_payload, metrics_payload, meta


def _self_check_joint_only_overlap_payload() -> tuple[dict[str, Any], dict[str, Any]]:
    ir_payload: dict[str, Any] = {
        "back_support": {
            "mode": "slats",
            "thickness_mm": 60.0,
        },
        "frame": {
            "thickness_mm": 58.0,
        },
    }
    metrics_payload: dict[str, Any] = {
        "kind": "metrics",
        "groups": {
            "back_slat_": {"count": 1},
            "frame_": {"count": 1},
        },
        "overlaps": {
            "back_slats_vs_frame": {
                "total_volume": 3.2e-5,
                "pairs": [
                    {
                        "left": "back_slat_1",
                        "right": "back_rail_left",
                        "volume": 3.2e-5,
                        "bbox_world": {
                            "min": [0.0, 0.0, 0.0],
                            "max": [0.0015, 0.0010, 0.0040],
                        },
                    }
                ],
            },
            "slats_vs_frame": {"total_volume": 0.0, "pairs": []},
            "slats_vs_arms": {"total_volume": 0.0, "pairs": []},
        },
    }
    return ir_payload, metrics_payload


if __name__ == "__main__":
    input_path = str(os.getenv("DEBUG_INPUT_JSON", "")).strip()
    if not input_path:
        input_path = str(os.getenv("DEBUG_METRICS_JSON", "")).strip()

    if not input_path:
        print("validators: running built-in joint-only overlap self-check", file=sys.stderr)
        ir_payload, metrics_payload = _self_check_joint_only_overlap_payload()
        result = validate(ir_payload, metrics_payload)
        print(json.dumps(result, ensure_ascii=False, indent=2))

        joint_top_found = False
        joint_top_len = 0
        hard_top_len = 0
        offenders_len = 0
        problems = result.get("problems", [])
        if isinstance(problems, list):
            for problem in problems:
                if not isinstance(problem, dict):
                    continue
                code = str(problem.get("code", "")).strip().upper()
                if code != "OVERLAP_BACK_SLATS_FRAME":
                    continue
                details = problem.get("details", {})
                if not isinstance(details, dict):
                    continue
                joint_pairs_top = details.get("joint_pairs_top", [])
                pairs_top = details.get("pairs_top", [])
                offenders = details.get("offenders", [])
                joint_top_found = isinstance(joint_pairs_top, list) and len(joint_pairs_top) > 0
                joint_top_len = len(joint_pairs_top) if isinstance(joint_pairs_top, list) else 0
                hard_top_len = len(pairs_top) if isinstance(pairs_top, list) else 0
                offenders_len = len(offenders) if isinstance(offenders, list) else 0
                break
        print(
            f"validators: self_check joint_pairs_top_found={joint_top_found} "
            f"joint_pairs_top_len={joint_top_len} hard_pairs_top_len={hard_top_len} "
            f"offenders_len={offenders_len}",
            file=sys.stderr,
        )
        raise SystemExit(0)

    try:
        ir_payload, metrics_payload, meta = load_debug_payload(input_path)
    except Exception as exc:
        print(f"validators: failed to load input: {exc}", file=sys.stderr)
        raise SystemExit(2)

    print(
        f"validators: loaded input kind={meta.get('kind')} format={meta.get('format')}",
        file=sys.stderr,
    )

    if meta.get("kind") == "run" and (not _looks_like_metrics(metrics_payload)):
        error_text = str(meta.get("metrics_error") or "run input metrics not found or unreadable")
        print(f"validators: {error_text}", file=sys.stderr)
        raise SystemExit(2)

    result = validate(ir_payload, metrics_payload)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print(
        f"validators: kind={meta.get('kind')} problems={int(result.get('problem_count', 0))}",
        file=sys.stderr,
    )



===== FILE: tools/blender/debug/visualize.py =====
"""Blender-only visualization helpers for debug overlap offenders."""

from __future__ import annotations

import os
from typing import Any


TARGET_GROUPS = ("frame_", "slat_", "back_slat_", "arm_", "leg_")


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _valid_bbox(bbox: Any) -> bool:
    if not isinstance(bbox, dict):
        return False
    min_corner = bbox.get("min")
    max_corner = bbox.get("max")
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return False
    return len(min_corner) >= 3 and len(max_corner) >= 3


def _bbox_union(a: dict[str, list[float]] | None, b: dict[str, list[float]] | None) -> dict[str, list[float]] | None:
    if not a:
        return b
    if not b:
        return a
    return {
        "min": [
            min(_safe_float(a["min"][0]), _safe_float(b["min"][0])),
            min(_safe_float(a["min"][1]), _safe_float(b["min"][1])),
            min(_safe_float(a["min"][2]), _safe_float(b["min"][2])),
        ],
        "max": [
            max(_safe_float(a["max"][0]), _safe_float(b["max"][0])),
            max(_safe_float(a["max"][1]), _safe_float(b["max"][1])),
            max(_safe_float(a["max"][2]), _safe_float(b["max"][2])),
        ],
    }


def _scene_bbox_from_metrics(metrics: dict[str, Any] | None) -> dict[str, list[float]] | None:
    if not isinstance(metrics, dict):
        return None

    groups = metrics.get("groups", {})
    bbox: dict[str, list[float]] | None = None
    if isinstance(groups, dict):
        for group_key in TARGET_GROUPS:
            payload = groups.get(group_key, {})
            if not isinstance(payload, dict):
                continue
            group_bbox = payload.get("bbox_world")
            if _valid_bbox(group_bbox):
                bbox = _bbox_union(bbox, group_bbox)

    if bbox:
        return bbox

    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return None
    for obj in objects:
        if not isinstance(obj, dict):
            continue
        if str(obj.get("type", "")).upper() != "MESH":
            continue
        obj_bbox = obj.get("bbox_world")
        if _valid_bbox(obj_bbox):
            bbox = _bbox_union(bbox, obj_bbox)
    return bbox


def _material(name: str, rgba: tuple[float, float, float, float]) -> Any:
    import bpy  # type: ignore

    mat = bpy.data.materials.get(name)
    if mat is None:
        mat = bpy.data.materials.new(name=name)

    if hasattr(mat, "use_nodes"):
        mat.use_nodes = True
        node_tree = getattr(mat, "node_tree", None)
        if node_tree and node_tree.nodes:
            principled = node_tree.nodes.get("Principled BSDF")
            if principled is not None:
                principled.inputs[0].default_value = rgba
                principled.inputs[7].default_value = 0.35

    if hasattr(mat, "diffuse_color"):
        mat.diffuse_color = rgba
    return mat


def _details(problem: dict[str, Any]) -> dict[str, Any]:
    details = problem.get("details", {})
    if isinstance(details, dict):
        return details
    return {}


def _add_name(target: set[str], value: Any) -> None:
    name = str(value).strip()
    if name:
        target.add(name)


def _names_from_pairs_field(details: dict[str, Any], field_name: str) -> set[str]:
    names: set[str] = set()
    pairs = details.get(field_name, [])
    if not isinstance(pairs, list):
        return names
    for pair in pairs:
        if not isinstance(pair, dict):
            continue
        _add_name(names, pair.get("left", ""))
        _add_name(names, pair.get("right", ""))
    return names


def _names_from_pairs_top(details: dict[str, Any]) -> set[str]:
    return _names_from_pairs_field(details, "pairs_top")


def _names_from_joint_pairs_top(details: dict[str, Any]) -> set[str]:
    return _names_from_pairs_field(details, "joint_pairs_top")


def _names_from_offenders(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    offenders = details.get("offenders")
    if isinstance(offenders, dict):
        _add_name(names, offenders.get("name", ""))
        _add_name(names, offenders.get("left", ""))
        _add_name(names, offenders.get("right", ""))
        return names
    if not isinstance(offenders, list):
        return names
    for item in offenders:
        if isinstance(item, dict):
            _add_name(names, item.get("name", ""))
            _add_name(names, item.get("left", ""))
            _add_name(names, item.get("right", ""))
        else:
            _add_name(names, item)
    return names


def _names_from_top_offender_pair(metrics: dict[str, Any] | None) -> set[str]:
    names: set[str] = set()
    if not isinstance(metrics, dict):
        return names
    pair = metrics.get("top_offender_pair")
    if not isinstance(pair, dict):
        return names
    _add_name(names, pair.get("left", ""))
    _add_name(names, pair.get("right", ""))
    return names


def _names_from_top5(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    top5 = details.get("top5", [])
    if not isinstance(top5, list):
        return names
    for item in top5:
        if not isinstance(item, dict):
            continue
        _add_name(names, item.get("name", ""))
    return names


def _names_from_missing_details(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    missing_by_object = details.get("missing_by_object", [])
    if isinstance(missing_by_object, list):
        for item in missing_by_object:
            if not isinstance(item, dict):
                continue
            _add_name(names, item.get("name", ""))
    elif isinstance(missing_by_object, dict):
        for key in missing_by_object.keys():
            _add_name(names, key)
    return names


def _names_from_no_effect_details(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    _add_name(names, details.get("name", ""))

    by_object = details.get("by_object")
    if isinstance(by_object, list):
        for item in by_object:
            if not isinstance(item, dict):
                continue
            _add_name(names, item.get("name", ""))
    elif isinstance(by_object, dict):
        for key in by_object.keys():
            _add_name(names, key)

    offenders = details.get("offenders")
    if isinstance(offenders, list):
        for item in offenders:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)

    top = details.get("top")
    if isinstance(top, list):
        for item in top:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)

    top5 = details.get("top5")
    if isinstance(top5, list):
        for item in top5:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)
    return names


def _collect_offenders_by_priority(
    validation: dict[str, Any],
    metrics: dict[str, Any] | None = None,
) -> tuple[set[str], set[str], set[str], set[str], set[str], set[str]]:
    red: set[str] = set()
    blue: set[str] = set()
    orange: set[str] = set()
    offender_codes: set[str] = set()
    hard_overlap_offenders: set[str] = set()
    joint_overlap_offenders: set[str] = set()

    problems = validation.get("problems", [])
    if not isinstance(problems, list):
        return red, blue, orange, offender_codes, hard_overlap_offenders, joint_overlap_offenders

    for problem in problems:
        if not isinstance(problem, dict):
            continue
        code = str(problem.get("code", "")).strip().upper()
        details = _details(problem)

        names: set[str] = set()
        if code.startswith("OVERLAP_"):
            hard_names = _names_from_pairs_top(details)
            offender_names = _names_from_offenders(details)
            joint_names = _names_from_joint_pairs_top(details)
            if hard_names:
                names = hard_names
                hard_overlap_offenders.update(hard_names)
            elif offender_names:
                names = offender_names
                if joint_names and not hard_names:
                    joint_overlap_offenders.update(offender_names)
                else:
                    hard_overlap_offenders.update(offender_names)
            elif joint_names:
                names = joint_names
                joint_overlap_offenders.update(joint_names)
            else:
                fallback_names = _names_from_top_offender_pair(metrics)
                if fallback_names:
                    names = fallback_names
                    hard_overlap_offenders.update(fallback_names)
            red.update(names)
        elif code in {"SLATS_NOT_BENT", "BACK_SLATS_NOT_BENT"}:
            names = _names_from_top5(details)
            blue.update(names)
        elif code == "MOD_EXPECTATION_MISSING":
            names = _names_from_missing_details(details)
            blue.update(names)
        elif code == "MOD_EXPECTATION_NO_EFFECT":
            names = _names_from_no_effect_details(details)
            orange.update(names)

        if names:
            offender_codes.add(code)

    return red, blue, orange, offender_codes, hard_overlap_offenders, joint_overlap_offenders


def _look_at_rotation(camera_obj: Any, target_xyz: tuple[float, float, float]) -> None:
    from mathutils import Vector  # type: ignore

    target_vec = Vector((target_xyz[0], target_xyz[1], target_xyz[2]))
    direction = target_vec - camera_obj.location
    if direction.length <= 1e-9:
        return
    camera_obj.rotation_euler = direction.to_track_quat("-Z", "Y").to_euler()


def _ensure_camera_and_light(
    scene_bbox: dict[str, list[float]] | None,
    lens_mm: float = 50.0,
) -> tuple[Any, Any]:
    import bpy  # type: ignore

    center_x = 0.0
    center_y = 0.0
    center_z = 0.0
    extent_x = 2.0
    extent_y = 2.0
    extent_z = 1.5
    if scene_bbox:
        min_corner = scene_bbox["min"]
        max_corner = scene_bbox["max"]
        center_x = 0.5 * (_safe_float(min_corner[0]) + _safe_float(max_corner[0]))
        center_y = 0.5 * (_safe_float(min_corner[1]) + _safe_float(max_corner[1]))
        center_z = 0.5 * (_safe_float(min_corner[2]) + _safe_float(max_corner[2]))
        extent_x = max(0.1, _safe_float(max_corner[0]) - _safe_float(min_corner[0]))
        extent_y = max(0.1, _safe_float(max_corner[1]) - _safe_float(min_corner[1]))
        extent_z = max(0.1, _safe_float(max_corner[2]) - _safe_float(min_corner[2]))

    extent = max(extent_x, extent_y, extent_z)
    cam_distance = max(2.5, extent * 2.4)

    camera_obj = bpy.data.objects.get("DEBUG_CAMERA")
    if camera_obj is None:
        camera_data = bpy.data.cameras.new(name="DEBUG_CAMERA")
        camera_obj = bpy.data.objects.new("DEBUG_CAMERA", camera_data)
        bpy.context.scene.collection.objects.link(camera_obj)
    if getattr(camera_obj, "data", None) is not None:
        camera_obj.data.lens = float(lens_mm)
        camera_obj.data.clip_end = max(200.0, cam_distance * 20.0)

    camera_obj.location.x = center_x + cam_distance
    camera_obj.location.y = center_y - cam_distance
    camera_obj.location.z = center_z + cam_distance * 0.75
    _look_at_rotation(camera_obj, (center_x, center_y, center_z))
    bpy.context.scene.camera = camera_obj

    light_obj = bpy.data.objects.get("DEBUG_LIGHT")
    if light_obj is None:
        light_data = bpy.data.lights.new(name="DEBUG_LIGHT", type="SUN")
        light_obj = bpy.data.objects.new(name="DEBUG_LIGHT", object_data=light_data)
        bpy.context.scene.collection.objects.link(light_obj)
    if getattr(light_obj, "data", None) is not None:
        light_obj.data.energy = 3.0

    light_obj.location.x = center_x + cam_distance * 0.4
    light_obj.location.y = center_y - cam_distance * 0.2
    light_obj.location.z = center_z + cam_distance * 1.2
    _look_at_rotation(light_obj, (center_x, center_y, center_z))
    return camera_obj, light_obj


def apply_debug_visualization(
    validation: dict[str, Any],
    metrics: dict[str, Any] | None = None,
    snapshot_blend_path: str | None = None,
    snapshot_png_path: str | None = None,
    camera_lens_mm: float = 50.0,
) -> dict[str, Any]:
    """Highlight offenders and optionally save .blend and PNG snapshots."""
    try:
        import bpy  # type: ignore
    except Exception:
        return {
            "offender_count": 0,
            "painted_red": 0,
            "painted_gray": 0,
            "snapshot_blend_path": "",
            "snapshot_png_path": "",
            "error": "bpy unavailable",
        }

    (
        red_offenders,
        blue_offenders,
        orange_offenders,
        offender_codes,
        hard_overlap_offenders,
        joint_overlap_offenders,
    ) = _collect_offenders_by_priority(validation, metrics=metrics)
    all_offenders = set(red_offenders) | set(blue_offenders) | set(orange_offenders)

    offender_mat = _material("MAT_DEBUG_OFFENDER", (0.92, 0.16, 0.16, 1.0))
    bent_mat = _material("MAT_DEBUG_BENT", (0.18, 0.42, 0.95, 1.0))
    orange_mat = _material("MAT_DEBUG_ORANGE", (0.95, 0.52, 0.14, 1.0))
    other_mat = _material("MAT_DEBUG_OTHER", (0.58, 0.58, 0.58, 1.0))

    painted_red = 0
    painted_blue = 0
    painted_orange = 0
    painted_gray = 0
    for obj in bpy.data.objects:
        if str(getattr(obj, "type", "")) != "MESH":
            continue
        mesh = getattr(obj, "data", None)
        if mesh is None or not hasattr(mesh, "materials"):
            continue

        if obj.name in red_offenders:
            target_material = offender_mat
            painted_red += 1
        elif obj.name in blue_offenders:
            target_material = bent_mat
            painted_blue += 1
        elif obj.name in orange_offenders:
            target_material = orange_mat
            painted_orange += 1
        else:
            target_material = other_mat
            painted_gray += 1

        if len(mesh.materials) == 0:
            mesh.materials.append(target_material)
        else:
            mesh.materials[0] = target_material

    scene_bbox = _scene_bbox_from_metrics(metrics)
    _ensure_camera_and_light(scene_bbox, lens_mm=camera_lens_mm)

    saved_blend_path = ""
    if snapshot_blend_path:
        blend_path = os.path.abspath(str(snapshot_blend_path).strip())
        if blend_path:
            parent_dir = os.path.dirname(blend_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)
            bpy.ops.wm.save_as_mainfile(filepath=blend_path)
            saved_blend_path = blend_path

    saved_png_path = ""
    if snapshot_png_path:
        png_path = os.path.abspath(str(snapshot_png_path).strip())
        if png_path:
            parent_dir = os.path.dirname(png_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)
            scene = bpy.context.scene
            scene.render.image_settings.file_format = "PNG"
            scene.render.filepath = png_path
            bpy.ops.render.render(write_still=True)
            saved_png_path = png_path

    codes_csv = ",".join(sorted(offender_codes))
    print(f"DEBUG_OFFENDERS_COUNT:{len(all_offenders)}")
    print(f"DEBUG_OFFENDER_CODES:{codes_csv}")

    return {
        "offender_count": len(all_offenders),
        "overlap_offender_count": len(red_offenders),
        "bent_offender_count": len(blue_offenders),
        "mod_offender_count": len(orange_offenders),
        "hard_offender_count": len(hard_overlap_offenders),
        "joint_offender_count": len(joint_overlap_offenders),
        "offender_codes": sorted(offender_codes),
        "painted_red": painted_red,
        "painted_blue": painted_blue,
        "painted_orange": painted_orange,
        "painted_gray": painted_gray,
        "snapshot_blend_path": saved_blend_path,
        "snapshot_png_path": saved_png_path,
    }



===== FILE: tools/blender/debug_run.py =====
"""Blender-level debug run orchestrator for sofa IR.

Usage:
  blender --background --python tools/blender/debug_run.py -- path/to/sofa_ir.json
"""

from __future__ import annotations

import json
import os
import sys
from copy import deepcopy
from typing import Any


REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.builders.blender.builder_v01 import build_plan_from_ir  # noqa: E402
from tools.blender.debug.autofix import fix_ir  # noqa: E402
from tools.blender.debug.io import (  # noqa: E402
    ensure_dir,
    make_run_id,
    make_run_tag,
    save_json,
    sha256_file,
    sha256_json,
)
from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
from tools.blender.debug.validators import validate  # noqa: E402
from tools.blender.run_builder_v01 import (  # noqa: E402
    _clear_scene,
    _create_anchor,
    _create_primitive,
    _ensure_mm_units,
)


def _read_ir_path() -> str:
    """Resolve IR path from argv after '--', then from IR_PATH env."""
    if "--" in sys.argv:
        idx = sys.argv.index("--")
        if len(sys.argv) > idx + 1:
            candidate = str(sys.argv[idx + 1]).strip()
            if candidate:
                return candidate

    env_candidate = str(os.environ.get("IR_PATH", "")).strip()
    if env_candidate:
        return env_candidate

    if len(sys.argv) > 1:
        fallback = str(sys.argv[-1]).strip()
        if fallback and fallback != "--":
            return fallback
    return ""


def _env_int(name: str, default: int, min_value: int = 1) -> int:
    raw = os.environ.get(name, str(default))
    try:
        value = int(raw)
    except (TypeError, ValueError):
        value = int(default)
    return max(int(min_value), value)


def _env_flag(name: str, default: bool = False) -> bool:
    raw = str(os.environ.get(name, "1" if default else "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _resolve_out_dir(path: str) -> str:
    if os.path.isabs(path):
        return path
    return os.path.abspath(os.path.join(REPO_ROOT, path))


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _problem_count(validation: dict[str, Any]) -> int:
    problems = validation.get("problems", [])
    if isinstance(problems, list):
        return len(problems)
    return 0


def _top_overlap_offender_pair(validation: dict[str, Any], metrics: dict[str, Any]) -> dict[str, Any] | None:
    best: dict[str, Any] | None = None
    best_volume = -1.0

    problems = validation.get("problems", [])
    if isinstance(problems, list):
        for problem in problems:
            if not isinstance(problem, dict):
                continue
            code = str(problem.get("code", "")).strip().upper()
            if not code.startswith("OVERLAP_"):
                continue
            details = problem.get("details", {})
            if not isinstance(details, dict):
                continue
            pairs = details.get("pairs_top", [])
            if not isinstance(pairs, list) or len(pairs) == 0:
                pairs = details.get("joint_pairs_top", [])
            if not isinstance(pairs, list):
                continue
            for pair in pairs:
                if not isinstance(pair, dict):
                    continue
                volume = _safe_float(pair.get("volume", 0.0), 0.0)
                if volume > best_volume:
                    best_volume = volume
                    best = {
                        "source": code,
                        "left": str(pair.get("left", "")),
                        "right": str(pair.get("right", "")),
                        "volume": float(volume),
                    }

    if best is not None:
        return best

    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return None

    for overlap_key, payload in overlaps.items():
        if not isinstance(payload, dict):
            continue
        pairs = payload.get("pairs", [])
        if not isinstance(pairs, list):
            continue
        for pair in pairs:
            if not isinstance(pair, dict):
                continue
            volume = _safe_float(pair.get("volume", 0.0), 0.0)
            if volume > best_volume:
                best_volume = volume
                best = {
                    "source": str(overlap_key),
                    "left": str(pair.get("left", "")),
                    "right": str(pair.get("right", "")),
                    "volume": float(volume),
                }
    return best


def _top_fixes_payload(patches_applied: list[dict[str, Any]], limit: int = 5) -> list[dict[str, Any]]:
    payload: list[dict[str, Any]] = []
    for patch in patches_applied[: max(0, int(limit))]:
        if not isinstance(patch, dict):
            continue
        payload.append(
            {
                "path": str(patch.get("path", "")),
                "new": patch.get("new"),
            }
        )
    return payload


def _has_severity_ge3(validation: dict[str, Any]) -> bool:
    problems = validation.get("problems", [])
    if not isinstance(problems, list):
        return False
    for problem in problems:
        if not isinstance(problem, dict):
            continue
        if int(_safe_float(problem.get("severity", 0), 0.0)) >= 3:
            return True
    return False


def _extract_build_counts(metrics: dict[str, Any]) -> dict[str, Any]:
    object_count = 0
    if isinstance(metrics.get("object_count"), int):
        object_count = int(metrics["object_count"])
    elif isinstance(metrics.get("objects"), list):
        object_count = len(metrics["objects"])

    group_counts: dict[str, int] = {}
    top_group_counts = metrics.get("group_counts", {})
    if isinstance(top_group_counts, dict):
        for key, value in top_group_counts.items():
            group_counts[str(key)] = int(_safe_float(value, 0.0))
    else:
        groups = metrics.get("groups", {})
        if isinstance(groups, dict):
            for key, value in groups.items():
                if isinstance(value, dict):
                    group_counts[str(key)] = int(_safe_float(value.get("count", 0), 0.0))

    return {
        "object_count": int(object_count),
        "group_counts": group_counts,
    }


def _build_scene_from_ir(ir: dict[str, Any]) -> dict[str, int]:
    """Build scene from IR using the existing builder primitive functions."""
    import bpy  # type: ignore

    _clear_scene()
    _ensure_mm_units()

    plan = build_plan_from_ir(ir)
    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_params = legs.get("params", {}) if isinstance(legs.get("params"), dict) else None

    for primitive in plan.primitives:
        _create_primitive(primitive, legs_params=legs_params)

    for anchor in plan.anchors:
        _create_anchor(anchor.name, anchor.location_mm)

    bpy.context.view_layer.update()
    return {"primitives": len(plan.primitives), "anchors": len(plan.anchors)}


def main() -> int:
    run_id = make_run_id()
    run_tag = make_run_tag(run_id=run_id)
    out_dir = _resolve_out_dir(os.environ.get("DEBUG_OUT_DIR", "out/logs/runs"))
    ensure_dir(out_dir)

    debug_iters = _env_int("DEBUG_ITERS", 1, min_value=1)
    debug_autofix = _env_flag("DEBUG_AUTOFIX", default=False)
    debug_visualize = _env_flag("DEBUG_VISUALIZE", default=False)

    ir_source_path = ""
    ir_in_path = ""
    ir_out_path = ""
    ir_sha256_in = ""
    ir_sha256_out = ""
    metrics_log_path = ""
    metrics_sha256 = ""
    validation_log_path = ""

    source_ir: dict[str, Any] = {}
    current_ir: dict[str, Any] = {}
    iter_index = 0
    iterations: list[dict[str, Any]] = []
    patches_applied: list[dict[str, Any]] = []

    final_metrics: dict[str, Any] = {}
    final_validation: dict[str, Any] = {
        "score": 0.0,
        "penalty": 1.0,
        "problem_count": 0,
        "problems": [],
    }
    final_build_counts: dict[str, Any] = {"object_count": 0, "group_counts": {}}
    final_top_offender_pair: dict[str, Any] | None = None
    prev_metrics: dict[str, Any] | None = None
    autofix_context: dict[str, Any] = {}

    status = "error"
    error_text: str | None = None
    snapshot_blend_saved = "N/A"
    snapshot_png_saved = "N/A"
    debug_offenders_count = 0
    hard_offenders_count = 0
    joint_offenders_count = 0

    try:
        ir_path = _read_ir_path()
        if not ir_path:
            raise RuntimeError("IR path is required. Pass it after '--' or set IR_PATH.")

        ir_source_path = os.path.abspath(ir_path)
        with open(ir_source_path, "r", encoding="utf-8") as handle:
            loaded_ir = json.load(handle)
        if not isinstance(loaded_ir, dict):
            raise RuntimeError(f"Expected IR JSON object, got {type(loaded_ir).__name__}")

        source_ir = loaded_ir
        current_ir = deepcopy(source_ir)

        ir_in_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_in.json"), source_ir)
        ir_sha256_in = sha256_json(source_ir)

        try:
            import bpy  # type: ignore  # noqa: F401
        except Exception as exc:
            raise RuntimeError("Blender Python runtime is required (module bpy is unavailable).") from exc

        for idx in range(1, debug_iters + 1):
            iter_index = idx
            plan_counts = _build_scene_from_ir(current_ir)
            metrics = collect_scene_metrics()
            validation_payload = validate(current_ir, metrics)
            build_counts = _extract_build_counts(metrics)

            iteration_patches: list[dict[str, Any]] = []
            if debug_autofix and idx < debug_iters:
                problems = validation_payload.get("problems", [])
                if not isinstance(problems, list):
                    problems = []
                updated_ir, iteration_patches = fix_ir(
                    current_ir,
                    problems,
                    metrics=metrics,
                    validation=validation_payload,
                    prev_metrics=prev_metrics,
                    context=autofix_context,
                )
                current_ir = updated_ir
                patches_applied.extend(iteration_patches)

            iterations.append(
                {
                    "iter_index": idx,
                    "plan_counts": plan_counts,
                    "build_counts": build_counts,
                    "validation": validation_payload,
                    "patches_applied": iteration_patches,
                }
            )
            final_metrics = metrics
            final_validation = validation_payload
            final_build_counts = build_counts
            prev_metrics = metrics

        final_top_offender_pair = _top_overlap_offender_pair(final_validation, final_metrics)
        if final_top_offender_pair and isinstance(final_metrics, dict):
            final_metrics["top_offender_pair"] = final_top_offender_pair

        if debug_visualize:
            try:
                from tools.blender.debug.visualize import apply_debug_visualization  # noqa: E402

                vis_payload = apply_debug_visualization(
                    validation=final_validation,
                    metrics=final_metrics,
                    snapshot_blend_path=str(os.environ.get("DEBUG_SNAPSHOT_BLEND", "")).strip() or None,
                    snapshot_png_path=str(os.environ.get("DEBUG_SNAPSHOT_PNG", "")).strip() or None,
                    camera_lens_mm=_safe_float(os.environ.get("DEBUG_SNAPSHOT_LENS_MM", "50"), 50.0),
                )
                debug_offenders_count = int(_safe_float(vis_payload.get("offender_count", 0), 0.0))
                hard_offenders_count = int(_safe_float(vis_payload.get("hard_offender_count", 0), 0.0))
                joint_offenders_count = int(_safe_float(vis_payload.get("joint_offender_count", 0), 0.0))
                snapshot_blend_saved = str(vis_payload.get("snapshot_blend_path", "")).strip() or "N/A"
                snapshot_png_saved = str(vis_payload.get("snapshot_png_path", "")).strip() or "N/A"
            except Exception as exc:
                print(f"DEBUG_VISUALIZE_ERROR:{exc}")

        score = _safe_float(final_validation.get("score", 0.0), 0.0)
        pass_result = score >= 0.95 and (not _has_severity_ge3(final_validation))
        status = "ok" if pass_result else "fail"

    except Exception as exc:
        status = "error"
        error_text = str(exc)

    ir_in_payload = source_ir if isinstance(source_ir, dict) else {}
    if not ir_in_path:
        ir_in_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_in.json"), ir_in_payload)
    if not ir_sha256_in:
        ir_sha256_in = sha256_json(ir_in_payload)

    if not current_ir and isinstance(source_ir, dict):
        current_ir = deepcopy(source_ir)
    ir_out_payload = current_ir if isinstance(current_ir, dict) else {}
    ir_out_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_out.json"), ir_out_payload)
    ir_sha256_out = sha256_json(ir_out_payload)

    metrics_log_payload: dict[str, Any] = {"kind": "metrics"}
    if isinstance(final_metrics, dict):
        metrics_log_payload.update(final_metrics)
    else:
        metrics_log_payload["metrics"] = final_metrics
    metrics_log_path = os.path.abspath(save_json(os.path.join(out_dir, f"{run_tag}.metrics.json"), metrics_log_payload))
    metrics_sha256 = sha256_file(metrics_log_path)
    validation_log_path = os.path.abspath(
        save_json(os.path.join(out_dir, f"{run_tag}.validation.json"), final_validation)
    )

    log_payload: dict[str, Any] = {
        "kind": "run",
        "status": status,
        "error": error_text,
        "run_id": run_id,
        "iter_index": int(iter_index),
        "ir_source_path": ir_source_path,
        "ir_in_path": ir_in_path,
        "ir_out_path": ir_out_path,
        "ir_sha256_in": ir_sha256_in,
        "ir_sha256_out": ir_sha256_out,
        "metrics_path": metrics_log_path,
        "metrics_sha256": metrics_sha256,
        "validation_path": validation_log_path,
        "build_counts": final_build_counts,
        "metrics": final_metrics,
        "validation": final_validation,
        "patches_applied": patches_applied,
        "iterations": iterations,
        "debug_autofix": bool(debug_autofix),
        "debug_iters": int(debug_iters),
        "debug_offenders_count": int(debug_offenders_count),
        "hard_offenders_count": int(hard_offenders_count),
        "joint_offenders_count": int(joint_offenders_count),
    }

    log_path = os.path.abspath(save_json(os.path.join(out_dir, f"{run_tag}.json"), log_payload))

    score = _safe_float(final_validation.get("score", 0.0), 0.0)
    problems = _problem_count(final_validation)
    top_pair = final_top_offender_pair or _top_overlap_offender_pair(final_validation, final_metrics)
    top_fixes = _top_fixes_payload(patches_applied, limit=5)
    ir_in_debug = os.path.abspath(ir_in_path) if ir_in_path else "N/A"
    ir_out_debug = os.path.abspath(ir_out_path) if ir_out_path else "N/A"
    metrics_debug = metrics_log_path if metrics_log_path else "N/A"

    print(f"status: {status}")
    print(f"iterations: {iter_index}")
    if top_pair:
        print(
            "top_offender_pair: "
            f"{top_pair.get('left')} vs {top_pair.get('right')} "
            f"volume_m3={_safe_float(top_pair.get('volume', 0.0), 0.0):.6g} "
            f"source={top_pair.get('source')}"
        )
    else:
        print("top_offender_pair: none")

    print(f"DEBUG_RUN_ID:{run_id}")
    print(f"DEBUG_RUN_LOG:{log_path}")
    print(f"DEBUG_RUN_METRICS:{metrics_debug}")
    print(f"DEBUG_IR_IN:{ir_in_debug}")
    print(f"DEBUG_IR_OUT:{ir_out_debug}")
    print(f"DEBUG_SCORE:{score:.6f}")
    print(f"DEBUG_PROBLEMS:{problems}")
    print(f"DEBUG_TOP_FIXES:{json.dumps(top_fixes, ensure_ascii=False)}")
    print(f"DEBUG_SNAPSHOT_BLEND_SAVED:{snapshot_blend_saved}")
    print(f"DEBUG_SNAPSHOT_PNG_SAVED:{snapshot_png_saved}")
    print(f"DEBUG_OFFENDERS_COUNT:{debug_offenders_count}")
    print(f"DEBUG_HARD_OFFENDERS_COUNT:{hard_offenders_count}")
    print(f"DEBUG_JOINT_OFFENDERS_COUNT:{joint_offenders_count}")

    if status == "error":
        return 3
    if score >= 0.95 and (not _has_severity_ge3(final_validation)):
        return 0
    return 2


if __name__ == "__main__":
    raise SystemExit(main())



===== FILE: tools/blender/DEBUG_USAGE.md =====
# Blender Debug Usage

Optional IR block for modifier expectations:

```json
"debug": {
  "expect_modifiers": {
    "slat_": ["SIMPLE_DEFORM:BEND", "SOLIDIFY", "BEVEL"],
    "back_slat_": ["SIMPLE_DEFORM:BEND"],
    "arm_": ["MIRROR"],
    "frame_": ["BEVEL"],
    "leg_": ["BEVEL"]
  }
}
```

## Color Legend

| Class | Color | Source problem codes |
|---|---|---|
| Overlap offenders | Red | `OVERLAP_*` |
| Missing expected modifiers | Blue | `MOD_EXPECTATION_MISSING` |
| Modifier no-effect offenders | Orange | `MOD_EXPECTATION_NO_EFFECT` |
| Non-offenders / other meshes | Gray | fallback |

Paint priority is fixed: `RED > BLUE > ORANGE > GRAY`.

## Highlight-Only (No Autofix)

```powershell
$env:DEBUG_VISUALIZE="1"
$env:DEBUG_AUTOFIX="0"
$env:DEBUG_ITERS="1"
$env:DEBUG_SNAPSHOT_BLEND="out/snapshots/sofa_highlight_only.blend"
$env:DEBUG_SNAPSHOT_PNG="out/snapshots/sofa_highlight_only.png"
& $env:BLENDER_EXE --background --python tools/blender/debug_run.py -- data/examples/sofa_ir.json
```

## Highlight + Autofix (Iterative)

```powershell
$env:DEBUG_VISUALIZE="1"
$env:DEBUG_AUTOFIX="1"
$env:DEBUG_ITERS="2"
$env:DEBUG_AUTOFIX_VERBOSE="1"
$env:DEBUG_AUTOFIX_SAFETY_MM="3"
$env:DEBUG_SNAPSHOT_BLEND="out/snapshots/sofa_autofix.blend"
$env:DEBUG_SNAPSHOT_PNG="out/snapshots/sofa_autofix.png"
& $env:BLENDER_EXE --background --python tools/blender/debug_run.py -- data/examples/sofa_ir.json
```

Autofix overlap safety margin:
- `DEBUG_AUTOFIX_SAFETY_MM` (default `2`) adds extra millimeters on top of bbox-derived penetration delta.

## Batch Run For Folder Of IR Files

Generates per-IR debug outputs and `summary.csv` with:
- `file_name`
- `debug_score`
- `problems_count`
- `overlaps_slats_m3`
- `overlaps_back_m3`
- `fixes_applied_count`

```powershell
$env:DEBUG_AUTOFIX="1"
$env:DEBUG_ITERS="2"
$env:DEBUG_SNAPSHOT_BLEND_DIR="out/snapshots/batch_blend"
& $env:BLENDER_EXE --background --python tools/blender/batch_debug_run.py -- data/examples out/logs/batch

Get-Item out/logs/batch/summary.csv
```



===== FILE: tools/blender/run_builder_v01.py =====
"""Run builder_v01 inside Blender.

Usage (called by export_blender.py):
blender --background --python tools/blender/run_builder_v01.py -- path/to/sofa_ir.json

This version FIXES slat bending by doing vertex-level bending (bmesh),
instead of relying on SimpleDeform (which can appear "flat" in some pipeline cases).

Env vars:
- IR_PATH: override IR path
- BLEND_PATH: if set, saves .blend to that path
- DEBUG_SLAT=1: adds an extra DEBUG_SLAT
- APPLY_DEBUG_SLAT=1: bakes modifiers for DEBUG_SLAT
- APPLY_ALL_SLATS=1: bakes modifiers for ALL slats (optional)
- DEBUG_JSON=1: writes debug JSON metrics/validation log
"""

import json
import math
import os
import sys
from typing import Optional, Tuple

# --- ensure repo root in sys.path so "src.*" imports work ---
REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.builders.blender import builder_v01 as builder_module  # noqa: E402
from src.builders.blender.builder_v01 import build_plan_from_ir  # noqa: E402


# -------------------------
# small helpers
# -------------------------

def _read_ir_path() -> str:
    """Resolve IR path from env or argv (after '--')."""
    if os.environ.get("IR_PATH"):
        return os.environ["IR_PATH"]

    if "--" in sys.argv:
        i = sys.argv.index("--")
        if len(sys.argv) > i + 1:
            return sys.argv[i + 1]

    # fallback: last arg
    if len(sys.argv) > 1:
        return sys.argv[-1]

    return ""


def _clear_scene() -> None:
    """Start from an empty scene."""
    import bpy  # type: ignore
    bpy.ops.wm.read_factory_settings(use_empty=True)


def _ensure_mm_units() -> None:
    """Configure the scene for millimeter units.

    Blender units: meters. So 1 mm = 0.001 m.
    """
    import bpy  # type: ignore
    scene = bpy.context.scene
    scene.unit_settings.system = "METRIC"
    scene.unit_settings.scale_length = 1.0


def _mm_to_m(v):
    return tuple(float(x) / 1000.0 for x in v)


def _apply_rotation_deg(obj, rotation_deg) -> None:
    if not rotation_deg:
        return
    try:
        rx, ry, rz = rotation_deg
    except (TypeError, ValueError):
        return
    if rx == 0 and ry == 0 and rz == 0:
        return
    obj.rotation_euler = (math.radians(rx), math.radians(ry), math.radians(rz))


def _bake_object_modifiers(obj) -> None:
    """Bake evaluated mesh into obj.data and clear modifiers."""
    import bpy  # type: ignore

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()
    try:
        depsgraph.update()
    except Exception:
        pass

    eval_obj = obj.evaluated_get(depsgraph)
    new_mesh = bpy.data.meshes.new_from_object(
        eval_obj,
        depsgraph=depsgraph,
        preserve_all_data_layers=True,
    )
    obj.data = new_mesh
    obj.modifiers.clear()


# -------------------------
# primitives
# -------------------------

def _create_cube(name, dimensions_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cube_add(size=1.0, location=_mm_to_m(location_mm))
    obj = bpy.context.active_object
    obj.name = name
    obj.dimensions = _mm_to_m(dimensions_mm)
    bpy.context.view_layer.update()
    return obj


def _create_cylinder(name, radius_mm, height_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cylinder_add(
        radius=float(radius_mm) / 1000.0,
        depth=float(height_mm) / 1000.0,
        location=_mm_to_m(location_mm),
    )
    obj = bpy.context.active_object
    obj.name = name
    return obj


def _create_cone(name, r_top_mm, r_bottom_mm, height_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cone_add(
        radius1=float(r_bottom_mm) / 1000.0,
        radius2=float(r_top_mm) / 1000.0,
        depth=float(height_mm) / 1000.0,
        location=_mm_to_m(location_mm),
    )
    obj = bpy.context.active_object
    obj.name = name
    return obj


def _create_anchor(name, location_mm):
    import bpy  # type: ignore
    empty = bpy.data.objects.new(name, None)
    empty.empty_display_type = "PLAIN_AXES"
    empty.location = _mm_to_m(location_mm)
    bpy.context.scene.collection.objects.link(empty)
    return empty


# -------------------------
# slats: mesh + vertex bend
# -------------------------

def _create_slat_mesh(
    name: str,
    width_mm: float,
    length_mm: float,
    location_mm,
    rotation_deg,
    segments_len: int,
    segments_w: int,
    orientation: str,
):
    """Creates a grid plane:
    - horizontal: plane in XY (length along +Y), normal ~ +Z
    - vertical:   plane in XZ (length along +Z), normal ~ +Y (or -Y)
    """
    import bpy  # type: ignore
    import bmesh  # type: ignore

    segments_len = max(1, int(segments_len))
    segments_w = max(1, int(segments_w))

    width_m = float(width_mm) / 1000.0
    length_m = float(length_mm) / 1000.0

    bm = bmesh.new()

    # Start with unit grid in XY centered at origin
    bmesh.ops.create_grid(bm, x_segments=segments_w, y_segments=segments_len, size=1.0)

    # Normalize to target width/length in local space
    if bm.verts:
        xs = [v.co.x for v in bm.verts]
        ys = [v.co.y for v in bm.verts]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        cx = (min_x + max_x) / 2.0
        cy = (min_y + max_y) / 2.0
        ext_x = max_x - min_x
        ext_y = max_y - min_y
        sx = (width_m / ext_x) if ext_x != 0.0 else 1.0
        sy = (length_m / ext_y) if ext_y != 0.0 else 1.0

        for v in bm.verts:
            v.co.x = (v.co.x - cx) * sx
            v.co.y = (v.co.y - cy) * sy
            v.co.z = 0.0

    # If vertical: rotate XY plane into XZ (so length becomes Z)
    if orientation == "vertical":
        from mathutils import Matrix  # type: ignore
        rot_m = Matrix.Rotation(math.radians(90.0), 4, "X")  # Y -> Z
        for v in bm.verts:
            v.co = rot_m @ v.co

    mesh = bpy.data.meshes.new(name)
    bm.to_mesh(mesh)
    bm.free()
    mesh.update()

    for poly in mesh.polygons:
        poly.use_smooth = True

    obj = bpy.data.objects.new(name, mesh)
    obj.location = _mm_to_m(location_mm)
    _apply_rotation_deg(obj, rotation_deg)
    bpy.context.scene.collection.objects.link(obj)
    bpy.context.view_layer.update()
    return obj


def _bend_vertices_arc(
    obj,
    orientation: str,
    length_mm: float,
    arc_height_mm: float,
    arc_sign: float,
) -> Tuple[float, float]:
    """Bend vertices into a circular arc (sagitta).
    Returns (radius_m, angle_rad).
    - horizontal: length along local Y, sag applied to local Z
    - vertical:   length along local Z, sag applied to local Y  (back curvature)
    """
    import bmesh  # type: ignore

    if arc_height_mm <= 0.0 or length_mm <= 0.0:
        return (0.0, 0.0)

    L = float(length_mm) / 1000.0
    h = float(arc_height_mm) / 1000.0
    sign = -1.0 if arc_sign < 0 else 1.0

    # radius from sagitta
    # R = L^2/(8h) + h/2
    R = (L * L) / (8.0 * h) + (h / 2.0)
    if not math.isfinite(R) or R <= 0:
        return (0.0, 0.0)

    angle = L / R
    angle = max(-math.pi, min(math.pi, angle))

    half = L / 2.0

    bm = bmesh.new()
    bm.from_mesh(obj.data)

    for v in bm.verts:
        if orientation == "vertical":
            t = v.co.z  # along length
        else:
            t = v.co.y

        t = max(-half, min(half, t))

        # sag = R - sqrt(R^2 - t^2)
        under = max(0.0, (R * R - t * t))
        sag = R - math.sqrt(under)

        if orientation == "vertical":
            v.co.y += sag * sign
        else:
            v.co.z += sag * sign

    bm.to_mesh(obj.data)
    bm.free()
    obj.data.update()

    return (R, angle)


def _axis_ranges_world(mesh, matrix_world):
    if not mesh or len(mesh.vertices) == 0:
        return None
    xs, ys, zs = [], [], []
    for v in mesh.vertices:
        w = matrix_world @ v.co
        xs.append(w.x)
        ys.append(w.y)
        zs.append(w.z)
    return (min(xs), max(xs)), (min(ys), max(ys)), (min(zs), max(zs))


# -------------------------
# plan primitive creator
# -------------------------

def _create_primitive(p, legs_params=None):
    """Create geometry for a Primitive from builder_v01 plan."""
    import bpy  # type: ignore

    shape = getattr(p, "shape", "cube")
    dims = getattr(p, "dimensions_mm", (100, 100, 100))
    loc = getattr(p, "location_mm", (0, 0, 0))
    rot = getattr(p, "rotation_deg", (0.0, 0.0, 0.0))

    if shape in {"cube", "beam", "board"}:
        obj = _create_cube(p.name, dims, loc)
        _apply_rotation_deg(obj, rot)
        return obj

    if shape == "slat":
        # defaults
        arc_height_mm = 0.0
        arc_sign = -1.0
        orientation = "horizontal"
        subdiv_cuts = 64
        edge_radius_mm = 1.0
        solidify_offset = 1.0

        params = getattr(p, "params", None)
        if isinstance(params, dict):
            try:
                arc_height_mm = float(params.get("arc_height_mm", 0.0))
            except (TypeError, ValueError):
                arc_height_mm = 0.0
            try:
                arc_sign = float(params.get("arc_sign", -1.0))
            except (TypeError, ValueError):
                arc_sign = -1.0
            try:
                orientation = str(params.get("orientation", "horizontal")).strip().lower()
            except (TypeError, ValueError):
                orientation = "horizontal"
            try:
                subdiv_cuts = int(params.get("subdiv_cuts", 64))
            except (TypeError, ValueError):
                subdiv_cuts = 64
            try:
                edge_radius_mm = float(params.get("edge_radius_mm", 1.0))
            except (TypeError, ValueError):
                edge_radius_mm = 1.0
            try:
                solidify_offset = float(params.get("solidify_offset", 1.0))
            except (TypeError, ValueError):
                solidify_offset = 1.0

        if orientation in {"seat"}:
            orientation = "horizontal"
        if orientation not in {"horizontal", "vertical"}:
            orientation = "horizontal"

        arc_sign = -1.0 if arc_sign < 0 else 1.0
        solidify_offset = max(-1.0, min(1.0, solidify_offset))

        # dims mapping
        if orientation == "vertical":
            # width X, thickness Y, length Z  (like your older logic)
            width_mm = float(dims[0])
            thickness_mm = float(dims[1])
            length_mm = float(dims[2])
        else:
            # width X, length Y, thickness Z
            width_mm = float(dims[0])
            length_mm = float(dims[1])
            thickness_mm = float(dims[2])

        # mesh density: must be high along length for nice arc
        subdiv_cuts = max(8, min(200, int(subdiv_cuts)))
        segments_len = max(40, min(240, subdiv_cuts * 2))
        segments_w = 4

        obj = _create_slat_mesh(
            name=p.name,
            width_mm=width_mm,
            length_mm=length_mm,
            location_mm=loc,
            rotation_deg=rot,
            segments_len=segments_len,
            segments_w=segments_w,
            orientation=orientation,
        )

        # do vertex bending (the fix)
        radius_m, angle_rad = (0.0, 0.0)
        if arc_height_mm > 0.0 and length_mm > 0.0:
            radius_m, angle_rad = _bend_vertices_arc(
                obj=obj,
                orientation=orientation,
                length_mm=length_mm,
                arc_height_mm=arc_height_mm,
                arc_sign=arc_sign,
            )

        # solidify thickness (works from normals of the plane)
        if thickness_mm > 0.0:
            solid = obj.modifiers.new(name="Solidify", type="SOLIDIFY")
            solid.thickness = float(thickness_mm) / 1000.0
            solid.offset = solidify_offset
            solid.use_even_offset = True

        # bevel edges
        if edge_radius_mm > 0.0:
            bevel = obj.modifiers.new(name="Bevel", type="BEVEL")
            bevel.width = float(edge_radius_mm) / 1000.0
            bevel.segments = 2
            bevel.limit_method = "ANGLE"
            bevel.angle_limit = math.radians(40.0)
            if hasattr(bevel, "harden_normals"):
                bevel.harden_normals = True

        # normals
        wn = obj.modifiers.new(name="WeightedNormal", type="WEIGHTED_NORMAL")
        wn.keep_sharp = True
        wn.weight = 50
        if hasattr(obj.data, "use_auto_smooth"):
            obj.data.use_auto_smooth = True
        if hasattr(obj.data, "auto_smooth_angle"):
            obj.data.auto_smooth_angle = math.radians(40.0)

        # optional baking
        if os.environ.get("APPLY_ALL_SLATS") == "1":
            _bake_object_modifiers(obj)

        # debug ranges (base/eval)
        if obj.name in {"DEBUG_SLAT", "slat_1"} or os.environ.get("DEBUG_SLAT") == "1":
            bpy.context.view_layer.update()
            depsgraph = bpy.context.evaluated_depsgraph_get()
            eval_obj = obj.evaluated_get(depsgraph)
            eval_mesh = eval_obj.to_mesh()

            base_ranges = _axis_ranges_world(obj.data, obj.matrix_world)
            eval_ranges = _axis_ranges_world(eval_mesh, eval_obj.matrix_world)

            print(
                f"[slat] name={obj.name} orientation={orientation} arc_height_mm={arc_height_mm} "
                f"radius_m={radius_m:.6f} angle_rad={angle_rad:.6f} "
                f"verts={len(obj.data.vertices)} mods={[m.type for m in obj.modifiers]}"
            )
            if base_ranges and eval_ranges:
                base_spans = (
                    base_ranges[0][1] - base_ranges[0][0],
                    base_ranges[1][1] - base_ranges[1][0],
                    base_ranges[2][1] - base_ranges[2][0],
                )
                eval_spans = (
                    eval_ranges[0][1] - eval_ranges[0][0],
                    eval_ranges[1][1] - eval_ranges[1][0],
                    eval_ranges[2][1] - eval_ranges[2][0],
                )
                dx = abs(eval_spans[0] - base_spans[0])
                dy = abs(eval_spans[1] - base_spans[1])
                dz = abs(eval_spans[2] - base_spans[2])
                print(
                    f"SLAT_RANGES_BASE x=({base_ranges[0][0]:.6f},{base_ranges[0][1]:.6f}) "
                    f"y=({base_ranges[1][0]:.6f},{base_ranges[1][1]:.6f}) "
                    f"z=({base_ranges[2][0]:.6f},{base_ranges[2][1]:.6f})"
                )
                print(
                    f"SLAT_RANGES_EVAL x=({eval_ranges[0][0]:.6f},{eval_ranges[0][1]:.6f}) "
                    f"y=({eval_ranges[1][0]:.6f},{eval_ranges[1][1]:.6f}) "
                    f"z=({eval_ranges[2][0]:.6f},{eval_ranges[2][1]:.6f})"
                )
                print(f"SLAT_RANGE_DELTAS dx={dx:.6f} dy={dy:.6f} dz={dz:.6f}")

            eval_obj.to_mesh_clear()

        return obj

    if shape == "cylindrical":
        obj = _create_cylinder(p.name, radius_mm=float(dims[0]) / 2.0, height_mm=float(dims[2]), location_mm=loc)
        _apply_rotation_deg(obj, rot)
        return obj

    if shape == "tapered_cone":
        r_top = None
        r_bottom = None
        if isinstance(legs_params, dict):
            try:
                if legs_params.get("r_top") is not None:
                    r_top = float(legs_params["r_top"])
                if legs_params.get("r_bottom") is not None:
                    r_bottom = float(legs_params["r_bottom"])
            except (TypeError, ValueError):
                r_top = None
                r_bottom = None
        if r_top is None or r_bottom is None:
            r_top = max(6.0, float(dims[0]) * 0.35)
            r_bottom = max(r_top + 2.0, float(dims[0]) * 0.6)
        obj = _create_cone(p.name, r_top_mm=r_top, r_bottom_mm=r_bottom, height_mm=float(dims[2]), location_mm=loc)
        _apply_rotation_deg(obj, rot)
        return obj

    # fallback -> cube
    obj = _create_cube(p.name, dims, loc)
    _apply_rotation_deg(obj, rot)
    return obj


# -------------------------
# main
# -------------------------

def main():
    import bpy  # type: ignore

    ir_path = _read_ir_path()
    if not ir_path:
        raise SystemExit("IR path is required. Pass it after '--' or set IR_PATH env var.")

    print(f"RUN_BUILDER_V01:{__file__}")
    print(f"REPO_ROOT:{REPO_ROOT}")
    print(f"BUILDER_MODULE:{builder_module.__file__}")

    _clear_scene()
    _ensure_mm_units()

    blend_path = os.environ.get("BLEND_PATH", "")
    print(f"IR_PATH:{ir_path}")
    print(f"BLEND_PATH:{blend_path}")

    with open(ir_path, "r", encoding="utf-8") as f:
        ir = json.load(f)

    plan = build_plan_from_ir(ir)
    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_params = legs.get("params", {}) if isinstance(legs.get("params"), dict) else None

    # build primitives
    for prim in plan.primitives:
        _create_primitive(prim, legs_params=legs_params)

    # optional debug slat
    if os.environ.get("DEBUG_SLAT") == "1":
        try:
            debug_slat = _create_primitive(
                builder_module.Primitive(
                    name="DEBUG_SLAT",
                    shape="slat",
                    dimensions_mm=(60.0, 600.0, 12.0),  # width, length, thickness (horizontal)
                    location_mm=(0.0, 900.0, 300.0),
                    rotation_deg=(0.0, 0.0, 0.0),
                    params={
                        "arc_height_mm": 35.0,
                        "arc_sign": -1.0,
                        "orientation": "horizontal",
                        "subdiv_cuts": 64,
                        "edge_radius_mm": 1.0,
                        "solidify_offset": 1.0,
                    },
                ),
                legs_params=legs_params,
            )
            print(f"DEBUG_SLAT_CREATED:{debug_slat.name} verts={len(debug_slat.data.vertices)}")
            if os.environ.get("APPLY_DEBUG_SLAT") == "1":
                _bake_object_modifiers(debug_slat)
                print("DEBUG_SLAT_BAKED:1")
        except Exception as exc:
            print(f"DEBUG_SLAT_CREATED:error={exc}")

    # anchors as empties
    for a in plan.anchors:
        _create_anchor(a.name, a.location_mm)

    object_names = sorted(obj.name for obj in bpy.data.objects)
    print(f"OBJECTS_TOTAL:{len(object_names)} FIRST:{object_names[:10]}")
    slat_count = sum(1 for name in object_names if name.startswith("slat_"))
    beam_count = sum(1 for name in object_names if name.startswith("beam_"))
    rail_count = sum(1 for name in object_names if name.startswith("rail_"))
    print(f"OBJECT_PREFIX_COUNTS slat_={slat_count} beam_={beam_count} rail_={rail_count}")

    if os.environ.get("DEBUG_JSON") == "1":
        try:
            from tools.blender.debug.io import ir_sha256, make_run_id, save_run_log  # noqa: E402
            from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
            from tools.blender.debug.validators import validate  # noqa: E402

            debug_run_id = make_run_id()
            metrics = collect_scene_metrics()
            validation = validate(metrics, ir)
            debug_payload = {
                "run_id": debug_run_id,
                "source": "run_builder_v01",
                "ir_path": os.path.abspath(ir_path),
                "ir_sha256": ir_sha256(ir),
                "build": {
                    "primitives": len(plan.primitives),
                    "anchors": len(plan.anchors),
                },
                "metrics": metrics,
                "validation": validation,
            }
            debug_log_path = save_run_log(
                debug_payload,
                out_dir=os.path.join(REPO_ROOT, "out", "logs", "runs"),
                run_id=debug_run_id,
            )
            print(f"DEBUG_JSON_LOG:{debug_log_path}")
        except Exception as exc:
            print(f"DEBUG_JSON_ERROR:{exc}")

    # optionally save .blend
    if blend_path:
        os.makedirs(os.path.dirname(blend_path), exist_ok=True)
        bpy.ops.wm.save_as_mainfile(filepath=blend_path)

    return {"status": "built", "primitives": len(plan.primitives), "anchors": len(plan.anchors)}


if __name__ == "__main__":
    main()



===== FILE: tools/blender/run_export_glb.py =====
"""Export GLB from Blender scene."""

import os
import sys

import bpy  # type: ignore  # Blender-only


def _read_glb_path() -> str:
    """Resolve GLB path from env or argv."""
    if os.environ.get("GLB_PATH"):
        return os.environ["GLB_PATH"]
    if "--" in sys.argv:
        index = sys.argv.index("--")
        if len(sys.argv) > index + 1:
            return sys.argv[index + 1]
    if len(sys.argv) > 1:
        return sys.argv[-1]
    return "out/glb/sofa.glb"


def _export_apply_kwargs():
    props = bpy.ops.export_scene.gltf.get_rna_type().properties
    if "export_apply" in props:
        return {"export_apply": True}
    if "export_apply_modifiers" in props:
        return {"export_apply_modifiers": True}
    return {}


def _is_exportable_mesh(obj) -> bool:
    if obj.type != "MESH":
        return False
    if obj.name.endswith("_bend_origin"):
        return False
    for col in obj.users_collection:
        if col.name == "_helpers":
            return False
    if obj.hide_get() or obj.hide_viewport or obj.hide_render:
        return False
    if not obj.visible_get():
        return False
    return True


def main():
    """Entry point for Blender execution."""
    glb_path = _read_glb_path()
    glb_path = os.path.abspath(glb_path)
    os.makedirs(os.path.dirname(glb_path), exist_ok=True)

    print(f"RUN_EXPORT_GLB:{__file__}")
    print(f"BLEND_PATH:{bpy.data.filepath}")
    print(f"GLB_PATH:{glb_path}")

    if os.path.exists(glb_path):
        try:
            os.remove(glb_path)
        except OSError as exc:
            print(f"WARNING: failed to remove existing GLB {glb_path}: {exc}")

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()

    helpers = bpy.data.collections.get("_helpers")
    if helpers is not None:
        helpers.hide_viewport = True
        helpers.hide_render = True

    export_objs = [obj for obj in bpy.data.objects if _is_exportable_mesh(obj)]
    tmp_coll = bpy.data.collections.get("_export_tmp")
    if tmp_coll is None:
        tmp_coll = bpy.data.collections.new("_export_tmp")
        bpy.context.scene.collection.children.link(tmp_coll)
    tmp_coll.hide_viewport = False
    tmp_coll.hide_render = False

    tmp_objects = []
    tmp_meshes = []
    for obj in export_objs:
        eval_obj = obj.evaluated_get(depsgraph)
        try:
            mesh = bpy.data.meshes.new_from_object(eval_obj, depsgraph=depsgraph)
            used_new_from_object = True
        except Exception:
            used_new_from_object = False
            mesh_eval = eval_obj.to_mesh()
            mesh = mesh_eval.copy()
            eval_obj.to_mesh_clear()
        tmp = bpy.data.objects.new(obj.name, mesh)
        tmp.matrix_world = obj.matrix_world
        tmp_coll.objects.link(tmp)
        tmp_objects.append(tmp)
        tmp_meshes.append(mesh)

    print(f"EXPORT_MESH_OBJECTS:{len(tmp_objects)}")

    bpy.ops.object.select_all(action="DESELECT")
    for obj in tmp_objects:
        obj.select_set(True)
    if tmp_objects:
        bpy.context.view_layer.objects.active = tmp_objects[0]

    export_kwargs = {
        "filepath": glb_path,
        "export_format": "GLB",
        "use_selection": True,
    }
    export_kwargs.update(_export_apply_kwargs())

    result = bpy.ops.export_scene.gltf(**export_kwargs)
    print(f"GLTF_EXPORT_RESULT:{result}")
    bpy.context.view_layer.update()

    size = os.path.getsize(glb_path) if os.path.exists(glb_path) else 0
    print(f"GLB_SIZE_BYTES:{size}")
    if size <= 0:
        raise SystemExit(2)

    for obj in tmp_objects:
        bpy.data.objects.remove(obj, do_unlink=True)
    for mesh in tmp_meshes:
        if mesh.users == 0:
            bpy.data.meshes.remove(mesh)

    return {
        "status": "exported",
        "path": glb_path,
    }


if __name__ == "__main__":
    main()



===== FILE: tools/blender/slat_lab.py =====
"""Isolated slat deformation lab for Blender 4.4.

Run:
  blender --background --factory-startup --python tools/blender/slat_lab.py -- [options]

Options (after "--"):
  --out_blend <path>   Save .blend (optional)
  --apply              Bake modifiers for variant C
  --arc_mm <float>     Sagitta height in mm (default 35)
  --length_mm <float>  Slat length in mm (default 600)
  --width_mm <float>   Slat width in mm (default 60)
  --thick_mm <float>   Slat thickness in mm (default 12)
  --segments <int>     Grid segments along length (default 80)
"""

from __future__ import annotations

import math
import os
import sys
from dataclasses import dataclass


def _mm_to_m(x_mm: float) -> float:
    return float(x_mm) / 1000.0


def _clamp(v, lo, hi):
    return max(lo, min(hi, v))


@dataclass
class Opts:
    out_blend: str = ""
    apply: bool = False
    arc_mm: float = 35.0
    length_mm: float = 600.0
    width_mm: float = 60.0
    thick_mm: float = 12.0
    segments: int = 80


def _parse_opts(argv: list[str]) -> Opts:
    opts = Opts()

    if "--" in argv:
        args = argv[argv.index("--") + 1 :]
    else:
        args = []

    i = 0
    while i < len(args):
        a = args[i]
        if a == "--apply":
            opts.apply = True
            i += 1
            continue
        if a == "--out_blend" and i + 1 < len(args):
            opts.out_blend = str(args[i + 1])
            i += 2
            continue
        if a == "--arc_mm" and i + 1 < len(args):
            try:
                opts.arc_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--length_mm" and i + 1 < len(args):
            try:
                opts.length_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--width_mm" and i + 1 < len(args):
            try:
                opts.width_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--thick_mm" and i + 1 < len(args):
            try:
                opts.thick_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--segments" and i + 1 < len(args):
            try:
                opts.segments = int(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue

        i += 1

    opts.segments = int(_clamp(opts.segments, 1, 500))
    return opts


def _bend_angle_from_sagitta(length_mm: float, arc_mm: float) -> tuple[float, float]:
    """Return (angle_rad, radius_mm)."""
    if length_mm <= 0.0 or arc_mm <= 0.0:
        return 0.0, 0.0
    arc_mm = min(max(0.0, arc_mm), length_mm / 2.0)
    radius_mm = (length_mm * length_mm) / (8.0 * arc_mm) + (arc_mm / 2.0)
    if radius_mm <= 0.0 or not math.isfinite(radius_mm):
        return 0.0, radius_mm
    angle_rad = length_mm / radius_mm
    angle_rad = max(-math.pi, min(math.pi, angle_rad))
    return angle_rad, radius_mm


def _ensure_child_collection(scene_coll, name: str, hide: bool) -> "bpy.types.Collection":
    import bpy  # type: ignore

    coll = bpy.data.collections.get(name)
    if coll is None:
        coll = bpy.data.collections.new(name)
    if coll.name not in scene_coll.children:
        scene_coll.children.link(coll)
    coll.hide_viewport = bool(hide)
    coll.hide_render = bool(hide)
    return coll


def _move_obj_to_collection(obj, dst_coll) -> None:
    # Ensure object is only linked to dst_coll.
    for c in list(obj.users_collection):
        if c != dst_coll:
            c.objects.unlink(obj)
    if obj not in dst_coll.objects:
        dst_coll.objects.link(obj)


def _create_origin_empty(name: str, location, rotation_euler, helpers_coll):
    import bpy  # type: ignore

    empty = bpy.data.objects.new(name, None)
    empty.empty_display_type = "PLAIN_AXES"
    empty.location = location
    if rotation_euler is not None:
        empty.rotation_euler = rotation_euler
    empty.hide_viewport = True
    empty.hide_render = True
    helpers_coll.objects.link(empty)
    return empty


def _mesh_bbox_world(mesh, matrix_world):
    from mathutils import Vector  # type: ignore

    if not mesh.vertices:
        zero = Vector((0.0, 0.0, 0.0))
        return zero, zero
    min_v = None
    max_v = None
    for v in mesh.vertices:
        co = matrix_world @ v.co
        if min_v is None:
            min_v = co.copy()
            max_v = co.copy()
        else:
            min_v.x = min(min_v.x, co.x)
            min_v.y = min(min_v.y, co.y)
            min_v.z = min(min_v.z, co.z)
            max_v.x = max(max_v.x, co.x)
            max_v.y = max(max_v.y, co.y)
            max_v.z = max(max_v.z, co.z)
    return min_v, max_v


def _print_obj_stats(obj, label: str) -> None:
    mesh = obj.data
    mods = [f"{m.name}:{m.type}" for m in obj.modifiers]
    bb_min, bb_max = _mesh_bbox_world(mesh, obj.matrix_world)
    print(
        f"OBJ {label} name={obj.name} verts={len(mesh.vertices)} polys={len(mesh.polygons)} "
        f"bbox_min=({bb_min.x:.6f},{bb_min.y:.6f},{bb_min.z:.6f}) "
        f"bbox_max=({bb_max.x:.6f},{bb_max.y:.6f},{bb_max.z:.6f}) mods={mods}"
    )


def _print_obj_eval_stats(obj, label: str) -> tuple[float, float]:
    import bpy  # type: ignore

    depsgraph = bpy.context.evaluated_depsgraph_get()
    eval_obj = obj.evaluated_get(depsgraph)
    eval_mesh = eval_obj.to_mesh()
    try:
        bb_min, bb_max = _mesh_bbox_world(eval_mesh, eval_obj.matrix_world)
        mods = [f"{m.name}:{m.type}" for m in obj.modifiers]
        print(
            f"OBJ_EVAL {label} name={obj.name} verts={len(eval_mesh.vertices)} polys={len(eval_mesh.polygons)} "
            f"bbox_min=({bb_min.x:.6f},{bb_min.y:.6f},{bb_min.z:.6f}) "
            f"bbox_max=({bb_max.x:.6f},{bb_max.y:.6f},{bb_max.z:.6f}) mods={mods}"
        )
        return bb_min.z, bb_max.z
    finally:
        eval_obj.to_mesh_clear()


def _create_grid_slat_object(name: str, width_m: float, length_m: float, segments_len: int, segments_w: int):
    import bpy  # type: ignore
    import bmesh  # type: ignore

    bm = bmesh.new()
    bmesh.ops.create_grid(bm, x_segments=segments_w, y_segments=segments_len, size=1.0)

    if bm.verts:
        xs = [v.co.x for v in bm.verts]
        ys = [v.co.y for v in bm.verts]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        cx = (min_x + max_x) / 2.0
        cy = (min_y + max_y) / 2.0
        ext_x = max_x - min_x
        ext_y = max_y - min_y
        sx = (width_m / ext_x) if ext_x != 0.0 else 1.0
        sy = (length_m / ext_y) if ext_y != 0.0 else 1.0
        for v in bm.verts:
            v.co.x = (v.co.x - cx) * sx
            v.co.y = (v.co.y - cy) * sy
            v.co.z = 0.0

    mesh = bpy.data.meshes.new(name)
    bm.to_mesh(mesh)
    bm.free()
    mesh.update()
    for poly in mesh.polygons:
        poly.use_smooth = True

    obj = bpy.data.objects.new(name, mesh)
    return obj


def _add_bend_modifier(obj, origin, axis: str, angle_rad: float) -> None:
    mod = obj.modifiers.new(name="Bend", type="SIMPLE_DEFORM")
    mod.deform_method = "BEND"
    mod.deform_axis = axis
    mod.angle = angle_rad
    mod.origin = origin
    if hasattr(mod, "show_viewport"):
        mod.show_viewport = True
    if hasattr(mod, "show_render"):
        mod.show_render = True
    if hasattr(mod, "show_in_editmode"):
        mod.show_in_editmode = True
    if hasattr(mod, "show_on_cage"):
        mod.show_on_cage = True


def main() -> None:
    import bpy  # type: ignore
    from mathutils import Vector  # type: ignore

    opts = _parse_opts(sys.argv)

    print(f"BLENDER_VERSION:{bpy.app.version_string}")
    print(f"FILEPATH:{bpy.data.filepath}")
    print(
        "OPTS "
        f"out_blend={opts.out_blend!r} apply={opts.apply} arc_mm={opts.arc_mm} "
        f"length_mm={opts.length_mm} width_mm={opts.width_mm} thick_mm={opts.thick_mm} segments={opts.segments}"
    )

    bpy.ops.wm.read_factory_settings(use_empty=True)
    scene = bpy.context.scene

    lab_coll = _ensure_child_collection(scene.collection, "_lab", hide=False)
    helpers_coll = _ensure_child_collection(scene.collection, "_helpers", hide=True)

    width_m = _mm_to_m(opts.width_mm)
    length_m = _mm_to_m(opts.length_mm)
    thick_m = _mm_to_m(opts.thick_mm)

    # Use negative angle to bend "upwards" in +Z for axis=Y in typical orientation.
    angle_rad, radius_mm = _bend_angle_from_sagitta(opts.length_mm, opts.arc_mm)
    bend_angle = -angle_rad
    print(f"BEND_CALC arc_mm={opts.arc_mm} length_mm={opts.length_mm} radius_mm={radius_mm} angle_rad={bend_angle}")

    # Layout: three objects spaced in X.
    base_z = 0.30
    loc_a = Vector((-0.45, 0.0, base_z))
    loc_b = Vector((0.00, 0.0, base_z))
    loc_c = Vector((0.45, 0.0, base_z))

    # A) SLAT_CUBE
    bpy.ops.mesh.primitive_cube_add(size=1.0, location=loc_a)
    obj_a = bpy.context.active_object
    obj_a.name = "SLAT_CUBE"
    obj_a.dimensions = (width_m, length_m, thick_m)
    _move_obj_to_collection(obj_a, lab_coll)
    origin_a = _create_origin_empty("SLAT_CUBE_ORIGIN", obj_a.location.copy(), obj_a.rotation_euler, helpers_coll)
    _add_bend_modifier(obj_a, origin_a, axis="Y", angle_rad=bend_angle)

    # B) SLAT_GRID
    obj_b = _create_grid_slat_object("SLAT_GRID", width_m=width_m, length_m=length_m, segments_len=opts.segments, segments_w=2)
    obj_b.location = loc_b
    lab_coll.objects.link(obj_b)
    mod_solid_b = obj_b.modifiers.new(name="Solidify", type="SOLIDIFY")
    mod_solid_b.thickness = thick_m
    mod_solid_b.offset = 0.0
    mod_solid_b.use_even_offset = True
    origin_b = _create_origin_empty(
        "SLAT_GRID_ORIGIN",
        obj_b.matrix_world @ Vector((0.0, -length_m / 2.0, 0.0)),
        obj_b.rotation_euler,
        helpers_coll,
    )
    _add_bend_modifier(obj_b, origin_b, axis="Y", angle_rad=bend_angle)

    # C) SLAT_GRID_APPLIED
    obj_c = obj_b.copy()
    obj_c.data = obj_b.data.copy()
    obj_c.name = "SLAT_GRID_APPLIED"
    obj_c.location = loc_c
    lab_coll.objects.link(obj_c)
    # Replace bend origin to avoid sharing the same empty.
    for m in obj_c.modifiers:
        if m.type == "SIMPLE_DEFORM":
            origin_c = _create_origin_empty(
                "SLAT_GRID_APPLIED_ORIGIN",
                obj_c.matrix_world @ Vector((0.0, -length_m / 2.0, 0.0)),
                obj_c.rotation_euler,
                helpers_coll,
            )
            m.origin = origin_c

    bpy.context.view_layer.update()

    # Logs: base mesh stats.
    _print_obj_stats(obj_a, label="BASE")
    _print_obj_stats(obj_b, label="BASE")
    _print_obj_stats(obj_c, label="BASE")

    # Logs: evaluated stats (show modifier effect).
    _print_obj_eval_stats(obj_a, label="EVAL")
    b_base_minz, b_base_maxz = _mesh_bbox_world(obj_b.data, obj_b.matrix_world)
    b_eval_minz, b_eval_maxz = _print_obj_eval_stats(obj_b, label="EVAL")
    print(f"Z_RANGE SLAT_GRID base=({b_base_minz.z:.6f},{b_base_maxz.z:.6f}) eval=({b_eval_minz:.6f},{b_eval_maxz:.6f})")

    c_base_minz, c_base_maxz = _mesh_bbox_world(obj_c.data, obj_c.matrix_world)
    c_eval_minz, c_eval_maxz = _print_obj_eval_stats(obj_c, label="EVAL")
    print(
        f"Z_RANGE SLAT_GRID_APPLIED base=({c_base_minz.z:.6f},{c_base_maxz.z:.6f}) "
        f"eval=({c_eval_minz:.6f},{c_eval_maxz:.6f})"
    )

    if opts.apply:
        depsgraph = bpy.context.evaluated_depsgraph_get()
        eval_obj = obj_c.evaluated_get(depsgraph)
        new_mesh = bpy.data.meshes.new_from_object(eval_obj, depsgraph=depsgraph)
        old_mesh = obj_c.data
        obj_c.data = new_mesh
        obj_c.modifiers.clear()
        if old_mesh.users == 0:
            bpy.data.meshes.remove(old_mesh)
        bpy.context.view_layer.update()
        _print_obj_stats(obj_c, label="APPLIED")

    if opts.out_blend:
        out_blend = os.path.abspath(opts.out_blend)
        out_dir = os.path.dirname(out_blend)
        if out_dir:
            os.makedirs(out_dir, exist_ok=True)
        bpy.ops.wm.save_as_mainfile(filepath=out_blend)
        print(f"SAVED_BLEND:{out_blend}")


if __name__ == "__main__":
    main()



===== FILE: tools/dump_debug.ps1 =====
param(
  [int]$MaxFileSizeKB = 500,
  [string]$OutDump = "repo_dump_debug.txt",
  [string]$OutIndex = "repo_dump_debug_index.txt"
)

$ErrorActionPreference = "Stop"
$root = (Resolve-Path ".").Path

# Список файлов debug-системы (поддерживаемый минимум)
$paths = @(
  "tools/blender/debug_run.py",
  "tools/blender/batch_debug_run.py",
  "tools/blender/DEBUG_USAGE.md",

  "tools/blender/debug/__init__.py",
  "tools/blender/debug/io.py",
  "tools/blender/debug/metrics.py",
  "tools/blender/debug/validators.py",
  "tools/blender/debug/visualize.py",
  "tools/blender/debug/autofix.py",

  # опционально, но часто нужно рядом
  "tools/blender/run_builder_v01.py",
  "tools/blender/run_export_glb.py",
  "tools/blender/slat_lab.py"
)

# нормализация
$files = @()
foreach ($p in $paths) {
  $abs = Join-Path $root $p
  if (Test-Path $abs) { $files += (Get-Item $abs) }
}

# индекс
$idx = @()
$i = 1
foreach ($f in $files) {
  $sizeKB = [math]::Round(($f.Length / 1KB), 2)
  $note = ""
  if ($sizeKB -gt $MaxFileSizeKB) { $note = "skipped_content_over_limit" }

  $idx += [pscustomobject]@{
    id = $i
    path = (Resolve-Path $f.FullName).Path.Substring($root.Length + 1) -replace "\\","/"
    size_kb = $sizeKB
    note = $note
  }
  $i++
}

$idx | ConvertTo-Json -Depth 6 | Set-Content -Encoding UTF8 $OutIndex

# дамп (в один текстовый файл)
$sb = New-Object System.Text.StringBuilder
$null = $sb.AppendLine("=== DEBUG DUMP (filtered) ===")
$null = $sb.AppendLine("root: $root")
$null = $sb.AppendLine("max_file_size_kb: $MaxFileSizeKB")
$null = $sb.AppendLine("generated_at: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')")
$null = $sb.AppendLine("")

foreach ($item in $idx) {
  $rel = $item.path -replace "/","\"
  $abs = Join-Path $root $rel

  $null = $sb.AppendLine("----- FILE: $($item.path) ($($item.size_kb) KB) -----")

  if ($item.note -eq "skipped_content_over_limit") {
    $null = $sb.AppendLine("[SKIPPED CONTENT: file is larger than MaxFileSizeKB]")
    $null = $sb.AppendLine("")
    continue
  }

  try {
    $content = Get-Content -Raw -Encoding UTF8 $abs
    $null = $sb.AppendLine($content)
  } catch {
    $null = $sb.AppendLine("[FAILED TO READ FILE AS UTF8] $($_.Exception.Message)")
  }

  $null = $sb.AppendLine("")
}

$sb.ToString() | Set-Content -Encoding UTF8 $OutDump

Write-Host "Wrote $OutDump"
Write-Host "Wrote $OutIndex (rows=$($idx.Count))"



===== FILE: tools/dump_repo.ps1 =====
<#
Usage:
  powershell -ExecutionPolicy Bypass -File tools/dump_repo.ps1

Creates in repository root:
  - repo_dump.txt
  - repo_dump_index.txt

Key excluded directories (any level):
  .git, __pycache__, .venv, venv, out, models, data/cache,
  .mypy_cache, .pytest_cache, .ruff_cache, node_modules,
  dist, build, .next, .idea, .vscode, .vs, logs, tmp, temp, .cache
#>

Set-StrictMode -Version Latest
$ErrorActionPreference = 'Stop'

$script:MaxFileSizeBytes = 2MB
$script:IncludedExtensions = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@('.py', '.ps1', '.md', '.txt', '.json', '.yml', '.yaml', '.toml', '.ini') | ForEach-Object {
    [void]$script:IncludedExtensions.Add($_)
}

$script:IncludedExactNames = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@('requirements.txt', 'pyproject.toml', 'README.md') | ForEach-Object {
    [void]$script:IncludedExactNames.Add($_)
}

$script:ExcludedDirNames = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@(
    '.git', '__pycache__', '.venv', 'venv', 'out', 'models',
    '.mypy_cache', '.pytest_cache', '.ruff_cache', 'node_modules',
    'dist', 'build', '.next', '.idea', '.vscode', '.vs',
    'logs', 'tmp', 'temp', '.cache'
) | ForEach-Object {
    [void]$script:ExcludedDirNames.Add($_)
}

$script:Utf8NoBom = New-Object System.Text.UTF8Encoding($false)

function Resolve-RepoRoot {
    param(
        [string]$StartPath = (Get-Location).Path
    )

    $startItem = Get-Item -LiteralPath $StartPath -Force -ErrorAction SilentlyContinue
    if ($null -eq $startItem) {
        return (Get-Location).Path
    }

    $initialDir = if ($startItem.PSIsContainer) {
        $startItem.FullName
    } else {
        Split-Path -LiteralPath $startItem.FullName -Parent
    }
    $currentPath = $initialDir

    while ($true) {
        if (Test-Path -LiteralPath (Join-Path -Path $currentPath -ChildPath '.git')) {
            return $currentPath
        }

        $parent = [System.IO.Directory]::GetParent($currentPath)
        if ($null -eq $parent) {
            return $initialDir
        }

        $currentPath = $parent.FullName
    }
}

function Get-RelativePath {
    param(
        [Parameter(Mandatory = $true)][string]$BasePath,
        [Parameter(Mandatory = $true)][string]$Path
    )

    $baseResolved = [System.IO.Path]::GetFullPath((Resolve-Path -LiteralPath $BasePath -ErrorAction Stop).Path).TrimEnd('\', '/')
    $pathResolved = [System.IO.Path]::GetFullPath((Resolve-Path -LiteralPath $Path -ErrorAction Stop).Path)

    if ($pathResolved.Equals($baseResolved, [System.StringComparison]::OrdinalIgnoreCase)) {
        return '.'
    }

    $basePrefix = $baseResolved + '\'
    if ($pathResolved.StartsWith($basePrefix, [System.StringComparison]::OrdinalIgnoreCase)) {
        return ($pathResolved.Substring($basePrefix.Length) -replace '\\', '/')
    }

    $baseUriText = 'file:///' + (($baseResolved -replace '\\', '/').TrimStart('/')) + '/'
    $pathUriText = 'file:///' + (($pathResolved -replace '\\', '/').TrimStart('/'))
    $baseUri = New-Object System.Uri($baseUriText)
    $pathUri = New-Object System.Uri($pathUriText)
    $relative = [System.Uri]::UnescapeDataString($baseUri.MakeRelativeUri($pathUri).ToString())
    return ($relative -replace '\\', '/')
}

function Is-ExcludedDir {
    param(
        [Parameter(Mandatory = $true)][string]$RepoRoot,
        [Parameter(Mandatory = $true)][string]$DirPath
    )

    $relative = Get-RelativePath -BasePath $RepoRoot -Path $DirPath
    if ($relative -eq '.') {
        return $false
    }

    $parts = @($relative -split '/' | Where-Object { $_ -ne '' })

    foreach ($part in $parts) {
        if ($script:ExcludedDirNames.Contains($part)) {
            return $true
        }
    }

    for ($i = 0; $i -lt ($parts.Count - 1); $i++) {
        if ($parts[$i].Equals('data', [System.StringComparison]::OrdinalIgnoreCase) -and
            $parts[$i + 1].Equals('cache', [System.StringComparison]::OrdinalIgnoreCase)) {
            return $true
        }
    }

    return $false
}

function Is-IncludedFile {
    param(
        [Parameter(Mandatory = $true)][System.IO.FileInfo]$File
    )

    if ($script:IncludedExactNames.Contains($File.Name)) {
        return $true
    }

    if ($script:IncludedExtensions.Contains($File.Extension)) {
        return $true
    }

    return $false
}

function Is-BinaryFile {
    param(
        [Parameter(Mandatory = $true)][string]$Path
    )

    try {
        $stream = [System.IO.File]::Open($Path, [System.IO.FileMode]::Open, [System.IO.FileAccess]::Read, [System.IO.FileShare]::ReadWrite)
        try {
            $buffer = New-Object byte[] 4096
            $bytesRead = $stream.Read($buffer, 0, $buffer.Length)
            for ($i = 0; $i -lt $bytesRead; $i++) {
                if ($buffer[$i] -eq 0) {
                    return $true
                }
            }
            return $false
        } finally {
            $stream.Dispose()
        }
    } catch {
        return $true
    }
}

function Write-Dump {
    param(
        [Parameter(Mandatory = $true)][array]$Entries,
        [Parameter(Mandatory = $true)][string]$DumpPath
    )

    $includedEntries = @($Entries | Where-Object { $_.Included } | Sort-Object RelativePath)

    $filesFound = $Entries.Count
    $filesWritten = @($Entries | Where-Object { $_.Status -eq 'OK' }).Count
    $filesSkippedLarge = @($Entries | Where-Object { $_.Status -eq 'SKIP_LARGE' }).Count
    $filesSkippedBinary = @($Entries | Where-Object { $_.Status -eq 'SKIP_BINARY' }).Count

    $renderDump = {
        param([long]$OutputBytesValue)

        $sb = New-Object System.Text.StringBuilder

        for ($i = 0; $i -lt $includedEntries.Count; $i++) {
            $entry = $includedEntries[$i]

            if ($i -gt 0) {
                [void]$sb.Append("`r`n`r`n`r`n")
            }

            [void]$sb.Append('===== FILE: ').Append($entry.RelativePath).Append(" =====`r`n")

            if ($entry.Status -eq 'OK') {
                if ($null -ne $entry.Content) {
                    [void]$sb.Append($entry.Content)
                }
            } elseif ($entry.Status -eq 'SKIP_LARGE') {
                [void]$sb.Append('[SKIP: file too large ').Append($entry.SizeBytes).Append(' bytes]')
            } elseif ($entry.Status -eq 'SKIP_BINARY') {
                [void]$sb.Append('[SKIP: unreadable or binary]')
            }
        }

        if ($includedEntries.Count -gt 0) {
            [void]$sb.Append("`r`n`r`n")
        }

        [void]$sb.Append("===== SUMMARY =====`r`n")
        [void]$sb.Append('files_found=').Append($filesFound).Append("`r`n")
        [void]$sb.Append('files_written=').Append($filesWritten).Append("`r`n")
        [void]$sb.Append('files_skipped_large=').Append($filesSkippedLarge).Append("`r`n")
        [void]$sb.Append('files_skipped_binary=').Append($filesSkippedBinary).Append("`r`n")
        [void]$sb.Append('output_bytes=').Append($OutputBytesValue)

        return $sb.ToString()
    }

    $outputBytes = 0L
    $content = ''

    for ($i = 0; $i -lt 8; $i++) {
        $content = & $renderDump $outputBytes
        $calculated = $script:Utf8NoBom.GetByteCount($content)
        if ($calculated -eq $outputBytes) {
            break
        }
        $outputBytes = $calculated
    }

    $content = & $renderDump $outputBytes
    [System.IO.File]::WriteAllText($DumpPath, $content, $script:Utf8NoBom)

    return (Get-Item -LiteralPath $DumpPath -ErrorAction Stop).Length
}

function Write-Index {
    param(
        [Parameter(Mandatory = $true)][array]$Entries,
        [Parameter(Mandatory = $true)][string]$IndexPath
    )

    $sb = New-Object System.Text.StringBuilder
    [void]$sb.Append("path`tsize_bytes`tstatus`r`n")

    foreach ($entry in $Entries) {
        [void]$sb.Append($entry.RelativePath).Append("`t").Append($entry.SizeBytes).Append("`t").Append($entry.Status).Append("`r`n")
    }

    [System.IO.File]::WriteAllText($IndexPath, $sb.ToString(), $script:Utf8NoBom)

    return ($Entries.Count + 1)
}

$repoRoot = Resolve-RepoRoot
$dumpPath = Join-Path -Path $repoRoot -ChildPath 'repo_dump.txt'
$indexPath = Join-Path -Path $repoRoot -ChildPath 'repo_dump_index.txt'

$allFiles = New-Object System.Collections.Generic.List[System.IO.FileInfo]
$stack = New-Object 'System.Collections.Generic.Stack[string]'
$stack.Push($repoRoot)

while ($stack.Count -gt 0) {
    $currentDir = $stack.Pop()

    try {
        $children = Get-ChildItem -LiteralPath $currentDir -Force -ErrorAction Stop
    } catch {
        continue
    }

    foreach ($child in $children) {
        if ($child.PSIsContainer) {
            if (($child.Attributes -band [System.IO.FileAttributes]::ReparsePoint) -ne 0) {
                continue
            }

            if (Is-ExcludedDir -RepoRoot $repoRoot -DirPath $child.FullName) {
                continue
            }

            $stack.Push($child.FullName)
            continue
        }

        $allFiles.Add([System.IO.FileInfo]$child)
    }
}

$entries = @(
    foreach ($file in ($allFiles | Sort-Object { Get-RelativePath -BasePath $repoRoot -Path $_.FullName })) {
        $relativePath = Get-RelativePath -BasePath $repoRoot -Path $file.FullName
        $included = Is-IncludedFile -File $file
        $status = 'SKIP_EXT'
        $content = $null

        if ($included) {
            if ($file.Length -gt $script:MaxFileSizeBytes) {
                $status = 'SKIP_LARGE'
            } elseif (Is-BinaryFile -Path $file.FullName) {
                $status = 'SKIP_BINARY'
            } else {
                try {
                    $content = [System.IO.File]::ReadAllText($file.FullName)
                    $status = 'OK'
                } catch {
                    $status = 'SKIP_BINARY'
                    $content = $null
                }
            }
        }

        [pscustomobject]@{
            RelativePath = $relativePath
            SizeBytes = [long]$file.Length
            Status = $status
            Included = $included
            Content = $content
        }
    }
)

$dumpBytes = Write-Dump -Entries $entries -DumpPath $dumpPath
$indexRows = Write-Index -Entries $entries -IndexPath $indexPath

Write-Output ("Wrote repo_dump.txt (bytes={0})" -f $dumpBytes)
Write-Output ("Wrote repo_dump_index.txt (rows={0})" -f $indexRows)



===== FILE: tools/generate_sofa_ner_dataset.py =====
import json
import random
import re
from pathlib import Path

# ----------------------------
# Config
# ----------------------------

TAGS = [
    "TYPE", "STYLE", "LAYOUT", "ORIENTATION",
    "SEAT_HEIGHT_MM", "SEAT_DEPTH_MM", "SEAT_WIDTH_RANGE_MM",
    "SEAT_COUNT", "HAS_CHAISE", "ARMRESTS", "LEG_FAMILY", "TRANSFORMABLE"
]

RANDOM_SEED = 42

# ----------------------------
# Lexicons
# ----------------------------

TYPE_WORDS = ["диван", "софа"]

STYLE_WORDS = {
    "scandi": ["сканди", "скандинавский", "scandi"],
    "loft": ["лофт", "industrial", "индастриал"],
    "modern": ["модерн", "современный", "modern"],
    "minimal": ["минимализм", "минималистичный", "minimal"],
    "classic": ["классика", "классический", "classic"],
}

LAYOUT_WORDS = {
    "straight": ["прямой", "прямолинейный", "обычный"],
    "corner": ["угловой", "Г-образный", "l-образный"],
    "u_shape": ["п-образный", "u-образный"],
    "modular": ["модульный", "секции", "модули"],
}

ORIENTATION_WORDS = {
    "left": ["левый", "слева", "левосторонний"],
    "right": ["правый", "справа", "правосторонний"],
}

LEG_FAMILY_WORDS = {
    "tapered_cone": ["конусные ножки", "конусообразные ножки", "tapered_cone"],
    "tapered_prism": ["призматические ножки", "скошенная пирамида", "tapered_prism"],
    "cylindrical": ["цилиндрические ножки", "круглые ножки", "cylindrical"],
    "block": ["блочные ножки", "квадратные ножки", "block"],
    "hairpin": ["hairpin", "шпильки", "ножки-шпильки"],
    "sled": ["салазки", "sled", "полозья"],
    "frame": ["рамные ножки", "металлическая рама", "frame"],
}

ARMREST_WORDS = {
    "none": ["без подлокотников", "подлокотники не нужны", "no armrests"],
    "both": ["с подлокотниками", "два подлокотника", "с двух сторон"],
    "left": ["подлокотник слева", "левый подлокотник"],
    "right": ["подлокотник справа", "правый подлокотник"],
}

CHAISE_WORDS_TRUE = ["с оттоманкой", "с шезлонгом", "с канапе", "с удлинением"]
CHAISE_WORDS_FALSE = ["без оттоманки", "без шезлонга", "без удлинения"]

TRANSFORM_TRUE = ["раскладной", "трансформер", "с механизмом раскладывания"]
TRANSFORM_FALSE = ["не раскладной", "без механизма", "стационарный"]

# ----------------------------
# Helpers
# ----------------------------

def tokenize_ru(text: str):
    # токенизация как у тебя в примерах (слова/числа/знаки)
    # разделяем числа, точки, запятые
    tokens = re.findall(r"\d+|[A-Za-zА-Яа-яЁё]+|[^\w\s]", text, flags=re.UNICODE)
    return tokens

def tag_span(tokens, start_idx, end_idx, label):
    # end_idx exclusive
    tags = ["O"] * len(tokens)
    tags[start_idx] = f"B-{label}"
    for i in range(start_idx + 1, end_idx):
        tags[i] = f"I-{label}"
    return tags

def merge_tags(base_tags, span_tags):
    # span_tags has O except labeled region; overlay onto base_tags
    out = base_tags[:]
    for i, t in enumerate(span_tags):
        if t != "O":
            out[i] = t
    return out

def mm_or_cm_value(mm_value: int):
    # иногда пишем в мм, иногда в см
    if random.random() < 0.65:
        # см
        cm = round(mm_value / 10)
        return cm, "см"
    return mm_value, "мм"

def format_dim_phrase(kind: str, mm_value: int):
    # kind: высота сиденья / глубина сиденья
    val, unit = mm_or_cm_value(mm_value)
    # варианты формулировок
    templates = [
        f"{kind} {val} {unit}",
        f"{kind} — {val}{unit}",
        f"{kind}: {val} {unit}",
        f"{kind} примерно {val} {unit}",
    ]
    return random.choice(templates)

def format_width_range(min_mm: int, max_mm: int):
    min_val, unit1 = mm_or_cm_value(min_mm)
    # чтобы не было несостыковки единиц в одном диапазоне, делаем одинаковую единицу
    if unit1 == "см":
        max_val = round(max_mm / 10)
        unit = "см"
    else:
        max_val = max_mm
        unit = "мм"
    templates = [
        f"ширина посадки {min_val}–{max_val} {unit}",
        f"ширина сиденья от {min_val} до {max_val} {unit}",
        f"посадочное место {min_val}-{max_val} {unit} по ширине",
    ]
    return random.choice(templates)

def pick_style():
    key = random.choice(list(STYLE_WORDS.keys()))
    return key, random.choice(STYLE_WORDS[key])

def pick_layout():
    key = random.choice(list(LAYOUT_WORDS.keys()))
    return key, random.choice(LAYOUT_WORDS[key])

def pick_orientation():
    key = random.choice(list(ORIENTATION_WORDS.keys()))
    return key, random.choice(ORIENTATION_WORDS[key])

def pick_legs():
    key = random.choice(list(LEG_FAMILY_WORDS.keys()))
    return key, random.choice(LEG_FAMILY_WORDS[key])

def pick_armrests():
    key = random.choice(list(ARMREST_WORDS.keys()))
    return key, random.choice(ARMREST_WORDS[key])

def maybe(include_prob=0.7):
    return random.random() < include_prob

# ----------------------------
# Sample generator
# ----------------------------

def generate_one():
    # Core choices
    type_word = random.choice(TYPE_WORDS)

    style_key, style_word = pick_style()
    layout_key, layout_word = pick_layout()

    # Orientation only for corner/u_shape sometimes mentioned
    orientation_key = None
    orientation_word = None
    if layout_key in ("corner", "u_shape") and maybe(0.85):
        orientation_key, orientation_word = pick_orientation()

    # Dimensions
    seat_height = random.randint(380, 500)   # mm typical
    seat_depth = random.randint(520, 700)    # mm typical

    w_min = random.randint(450, 650)
    w_max = random.randint(max(w_min + 50, 520), min(w_min + 300, 900))

    # Seat count
    seat_count = random.choice([2, 3, 4, 5])

    # Options
    has_chaise = random.random() < 0.35
    leg_key, leg_word = pick_legs()
    arm_key, arm_word = pick_armrests()
    transformable = random.random() < 0.25

    # Text templates (shuffled clauses)
    clauses = []

    # intro
    intro_templates = [
        f"Мне нужен {type_word}",
        f"Хочу {type_word}",
        f"Подберите {type_word}",
        f"Нужен {type_word} для гостиной",
    ]
    clauses.append(random.choice(intro_templates))

    # style + layout
    style_layout_templates = [
        f"в стиле {style_word}",
        f"{style_word} стиль",
        f"стиль {style_word}",
    ]
    clauses.append(random.choice(style_layout_templates))

    layout_templates = [
        f"{layout_word}",
        f"компоновка {layout_word}",
        f"формат {layout_word}",
    ]
    clauses.append(random.choice(layout_templates))

    # orientation clause
    if orientation_word:
        orientation_templates = [
            f"угол {orientation_word}",
            f"ориентация {orientation_word}",
            f"{orientation_word} угол",
        ]
        clauses.append(random.choice(orientation_templates))

    # seat count
    if maybe(0.75):
        seat_templates = [
            f"на {seat_count} места",
            f"{seat_count}-местный",
            f"количество мест {seat_count}",
        ]
        clauses.append(random.choice(seat_templates))

    # dimensions
    if maybe(0.8):
        clauses.append(format_dim_phrase("высота сиденья", seat_height))
    if maybe(0.8):
        clauses.append(format_dim_phrase("глубина сиденья", seat_depth))
    if maybe(0.7):
        clauses.append(format_width_range(w_min, w_max))

    # legs
    if maybe(0.75):
        legs_templates = [
            f"ножки {leg_word}",
            f"с ножками: {leg_word}",
            f"тип ножек {leg_word}",
        ]
        clauses.append(random.choice(legs_templates))

    # armrests
    if maybe(0.75):
        clauses.append(arm_word)

    # chaise
    if maybe(0.65):
        clauses.append(random.choice(CHAISE_WORDS_TRUE if has_chaise else CHAISE_WORDS_FALSE))

    # transformable
    if maybe(0.6):
        clauses.append(random.choice(TRANSFORM_TRUE if transformable else TRANSFORM_FALSE))

    # Shuffle clauses and join
    random.shuffle(clauses)
    text = ", ".join(clauses) + "."

    tokens = tokenize_ru(text)
    tags = ["O"] * len(tokens)

    # Labeling helper to find token spans of inserted phrases
    def label_phrase(phrase: str, label: str):
        nonlocal tags
        phrase_tokens = tokenize_ru(phrase)
        # find first occurrence
        for i in range(len(tokens) - len(phrase_tokens) + 1):
            if tokens[i:i+len(phrase_tokens)] == phrase_tokens:
                span = tag_span(tokens, i, i+len(phrase_tokens), label)
                tags = merge_tags(tags, span)
                return True
        return False

    # TYPE
    label_phrase(type_word, "TYPE")

    # STYLE (label only the style word/phrase)
    label_phrase(style_word, "STYLE")

    # LAYOUT
    # label the main layout_word if present
    label_phrase(layout_word, "LAYOUT")

    # ORIENTATION
    if orientation_word:
        label_phrase(orientation_word, "ORIENTATION")

    # SEAT_COUNT: label the number token only (simpler and consistent)
    # locate seat_count as token
    for i, tok in enumerate(tokens):
        if tok == str(seat_count):
            tags[i] = "B-SEAT_COUNT"
            break

    # SEAT_HEIGHT_MM / SEAT_DEPTH_MM: label the numeric+unit region where possible
    # we label [число][единица] (e.g. "44", "см")
    def label_number_unit(mm_kind_label: str):
        nonlocal tags
        # look for pattern: number then unit token
        for i in range(len(tokens) - 1):
            if tokens[i].isdigit() and tokens[i+1] in ("см", "мм"):
                # Heuristic: check previous token context in window
                window = " ".join(tokens[max(0, i-4):i])
                if mm_kind_label == "SEAT_HEIGHT_MM" and ("высота" in window and "сиденья" in window):
                    tags[i] = f"B-{mm_kind_label}"
                    tags[i+1] = f"I-{mm_kind_label}"
                    return
                if mm_kind_label == "SEAT_DEPTH_MM" and ("глубина" in window and "сиденья" in window):
                    tags[i] = f"B-{mm_kind_label}"
                    tags[i+1] = f"I-{mm_kind_label}"
                    return

    label_number_unit("SEAT_HEIGHT_MM")
    label_number_unit("SEAT_DEPTH_MM")

    # SEAT_WIDTH_RANGE_MM: label the min–max + unit
    # patterns: number, "–"/"-", number, unit  OR  "от", number, "до", number, unit
    def label_width_range():
        nonlocal tags
        # pattern 1: N – N unit
        for i in range(len(tokens) - 3):
            if tokens[i].isdigit() and tokens[i+1] in ("–", "-") and tokens[i+2].isdigit() and tokens[i+3] in ("см", "мм"):
                tags[i] = "B-SEAT_WIDTH_RANGE_MM"
                tags[i+1] = "I-SEAT_WIDTH_RANGE_MM"
                tags[i+2] = "I-SEAT_WIDTH_RANGE_MM"
                tags[i+3] = "I-SEAT_WIDTH_RANGE_MM"
                return
        # pattern 2: от N до N unit
        for i in range(len(tokens) - 4):
            if tokens[i].lower() == "от" and tokens[i+1].isdigit() and tokens[i+2].lower() == "до" and tokens[i+3].isdigit() and tokens[i+4] in ("см", "мм"):
                tags[i] = "B-SEAT_WIDTH_RANGE_MM"
                for j in range(i+1, i+5):
                    tags[j] = "I-SEAT_WIDTH_RANGE_MM"
                return

    label_width_range()

    # HAS_CHAISE: label whole phrase (simple)
    chaise_phrase = random.choice(CHAISE_WORDS_TRUE if has_chaise else CHAISE_WORDS_FALSE)
    # but note: we used random choice when building clauses; we must find which one ended up in text
    for ph in CHAISE_WORDS_TRUE + CHAISE_WORDS_FALSE:
        if ph in text:
            label_phrase(ph, "HAS_CHAISE")
            break

    # ARMRESTS: label phrase
    for ph in sum(ARMREST_WORDS.values(), []):
        if ph in text:
            label_phrase(ph, "ARMRESTS")
            break

    # LEG_FAMILY: label phrase
    for ph in sum(LEG_FAMILY_WORDS.values(), []):
        if ph in text:
            label_phrase(ph, "LEG_FAMILY")
            break

    # TRANSFORMABLE: label phrase
    for ph in TRANSFORM_TRUE + TRANSFORM_FALSE:
        if ph in text:
            label_phrase(ph, "TRANSFORMABLE")
            break

    return {"tokens": tokens, "tags": tags}


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--n", type=int, default=20000, help="number of samples")
    parser.add_argument("--out", type=str, default="data/sofa_ner_train.jsonl")
    args = parser.parse_args()

    random.seed(RANDOM_SEED)

    out_path = Path(args.out)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with out_path.open("w", encoding="utf-8") as f:
        for _ in range(args.n):
            sample = generate_one()
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")

    print(f"✅ Wrote {args.n} samples to: {out_path.resolve()}")


if __name__ == "__main__":
    main()



===== FILE: tools/inspect_blend.py =====
# tools/inspect_blend.py
# Usage:
#   blender --background out/logs/sofa.blend --python C:\Users\Gigabyte\AMS\tools\inspect_blend.py

print("INSPECT_BLEND_START")

import bpy  # type: ignore


def axis_ranges_world(mesh, matrix_world):
    if not mesh or not getattr(mesh, "vertices", None):
        return None
    if len(mesh.vertices) == 0:
        return None

    xs = []
    ys = []
    zs = []
    for v in mesh.vertices:
        w = matrix_world @ v.co
        xs.append(w.x)
        ys.append(w.y)
        zs.append(w.z)

    return (
        (min(xs), max(xs)),
        (min(ys), max(ys)),
        (min(zs), max(zs)),
    )


def axis_spans(ranges):
    return (
        ranges[0][1] - ranges[0][0],
        ranges[1][1] - ranges[1][0],
        ranges[2][1] - ranges[2][0],
    )


def fmt_axis(ranges):
    return (
        f"x=({ranges[0][0]:.6f},{ranges[0][1]:.6f}) "
        f"y=({ranges[1][0]:.6f},{ranges[1][1]:.6f}) "
        f"z=({ranges[2][0]:.6f},{ranges[2][1]:.6f})"
    )


def mesh_counts(mesh):
    if not mesh:
        return (0, 0)
    verts = len(mesh.vertices) if getattr(mesh, "vertices", None) is not None else 0
    polys = len(mesh.polygons) if getattr(mesh, "polygons", None) is not None else 0
    return (verts, polys)


def fmt_modifiers(obj):
    if len(obj.modifiers) == 0:
        return "[]"

    rows = []
    for mod in obj.modifiers:
        show_viewport = bool(getattr(mod, "show_viewport", False))
        show_render = bool(getattr(mod, "show_render", False))
        show_in_editmode = bool(getattr(mod, "show_in_editmode", False))
        show_on_cage = bool(getattr(mod, "show_on_cage", False))
        rows.append(
            f"{mod.name}:{mod.type} "
            f"viewport={int(show_viewport)} render={int(show_render)} "
            f"edit={int(show_in_editmode)} cage={int(show_on_cage)}"
        )
    return "[" + ", ".join(rows) + "]"


def print_bend_modifiers(obj):
    for mod in obj.modifiers:
        if mod.type == "SIMPLE_DEFORM" and getattr(mod, "deform_method", "") == "BEND":
            origin = mod.origin.name if getattr(mod, "origin", None) else "None"
            print(f"BEND axis={mod.deform_axis} angle={float(mod.angle):.6f} origin={origin}")


def main():
    print("FILE:", bpy.data.filepath)
    print("BLENDER_VERSION:", bpy.app.version_string)
    print("Objects:", len(bpy.data.objects))

    depsgraph = bpy.context.evaluated_depsgraph_get()

    slats = [
        o
        for o in bpy.data.objects
        if o.type == "MESH" and ("slat" in o.name.lower() or o.name == "DEBUG_SLAT")
    ]
    slats = sorted(slats, key=lambda x: x.name)

    print("Slat-like:", len(slats))
    print("--- SLATS DUMP (first 60) ---")

    for obj in slats[:60]:
        eval_obj = obj.evaluated_get(depsgraph)
        eval_mesh = None
        base_verts, base_polys = mesh_counts(obj.data)
        try:
            eval_mesh = eval_obj.to_mesh()
            base_ranges = axis_ranges_world(obj.data, obj.matrix_world)
            eval_ranges = axis_ranges_world(eval_mesh, eval_obj.matrix_world)
        finally:
            if eval_mesh is not None:
                eval_obj.to_mesh_clear()

        print(f"\n- {obj.name}")
        print(f"BASE_MESH verts={base_verts} polys={base_polys}")
        print(f"MODIFIERS {fmt_modifiers(obj)}")
        print_bend_modifiers(obj)

        if base_ranges is None or eval_ranges is None:
            print("AXIS_RANGES_BASE x=(nan,nan) y=(nan,nan) z=(nan,nan)")
            print("AXIS_RANGES_EVAL x=(nan,nan) y=(nan,nan) z=(nan,nan)")
            print("RANGE_DELTAS dx=nan dy=nan dz=nan")
            print("BEND_EFFECT=NO")
            continue

        base_spans = axis_spans(base_ranges)
        eval_spans = axis_spans(eval_ranges)
        dx = abs(eval_spans[0] - base_spans[0])
        dy = abs(eval_spans[1] - base_spans[1])
        dz = abs(eval_spans[2] - base_spans[2])
        bend_effect = "OK" if max(dx, dy, dz) > 1e-5 else "NO"

        print(f"AXIS_RANGES_BASE {fmt_axis(base_ranges)}")
        print(f"AXIS_RANGES_EVAL {fmt_axis(eval_ranges)}")
        print(f"RANGE_DELTAS dx={dx:.6f} dy={dy:.6f} dz={dz:.6f}")
        print(f"BEND_EFFECT={bend_effect}")

    print("\nINSPECT_BLEND_DONE")


if __name__ == "__main__":
    main()



===== FILE: tools/ner_to_schema_demo.py =====
import sys
import re
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(ROOT))

from src.ner_infer import predict
from src.schema import SofaRequest, resolve_sofa

MODEL_DIR = "models/sofa_ner_rubert"


def parse_length_to_mm(s: str) -> int:
    t = s.lower().replace(",", ".")
    m = re.search(r"(\d+(?:\.\d+)?)", t)
    if not m:
        raise ValueError(f"Cannot parse length: {s}")
    value = float(m.group(1))

    if "мм" in t:
        mm = value
    elif "см" in t:
        mm = value * 10
    elif "м" in t:
        mm = value * 1000
    else:
        mm = value  # по умолчанию считаем мм

    return int(round(mm))


def parse_int(s: str) -> int:
    m = re.search(r"\d+", s)
    if not m:
        raise ValueError(f"Cannot parse int: {s}")
    return int(m.group(0))


def normalize_entities(entities: dict) -> dict:
    data: dict = {}

    # простые строковые
    for key in ["type", "style", "layout", "orientation", "leg_family", "armrests"]:
        K = key.upper()
        if K in entities and entities[K]:
            data[key] = entities[K][0].strip()

    # числовые
    if "SEAT_HEIGHT_MM" in entities and entities["SEAT_HEIGHT_MM"]:
        data["seat_height_mm"] = parse_length_to_mm(entities["SEAT_HEIGHT_MM"][0])

    if "SEAT_DEPTH_MM" in entities and entities["SEAT_DEPTH_MM"]:
        data["seat_depth_mm"] = parse_length_to_mm(entities["SEAT_DEPTH_MM"][0])

    if "SEAT_COUNT" in entities and entities["SEAT_COUNT"]:
        data["seat_count"] = parse_int(entities["SEAT_COUNT"][0])

    if "SEAT_WIDTH_RANGE_MM" in entities and entities["SEAT_WIDTH_RANGE_MM"]:
        joined = " ".join(entities["SEAT_WIDTH_RANGE_MM"])
        nums = [int(x) for x in re.findall(r"\d+", joined)]
        if len(nums) >= 2:
            data["seat_width_range_mm"] = (nums[0], nums[1])

    if "TRANSFORMABLE" in entities and entities["TRANSFORMABLE"]:
        t = " ".join(entities["TRANSFORMABLE"]).lower()
        data["transformable"] = not ("без" in t or "нет" in t)

    return data


def main():
    text = (
        "Мне нужен скандинавский угловой диван, "
        "высота сиденья 44 см, глубина 60 см, "
        "на 3 места, без механизма, ножки конусные."
    )

    print("\n=== USER TEXT ===")
    print(text)

    out = predict(text, MODEL_DIR, max_len=128)

    print("\n=== TOKENS ===")
    print(out.tokens)

    print("\n=== TAGS ===")
    print(out.tags)

    print("\n=== NER ENTITIES ===")
    for k, v in out.entities.items():
        print(f"{k}: {v}")

    params = normalize_entities(out.entities)
    print("\n=== NORMALIZED PARAMS ===")
    print(params)

    # 1) validate + aliases (Request)
    req = SofaRequest(**params)

    # 2) deterministic resolve (IR for Builder)
    resolved = resolve_sofa(req)

    print("\n=== SOFA RESOLVED (IR) ===")
    # красиво JSON-ом
    print(resolved.model_dump_json(indent=2, ensure_ascii=False))

    # если нужен dict:
    # print(resolved.model_dump())


if __name__ == "__main__":
    main()



===== FILE: tools/predict_sofa_ner.py =====



===== FILE: tools/train_sofa_ner.py =====
from __future__ import annotations
import json
import random
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    DataCollatorForTokenClassification,
    TrainingArguments,
    Trainer,
)
from seqeval.metrics import f1_score, precision_score, recall_score, classification_report


# ----------------------------
# Config
# ----------------------------
RANDOM_SEED = 42

# стабильная, хорошая стартовая RU-модель для NER
DEFAULT_MODEL_NAME = "DeepPavlov/rubert-base-cased"


def read_jsonl(path: str) -> List[Dict]:
    items = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            items.append(json.loads(line))
    return items


def build_label_list(items: List[Dict]) -> List[str]:
    # собираем список всех тегов, чтобы label2id/id2label были стабильны
    labels = set()
    for it in items:
        for t in it["tags"]:
            labels.add(t)
    # важно: O первым
    labels = sorted(labels)
    if "O" in labels:
        labels.remove("O")
    return ["O"] + labels


def split_items(items: List[Dict], train_ratio=0.9) -> Tuple[List[Dict], List[Dict]]:
    random.shuffle(items)
    n_train = int(len(items) * train_ratio)
    return items[:n_train], items[n_train:]


def align_labels_with_tokens(tokenizer, tokens: List[str], tags: List[str], label2id: Dict[str, int], max_length: int):
    # токенизация по словам + alignment
    enc = tokenizer(
        tokens,
        is_split_into_words=True,
        truncation=True,
        max_length=max_length,
    )
    word_ids = enc.word_ids()
    label_ids = []
    prev_word_id = None

    for word_id in word_ids:
        if word_id is None:
            label_ids.append(-100)
        elif word_id != prev_word_id:
            label_ids.append(label2id[tags[word_id]])
        else:
            # если токен является продолжением слова:
            # B-XXX -> I-XXX, иначе остаётся как есть
            tag = tags[word_id]
            if tag.startswith("B-"):
                tag = "I-" + tag[2:]
                tag = tag if tag in label2id else tags[word_id]
            label_ids.append(label2id[tag])
        prev_word_id = word_id

    enc["labels"] = label_ids
    return enc


def compute_metrics_builder(id2label: Dict[int, str]):
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)

        true_labels = []
        true_preds = []

        for pred_row, label_row in zip(preds, labels):
            seq_true = []
            seq_pred = []
            for p, l in zip(pred_row, label_row):
                if l == -100:
                    continue
                seq_true.append(id2label[int(l)])
                seq_pred.append(id2label[int(p)])
            true_labels.append(seq_true)
            true_preds.append(seq_pred)

        return {
            "precision": precision_score(true_labels, true_preds),
            "recall": recall_score(true_labels, true_preds),
            "f1": f1_score(true_labels, true_preds),
        }
    return compute_metrics


def main():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, default="data/sofa_ner_train.jsonl")
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL_NAME)
    parser.add_argument("--out", type=str, default="models/sofa_ner_rubert")
    parser.add_argument("--max_len", type=int, default=192)
    parser.add_argument("--epochs", type=int, default=5)
    parser.add_argument("--batch", type=int, default=16)
    parser.add_argument("--lr", type=float, default=3e-5)
    args = parser.parse_args()

    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)

    items = read_jsonl(args.data)
    if not items:
        raise RuntimeError("Dataset is empty")

    labels = build_label_list(items)
    label2id = {l: i for i, l in enumerate(labels)}
    id2label = {i: l for l, i in label2id.items()}

    train_items, val_items = split_items(items, train_ratio=0.9)

    tokenizer = AutoTokenizer.from_pretrained(args.model)

    def to_features(item):
        return align_labels_with_tokens(
            tokenizer,
            item["tokens"],
            item["tags"],
            label2id=label2id,
            max_length=args.max_len,
        )

    train_ds = Dataset.from_list(train_items).map(to_features, remove_columns=["tokens", "tags"])
    val_ds = Dataset.from_list(val_items).map(to_features, remove_columns=["tokens", "tags"])

    model = AutoModelForTokenClassification.from_pretrained(
        args.model,
        num_labels=len(labels),
        id2label=id2label,
        label2id=label2id,
    )

    collator = DataCollatorForTokenClassification(tokenizer)

    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    training_args = TrainingArguments(
    output_dir=str(out_dir),
    eval_strategy="epoch",
    save_strategy="epoch",
        learning_rate=args.lr,
        per_device_train_batch_size=args.batch,
        per_device_eval_batch_size=args.batch,
        num_train_epochs=args.epochs,
        weight_decay=0.01,
        logging_steps=100,
        report_to="none",
        fp16=True,  # на RTX 5070 обычно ок
        seed=RANDOM_SEED,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        tokenizer=tokenizer,
        data_collator=collator,
        compute_metrics=compute_metrics_builder(id2label),
    )

    trainer.train()

    # финальная оценка + отчёт
    preds = trainer.predict(val_ds)
    logits, labels_ids = preds.predictions, preds.label_ids
    preds_ids = np.argmax(logits, axis=-1)

    true_labels = []
    true_preds = []
    for pr, lb in zip(preds_ids, labels_ids):
        seq_true = []
        seq_pred = []
        for p, l in zip(pr, lb):
            if l == -100:
                continue
            seq_true.append(id2label[int(l)])
            seq_pred.append(id2label[int(p)])
        true_labels.append(seq_true)
        true_preds.append(seq_pred)

    print("\n=== SeqEval report (VAL) ===")
    print(classification_report(true_labels, true_preds))

    # сохраняем модель
    trainer.save_model(str(out_dir))
    tokenizer.save_pretrained(str(out_dir))
    print(f"\n✅ Saved model to: {out_dir.resolve()}")


if __name__ == "__main__":
    main()



===== FILE: tools/validate_schema.py =====
# tools/validate_schema.py
import json
import sys
from pathlib import Path

from pydantic import ValidationError

ROOT = Path(__file__).resolve().parents[1]  # AMS/
sys.path.insert(0, str(ROOT))

from src.schema import SofaRequest, resolve_sofa  # noqa: E402


def main():
    path = ROOT / "data" / "examples" / "request_scandi.json"
    raw = json.loads(path.read_text(encoding="utf-8"))

    print("INPUT JSON:")
    print(json.dumps(raw, ensure_ascii=False, indent=2))

    try:
        req = SofaRequest.model_validate(raw)
        print("\nSofaRequest OK ✅")
        print(req.model_dump())

        resolved = resolve_sofa(req)
        print("\nSofaResolved OK ✅")
        print(json.dumps(resolved.model_dump(), ensure_ascii=False, indent=2))

    except ValidationError as e:
        print("\nVALIDATION ERROR ❌")
        print(e)


if __name__ == "__main__":
    main()


===== SUMMARY =====
files_found=43
files_written=41
files_skipped_large=0
files_skipped_binary=0
output_bytes=553772


===== FILE: repo_dump_index.txt =====
path	size_bytes	status
.gitignore	558	SKIP_EXT
data/examples/request_scandi.json	346	OK
data/examples/sofa_ir.json	1190	OK
data/examples/sofa_request.json	205	OK
data/examples/user_text.txt	79	OK
data/sofa_ner_train.jsonl	17226902	SKIP_EXT
NER_Parametric_model_1.1.py	390	OK
README.md	916	OK
repo_dump.txt	273103	OK
repo_dump_index.txt	1501	OK
requirements.txt	71	OK
src/__init__.py	0	OK
src/builders/__init__.py	118	OK
src/builders/blender/__init__.py	103	OK
src/builders/blender/builder_v01.py	28001	OK
src/builders/blender/export_blender.py	2773	OK
src/builders/cad/__init__.py	81	OK
src/builders/cad/export_step_stub.py	372	OK
src/ner_infer.py	3301	OK
src/pipeline/__init__.py	146	OK
src/pipeline/ner_to_request.py	696	OK
src/pipeline/resolve.py	554	OK
src/schema.py	14427	OK
tools/blender/batch_debug_run.py	9660	OK
tools/blender/debug/__init__.py	48	OK
tools/blender/debug/autofix.py	40519	OK
tools/blender/debug/io.py	3502	OK
tools/blender/debug/metrics.py	9595	OK
tools/blender/debug/validators.py	44522	OK
tools/blender/debug/visualize.py	16172	OK
tools/blender/debug_run.py	17024	OK
tools/blender/DEBUG_USAGE.md	2091	OK
tools/blender/run_builder_v01.py	20905	OK
tools/blender/run_export_glb.py	3863	OK
tools/blender/slat_lab.py	12374	OK
tools/dump_debug.ps1	2486	OK
tools/dump_repo.ps1	10484	OK
tools/generate_sofa_ner_dataset.py	14299	OK
tools/inspect_blend.py	4265	OK
tools/ner_to_schema_demo.py	3293	OK
tools/predict_sofa_ner.py	0	OK
tools/train_sofa_ner.py	7132	OK
tools/validate_schema.py	922	OK



===== FILE: requirements.txt =====
# Minimal dependencies for development; expand as the pipeline grows.



===== FILE: src/__init__.py =====



===== FILE: src/builders/__init__.py =====
"""Builders package for exporting geometry from resolved IR."""

# TODO: expose builder registries when available.



===== FILE: src/builders/blender/__init__.py =====
"""Blender-specific builders and exporters."""

# TODO: register Blender builders when implemented.



===== FILE: src/builders/blender/builder_v01.py =====
"""Generate a geometry plan and anchors for Blender builds."""

from dataclasses import dataclass, field
from typing import Dict, List, Tuple


@dataclass
class Primitive:
    """Represents a basic geometry primitive."""

    name: str
    shape: str
    dimensions_mm: Tuple[float, float, float]
    location_mm: Tuple[float, float, float]
    rotation_deg: Tuple[float, float, float] = (0.0, 0.0, 0.0)
    params: Dict[str, float] = field(default_factory=dict)


@dataclass
class Anchor:
    """Named anchor or empty location."""

    name: str
    location_mm: Tuple[float, float, float]


@dataclass
class BuildPlan:
    """Container for primitives and anchors to build a sofa frame."""

    primitives: List[Primitive] = field(default_factory=list)
    anchors: List[Anchor] = field(default_factory=list)
    metadata: Dict[str, str] = field(default_factory=dict)


def _ir_value(ir: dict, key: str, default: float) -> float:
    """Helper to fetch numeric values from IR with defaults."""
    value = ir.get(key, default)
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _ir_bool(ir: dict, key: str, default: bool) -> bool:
    value = ir.get(key, default)
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    if isinstance(value, str):
        normalized = value.strip().lower()
        if normalized in {"1", "true", "yes", "on"}:
            return True
        if normalized in {"0", "false", "no", "off"}:
            return False
    return bool(default)


def _canon_arms_type(value: str) -> str:
    """Normalize arms type to one of: none, left, right, both."""
    if not isinstance(value, str):
        return "none"
    normalized = value.strip().lower()
    if normalized in {"left", "right", "both", "none"}:
        return normalized
    return "none"


def _arms_count(arms_type: str) -> int:
    """Return number of arm blocks for a canonical arms_type."""
    if arms_type == "both":
        return 2
    if arms_type in {"left", "right"}:
        return 1
    return 0


def _clamp(value: float, min_value: float, max_value: float) -> float:
    return max(min_value, min(max_value, float(value)))


def _primitive_bbox_world(primitive: Primitive) -> Dict[str, Tuple[float, float, float]]:
    """Axis-aligned bbox for a primitive in world coordinates (plan space)."""
    dx, dy, dz = primitive.dimensions_mm
    cx, cy, cz = primitive.location_mm
    half_x = float(dx) / 2.0
    half_y = float(dy) / 2.0
    half_z = float(dz) / 2.0
    return {
        "min": (cx - half_x, cy - half_y, cz - half_z),
        "max": (cx + half_x, cy + half_y, cz + half_z),
    }


def build_plan_from_ir(ir: dict) -> BuildPlan:
    """Create a sofa-frame geometry plan from resolved IR.

    Coordinate system: X is width (left/right), Y is depth (front/back),
    Z is up. seat_height_mm defines the top of the seat support board.
    """
    seat_width_mm = _ir_value(ir, "seat_width_mm", 600.0)
    seat_depth_mm = _ir_value(ir, "seat_depth_mm", 600.0)
    seat_height_mm = _ir_value(ir, "seat_height_mm", 440.0)
    seat_count = max(1, int(_ir_value(ir, "seat_count", 3)))
    seat_total_width_mm = seat_width_mm * seat_count

    frame = ir.get("frame", {}) if isinstance(ir.get("frame"), dict) else {}
    frame_thickness_mm = _ir_value(frame, "thickness_mm", 35.0)
    back_height_mm = _ir_value(frame, "back_height_above_seat_mm", 420.0)
    back_thickness_mm = _ir_value(frame, "back_thickness_mm", 90.0)

    arms = ir.get("arms", {}) if isinstance(ir.get("arms"), dict) else {}
    arms_type = _canon_arms_type(arms.get("type", "none"))
    arms_width_mm = _ir_value(arms, "width_mm", 120.0)
    arms_total_mm = arms_width_mm * _arms_count(arms_type)
    total_width_mm = seat_total_width_mm + arms_total_mm

    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_height_mm = _ir_value(legs, "height_mm", 160.0)
    legs_family = legs.get("family", "block")

    seat_support_thickness_mm = frame_thickness_mm

    slats = ir.get("slats", {}) if isinstance(ir.get("slats"), dict) else {}
    slats_enabled = bool(slats.get("enabled", False))
    slat_count = max(1, int(_ir_value(slats, "count", 14)))
    slat_width_mm = _ir_value(slats, "width_mm", 55.0)
    slat_thickness_mm = _ir_value(slats, "thickness_mm", 10.0)
    slat_arc_height_mm = _ir_value(slats, "arc_height_mm", 0.0)
    slat_arc_sign = _ir_value(slats, "arc_sign", -1.0)
    slat_margin_x_mm = _ir_value(slats, "margin_x_mm", 40.0)
    slat_margin_y_mm = _ir_value(slats, "margin_y_mm", 60.0)
    slat_clearance_mm = _ir_value(slats, "clearance_mm", 0.0)
    slat_mount_mode = slats.get("mount_mode", "rests_on_plane")
    if not isinstance(slat_mount_mode, str):
        slat_mount_mode = "rests_on_plane"
    slat_mount_mode = slat_mount_mode.strip().lower()
    if slat_mount_mode not in {"rests_on_plane", "centered"}:
        slat_mount_mode = "rests_on_plane"
    slat_mount_offset_mm = _ir_value(slats, "mount_offset_mm", 0.0)
    slat_rail_inset_mm = _ir_value(slats, "rail_inset_mm", 0.0)
    slat_rail_height_mm = _ir_value(slats, "rail_height_mm", frame_thickness_mm)
    slat_rail_width_mm = _ir_value(slats, "rail_width_mm", frame_thickness_mm)
    slat_rail_inset_y_mm = _ir_value(slats, "rail_inset_y_mm", slat_margin_y_mm)

    has_back_support = "back_support" in ir
    back_support = ir.get("back_support", {}) if isinstance(ir.get("back_support"), dict) else {}
    back_support_mode = back_support.get("mode", "panel")
    if not isinstance(back_support_mode, str):
        back_support_mode = "panel"
    back_support_mode = back_support_mode.strip().lower()
    if back_support_mode not in {"panel", "slats", "straps"}:
        back_support_mode = "panel"

    back_height_mm = _ir_value(back_support, "height_above_seat_mm", back_height_mm)
    back_thickness_mm = _ir_value(back_support, "thickness_mm", back_thickness_mm)
    back_offset_y_mm = _ir_value(back_support, "offset_y_mm", 0.0)
    back_margin_x_mm = _ir_value(back_support, "margin_x_mm", 40.0)
    back_margin_z_mm = _ir_value(back_support, "margin_z_mm", 30.0)
    back_rail_inset_mm = _ir_value(back_support, "rail_inset_mm", 0.0)
    back_rail_width_mm = _ir_value(back_support, "rail_width_mm", frame_thickness_mm)
    back_rail_depth_mm = _ir_value(back_support, "rail_depth_mm", frame_thickness_mm)
    back_rail_height_mm = _ir_value(back_support, "rail_height_mm", back_rail_width_mm)
    bottom_rail_split = _ir_bool(back_support, "bottom_rail_split", False)
    bottom_rail_gap_mm = _ir_value(back_support, "bottom_rail_gap_mm", 60.0)
    bottom_rail_attach_mode = str(back_support.get("bottom_rail_attach_mode", "seat_rear_beam")).strip().lower()
    if bottom_rail_attach_mode not in {"seat_rear_beam", "none"}:
        bottom_rail_attach_mode = "seat_rear_beam"
    raw_frame_layout = back_support.get("frame_layout")
    if isinstance(raw_frame_layout, str):
        frame_layout = raw_frame_layout.strip().lower()
    else:
        frame_layout = "split_2" if bottom_rail_split else "single"
    if frame_layout not in {"single", "split_2"}:
        frame_layout = "single"
    center_post_width_mm = _ir_value(back_support, "center_post_width_mm", back_rail_width_mm)
    default_bottom_rail_height_mm = max(10.0, round(back_rail_height_mm * 0.5))
    has_bottom_rail_height = "bottom_rail_height_mm" in back_support
    has_legacy_bottom_rail_thickness = "bottom_rail_thickness_mm" in back_support
    if has_bottom_rail_height:
        bottom_rail_height_mm = _ir_value(back_support, "bottom_rail_height_mm", default_bottom_rail_height_mm)
    elif has_legacy_bottom_rail_thickness:
        legacy_value = _ir_value(back_support, "bottom_rail_thickness_mm", default_bottom_rail_height_mm)
        if legacy_value < back_rail_height_mm:
            bottom_rail_height_mm = legacy_value
        else:
            bottom_rail_height_mm = default_bottom_rail_height_mm
    else:
        bottom_rail_height_mm = default_bottom_rail_height_mm

    back_slats = back_support.get("slats", {}) if isinstance(back_support.get("slats"), dict) else {}
    back_slat_count = max(1, int(_ir_value(back_slats, "count", 10)))
    back_slat_width_mm = _ir_value(back_slats, "width_mm", 35.0)
    back_slat_thickness_mm = _ir_value(back_slats, "thickness_mm", 10.0)
    back_slat_arc_height_mm = _ir_value(back_slats, "arc_height_mm", 0.0)
    back_slat_arc_sign = _ir_value(back_slats, "arc_sign", -1.0)
    back_slat_orientation_raw = back_slats.get("orientation", "vertical")
    if isinstance(back_slat_orientation_raw, str):
        back_slat_orientation = back_slat_orientation_raw.strip().lower()
    else:
        back_slat_orientation = "vertical"
    if back_slat_orientation not in {"vertical", "horizontal"}:
        back_slat_orientation = "vertical"
    back_slat_layout_raw = back_slats.get("layout", "full")
    if isinstance(back_slat_layout_raw, str):
        back_slat_layout = back_slat_layout_raw.strip().lower()
    else:
        back_slat_layout = "full"
    if back_slat_layout not in {"full", "split_center"}:
        back_slat_layout = "full"
    has_back_slat_gap = "gap_mm" in back_slats
    back_slat_gap_mm = max(0.0, _ir_value(back_slats, "gap_mm", 0.0))
    back_slat_center_gap_mm = max(0.0, _ir_value(back_slats, "center_gap_mm", 0.0))

    back_straps = back_support.get("straps", {}) if isinstance(back_support.get("straps"), dict) else {}
    back_strap_count = max(1, int(_ir_value(back_straps, "count", 6)))
    back_strap_width_mm = _ir_value(back_straps, "width_mm", 30.0)
    back_strap_thickness_mm = _ir_value(back_straps, "thickness_mm", 6.0)

    # Z placement stack: legs -> base frame -> seat support -> back frame -> arms.
    # Seat support top aligns to seat_height_mm.
    seat_support_top_z = seat_height_mm
    seat_support_center_z = seat_support_top_z - (seat_support_thickness_mm / 2.0)
    base_frame_top_z = seat_support_top_z - seat_support_thickness_mm
    base_frame_center_z = base_frame_top_z - (frame_thickness_mm / 2.0)
    base_frame_bottom_z = base_frame_top_z - frame_thickness_mm
    legs_center_z = base_frame_bottom_z - (legs_height_mm / 2.0)

    plan = BuildPlan(metadata={
        "seat_count": str(seat_count),
        "legs_family": str(legs_family),
        "arms_type": str(arms_type),
        "seat_total_width_mm": str(seat_total_width_mm),
        "total_width_mm": str(total_width_mm),
    })

    # Base frame beams (outer perimeter of total frame).
    front_y = (seat_depth_mm / 2.0) - (frame_thickness_mm / 2.0)
    back_y = -(seat_depth_mm / 2.0) + (frame_thickness_mm / 2.0)
    left_x = -(total_width_mm / 2.0) + (frame_thickness_mm / 2.0)
    right_x = (total_width_mm / 2.0) - (frame_thickness_mm / 2.0)

    plan.primitives.extend(
        [
            Primitive(
                name="beam_front",
                shape="beam",
                dimensions_mm=(total_width_mm, frame_thickness_mm, frame_thickness_mm),
                location_mm=(0.0, front_y, base_frame_center_z),
            ),
            Primitive(
                name="beam_back",
                shape="beam",
                dimensions_mm=(total_width_mm, frame_thickness_mm, frame_thickness_mm),
                location_mm=(0.0, back_y, base_frame_center_z),
            ),
            Primitive(
                name="beam_left",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm, frame_thickness_mm),
                location_mm=(left_x, 0.0, base_frame_center_z),
            ),
            Primitive(
                name="beam_right",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm, frame_thickness_mm),
                location_mm=(right_x, 0.0, base_frame_center_z),
            ),
        ]
    )

    # Cross beams across depth (along Y), evenly spaced along X.
    cross_count = max(2, min(4, seat_count + 1))
    inner_width_mm = max(1.0, total_width_mm - (2.0 * frame_thickness_mm))
    cross_spacing_mm = inner_width_mm / (cross_count + 1)
    for i in range(cross_count):
        x = -(inner_width_mm / 2.0) + cross_spacing_mm * (i + 1)
        plan.primitives.append(
            Primitive(
                name=f"beam_cross_{i + 1}",
                shape="beam",
                dimensions_mm=(frame_thickness_mm, seat_depth_mm - (2.0 * frame_thickness_mm), frame_thickness_mm),
                location_mm=(x, 0.0, base_frame_center_z),
            )
        )

    # Seat support board (seat area only) on top of base frame.
    if not slats_enabled:
        plan.primitives.append(
            Primitive(
                name="seat_support",
                shape="board",
                dimensions_mm=(seat_total_width_mm, seat_depth_mm, seat_support_thickness_mm),
                location_mm=(0.0, 0.0, seat_support_center_z),
            )
        )

    # Slats (lamellas) across X, running along Y with front/back margins.
    if slats_enabled:
        slat_length_mm = max(1.0, seat_depth_mm - (2.0 * slat_margin_y_mm))
        rail_length_mm = max(1.0, seat_depth_mm - (2.0 * slat_rail_inset_y_mm))
        usable_width_mm = max(1.0, seat_total_width_mm - (2.0 * slat_margin_x_mm))
        if slat_count == 1:
            slat_centers_x = [0.0]
        else:
            span_mm = max(0.0, usable_width_mm - slat_width_mm)
            step_mm = span_mm / (slat_count - 1)
            start_x = -(usable_width_mm / 2.0) + (slat_width_mm / 2.0)
            slat_centers_x = [start_x + (step_mm * i) for i in range(slat_count)]

        # Slats mount to the base frame top plane unless explicitly centered.
        slat_plane_z_mm = base_frame_top_z
        if slat_mount_mode == "centered":
            slat_center_z = seat_support_top_z - (slat_thickness_mm / 2.0) + slat_clearance_mm
        else:
            slat_center_z = (
                slat_plane_z_mm
                + slat_mount_offset_mm
                + slat_clearance_mm
                + (slat_thickness_mm / 2.0)
            )

        min_x = min(slat_centers_x) - (slat_width_mm / 2.0)
        max_x = max(slat_centers_x) + (slat_width_mm / 2.0)
        rail_height_mm = slat_rail_height_mm
        rail_width_mm = slat_rail_width_mm
        rail_depth_mm = rail_length_mm
        rail_top_z = slat_plane_z_mm
        rail_center_z = rail_top_z - (rail_height_mm / 2.0)
        rail_left_x = min_x + (rail_width_mm / 2.0) + slat_rail_inset_mm
        rail_right_x = max_x - (rail_width_mm / 2.0) - slat_rail_inset_mm
        if rail_left_x < rail_right_x:
            plan.primitives.append(
                Primitive(
                    name="rail_left",
                    shape="beam",
                    dimensions_mm=(rail_width_mm, rail_depth_mm, rail_height_mm),
                    location_mm=(rail_left_x, 0.0, rail_center_z),
                )
            )
            plan.primitives.append(
                Primitive(
                    name="rail_right",
                    shape="beam",
                    dimensions_mm=(rail_width_mm, rail_depth_mm, rail_height_mm),
                    location_mm=(rail_right_x, 0.0, rail_center_z),
                )
            )
            plan.anchors.append(
                Anchor(name="rail_left", location_mm=(rail_left_x, 0.0, rail_center_z))
            )
            plan.anchors.append(
                Anchor(name="rail_right", location_mm=(rail_right_x, 0.0, rail_center_z))
            )

        plan.anchors.append(Anchor(name="slat_plane_z", location_mm=(0.0, 0.0, slat_plane_z_mm)))
        plan.anchors.append(Anchor(name="slat_area_center", location_mm=(0.0, 0.0, slat_center_z)))
        for i, x in enumerate(slat_centers_x, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"slat_{i}",
                    shape="slat",
                    dimensions_mm=(slat_width_mm, slat_length_mm, slat_thickness_mm),
                    location_mm=(x, 0.0, slat_center_z),
                    params={
                        "arc_height_mm": slat_arc_height_mm,
                        "arc_sign": slat_arc_sign,
                        "orientation": "horizontal",
                        "mount_mode": slat_mount_mode,
                        "mount_offset_mm": slat_mount_offset_mm,
                        "clearance_mm": slat_clearance_mm,
                    },
                )
            )

    # Back support uses a frame tied directly to the rear seat rail.
    back_offset_y_micro_mm = _clamp(back_offset_y_mm, -80.0, 80.0)
    seat_back_rail_center_y = back_y
    seat_back_rail_outer_face_y = seat_back_rail_center_y - (frame_thickness_mm / 2.0)
    y_back_seat = seat_back_rail_outer_face_y
    seat_rear_rail_center = (0.0, seat_back_rail_center_y, base_frame_center_z)
    seat_rear_rail_top_z = base_frame_top_z

    back_rail_width_mm = max(1.0, back_rail_width_mm)
    back_rail_depth_mm = max(1.0, back_rail_depth_mm)
    back_rail_height_mm = max(1.0, back_rail_height_mm)
    back_frame_member_mm = max(1.0, back_thickness_mm)
    bottom_rail_height_mm = max(10.0, bottom_rail_height_mm)
    center_post_width_mm = max(1.0, center_post_width_mm)

    if bottom_rail_attach_mode == "seat_rear_beam":
        back_frame_plane_y = y_back_seat + back_offset_y_micro_mm
    else:
        back_frame_plane_y = (-(seat_depth_mm / 2.0)) + back_offset_y_mm
    back_frame_base_z = seat_rear_rail_top_z
    back_frame_top_z = max(back_frame_base_z + 1.0, seat_support_top_z + back_height_mm)
    back_frame_height_mm = back_frame_top_z - back_frame_base_z
    back_frame_center_y = back_frame_plane_y - (back_rail_depth_mm / 2.0)
    back_frame_origin = (0.0, back_frame_plane_y, back_frame_base_z)
    back_center_z = back_frame_base_z + (back_frame_height_mm / 2.0)
    back_panel_center = (0.0, back_frame_center_y, back_center_z)
    rail_left_x = -(seat_total_width_mm / 2.0) + (back_rail_width_mm / 2.0)
    rail_right_x = (seat_total_width_mm / 2.0) - (back_rail_width_mm / 2.0)

    back_frame_debug_primitives: List[Primitive] = []
    back_slat_debug_primitives: List[Primitive] = []
    back_slats_bbox_inner_text = "n/a"

    if has_back_support:
        back_upright_center_z = back_frame_base_z + (back_frame_height_mm / 2.0)

        back_rail_left = Primitive(
            name="back_rail_left",
            shape="beam",
            dimensions_mm=(back_rail_width_mm, back_rail_depth_mm, back_frame_height_mm),
            location_mm=(rail_left_x, back_frame_center_y, back_upright_center_z),
        )
        back_rail_right = Primitive(
            name="back_rail_right",
            shape="beam",
            dimensions_mm=(back_rail_width_mm, back_rail_depth_mm, back_frame_height_mm),
            location_mm=(rail_right_x, back_frame_center_y, back_upright_center_z),
        )
        plan.primitives.extend([back_rail_left, back_rail_right])
        back_frame_debug_primitives.extend([back_rail_left, back_rail_right])
        plan.anchors.extend(
            [
                Anchor(name="back_rail_left", location_mm=back_rail_left.location_mm),
                Anchor(name="back_rail_right", location_mm=back_rail_right.location_mm),
            ]
        )

    if not has_back_support:
        # Backward-compatible panel using frame.back_* dimensions.
        legacy_back_plane_y = seat_back_rail_outer_face_y - (back_thickness_mm / 2.0) + back_offset_y_mm
        legacy_back_center_z = seat_support_top_z + (back_height_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="back_frame",
                shape="board",
                dimensions_mm=(total_width_mm, back_thickness_mm, back_height_mm),
                location_mm=(0.0, legacy_back_plane_y, legacy_back_center_z),
            )
        )
    elif back_support_mode == "panel":
        plan.primitives.append(
            Primitive(
                name="back_panel",
                shape="board",
                dimensions_mm=(seat_total_width_mm, back_frame_member_mm, back_frame_height_mm),
                location_mm=back_panel_center,
            )
        )
    elif back_support_mode == "slats":
        inset_x_mm = max(3.0, back_rail_inset_mm)
        inset_z_mm = max(3.0, back_rail_inset_mm)
        margin_x_mm = max(0.0, back_margin_x_mm)
        margin_z_mm = max(0.0, back_margin_z_mm)

        frame_inner_min_x = rail_left_x + (back_rail_width_mm / 2.0)
        frame_inner_max_x = rail_right_x - (back_rail_width_mm / 2.0)
        frame_inner_width_mm = max(1.0, frame_inner_max_x - frame_inner_min_x)

        bottom_rail_center_z = back_frame_base_z + (bottom_rail_height_mm / 2.0)
        top_rail_center_z = back_frame_top_z - (back_rail_height_mm / 2.0)

        back_rail_bottom = Primitive(
            name="back_rail_bottom",
            shape="beam",
            dimensions_mm=(frame_inner_width_mm, back_rail_depth_mm, bottom_rail_height_mm),
            location_mm=(0.0, back_frame_center_y, bottom_rail_center_z),
        )
        back_rail_top = Primitive(
            name="back_rail_top",
            shape="beam",
            dimensions_mm=(frame_inner_width_mm, back_rail_depth_mm, back_rail_height_mm),
            location_mm=(0.0, back_frame_center_y, top_rail_center_z),
        )
        inner_bottom_frame_z = bottom_rail_center_z + (bottom_rail_height_mm / 2.0)
        inner_top_frame_z = top_rail_center_z - (back_rail_height_mm / 2.0)
        center_gap_half_x = 0.0

        plan.primitives.extend([back_rail_bottom, back_rail_top])
        back_frame_debug_primitives.extend([back_rail_bottom, back_rail_top])
        plan.anchors.extend(
            [
                Anchor(name="back_rail_bottom", location_mm=back_rail_bottom.location_mm),
                Anchor(name="back_rail_top", location_mm=back_rail_top.location_mm),
            ]
        )

        if frame_layout == "split_2":
            center_post_height_mm = max(1.0, inner_top_frame_z - inner_bottom_frame_z)
            center_post_center_z = inner_bottom_frame_z + (center_post_height_mm / 2.0)
            back_rail_center = Primitive(
                name="back_rail_center",
                shape="beam",
                dimensions_mm=(center_post_width_mm, back_rail_depth_mm, center_post_height_mm),
                location_mm=(0.0, back_frame_center_y, center_post_center_z),
            )
            plan.primitives.append(back_rail_center)
            back_frame_debug_primitives.append(back_rail_center)
            plan.anchors.append(Anchor(name="back_rail_center", location_mm=back_rail_center.location_mm))
            center_gap_half_x = (center_post_width_mm / 2.0) + inset_x_mm

        inner_min_x = frame_inner_min_x + inset_x_mm + margin_x_mm
        inner_max_x = frame_inner_max_x - inset_x_mm - margin_x_mm
        if inner_max_x <= inner_min_x:
            inner_min_x = frame_inner_min_x + inset_x_mm
            inner_max_x = frame_inner_max_x - inset_x_mm
        inner_bottom_z = inner_bottom_frame_z + inset_z_mm + margin_z_mm
        inner_top_z = inner_top_frame_z - inset_z_mm - margin_z_mm
        if inner_top_z <= inner_bottom_z:
            inner_bottom_z = inner_bottom_frame_z + inset_z_mm
            inner_top_z = inner_top_frame_z - inset_z_mm
        if inner_top_z <= inner_bottom_z:
            inner_top_z = inner_bottom_z + 1.0

        slat_span_z_mm = max(1.0, inner_top_z - inner_bottom_z)
        back_slat_center_z = inner_bottom_z + (slat_span_z_mm / 2.0)
        y_slat_inset_max = max(0.0, ((back_rail_depth_mm - back_slat_thickness_mm) / 2.0) - 0.5)
        y_slat_inset_mm = min(2.0, y_slat_inset_max)
        back_slat_center_y = back_frame_center_y - y_slat_inset_mm
        back_slat_plane_y = back_slat_center_y + (back_slat_thickness_mm / 2.0)
        split_center_layout = (frame_layout == "split_2") or (back_slat_layout == "split_center")
        center_split_gap_half_x = max(
            center_gap_half_x,
            (center_post_width_mm / 2.0)
            + max(2.0, back_slat_center_gap_mm if back_slat_center_gap_mm > 0.0 else inset_x_mm),
        )

        def _centers_for_range(
            axis_min: float,
            axis_max: float,
            count: int,
            item_size_mm: float,
            gap_mm=None,
        ) -> List[float]:
            if count <= 0:
                return []
            range_min = min(float(axis_min), float(axis_max))
            range_max = max(float(axis_min), float(axis_max))
            if count == 1:
                return [0.5 * (range_min + range_max)]
            item_size_mm = max(1.0, float(item_size_mm))
            span_mm = max(0.0, range_max - range_min)
            if gap_mm is not None and float(gap_mm) > 0.0:
                required_span_mm = (item_size_mm * count) + (float(gap_mm) * float(count - 1))
                if required_span_mm <= span_mm:
                    start_axis = range_min + ((span_mm - required_span_mm) / 2.0) + (item_size_mm / 2.0)
                    step_axis = item_size_mm + float(gap_mm)
                    return [start_axis + (step_axis * i) for i in range(count)]

            free_span_mm = max(0.0, span_mm - item_size_mm)
            step_axis = free_span_mm / float(count - 1)
            start_axis = range_min + (item_size_mm / 2.0)
            return [start_axis + (step_axis * i) for i in range(count)]

        plan.anchors.append(Anchor(name="back_slat_plane_y", location_mm=(0.0, back_slat_plane_y, 0.0)))
        plan.anchors.append(Anchor(name="back_slat_center_z", location_mm=(0.0, 0.0, back_slat_center_z)))
        plan.anchors.append(
            Anchor(name="back_frame_inner_rect_min", location_mm=(inner_min_x, back_frame_center_y, inner_bottom_z))
        )
        plan.anchors.append(
            Anchor(name="back_frame_inner_rect_max", location_mm=(inner_max_x, back_frame_center_y, inner_top_z))
        )

        if back_slat_orientation == "horizontal":
            row_height_mm = max(1.0, back_slat_width_mm)
            row_gap_mm = back_slat_gap_mm if has_back_slat_gap else None
            row_centers_z = _centers_for_range(
                inner_bottom_z,
                inner_top_z,
                back_slat_count,
                row_height_mm,
                gap_mm=row_gap_mm,
            )

            segments: List[Tuple[str, float, float]] = []
            if split_center_layout:
                left_min_x = inner_min_x
                left_max_x = min(inner_max_x, -center_split_gap_half_x)
                right_min_x = max(inner_min_x, center_split_gap_half_x)
                right_max_x = inner_max_x
                if (left_max_x - left_min_x) >= 1.0:
                    segments.append(("left", left_min_x, left_max_x))
                if (right_max_x - right_min_x) >= 1.0:
                    segments.append(("right", right_min_x, right_max_x))
            if not segments:
                segments.append(("full", inner_min_x, inner_max_x))

            back_slats_bbox_inner_text = (
                f"orientation={back_slat_orientation} "
                f"layout={back_slat_layout} "
                f"frame_layout={frame_layout} "
                f"bottom_split={int(bool(bottom_rail_split))} "
                f"bottom_gap_mm={float(bottom_rail_gap_mm):.3f} "
                f"min=({inner_min_x:.3f},{inner_bottom_z:.3f}) "
                f"max=({inner_max_x:.3f},{inner_top_z:.3f}) y={back_slat_center_y:.3f} "
                f"center_gap_half={center_split_gap_half_x:.3f}"
            )

            next_full_index = 1
            for row_idx, z in enumerate(row_centers_z, start=1):
                for segment_name, segment_min_x, segment_max_x in segments:
                    segment_len_x = max(1.0, segment_max_x - segment_min_x)
                    segment_center_x = segment_min_x + (segment_len_x / 2.0)
                    if segment_name == "full":
                        slat_name = f"back_slat_{next_full_index}"
                        next_full_index += 1
                    else:
                        slat_name = f"back_slat_{row_idx}_{segment_name}"
                    back_slat = Primitive(
                        name=slat_name,
                        shape="beam",
                        dimensions_mm=(segment_len_x, back_slat_thickness_mm, row_height_mm),
                        location_mm=(segment_center_x, back_slat_center_y, z),
                        params={"orientation": "horizontal"},
                    )
                    plan.primitives.append(back_slat)
                    if len(back_slat_debug_primitives) < 2:
                        back_slat_debug_primitives.append(back_slat)
                    plan.anchors.append(
                        Anchor(name=slat_name, location_mm=(segment_center_x, back_slat_center_y, z))
                    )
        else:
            slat_height_mm = slat_span_z_mm
            if split_center_layout:
                left_min_x = inner_min_x
                left_max_x = min(inner_max_x, -center_split_gap_half_x)
                right_min_x = max(inner_min_x, center_split_gap_half_x)
                right_max_x = inner_max_x
                left_valid = (left_max_x - left_min_x) >= 1.0
                right_valid = (right_max_x - right_min_x) >= 1.0
                left_count = (back_slat_count + 1) // 2
                right_count = back_slat_count // 2
                if not left_valid and not right_valid:
                    slat_centers_x = _centers_for_range(inner_min_x, inner_max_x, back_slat_count, back_slat_width_mm)
                elif not left_valid:
                    slat_centers_x = _centers_for_range(right_min_x, right_max_x, back_slat_count, back_slat_width_mm)
                elif not right_valid:
                    slat_centers_x = _centers_for_range(left_min_x, left_max_x, back_slat_count, back_slat_width_mm)
                else:
                    slat_centers_x = _centers_for_range(left_min_x, left_max_x, left_count, back_slat_width_mm)
                    slat_centers_x.extend(_centers_for_range(right_min_x, right_max_x, right_count, back_slat_width_mm))
            else:
                slat_centers_x = _centers_for_range(inner_min_x, inner_max_x, back_slat_count, back_slat_width_mm)

            back_slats_bbox_inner_text = (
                f"orientation={back_slat_orientation} "
                f"layout={back_slat_layout} "
                f"frame_layout={frame_layout} "
                f"bottom_split={int(bool(bottom_rail_split))} "
                f"bottom_gap_mm={float(bottom_rail_gap_mm):.3f} "
                f"min=({inner_min_x:.3f},{inner_bottom_z:.3f}) "
                f"max=({inner_max_x:.3f},{inner_top_z:.3f}) y={back_slat_center_y:.3f} "
                f"center_gap_half={center_split_gap_half_x:.3f}"
            )

            for i, x in enumerate(slat_centers_x, start=1):
                back_slat = Primitive(
                    name=f"back_slat_{i}",
                    shape="slat",
                    dimensions_mm=(back_slat_width_mm, back_slat_thickness_mm, slat_height_mm),
                    location_mm=(x, back_slat_center_y, back_slat_center_z),
                    params={
                        "arc_height_mm": back_slat_arc_height_mm,
                        "arc_sign": back_slat_arc_sign,
                        "orientation": "vertical",
                    },
                )
                plan.primitives.append(back_slat)
                if i <= 2:
                    back_slat_debug_primitives.append(back_slat)
                plan.anchors.append(
                    Anchor(name=f"back_slat_{i}", location_mm=(x, back_slat_center_y, back_slat_center_z))
                )
    elif back_support_mode == "straps":
        strap_center_x = 0.0
        strap_span_z_mm = max(1.0, (back_frame_height_mm - back_frame_member_mm) - (2.0 * back_margin_z_mm))
        if back_strap_count == 1:
            strap_centers_z = [back_frame_base_z + ((back_frame_height_mm - back_frame_member_mm) / 2.0)]
        else:
            step_mm = strap_span_z_mm / (back_strap_count - 1)
            start_z = back_frame_base_z + back_margin_z_mm
            strap_centers_z = [start_z + (step_mm * i) for i in range(back_strap_count)]

        for i, z in enumerate(strap_centers_z, start=1):
            plan.primitives.append(
                Primitive(
                    name=f"back_strap_{i}",
                    shape="board",
                    dimensions_mm=(seat_total_width_mm, back_strap_thickness_mm, back_strap_width_mm),
                    location_mm=(strap_center_x, back_frame_center_y, z),
                )
            )

    if has_back_support:
        print(f"BACK_ANCHOR y_back_seat={y_back_seat:.3f}")
        print(
            "BACK_FRAME "
            f"y={back_frame_center_y:.3f} "
            f"plane_y={back_frame_plane_y:.3f} "
            f"attach_mode={bottom_rail_attach_mode}"
        )
        print(f"BACK_SLATS bbox_inner={back_slats_bbox_inner_text}")
        print(f"[builder_v01] back_frame back_frame_origin={back_frame_origin}")
        for primitive in back_frame_debug_primitives:
            bbox = _primitive_bbox_world(primitive)
            print(
                "[builder_v01] back_frame "
                f"{primitive.name} bbox_world.min={bbox['min']} bbox_world.max={bbox['max']}"
            )
        for primitive in back_slat_debug_primitives:
            bbox = _primitive_bbox_world(primitive)
            print(
                "[builder_v01] back_frame "
                f"{primitive.name} bbox_world.min={bbox['min']} bbox_world.max={bbox['max']}"
            )

    # Simple arm frames as boards when present.
    # Arms sit outside the seat area in X, and their bottoms align to the base frame top.
    arm_height_mm = max(frame_thickness_mm * 2.0, seat_height_mm * 0.65)
    arm_center_z = base_frame_top_z + (arm_height_mm / 2.0)
    if arms_type in {"both", "left"}:
        left_arm_center_x = -(seat_total_width_mm / 2.0) - (arms_width_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="left_arm_frame",
                shape="board",
                dimensions_mm=(arms_width_mm, seat_depth_mm, arm_height_mm),
                location_mm=(left_arm_center_x, 0.0, arm_center_z),
            )
        )
        plan.anchors.append(
            Anchor(name="arm_left_zone", location_mm=(left_arm_center_x, 0.0, seat_height_mm))
        )
    if arms_type in {"both", "right"}:
        right_arm_center_x = (seat_total_width_mm / 2.0) + (arms_width_mm / 2.0)
        plan.primitives.append(
            Primitive(
                name="right_arm_frame",
                shape="board",
                dimensions_mm=(arms_width_mm, seat_depth_mm, arm_height_mm),
                location_mm=(right_arm_center_x, 0.0, arm_center_z),
            )
        )
        plan.anchors.append(
            Anchor(name="arm_right_zone", location_mm=(right_arm_center_x, 0.0, seat_height_mm))
        )

    # Leg anchors and leg primitives at corners.
    leg_offset_x = (total_width_mm / 2.0) - (frame_thickness_mm / 2.0)
    leg_offset_y = (seat_depth_mm / 2.0) - (frame_thickness_mm / 2.0)
    leg_points = [
        (-leg_offset_x, -leg_offset_y, legs_center_z),
        (leg_offset_x, -leg_offset_y, legs_center_z),
        (-leg_offset_x, leg_offset_y, legs_center_z),
        (leg_offset_x, leg_offset_y, legs_center_z),
    ]

    for index, point in enumerate(leg_points, start=1):
        plan.anchors.append(Anchor(name=f"leg_point_{index}", location_mm=point))
        plan.primitives.append(
            Primitive(
                name=f"leg_{index}",
                shape=legs_family,
                dimensions_mm=(frame_thickness_mm, frame_thickness_mm, legs_height_mm),
                location_mm=point,
            )
        )

    # Anchors for zones.
    if has_back_support:
        back_anchor_y = back_frame_center_y
        back_bottom_z = back_frame_base_z
        back_top_z = back_frame_top_z
        back_inner_center = (0.0, back_frame_center_y, back_center_z)
    else:
        back_anchor_y = seat_back_rail_outer_face_y - (back_thickness_mm / 2.0) + back_offset_y_mm
        back_bottom_z = seat_support_top_z
        back_top_z = seat_support_top_z + back_height_mm
        back_inner_center = (0.0, back_anchor_y, seat_support_top_z + (back_height_mm / 2.0))
    left_back_corner = (-(seat_total_width_mm / 2.0), back_anchor_y, back_bottom_z)
    right_back_corner = ((seat_total_width_mm / 2.0), back_anchor_y, back_bottom_z)

    plan.anchors.extend(
        [
            Anchor(name="seat_zone", location_mm=(0.0, 0.0, seat_support_center_z)),
            Anchor(name="back_zone", location_mm=back_panel_center),
            Anchor(name="seat_rear_rail", location_mm=seat_rear_rail_center),
            Anchor(
                name="seat_back_rail_center_y",
                location_mm=(0.0, seat_back_rail_center_y, base_frame_center_z),
            ),
            Anchor(
                name="seat_back_rail_outer_face_y",
                location_mm=(0.0, seat_back_rail_outer_face_y, base_frame_center_z),
            ),
            Anchor(name="y_back_seat", location_mm=(0.0, y_back_seat, base_frame_center_z)),
            Anchor(name="seat_back_plane", location_mm=(0.0, seat_back_rail_outer_face_y, back_bottom_z)),
            Anchor(name="back_frame_origin", location_mm=back_frame_origin),
            Anchor(name="back_bottom_edge_center", location_mm=(0.0, back_anchor_y, back_bottom_z)),
            Anchor(name="back_top_edge_center", location_mm=(0.0, back_anchor_y, back_top_z)),
            Anchor(name="back_inner_plane_center", location_mm=back_inner_center),
            Anchor(name="left_back_corner", location_mm=left_back_corner),
            Anchor(name="right_back_corner", location_mm=right_back_corner),
        ]
    )

    return plan



===== FILE: src/builders/blender/export_blender.py =====
"""Runner that triggers Blender build from an IR JSON path."""

from __future__ import annotations

import argparse
import os
import subprocess
from pathlib import Path


DEFAULT_GLB_PATH = Path("out/glb/sofa.glb")
DEFAULT_LOG_PATH = Path("out/logs/build.log")
DEFAULT_BLEND_PATH = Path("out/logs/sofa.blend")


def _blender_executable() -> str:
    """Resolve Blender executable path."""
    return os.environ.get("BLENDER_EXE", "blender")


def _run_blender(args: list[str], log_path: Path, env: dict[str, str] | None = None) -> None:
    """Run a Blender command and write output to log."""
    log_path.parent.mkdir(parents=True, exist_ok=True)
    with log_path.open("a", encoding="utf-8") as handle:
        subprocess.run(args, stdout=handle, stderr=subprocess.STDOUT, check=True, env=env)


def run_blender_build(ir_json_path: str, glb_path: str | None = None) -> Path:
    """Run Blender build for the given IR JSON path."""
    ir_path = Path(ir_json_path)
    out_path = Path(glb_path) if glb_path else DEFAULT_GLB_PATH
    blender = _blender_executable()
    blend_path = DEFAULT_BLEND_PATH

    builder_script = Path("tools/blender/run_builder_v01.py")
    export_script = Path("tools/blender/run_export_glb.py")

    builder_env = os.environ.copy()
    builder_env["IR_PATH"] = str(ir_path)
    builder_env["BLEND_PATH"] = str(blend_path)

    _run_blender(
        [
            blender,
            "--background",
            "--python",
            str(builder_script),
            "--",
            str(ir_path),
        ],
        DEFAULT_LOG_PATH,
        env=builder_env,
    )
    if not blend_path.exists() or blend_path.stat().st_size == 0:
        raise RuntimeError(f"Blend file missing or empty: {blend_path.resolve()}")

    export_env = os.environ.copy()
    export_env["GLB_PATH"] = str(out_path)

    _run_blender(
        [
            blender,
            "--background",
            str(blend_path),
            "--python",
            str(export_script),
            "--",
            str(out_path),
        ],
        DEFAULT_LOG_PATH,
        env=export_env,
    )
    if not out_path.exists() or out_path.stat().st_size == 0:
        raise RuntimeError(f"GLB file missing or empty: {out_path.resolve()}")

    return out_path


def main() -> None:
    """CLI entry point."""
    parser = argparse.ArgumentParser(description="Run Blender builder and export GLB.")
    parser.add_argument("ir_json_path", help="Path to resolved IR JSON.")
    parser.add_argument("glb_path", nargs="?", default=str(DEFAULT_GLB_PATH), help="Output GLB path.")
    args = parser.parse_args()

    run_blender_build(args.ir_json_path, args.glb_path)


if __name__ == "__main__":
    main()



===== FILE: src/builders/cad/__init__.py =====
"""CAD-oriented exporters."""

# TODO: register CAD exporters when available.



===== FILE: src/builders/cad/export_step_stub.py =====
"""Placeholder module for STEP export."""

# TODO: implement STEP export once CAD pipeline is defined.

def export_step(resolved_ir, output_path):
    """Export resolved IR to a STEP file."""
    # TODO: translate resolved IR to STEP format.
    return {
        "resolved_ir": resolved_ir,
        "output_path": output_path,
        "exported": False,
    }



===== FILE: src/ner_infer.py =====
from __future__ import annotations

import re
from dataclasses import dataclass
from functools import lru_cache
from typing import Dict, List, Tuple, Optional

import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification


# Простая токенизация, похожая на твою разметку датасета:
# числа, слова, отдельные знаки препинания.
_TOKEN_RE = re.compile(r"\d+(?:[.,]\d+)?|[A-Za-zА-Яа-яЁё]+|[^\w\s]", re.UNICODE)


def basic_tokenize(text: str) -> List[str]:
    return _TOKEN_RE.findall(text)


@dataclass
class NEROutput:
    tokens: List[str]
    tags: List[str]
    entities: Dict[str, List[str]]


@lru_cache(maxsize=4)
def _load(model_dir: str):
    tok = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForTokenClassification.from_pretrained(model_dir)
    model.eval()
    return tok, model


def _bio_to_entities(tokens: List[str], tags: List[str]) -> Dict[str, List[str]]:
    entities: Dict[str, List[str]] = {}
    cur_type: Optional[str] = None
    cur_tokens: List[str] = []

    def flush():
        nonlocal cur_type, cur_tokens
        if cur_type and cur_tokens:
            entities.setdefault(cur_type, []).append(" ".join(cur_tokens))
        cur_type = None
        cur_tokens = []

    for tok, tag in zip(tokens, tags):
        if tag.startswith("B-"):
            flush()
            cur_type = tag[2:]
            cur_tokens = [tok]
        elif tag.startswith("I-") and cur_type == tag[2:]:
            cur_tokens.append(tok)
        else:
            flush()

    flush()
    return entities


def predict(text: str, model_dir: str, max_len: int = 128, device: Optional[str] = None) -> NEROutput:
    tokenizer, model = _load(model_dir)

    words = basic_tokenize(text)

    enc = tokenizer(
        words,
        is_split_into_words=True,
        return_tensors="pt",
        truncation=True,
        max_length=max_len,
    )

    # ВАЖНО: word_ids берём ДО переноса на device и ДО любых преобразований
    if hasattr(enc, "word_ids"):
        word_ids = enc.word_ids(batch_index=0)
    else:
        raise RuntimeError(
            "Tokenizer returned a plain dict without word_ids(). "
            "Ensure you are using a fast tokenizer or keep BatchEncoding object."
        )

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    model.to(device)

    # переносим тензоры, но НЕ затираем enc целиком
    enc_on_device = {k: v.to(device) for k, v in enc.items()}

    with torch.no_grad():
        logits = model(**enc_on_device).logits

    pred_ids = torch.argmax(logits, dim=-1)[0].tolist()
    id2label = model.config.id2label

    word_tags: List[str] = ["O"] * len(words)
    used = set()
    for i, w_id in enumerate(word_ids):
        if w_id is None:
            continue
        if w_id in used:
            continue
        used.add(w_id)
        word_tags[w_id] = id2label[pred_ids[i]]

    entities = _bio_to_entities(words, word_tags)
    return NEROutput(tokens=words, tags=word_tags, entities=entities)




===== FILE: src/pipeline/__init__.py =====
"""Pipeline package for converting NER outputs into buildable IR."""

# TODO: expose high-level pipeline helpers when implementation is ready.



===== FILE: src/pipeline/ner_to_request.py =====
"""Normalize extracted entities into a SofaRequest payload."""

# TODO: define a mapping between NER outputs and SofaRequest fields.
# TODO: validate and normalize entity values (materials, dimensions, styles).

def normalize_entities(entities):
    """Normalize raw NER entities into canonical request fields."""
    # TODO: implement normalization logic once schema is finalized.
    return {
        "raw_entities": entities,
    }


def map_ner_to_request(entities):
    """Map normalized entities into a SofaRequest structure."""
    # TODO: build SofaRequest payload structure from normalized entities.
    return {
        "request": normalize_entities(entities),
    }



===== FILE: src/pipeline/resolve.py =====
"""Wrapper around resolve_sofa for building resolved IR."""

from __future__ import annotations

from typing import Dict

from src.schema import SofaRequest, resolve_sofa


def resolve_request_to_ir(sofa_request: SofaRequest) -> Dict:
    """Resolve a SofaRequest into an intermediate representation."""
    resolved = resolve_sofa(sofa_request)
    return resolved.model_dump()


def resolve_sofa_request(sofa_request: SofaRequest) -> Dict:
    """Backward-compatible wrapper for resolving SofaRequest."""
    return resolve_request_to_ir(sofa_request)



===== FILE: src/schema.py =====
from __future__ import annotations

import re
from enum import Enum
from typing import Any, Dict, Optional, Tuple
from typing_extensions import Literal

from pydantic import BaseModel, Field, field_validator, model_validator


# =========================
# Enums / core types
# =========================

class SofaStyle(str, Enum):
    scandi = "scandi"
    loft = "loft"
    modern = "modern"
    minimal = "minimal"
    classic = "classic"


class SofaLayout(str, Enum):
    straight = "straight"
    corner = "corner"
    u_shape = "u_shape"
    modular = "modular"


class Orientation(str, Enum):
    left = "left"
    right = "right"


class ArmrestType(str, Enum):
    none = "none"
    left = "left"
    right = "right"
    both = "both"


class LegFamily(str, Enum):
    tapered_cone = "tapered_cone"
    tapered_prism = "tapered_prism"
    cylindrical = "cylindrical"
    block = "block"
    hairpin = "hairpin"
    sled = "sled"
    frame = "frame"


class SeatType(str, Enum):
    single = "single"
    cushions = "cushions"


# =========================
# Preferences (level-2)
# =========================

class RawPreferences(BaseModel):
    # thin / medium / thick — можно расширять позже
    leg_thickness_bias: Optional[Literal["thin", "medium", "thick"]] = None
    # box / rounded_bottom / rolled — пока совпадает с ArmsSpec.profile
    arm_profile: Optional[Literal["box", "rounded_bottom", "rolled"]] = None
    # soft / medium / firm — пока влияет только на seat_type
    seat_softness: Optional[Literal["soft", "medium", "firm"]] = None


# =========================
# Aliases / Canonicalization
# =========================

def _canon(s: str) -> str:
    s = s.strip().lower()
    s = s.replace("ё", "е")
    s = s.replace("-", " ")
    s = s.replace("_", " ")
    s = re.sub(r"\s+", " ", s)
    return s


TYPE_ALIASES = {
    "диван": "sofa",
    "софа": "sofa",
    "sofa": "sofa",
}

STYLE_ALIASES = {
    "сканди": "scandi",
    "скандинавский": "scandi",
    "scandi": "scandi",

    "лофт": "loft",
    "loft": "loft",

    "современный": "modern",
    "модерн": "modern",
    "modern": "modern",

    "минимализм": "minimal",
    "минимальный": "minimal",
    "minimal": "minimal",

    "классический": "classic",
    "классика": "classic",
    "classic": "classic",
}

LAYOUT_ALIASES = {
    "прямой": "straight",
    "прямая": "straight",
    "straight": "straight",

    "угловой": "corner",
    "угловая": "corner",
    "corner": "corner",

    "п образный": "u_shape",
    "побразный": "u_shape",
    "u образный": "u_shape",
    "u shape": "u_shape",
    "u_shape": "u_shape",

    "секционный": "modular",
    "модульный": "modular",
    "modular": "modular",
}

LEG_ALIASES = {
    "конусные": "tapered_cone",
    "конус": "tapered_cone",
    "tapered cone": "tapered_cone",
    "tapered_cone": "tapered_cone",

    "пирамида": "tapered_prism",
    "призма": "tapered_prism",
    "скошенная пирамида": "tapered_prism",
    "tapered prism": "tapered_prism",
    "tapered_prism": "tapered_prism",

    "цилиндрические": "cylindrical",
    "цилиндр": "cylindrical",
    "cylindrical": "cylindrical",

    "блочные": "block",
    "кубики": "block",
    "block": "block",

    "hairpin": "hairpin",
    "шпильки": "hairpin",

    "sled": "sled",
    "полозья": "sled",

    "frame": "frame",
    "рамные": "frame",
}


# =========================
# Request model (сырой ввод)
# =========================

class SofaRequest(BaseModel):
    """
    Сырые параметры, извлечённые из текста (NER + нормализация).
    Могут быть неполными — Resolver заполнит дефолты.
    """

    type: Literal["sofa"] = "sofa"

    style: SofaStyle
    layout: SofaLayout
    orientation: Optional[Orientation] = None  # may be None; resolver fills for corner/u_shape

    seat_height_mm: Optional[int] = Field(default=None, ge=250, le=650)
    seat_depth_mm: Optional[int] = Field(default=None, ge=350, le=900)

    seat_width_range_mm: Optional[Tuple[int, int]] = None  # (min,max) mm
    seat_count: Optional[int] = Field(default=None, ge=1, le=8)

    has_chaise: Optional[bool] = None
    armrests: Optional[ArmrestType] = None
    leg_family: Optional[LegFamily] = None
    transformable: Optional[bool] = None

    preferences: Optional[RawPreferences] = None

    # --- Alias validators (before enum parsing) ---

    @field_validator("type", mode="before")
    @classmethod
    def _v_type(cls, v):
        if v is None:
            return v
        return TYPE_ALIASES.get(_canon(str(v)), v)

    @field_validator("style", mode="before")
    @classmethod
    def _v_style(cls, v):
        if v is None:
            return v
        return STYLE_ALIASES.get(_canon(str(v)), v)

    @field_validator("layout", mode="before")
    @classmethod
    def _v_layout(cls, v):
        if v is None:
            return v
        return LAYOUT_ALIASES.get(_canon(str(v)), v)

    @field_validator("leg_family", mode="before")
    @classmethod
    def _v_leg_family(cls, v):
        if v is None:
            return v
        return LEG_ALIASES.get(_canon(str(v)), v)

    # --- Structural validators ---

    @field_validator("seat_width_range_mm")
    @classmethod
    def validate_seat_width_range(cls, v: Optional[Tuple[int, int]]):
        if v is None:
            return None
        a, b = v
        if a <= 0 or b <= 0:
            raise ValueError("seat_width_range_mm values must be > 0")
        if a > b:
            raise ValueError("seat_width_range_mm min must be <= max")
        if a < 350 or b > 1200:
            raise ValueError("seat_width_range_mm out of bounds (350..1200 mm)")
        return v

    @model_validator(mode="after")
    def validate_layout_orientation(self):
        # В Request допускаем отсутствие orientation.
        # Resolver заполнит дефолт, если layout corner/u_shape.
        return self


# =========================
# Resolved specs (Builder input)
# =========================

class LegsSpec(BaseModel):
    family: LegFamily
    height_mm: int = Field(ge=30, le=260)
    params: Dict[str, Any] = Field(default_factory=dict)


class ArmsSpec(BaseModel):
    type: ArmrestType
    width_mm: int = Field(ge=0, le=400)
    profile: Literal["box", "rounded_bottom", "rolled"] = "box"


class FrameSpec(BaseModel):
    thickness_mm: int = Field(ge=20, le=80)
    back_thickness_mm: int = Field(ge=50, le=180)
    back_height_above_seat_mm: int = Field(ge=250, le=700)


class SofaResolved(BaseModel):
    """
    Полная спецификация. Builder обязан уметь собирать любой SofaResolved.
    """

    style: SofaStyle
    layout: SofaLayout
    orientation: Optional[Orientation] = None  # resolved for corner/u_shape

    seat_count: int = Field(ge=1, le=8)

    seat_height_mm: int = Field(ge=250, le=650)
    seat_depth_mm: int = Field(ge=350, le=900)
    seat_width_mm: int = Field(ge=350, le=1200)

    has_chaise: bool
    transformable: bool
    seat_type: SeatType

    legs: LegsSpec
    arms: ArmsSpec
    frame: FrameSpec

    @model_validator(mode="after")
    def sanity(self):
        total_seat_width = self.seat_count * self.seat_width_mm
        if self.arms.type == ArmrestType.both and total_seat_width < 900:
            raise ValueError("Too small sofa for two armrests with given seat_count/seat_width_mm")
        return self


# =========================
# Resolver defaults
# =========================

STYLE_DEFAULTS: Dict[SofaStyle, Dict[str, Any]] = {
    SofaStyle.scandi: dict(
        seat_count=3,
        seat_height_mm=440,
        seat_depth_mm=600,
        seat_width_mm=600,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.cushions,
        legs=dict(family=LegFamily.tapered_cone, height_mm=160, params={"r_top": 22, "r_bottom": 12}),
        arms=dict(type=ArmrestType.both, width_mm=120, profile="box"),
        frame=dict(thickness_mm=35, back_thickness_mm=90, back_height_above_seat_mm=420),
    ),
    SofaStyle.loft: dict(
        seat_count=3,
        seat_height_mm=430,
        seat_depth_mm=620,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.frame, height_mm=120, params={}),
        arms=dict(type=ArmrestType.both, width_mm=140, profile="box"),
        frame=dict(thickness_mm=40, back_thickness_mm=110, back_height_above_seat_mm=420),
    ),
    SofaStyle.modern: dict(
        seat_count=3,
        seat_height_mm=450,
        seat_depth_mm=620,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.block, height_mm=80, params={}),
        arms=dict(type=ArmrestType.both, width_mm=130, profile="rounded_bottom"),
        frame=dict(thickness_mm=40, back_thickness_mm=100, back_height_above_seat_mm=400),
    ),
    SofaStyle.minimal: dict(
        seat_count=3,
        seat_height_mm=430,
        seat_depth_mm=600,
        seat_width_mm=620,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.single,
        legs=dict(family=LegFamily.block, height_mm=40, params={}),
        arms=dict(type=ArmrestType.both, width_mm=110, profile="box"),
        frame=dict(thickness_mm=35, back_thickness_mm=90, back_height_above_seat_mm=380),
    ),
    SofaStyle.classic: dict(
        seat_count=3,
        seat_height_mm=460,
        seat_depth_mm=590,
        seat_width_mm=600,
        has_chaise=False,
        transformable=False,
        seat_type=SeatType.cushions,
        legs=dict(family=LegFamily.tapered_prism, height_mm=120, params={"top": [45, 45], "bottom": [30, 30]}),
        arms=dict(type=ArmrestType.both, width_mm=170, profile="rolled"),
        frame=dict(thickness_mm=45, back_thickness_mm=120, back_height_above_seat_mm=480),
    ),
}


# =========================
# Resolver (детерминированный)
# =========================

def resolve_sofa(req: SofaRequest) -> SofaResolved:
    """
    Детерминированно заполняет пропуски и приводит к полной спецификации для Builder.
    """

    defaults = STYLE_DEFAULTS[req.style]

    # 1) Orientation: required for corner/u_shape, but can be missing in Request.
    orientation = req.orientation
    if req.layout in {SofaLayout.corner, SofaLayout.u_shape} and orientation is None:
        orientation = Orientation.left  # system default

    # 2) Seat width: if user gave range — take midpoint; else style default.
    seat_width_mm = defaults["seat_width_mm"]
    if req.seat_width_range_mm is not None:
        a, b = req.seat_width_range_mm
        seat_width_mm = int(round((a + b) / 2))

    # 3) User overrides > defaults
    seat_count = req.seat_count or defaults["seat_count"]
    seat_height_mm = req.seat_height_mm or defaults["seat_height_mm"]
    seat_depth_mm = req.seat_depth_mm or defaults["seat_depth_mm"]

    has_chaise = req.has_chaise if req.has_chaise is not None else defaults["has_chaise"]
    transformable = req.transformable if req.transformable is not None else defaults["transformable"]

    # 4) legs/arms/frame dicts
    legs_dict = dict(defaults["legs"])
    if req.leg_family is not None:
        legs_dict["family"] = req.leg_family

    arms_dict = dict(defaults["arms"])
    if req.armrests is not None:
        arms_dict["type"] = req.armrests
        if req.armrests == ArmrestType.none:
            arms_dict["width_mm"] = 0

    frame_dict = dict(defaults["frame"])

    # 5) Preferences bias (safe, optional)
    if req.preferences is not None:
        prefs = req.preferences

        # leg thickness bias: only applies to families that use radii
        if prefs.leg_thickness_bias in {"thin", "thick"}:
            fam = legs_dict.get("family")
            params = dict(legs_dict.get("params", {}))

            # only for tapered_cone/cylindrical where r_top/r_bottom make sense
            if fam in {LegFamily.tapered_cone, LegFamily.cylindrical}:
                r_top = int(params.get("r_top", 22))
                r_bottom = int(params.get("r_bottom", 12))

                if prefs.leg_thickness_bias == "thin":
                    r_top = max(10, int(round(r_top * 0.8)))
                    r_bottom = max(6, int(round(r_bottom * 0.8)))
                else:  # thick
                    r_top = min(45, int(round(r_top * 1.2)))
                    r_bottom = min(40, int(round(r_bottom * 1.2)))

                params["r_top"] = r_top
                params["r_bottom"] = r_bottom
                legs_dict["params"] = params

        # arm profile preference
        if prefs.arm_profile is not None:
            arms_dict["profile"] = prefs.arm_profile

        # seat softness -> choose cushion seat type for soft/medium
        if prefs.seat_softness in {"soft", "medium"}:
            seat_type = SeatType.cushions
        else:
            seat_type = defaults["seat_type"]
    else:
        seat_type = defaults["seat_type"]

    return SofaResolved(
        style=req.style,
        layout=req.layout,
        orientation=orientation,

        seat_count=seat_count,
        seat_height_mm=seat_height_mm,
        seat_depth_mm=seat_depth_mm,
        seat_width_mm=seat_width_mm,

        has_chaise=has_chaise,
        transformable=transformable,
        seat_type=seat_type,

        legs=LegsSpec(**legs_dict),
        arms=ArmsSpec(**arms_dict),
        frame=FrameSpec(**frame_dict),
    )



===== FILE: tools/blender/batch_debug_run.py =====
"""Batch Blender debug runs for a directory of IR JSON files.

Usage:
  blender --background --python tools/blender/batch_debug_run.py -- <input_dir> <output_dir>
"""

from __future__ import annotations

import csv
import json
import os
import sys
from copy import deepcopy
from pathlib import Path
from typing import Any


REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from tools.blender import debug_run as single_debug_run  # noqa: E402
from tools.blender.debug.autofix import fix_ir  # noqa: E402
from tools.blender.debug.io import ensure_dir, save_json  # noqa: E402
from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
from tools.blender.debug.validators import validate  # noqa: E402
from tools.blender.debug.visualize import apply_debug_visualization  # noqa: E402


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _safe_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def _env_flag(name: str, default: bool = False) -> bool:
    raw = str(os.environ.get(name, "1" if default else "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _env_int(name: str, default: int, min_value: int = 1) -> int:
    raw = os.environ.get(name, str(default))
    try:
        value = int(raw)
    except (TypeError, ValueError):
        value = int(default)
    return max(int(min_value), int(value))


def _resolve_path(path: str) -> Path:
    candidate = Path(path)
    if candidate.is_absolute():
        return candidate
    return Path(REPO_ROOT) / candidate


def _parse_args() -> tuple[Path, Path]:
    args: list[str]
    if "--" in sys.argv:
        idx = sys.argv.index("--")
        args = [str(item).strip() for item in sys.argv[idx + 1 :]]
    else:
        args = [str(item).strip() for item in sys.argv[1:]]

    if len(args) >= 2:
        return _resolve_path(args[0]), _resolve_path(args[1])

    env_in = str(os.environ.get("DEBUG_BATCH_INPUT_DIR", "")).strip()
    env_out = str(os.environ.get("DEBUG_BATCH_OUTPUT_DIR", "")).strip()
    if env_in and env_out:
        return _resolve_path(env_in), _resolve_path(env_out)

    raise RuntimeError(
        "Usage: blender --background --python tools/blender/batch_debug_run.py -- <input_dir> <output_dir>"
    )


def _looks_like_ir(payload: Any) -> bool:
    return isinstance(payload, dict) and any(
        key in payload for key in ("slats", "back_support", "seat_width_mm", "seat_depth_mm")
    )


def _load_ir(path: Path) -> dict[str, Any]:
    with path.open("r", encoding="utf-8") as handle:
        payload = json.load(handle)
    if not _looks_like_ir(payload):
        raise ValueError(f"{path.name}: payload is not an IR JSON object")
    return payload


def _overlap_total(metrics: dict[str, Any], key: str) -> float:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return 0.0
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return 0.0
    return float(_safe_float(entry.get("total_volume", 0.0), 0.0))


def _run_one_ir(
    ir_path: Path,
    *,
    debug_iters: int,
    debug_autofix: bool,
    snapshot_blend_dir: Path | None,
    camera_lens_mm: float,
) -> dict[str, Any]:
    source_ir = _load_ir(ir_path)
    current_ir = deepcopy(source_ir)

    prev_metrics: dict[str, Any] | None = None
    autofix_context: dict[str, Any] = {}
    patches_applied: list[dict[str, Any]] = []

    final_metrics: dict[str, Any] = {}
    final_validation: dict[str, Any] = {"score": 0.0, "problem_count": 0, "problems": []}

    for idx in range(1, debug_iters + 1):
        single_debug_run._build_scene_from_ir(current_ir)
        metrics = collect_scene_metrics()
        validation_payload = validate(current_ir, metrics)

        if debug_autofix and idx < debug_iters:
            problems = validation_payload.get("problems", [])
            if not isinstance(problems, list):
                problems = []
            updated_ir, iteration_patches = fix_ir(
                current_ir,
                problems,
                metrics=metrics,
                validation=validation_payload,
                prev_metrics=prev_metrics,
                context=autofix_context,
            )
            current_ir = updated_ir
            patches_applied.extend(iteration_patches)

        final_metrics = metrics
        final_validation = validation_payload
        prev_metrics = metrics

    top_pair = single_debug_run._top_overlap_offender_pair(final_validation, final_metrics)
    if top_pair and isinstance(final_metrics, dict):
        final_metrics["top_offender_pair"] = top_pair

    if snapshot_blend_dir is not None:
        ensure_dir(str(snapshot_blend_dir))
        blend_path = snapshot_blend_dir / f"{ir_path.stem}.blend"
        apply_debug_visualization(
            validation=final_validation,
            metrics=final_metrics,
            snapshot_blend_path=str(blend_path),
            snapshot_png_path=None,
            camera_lens_mm=float(camera_lens_mm),
        )

    return {
        "ir_path": str(ir_path),
        "ir_out": current_ir,
        "metrics": final_metrics,
        "validation": final_validation,
        "patches_applied": patches_applied,
    }


def _write_summary_csv(path: Path, rows: list[dict[str, Any]]) -> None:
    fieldnames = [
        "file_name",
        "debug_score",
        "problems_count",
        "overlaps_slats_m3",
        "overlaps_back_m3",
        "fixes_applied_count",
    ]
    ensure_dir(str(path.parent))
    with path.open("w", encoding="utf-8", newline="") as handle:
        writer = csv.DictWriter(handle, fieldnames=fieldnames)
        writer.writeheader()
        for row in rows:
            writer.writerow(row)


def main() -> int:
    try:
        import bpy  # type: ignore  # noqa: F401
    except Exception as exc:
        print(f"BATCH_DEBUG_ERROR:bpy unavailable ({exc})", file=sys.stderr)
        return 3

    try:
        input_dir, output_dir = _parse_args()
    except Exception as exc:
        print(f"BATCH_DEBUG_ERROR:{exc}", file=sys.stderr)
        return 2

    if not input_dir.exists() or not input_dir.is_dir():
        print(f"BATCH_DEBUG_ERROR: input_dir not found: {input_dir}", file=sys.stderr)
        return 2

    ensure_dir(str(output_dir))
    debug_iters = _env_int("DEBUG_ITERS", 1, min_value=1)
    debug_autofix = _env_flag("DEBUG_AUTOFIX", default=False)
    camera_lens_mm = float(_safe_float(os.environ.get("DEBUG_SNAPSHOT_LENS_MM", "50"), 50.0))

    snapshot_blend_dir_raw = str(os.environ.get("DEBUG_SNAPSHOT_BLEND_DIR", "")).strip()
    snapshot_blend_dir = _resolve_path(snapshot_blend_dir_raw) if snapshot_blend_dir_raw else None

    ir_files = sorted(input_dir.glob("*.json"))
    if not ir_files:
        print(f"BATCH_DEBUG_FILES:0")
        print(f"BATCH_DEBUG_SUMMARY:{output_dir / 'summary.csv'}")
        return 0

    summary_rows: list[dict[str, Any]] = []
    for ir_path in ir_files:
        print(f"BATCH_DEBUG_RUN:{ir_path.name}")
        try:
            result = _run_one_ir(
                ir_path,
                debug_iters=debug_iters,
                debug_autofix=debug_autofix,
                snapshot_blend_dir=snapshot_blend_dir,
                camera_lens_mm=camera_lens_mm,
            )
            metrics = result.get("metrics", {})
            validation = result.get("validation", {})
            patches_applied = result.get("patches_applied", [])

            out_prefix = output_dir / ir_path.stem
            save_json(str(out_prefix.with_suffix(".validation.json")), validation)
            save_json(str(out_prefix.with_suffix(".metrics.json")), metrics)
            save_json(str(out_prefix.with_suffix(".ir_out.json")), result.get("ir_out", {}))

            summary_rows.append(
                {
                    "file_name": ir_path.name,
                    "debug_score": f"{_safe_float(validation.get('score', 0.0), 0.0):.6f}",
                    "problems_count": int(_safe_int(validation.get("problem_count", 0), 0)),
                    "overlaps_slats_m3": f"{_overlap_total(metrics, 'slats_vs_frame'):.6g}",
                    "overlaps_back_m3": f"{_overlap_total(metrics, 'back_slats_vs_frame'):.6g}",
                    "fixes_applied_count": len(patches_applied) if isinstance(patches_applied, list) else 0,
                }
            )
        except Exception as exc:
            print(f"BATCH_DEBUG_ERROR file={ir_path.name}: {exc}", file=sys.stderr)
            summary_rows.append(
                {
                    "file_name": ir_path.name,
                    "debug_score": "0.000000",
                    "problems_count": -1,
                    "overlaps_slats_m3": "0",
                    "overlaps_back_m3": "0",
                    "fixes_applied_count": 0,
                }
            )

    summary_path = output_dir / "summary.csv"
    _write_summary_csv(summary_path, summary_rows)
    print(f"BATCH_DEBUG_FILES:{len(summary_rows)}")
    print(f"BATCH_DEBUG_SUMMARY:{summary_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())



===== FILE: tools/blender/debug/__init__.py =====
"""Debug tooling for Blender sofa builds."""




===== FILE: tools/blender/debug/autofix.py =====
"""Rule-based IR autofixes for debug validator problems."""

from __future__ import annotations

import json
import math
import os
from copy import deepcopy
from typing import Any


def _as_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _as_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def read_env_float(name: str, default: float) -> float:
    raw = os.getenv(name, str(default))
    try:
        return float(raw)
    except (TypeError, ValueError):
        return float(default)


def bbox_spans_m(bbox_world: Any) -> tuple[float, float, float]:
    if not isinstance(bbox_world, dict):
        return 0.0, 0.0, 0.0

    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return 0.0, 0.0, 0.0
    if len(min_corner) < 3 or len(max_corner) < 3:
        return 0.0, 0.0, 0.0

    sx = max(0.0, _as_float(max_corner[0], 0.0) - _as_float(min_corner[0], 0.0))
    sy = max(0.0, _as_float(max_corner[1], 0.0) - _as_float(min_corner[1], 0.0))
    sz = max(0.0, _as_float(max_corner[2], 0.0) - _as_float(min_corner[2], 0.0))
    return float(sx), float(sy), float(sz)


def bbox_min_span_axis(bbox_world: Any) -> tuple[str, float]:
    sx, sy, sz = bbox_spans_m(bbox_world)
    axis, span = min(
        (("x", sx), ("y", sy), ("z", sz)),
        key=lambda item: float(item[1]),
    )
    return str(axis), float(span)


def _axis_index(axis: str) -> int:
    axis_map = {"x": 0, "y": 1, "z": 2}
    return int(axis_map.get(str(axis).strip().lower(), 0))


def _bbox_center_axis(bbox_world: Any, axis: str) -> float:
    if not isinstance(bbox_world, dict):
        return 0.0
    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return 0.0
    index = _axis_index(axis)
    if len(min_corner) <= index or len(max_corner) <= index:
        return 0.0
    min_value = _as_float(min_corner[index], 0.0)
    max_value = _as_float(max_corner[index], 0.0)
    return float((min_value + max_value) * 0.5)


def _bbox_axis_bounds(bbox_world: Any, axis: str) -> tuple[float, float] | None:
    if not isinstance(bbox_world, dict):
        return None
    min_corner = bbox_world.get("min", [])
    max_corner = bbox_world.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return None
    index = _axis_index(axis)
    if len(min_corner) <= index or len(max_corner) <= index:
        return None
    min_value = _as_float(min_corner[index], 0.0)
    max_value = _as_float(max_corner[index], 0.0)
    if min_value <= max_value:
        return float(min_value), float(max_value)
    return float(max_value), float(min_value)


def _signed_delta_mm(delta_mm: int, direction: int) -> int:
    magnitude = max(1, abs(int(delta_mm)))
    sign = 1 if int(direction) >= 0 else -1
    return int(sign * magnitude)


def _metrics_object_bbox(metrics: dict[str, Any] | None, name: str) -> dict[str, Any] | None:
    if not isinstance(metrics, dict):
        return None
    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return None
    needle = str(name).strip().lower()
    if not needle:
        return None
    for obj in objects:
        if not isinstance(obj, dict):
            continue
        if str(obj.get("name", "")).strip().lower() != needle:
            continue
        bbox_world = obj.get("bbox_world")
        if isinstance(bbox_world, dict):
            return bbox_world
        return None
    return None


def _rail_direction_hint(name: str) -> int | None:
    lowered = str(name).strip().lower()
    if not lowered:
        return None
    if ("back_rail_left" in lowered) or ("rail_left" in lowered):
        return 1
    if ("back_rail_right" in lowered) or ("rail_right" in lowered):
        return -1
    return None


def _resolve_direction(pair: dict[str, Any] | None, axis: str, metrics: dict[str, Any] | None) -> int:
    axis_name = str(axis).strip().lower()
    left_name = str((pair or {}).get("left", ""))
    right_name = str((pair or {}).get("right", ""))
    left_bbox = _metrics_object_bbox(metrics, left_name)
    right_bbox = _metrics_object_bbox(metrics, right_name)
    if left_bbox and right_bbox:
        left_center = _bbox_center_axis(left_bbox, axis_name)
        right_center = _bbox_center_axis(right_bbox, axis_name)
        return 1 if left_center > right_center else -1

    if axis_name == "x":
        rail_hint = _rail_direction_hint(right_name)
        if rail_hint is not None:
            return int(rail_hint)

    overlap_center = _bbox_center_axis((pair or {}).get("bbox_world"), axis_name)
    if axis_name == "x":
        if overlap_center < 0.0:
            return 1
        if overlap_center > 0.0:
            return -1
    return 1 if overlap_center < 0.0 else -1


def mm_from_m(m: float) -> int:
    return int(math.ceil(max(0.0, float(m)) * 1000.0))


def _clamp(value: float, min_value: float | None = None, max_value: float | None = None) -> float:
    result = float(value)
    if min_value is not None:
        result = max(float(min_value), result)
    if max_value is not None:
        result = min(float(max_value), result)
    return result


def _verbose_enabled() -> bool:
    raw = str(os.getenv("DEBUG_AUTOFIX_VERBOSE", "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _vprint(enabled: bool, message: str) -> None:
    if enabled:
        print(message)


def _get_path(root: dict[str, Any], path: str) -> tuple[bool, Any]:
    keys = [k for k in path.split(".") if k]
    if not keys:
        return False, None

    node: Any = root
    for key in keys[:-1]:
        if not isinstance(node, dict):
            return False, None
        node = node.get(key)
        if node is None:
            return False, None

    if not isinstance(node, dict):
        return False, None
    leaf = keys[-1]
    if leaf not in node:
        return False, None
    return True, node.get(leaf)


def _set_path(root: dict[str, Any], path: str, new_value: Any, patches: list[dict[str, Any]]) -> bool:
    keys = [k for k in path.split(".") if k]
    if not keys:
        return False

    node: dict[str, Any] = root
    for key in keys[:-1]:
        next_node = node.get(key)
        if not isinstance(next_node, dict):
            next_node = {}
            node[key] = next_node
        node = next_node

    leaf = keys[-1]
    old_value = node.get(leaf)
    if old_value == new_value:
        return False

    node[leaf] = new_value
    patches.append({"path": path, "old": old_value, "new": new_value})
    return True


def _coerce_numeric(value: float, old_value: Any) -> int | float:
    if isinstance(old_value, bool):
        return int(round(value))
    if isinstance(old_value, int):
        return int(round(value))
    if isinstance(old_value, float):
        return float(value)
    rounded = round(float(value))
    if abs(float(value) - float(rounded)) < 1e-9:
        return int(rounded)
    return float(value)


def _inc_path_clamped(
    ir: dict[str, Any],
    path: str,
    delta: float,
    min_value: float,
    max_value: float,
    patches: list[dict[str, Any]],
) -> tuple[bool, int | float, Any]:
    exists, old_value = _get_path(ir, path)
    base_value = _as_float(old_value, 0.0) if exists else 0.0
    new_numeric = _clamp(base_value + float(delta), min_value=min_value, max_value=max_value)
    new_value = _coerce_numeric(new_numeric, old_value)
    changed = _set_path(ir, path, new_value, patches)
    return changed, new_value, old_value


def _log_pair_context(
    *,
    verbose: bool,
    code: str,
    pair: dict[str, Any] | None,
    axis: str,
    span_m: float,
    delta_mm: int,
    safety_mm: int,
) -> None:
    if not verbose:
        return
    left_name = str((pair or {}).get("left", ""))
    right_name = str((pair or {}).get("right", ""))
    _vprint(
        True,
        (
            f"[autofix] code={code} "
            f"pair={left_name}->{right_name} "
            f"axis={axis} span_m={span_m:.6g} "
            f"delta_mm={delta_mm} safety_mm={safety_mm}"
        ),
    )


def _log_patch_change(
    *,
    verbose: bool,
    code: str,
    path: str,
    old_value: Any,
    new_value: Any,
) -> None:
    if not verbose:
        return
    _vprint(True, f"[autofix] code={code} patch {path}: {old_value} -> {new_value}")


def _normalize_code(code: str) -> str:
    normalized = code.strip().upper()
    aliases = {
        "INTERSECTION_SLATS_FRAME": "OVERLAP_SLATS_FRAME",
        "INTERSECTION_SLATS_ARMS": "OVERLAP_SLATS_ARMS",
    }
    return aliases.get(normalized, normalized)


def _problem_details(problem: dict[str, Any]) -> dict[str, Any]:
    details = problem.get("details", {})
    if isinstance(details, dict):
        return details
    return {}


def _problem_total_volume(problem: dict[str, Any]) -> float:
    details = _problem_details(problem)
    for key in ("total_volume_m3", "volume_m3", "total_volume"):
        if key in details:
            return _as_float(details.get(key), 0.0)
    return 0.0


def _problem_pairs_top(problem: dict[str, Any]) -> list[dict[str, Any]]:
    details = _problem_details(problem)
    pairs = details.get("pairs_top", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def get_top_pair(problem: dict[str, Any]) -> dict[str, Any] | None:
    pairs = _problem_pairs_top(problem)
    if not pairs:
        return None
    return pairs[0]


def _top_pair(problem: dict[str, Any], metrics: dict[str, Any] | None, overlap_key: str) -> dict[str, Any] | None:
    from_problem = get_top_pair(problem)
    if from_problem is not None:
        return from_problem

    pairs = _overlap_pairs(metrics, overlap_key)
    if not pairs:
        return None
    return max(pairs, key=lambda pair: _as_float(pair.get("volume", 0.0), 0.0))


def _safety_mm() -> int:
    return max(0, int(math.ceil(read_env_float("DEBUG_AUTOFIX_SAFETY_MM", 2.0))))


def _delta_from_pair(pair: dict[str, Any] | None, safety_mm: int) -> tuple[str, float, int]:
    if not isinstance(pair, dict):
        return "x", 0.0, 2
    axis, span_m = bbox_min_span_axis(pair.get("bbox_world"))
    if span_m <= 0.0:
        return axis, 0.0, 2
    delta_mm = mm_from_m(span_m) + int(max(0, safety_mm))
    return axis, float(span_m), int(max(1, delta_mm))


def _overlap_total_m3(metrics: dict[str, Any] | None, key: str) -> float | None:
    if not isinstance(metrics, dict):
        return None
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return None
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return None
    return float(_as_float(entry.get("total_volume", 0.0), 0.0))


def is_effective(
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    key: str,
    eps_m3: float | None = None,
) -> bool:
    eps = float(read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8) if eps_m3 is None else eps_m3)
    raw_prev = _overlap_total_m3(prev_metrics, key)
    raw_new = _overlap_total_m3(metrics, key)
    if (raw_prev is None) and (raw_new is None):
        return False
    prev_overlap, new_overlap = _resolved_overlap_pair_m3(prev_metrics, metrics, key)
    if float(new_overlap) <= eps:
        return True
    return (float(prev_overlap) - float(new_overlap)) >= eps


def _format_overlap(value: float | None) -> str:
    if value is None:
        return "n/a"
    return f"{float(value):.6g}"


def _resolved_overlap_pair_m3(
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    key: str,
) -> tuple[float, float]:
    prev_overlap = _overlap_total_m3(prev_metrics, key)
    new_overlap = _overlap_total_m3(metrics, key)
    if prev_overlap is None and new_overlap is None:
        return 0.0, 0.0
    if prev_overlap is None:
        prev_overlap = float(_as_float(new_overlap, 0.0))
    if new_overlap is None:
        new_overlap = float(_as_float(prev_overlap, 0.0))
    return float(prev_overlap), float(new_overlap)


def _log_effect_decision(
    *,
    verbose: bool,
    code: str,
    key: str,
    prev_metrics: dict[str, Any] | None,
    metrics: dict[str, Any] | None,
    eps_m3: float,
) -> tuple[bool, float, float, float]:
    prev_overlap, new_overlap = _resolved_overlap_pair_m3(prev_metrics, metrics, key)
    delta_overlap = float(prev_overlap - new_overlap)
    effective = is_effective(prev_metrics, metrics, key, eps_m3=eps_m3)
    if verbose:
        _vprint(
            True,
            (
                f"[autofix] code={code} overlap_key={key} "
                f"prev_overlap={_format_overlap(prev_overlap)} "
                f"new_overlap={_format_overlap(new_overlap)} "
                f"delta_overlap={delta_overlap:.6g} "
                f"effect_eps_m3={float(eps_m3):.6g} "
                f"effective={effective}"
            ),
        )
    return effective, prev_overlap, new_overlap, delta_overlap


def _overlap_entry(metrics: dict[str, Any] | None, key: str) -> dict[str, Any]:
    if not isinstance(metrics, dict):
        return {}
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return {}
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return {}
    return entry


def _overlap_pairs(metrics: dict[str, Any] | None, key: str) -> list[dict[str, Any]]:
    entry = _overlap_entry(metrics, key)
    pairs = entry.get("pairs", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def _overlap_total(metrics: dict[str, Any] | None, key: str, problem: dict[str, Any]) -> float:
    entry = _overlap_entry(metrics, key)
    total = _as_float(entry.get("total_volume", 0.0), 0.0)
    if total > 0.0:
        return total
    return _problem_total_volume(problem)


def _fix_slats_not_bent(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    slats = ir.get("slats", {})
    if not isinstance(slats, dict):
        slats = {}
        ir["slats"] = slats

    old_arc = _as_float(slats.get("arc_height_mm", 0.0), 0.0)
    new_arc = _clamp(old_arc + 5.0, max_value=60.0)
    _set_path(ir, "slats.arc_height_mm", new_arc, patches)

    if "subdiv_cuts" in slats:
        old_cuts = _as_int(slats.get("subdiv_cuts", 0), 0)
        new_cuts = int(_clamp(float(old_cuts + 8), min_value=0.0, max_value=256.0))
        _set_path(ir, "slats.subdiv_cuts", new_cuts, patches)


def _fix_back_slats_not_bent(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    back_support = ir.get("back_support", {})
    if not isinstance(back_support, dict):
        back_support = {}
        ir["back_support"] = back_support
    slats = back_support.get("slats", {})
    if not isinstance(slats, dict):
        slats = {}
        back_support["slats"] = slats

    old_arc = _as_float(slats.get("arc_height_mm", 0.0), 0.0)
    new_arc = _clamp(old_arc + 3.0, max_value=40.0)
    _set_path(ir, "back_support.slats.arc_height_mm", new_arc, patches)


def _fix_overlap_slats_frame(
    ir: dict[str, Any],
    patches: list[dict[str, Any]],
    metrics: dict[str, Any] | None,
    prev_metrics: dict[str, Any] | None,
    problem: dict[str, Any],
    verbose: bool,
) -> None:
    code = "OVERLAP_SLATS_FRAME"
    overlap_key = "slats_vs_frame"
    pair = _top_pair(problem, metrics, "slats_vs_frame")
    right_name = str((pair or {}).get("right", "")).lower()
    safety_mm = _safety_mm()
    axis, span_m, delta_mm = _delta_from_pair(pair, safety_mm=safety_mm)
    effect_eps_m3 = read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8)
    _log_pair_context(
        verbose=verbose,
        code=code,
        pair=pair,
        axis=axis,
        span_m=span_m,
        delta_mm=delta_mm,
        safety_mm=safety_mm,
    )
    effective, _, _, _ = _log_effect_decision(
        verbose=verbose,
        code=code,
        key=overlap_key,
        prev_metrics=prev_metrics,
        metrics=metrics,
        eps_m3=effect_eps_m3,
    )

    has_mount_offset, _ = _get_path(ir, "slats.mount_offset_mm")
    has_rail_inset, _ = _get_path(ir, "slats.rail_inset_mm")

    clearance_delta = float(max(1, int(math.ceil(float(delta_mm) / 4.0))))
    mount_delta = float(max(1, int(math.ceil(float(delta_mm) / 2.0))))
    rail_inset_delta = float(max(1, int(math.ceil(float(delta_mm) / 2.0))))
    safe_fallback_clearance = float(2 if int(delta_mm) >= 4 else 1)

    Strategy = tuple[str, str, float, float, float, bool]

    def _apply_strategy(strategy: Strategy, step: str) -> bool:
        strategy_name, path, delta, min_value, max_value, require_existing = strategy
        if require_existing:
            exists, _ = _get_path(ir, path)
            if not exists:
                if verbose:
                    _vprint(
                        True,
                        f"[autofix] code={code} skip_strategy={strategy_name} reason=missing_path path={path}",
                    )
                return False
        changed, new_value, old_value = _inc_path_clamped(
            ir,
            path,
            float(delta),
            float(min_value),
            float(max_value),
            patches,
        )
        if changed:
            _log_patch_change(
                verbose=verbose,
                code=code,
                path=path,
                old_value=old_value,
                new_value=new_value,
            )
        if verbose:
            _vprint(
                True,
                f"[autofix] code={code} chosen_strategy={strategy_name} chosen_param={path} step={step}",
            )
        return True

    group = "other"
    if right_name.startswith("rail_") or ("rail_left" in right_name) or ("rail_right" in right_name):
        group = "rail"
    elif right_name.startswith("beam_cross_"):
        group = "beam"

    primary: Strategy
    secondary: Strategy | None = None
    fallback: Strategy = (
        "safe_fallback_clearance",
        "slats.clearance_mm",
        safe_fallback_clearance,
        0.0,
        12.0,
        False,
    )

    if group == "rail":
        if axis == "x":
            primary = ("rail_axis_x_margin_x", "slats.margin_x_mm", float(delta_mm), 0.0, 80.0, False)
            secondary = ("rail_axis_x_rail_inset", "slats.rail_inset_mm", rail_inset_delta, 0.0, 20.0, True)
        elif axis == "y":
            primary = ("rail_axis_y_margin_y", "slats.margin_y_mm", float(delta_mm), 0.0, 120.0, False)
        else:  # axis == "z"
            if has_mount_offset:
                primary = ("rail_axis_z_mount_offset", "slats.mount_offset_mm", mount_delta, 0.0, 80.0, True)
                secondary = ("rail_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
            else:
                primary = ("rail_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)

    elif group == "beam":
        if axis == "y":
            primary = ("beam_axis_y_margin_y", "slats.margin_y_mm", float(delta_mm), 0.0, 120.0, False)
        elif axis == "z":
            if has_mount_offset:
                primary = ("beam_axis_z_mount_offset", "slats.mount_offset_mm", mount_delta, 0.0, 80.0, True)
                secondary = ("beam_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
            else:
                primary = ("beam_axis_z_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)
        else:  # axis == "x"
            primary = ("beam_axis_x_margin_x_fallback", "slats.margin_x_mm", float(delta_mm), 0.0, 80.0, False)

    else:
        primary = ("other_axis_clearance", "slats.clearance_mm", clearance_delta, 0.0, 12.0, False)

    _apply_strategy(primary, step="primary")
    if effective:
        return

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_primary effective=False")
    secondary_applied = _apply_strategy(secondary, step="secondary") if secondary is not None else False
    if verbose and (secondary is None):
        _vprint(True, f"[autofix] code={code} secondary_strategy=none")
    if not secondary_applied and (secondary is not None) and verbose:
        _vprint(True, f"[autofix] code={code} secondary_strategy_skipped")

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_secondary effective=False fallback=true")
    _apply_strategy(fallback, step="fallback")


def _fix_overlap_back_slats_frame(
    ir: dict[str, Any],
    patches: list[dict[str, Any]],
    metrics: dict[str, Any] | None,
    prev_metrics: dict[str, Any] | None,
    problem: dict[str, Any],
    context: dict[str, Any] | None,
    verbose: bool,
) -> None:
    del context
    code = "OVERLAP_BACK_SLATS_FRAME"
    overlap_key = "back_slats_vs_frame"
    pair = _top_pair(problem, metrics, "back_slats_vs_frame")
    right_name = str((pair or {}).get("right", ""))
    right_name_lower = right_name.lower()
    left_name = str((pair or {}).get("left", ""))
    safety_mm = _safety_mm()
    axis, span_m, delta_mm = _delta_from_pair(pair, safety_mm=safety_mm)
    effect_eps_m3 = read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8)
    left_bbox_world = _metrics_object_bbox(metrics, left_name)
    right_bbox_world = _metrics_object_bbox(metrics, right_name)
    left_center_axis = _bbox_center_axis(left_bbox_world, axis) if left_bbox_world else None
    right_center_axis = _bbox_center_axis(right_bbox_world, axis) if right_bbox_world else None
    overlap_center_axis = _bbox_center_axis((pair or {}).get("bbox_world"), axis)
    slat_bounds = _bbox_axis_bounds(left_bbox_world, axis)
    rail_bounds = _bbox_axis_bounds(right_bbox_world, axis)
    slat_min_axis: float | None = None
    slat_max_axis: float | None = None
    rail_min_axis: float | None = None
    rail_max_axis: float | None = None
    if slat_bounds is not None:
        slat_min_axis, slat_max_axis = slat_bounds
    if rail_bounds is not None:
        rail_min_axis, rail_max_axis = rail_bounds

    push_plus_mm: int | None = None
    push_minus_mm: int | None = None
    rail_side_direction = _rail_direction_hint(right_name_lower)
    if axis in {"y", "z"} and (slat_bounds is not None) and (rail_bounds is not None):
        safety = int(max(0, safety_mm))
        push_plus_mm = int(math.ceil((float(rail_max_axis) - float(slat_min_axis)) * 1000.0)) + safety
        push_minus_mm = int(math.ceil((float(slat_max_axis) - float(rail_min_axis)) * 1000.0)) + safety
        chosen_signed_delta_mm = int(push_plus_mm if push_plus_mm <= push_minus_mm else -push_minus_mm)
        direction = 1 if chosen_signed_delta_mm >= 0 else -1
    else:
        direction = _resolve_direction(pair, axis, metrics)
        if axis == "x" and rail_side_direction is not None:
            direction = int(rail_side_direction)
        chosen_signed_delta_mm = _signed_delta_mm(delta_mm, direction)

    primary_direction = int(direction)
    axis_delta_mm = max(1, abs(int(chosen_signed_delta_mm)))
    left_center_text = "n/a" if left_center_axis is None else f"{float(left_center_axis):.6g}"
    right_center_text = "n/a" if right_center_axis is None else f"{float(right_center_axis):.6g}"
    slat_min_text = "n/a" if slat_min_axis is None else f"{float(slat_min_axis):.6g}"
    slat_max_text = "n/a" if slat_max_axis is None else f"{float(slat_max_axis):.6g}"
    rail_min_text = "n/a" if rail_min_axis is None else f"{float(rail_min_axis):.6g}"
    rail_max_text = "n/a" if rail_max_axis is None else f"{float(rail_max_axis):.6g}"
    push_plus_text = "n/a" if push_plus_mm is None else str(int(push_plus_mm))
    push_minus_text = "n/a" if push_minus_mm is None else str(int(push_minus_mm))
    _log_pair_context(
        verbose=verbose,
        code=code,
        pair=pair,
        axis=axis,
        span_m=span_m,
        delta_mm=axis_delta_mm,
        safety_mm=safety_mm,
    )
    if verbose:
        _vprint(
            True,
            (
                f"[autofix] code={code} pair={left_name}->{right_name} "
                f"axis={axis} dir={int(primary_direction):+d} span_m={span_m:.6g} delta_mm={axis_delta_mm} "
                f"slat_min={slat_min_text} slat_max={slat_max_text} "
                f"rail_min={rail_min_text} rail_max={rail_max_text} "
                f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                f"chosen_signed_delta_mm={int(chosen_signed_delta_mm)} "
                f"left_center={left_center_text} right_center={right_center_text} "
                f"overlap_center={overlap_center_axis:.6g}"
            ),
        )
    effective, _, _, _ = _log_effect_decision(
        verbose=verbose,
        code=code,
        key=overlap_key,
        prev_metrics=prev_metrics,
        metrics=metrics,
        eps_m3=effect_eps_m3,
    )

    Strategy = tuple[str, str, int, float, float, bool, int | None, int | None]

    def _apply_strategy(strategy: Strategy | None, step: str) -> bool:
        if strategy is None:
            return False
        (
            strategy_name,
            path,
            delta_mm_value,
            min_value,
            max_value,
            require_existing,
            forced_direction,
            forced_signed_delta_mm,
        ) = strategy
        direction_used = int(primary_direction if forced_direction is None else forced_direction)
        signed_delta = (
            int(forced_signed_delta_mm)
            if forced_signed_delta_mm is not None
            else _signed_delta_mm(delta_mm_value, direction_used)
        )
        if forced_signed_delta_mm is not None:
            direction_used = 1 if int(signed_delta) >= 0 else -1
        if require_existing:
            exists, _ = _get_path(ir, path)
            if not exists:
                if verbose:
                    _vprint(
                        True,
                        (
                            f"[autofix] code={code} pair={left_name}->{right_name} "
                            f"axis={axis} dir={int(direction_used):+d} span_m={span_m:.6g} delta_mm={delta_mm_value} "
                            f"slat_min={slat_min_text} slat_max={slat_max_text} "
                            f"rail_min={rail_min_text} rail_max={rail_max_text} "
                            f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                            f"chosen_signed_delta_mm={int(signed_delta)} "
                            f"chosen_strategy={strategy_name} param={path} reason=missing_path step={step}"
                        ),
                    )
                return False
        changed, new_value, old_value = _inc_path_clamped(
            ir,
            path,
            float(signed_delta),
            float(min_value),
            float(max_value),
            patches,
        )
        if verbose:
            left_center_text = "n/a" if left_center_axis is None else f"{float(left_center_axis):.6g}"
            right_center_text = "n/a" if right_center_axis is None else f"{float(right_center_axis):.6g}"
            _vprint(
                True,
                (
                    f"[autofix] code={code} pair={left_name}->{right_name} "
                    f"axis={axis} dir={int(direction_used):+d} span_m={span_m:.6g} delta_mm={delta_mm_value} "
                    f"slat_min={slat_min_text} slat_max={slat_max_text} "
                    f"rail_min={rail_min_text} rail_max={rail_max_text} "
                    f"push_plus_mm={push_plus_text} push_minus_mm={push_minus_text} "
                    f"chosen_signed_delta_mm={int(signed_delta)} chosen_strategy={strategy_name} param={path} "
                    f"old->new={old_value}->{new_value} changed={changed} step={step} "
                    f"left_center={left_center_text} right_center={right_center_text} "
                    f"overlap_center={overlap_center_axis:.6g}"
                ),
            )
        return True

    offset_delta_mm = max(1, int(math.ceil(float(axis_delta_mm) / 2.0)))
    safe_delta_mm = 2 if int(axis_delta_mm) >= 4 else 1
    safe_offset_delta_mm = max(1, int(math.ceil(float(safe_delta_mm) / 2.0)))

    primary: Strategy
    secondary: Strategy | None = None
    fallback: Strategy

    if axis == "y":
        primary = (
            "axis_y_offset_y_primary",
            "back_support.offset_y_mm",
            int(axis_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            int(chosen_signed_delta_mm),
        )
        secondary = (
            "axis_y_margin_z_secondary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            None,
        )
        fallback = (
            "axis_y_offset_y_safe_fallback",
            "back_support.offset_y_mm",
            int(safe_offset_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            None,
        )
    elif axis == "z":
        primary = (
            "axis_z_margin_z_primary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            int(chosen_signed_delta_mm),
        )
        secondary = (
            "axis_z_offset_y_secondary",
            "back_support.offset_y_mm",
            int(offset_delta_mm),
            -50.0,
            80.0,
            False,
            int(direction),
            None,
        )
        fallback = (
            "axis_z_margin_z_safe_fallback",
            "back_support.margin_z_mm",
            int(safe_delta_mm),
            0.0,
            120.0,
            False,
            int(direction),
            None,
        )
    else:  # axis == "x"
        primary = (
            "axis_x_margin_x_primary",
            "back_support.margin_x_mm",
            int(axis_delta_mm),
            0.0,
            80.0,
            False,
            int(primary_direction),
            None,
        )
        secondary = (
            "axis_x_margin_z_secondary",
            "back_support.margin_z_mm",
            int(axis_delta_mm),
            0.0,
            120.0,
            False,
            int(primary_direction),
            None,
        )
        fallback = (
            "axis_x_margin_x_safe_fallback",
            "back_support.margin_x_mm",
            int(safe_delta_mm),
            0.0,
            80.0,
            False,
            int(primary_direction),
            None,
        )

    _apply_strategy(primary, step="primary")
    if effective:
        return

    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_primary effective=False")
    secondary_applied = _apply_strategy(secondary, step="secondary")
    if verbose and (secondary is None):
        _vprint(True, f"[autofix] code={code} secondary_strategy=none")
    if not secondary_applied and (secondary is not None) and verbose:
        _vprint(True, f"[autofix] code={code} secondary_strategy_skipped")
    if verbose:
        _vprint(True, f"[autofix] code={code} no_effect_after_secondary effective=False fallback=true")
    _apply_strategy(fallback, step="fallback")


def _fix_overlap_slats_arms(ir: dict[str, Any], patches: list[dict[str, Any]]) -> None:
    _inc_path_clamped(ir, "slats.margin_x_mm", 5.0, 0.0, 200.0, patches)


def _resolve_problems(
    problems: list[dict[str, Any]] | None,
    validation: dict[str, Any] | None,
) -> list[dict[str, Any]]:
    if isinstance(problems, list):
        return [item for item in problems if isinstance(item, dict)]
    if isinstance(validation, dict):
        candidate = validation.get("problems", [])
        if isinstance(candidate, list):
            return [item for item in candidate if isinstance(item, dict)]
    return []


def fix_ir(
    ir: dict[str, Any],
    problems: list[dict[str, Any]] | None = None,
    *,
    metrics: dict[str, Any] | None = None,
    validation: dict[str, Any] | None = None,
    prev_metrics: dict[str, Any] | None = None,
    context: dict[str, Any] | None = None,
) -> tuple[dict[str, Any], list[dict[str, Any]]]:
    """Apply MVP debug autofixes and return (new_ir, patches_applied)."""
    patched = deepcopy(ir)
    patches_applied: list[dict[str, Any]] = []
    handled_codes: set[str] = set()
    resolved_problems = _resolve_problems(problems, validation)
    verbose = _verbose_enabled()

    for problem in resolved_problems:
        code = _normalize_code(str(problem.get("code", "")))
        if not code or code in handled_codes:
            continue

        if code == "SLATS_NOT_BENT":
            _fix_slats_not_bent(patched, patches_applied)
            handled_codes.add(code)
            continue

        if code == "BACK_SLATS_NOT_BENT":
            _fix_back_slats_not_bent(patched, patches_applied)
            handled_codes.add(code)
            continue

        if code == "OVERLAP_SLATS_FRAME":
            _fix_overlap_slats_frame(
                patched,
                patches_applied,
                metrics=metrics,
                prev_metrics=prev_metrics,
                problem=problem,
                verbose=verbose,
            )
            handled_codes.add(code)
            continue

        if code == "OVERLAP_BACK_SLATS_FRAME":
            _fix_overlap_back_slats_frame(
                patched,
                patches_applied,
                metrics=metrics,
                prev_metrics=prev_metrics,
                problem=problem,
                context=context,
                verbose=verbose,
            )
            handled_codes.add(code)
            continue

        if code == "OVERLAP_SLATS_ARMS":
            _fix_overlap_slats_arms(patched, patches_applied)
            handled_codes.add(code)

    return patched, patches_applied


if __name__ == "__main__":
    os.environ["DEBUG_AUTOFIX_SAFETY_MM"] = str(_as_int(os.getenv("DEBUG_AUTOFIX_SAFETY_MM", 2), 2))
    os.environ["DEBUG_AUTOFIX_EFFECT_EPS_M3"] = str(read_env_float("DEBUG_AUTOFIX_EFFECT_EPS_M3", 1e-8))

    ir_base: dict[str, Any] = {
        "slats": {
            "margin_x_mm": 40,
            "margin_y_mm": 55,
            "clearance_mm": 4,
            "mount_offset_mm": 3,
            "rail_inset_mm": 3,
        }
    }

    problem_axis_z = {
        "code": "OVERLAP_SLATS_FRAME",
        "details": {
            "pairs_top": [
                {
                    "left": "slat_1",
                    "right": "rail_left",
                    "volume": 1.0e-4,
                    "bbox_world": {
                        "min": [0.0, 0.0, 0.0],
                        "max": [0.010, 0.008, 0.001],
                    },
                }
            ]
        },
    }
    pair_z = get_top_pair(problem_axis_z)
    axis_z, span_z, delta_z = _delta_from_pair(pair_z, safety_mm=_safety_mm())
    before_margin_x_z = _as_int(ir_base["slats"]["margin_x_mm"], 0)
    before_clearance_z = _as_int(ir_base["slats"]["clearance_mm"], 0)
    before_mount_z = _as_int(ir_base["slats"]["mount_offset_mm"], 0)
    fixed_ir_z, patches_z = fix_ir(
        ir_base,
        problems=[problem_axis_z],
        metrics={"overlaps": {"slats_vs_frame": {"total_volume": 1.0e-3}}},
        prev_metrics=None,
        context=None,
        validation=None,
    )
    after_margin_x_z = _as_int(fixed_ir_z.get("slats", {}).get("margin_x_mm", 0), 0)
    after_clearance_z = _as_int(fixed_ir_z.get("slats", {}).get("clearance_mm", 0), 0)
    after_mount_z = _as_int(fixed_ir_z.get("slats", {}).get("mount_offset_mm", 0), 0)
    primary_path_z = str((patches_z[0] if patches_z else {}).get("path", ""))
    ok_axis_z = bool(
        (axis_z == "z")
        and (primary_path_z in {"slats.clearance_mm", "slats.mount_offset_mm"})
        and (after_margin_x_z == before_margin_x_z)
        and ((after_clearance_z > before_clearance_z) or (after_mount_z > before_mount_z))
    )

    print(f"SELF_TEST_SLATS_RAIL_AXIS_Z axis={axis_z} span_m={span_z:.6g} delta_mm={delta_z}")
    print(
        "SELF_TEST_SLATS_RAIL_AXIS_Z "
        f"margin_x before={before_margin_x_z} after={after_margin_x_z} "
        f"clearance before={before_clearance_z} after={after_clearance_z} "
        f"mount_offset before={before_mount_z} after={after_mount_z}"
    )
    print(f"SELF_TEST_SLATS_RAIL_AXIS_Z primary_patch={primary_path_z} ok={ok_axis_z}")
    print(json.dumps(patches_z, ensure_ascii=False, indent=2))

    problem_axis_x = {
        "code": "OVERLAP_SLATS_FRAME",
        "details": {
            "pairs_top": [
                {
                    "left": "slat_2",
                    "right": "rail_right",
                    "volume": 1.0e-4,
                    "bbox_world": {
                        "min": [0.0, 0.0, 0.0],
                        "max": [0.001, 0.010, 0.020],
                    },
                }
            ]
        },
    }
    pair_x = get_top_pair(problem_axis_x)
    axis_x, span_x, delta_x = _delta_from_pair(pair_x, safety_mm=_safety_mm())
    before_margin_x = _as_int(ir_base["slats"]["margin_x_mm"], 0)
    fixed_ir_x, patches_x = fix_ir(
        ir_base,
        problems=[problem_axis_x],
        metrics={"overlaps": {"slats_vs_frame": {"total_volume": 1.0e-3}}},
        prev_metrics=None,
        context=None,
        validation=None,
    )
    after_margin_x = _as_int(fixed_ir_x.get("slats", {}).get("margin_x_mm", 0), 0)
    primary_path_x = str((patches_x[0] if patches_x else {}).get("path", ""))
    ok_axis_x = bool((axis_x == "x") and (primary_path_x == "slats.margin_x_mm") and (after_margin_x > before_margin_x))

    print(f"SELF_TEST_SLATS_RAIL_AXIS_X axis={axis_x} span_m={span_x:.6g} delta_mm={delta_x}")
    print(f"SELF_TEST_SLATS_RAIL_AXIS_X margin_x before={before_margin_x} after={after_margin_x}")
    print(f"SELF_TEST_SLATS_RAIL_AXIS_X primary_patch={primary_path_x} ok={ok_axis_x}")
    print(json.dumps(patches_x, ensure_ascii=False, indent=2))

    direction_pair_left = {
        "left": "back_slat_1",
        "right": "back_rail_left",
        "bbox_world": {
            "min": [-0.024, 0.10, 0.42],
            "max": [-0.018, 0.14, 0.47],
        },
    }
    direction_pair_right = {
        "left": "back_slat_7",
        "right": "back_rail_right",
        "bbox_world": {
            "min": [0.018, 0.10, 0.42],
            "max": [0.024, 0.14, 0.47],
        },
    }
    direction_left = _resolve_direction(direction_pair_left, "x", metrics=None)
    direction_right = _resolve_direction(direction_pair_right, "x", metrics=None)
    ok_direction_left = bool(direction_left == 1)
    ok_direction_right = bool(direction_right == -1)
    print(
        f"SELF_TEST_BACK_DIRECTION_LEFT axis=x dir={direction_left:+d} "
        f"expected=+1 ok={ok_direction_left}"
    )
    print(
        f"SELF_TEST_BACK_DIRECTION_RIGHT axis=x dir={direction_right:+d} "
        f"expected=-1 ok={ok_direction_right}"
    )



===== FILE: tools/blender/debug/io.py =====
"""JSON I/O helpers for debug runs."""

from __future__ import annotations

import hashlib
import json
import os
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Mapping


def ir_sha256(ir: Mapping[str, Any]) -> str:
    """Return SHA256 of canonical IR JSON."""
    payload = json.dumps(ir, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(payload.encode("utf-8")).hexdigest()


def make_run_id(short_len: int = 8) -> str:
    """Return run id as run_YYYYmmdd_HHMMSS_<shortid>."""
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    short_id = uuid.uuid4().hex[: max(4, int(short_len))]
    return f"run_{timestamp}_{short_id}"


def save_json(path: str | os.PathLike[str], payload: Mapping[str, Any]) -> str:
    """Save JSON payload to path, creating parent directories."""
    output_path = Path(path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    return str(output_path)


def load_json(path: str | os.PathLike[str]) -> dict[str, Any]:
    """Load JSON object from path."""
    data = json.loads(Path(path).read_text(encoding="utf-8"))
    if not isinstance(data, dict):
        raise ValueError(f"Expected JSON object in {path}, got {type(data).__name__}")
    return data


def save_run_log(
    payload: Mapping[str, Any],
    out_dir: str | os.PathLike[str] = "out/logs/runs",
    run_id: str | None = None,
) -> str:
    """Save debug run payload as out/logs/runs/run_<timestamp>_<shortid>.json."""
    resolved_run_id = run_id or make_run_id()
    file_path = Path(out_dir) / f"{resolved_run_id}.json"
    return save_json(file_path, payload)


def load_run_log(path: str | os.PathLike[str]) -> dict[str, Any]:
    """Load a previously saved debug run log."""
    return load_json(path)

def ensure_dir(path: str | os.PathLike[str]) -> str:
    """Create directory if it doesn't exist. Returns normalized string path."""
    p = Path(path)
    p.mkdir(parents=True, exist_ok=True)
    return str(p)
def ensure_parent(path: str | os.PathLike[str]) -> str:
    """Ensure parent directory for a file path exists. Returns normalized string path."""
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    return str(p)
def ensure_dir(path: str | os.PathLike[str]) -> str:
    """Create directory if it doesn't exist. Returns normalized string path."""
    p = Path(path)
    p.mkdir(parents=True, exist_ok=True)
    return str(p)


def make_run_tag(*, run_id: str) -> str:
    """Return a stable tag for artifacts based on run_id."""
    # debug_run ожидает, что run_tag используется в именах файлов: <run_tag>.json / .metrics.json / .ir_in.json ...
    return str(run_id)


def sha256_file(path: str | os.PathLike[str]) -> str:
    """Compute SHA256 hex digest of a file."""
    p = Path(path)
    h = hashlib.sha256()
    with p.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def sha256_json(payload: Mapping[str, Any]) -> str:
    """Compute SHA256 of canonical JSON (stable across key order)."""
    s = json.dumps(payload, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(s.encode("utf-8")).hexdigest()



===== FILE: tools/blender/debug/metrics.py =====
"""Scene metrics collection for Blender debug runs."""

from __future__ import annotations

from datetime import datetime, timezone
from typing import Any, Iterable


GROUP_KEYS = ("slat_", "back_slat_", "arm_", "frame_", "leg_")


def _bbox_from_points(points: Iterable[tuple[float, float, float]]) -> dict[str, list[float]] | None:
    coords = list(points)
    if not coords:
        return None
    xs = [p[0] for p in coords]
    ys = [p[1] for p in coords]
    zs = [p[2] for p in coords]
    return {
        "min": [float(min(xs)), float(min(ys)), float(min(zs))],
        "max": [float(max(xs)), float(max(ys)), float(max(zs))],
    }


def _bbox_union(bboxes: Iterable[dict[str, list[float]] | None]) -> dict[str, list[float]] | None:
    valid = [b for b in bboxes if b]
    if not valid:
        return None
    return {
        "min": [
            float(min(b["min"][0] for b in valid)),
            float(min(b["min"][1] for b in valid)),
            float(min(b["min"][2] for b in valid)),
        ],
        "max": [
            float(max(b["max"][0] for b in valid)),
            float(max(b["max"][1] for b in valid)),
            float(max(b["max"][2] for b in valid)),
        ],
    }


def _bbox_spans(bbox: dict[str, list[float]] | None) -> dict[str, float]:
    if not bbox:
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    return {
        "x": float(max(0.0, bbox["max"][0] - bbox["min"][0])),
        "y": float(max(0.0, bbox["max"][1] - bbox["min"][1])),
        "z": float(max(0.0, bbox["max"][2] - bbox["min"][2])),
    }


def _bbox_overlap(a: dict[str, list[float]] | None, b: dict[str, list[float]] | None) -> tuple[float, dict[str, list[float]] | None]:
    if not a or not b:
        return 0.0, None
    min_corner = [
        max(float(a["min"][0]), float(b["min"][0])),
        max(float(a["min"][1]), float(b["min"][1])),
        max(float(a["min"][2]), float(b["min"][2])),
    ]
    max_corner = [
        min(float(a["max"][0]), float(b["max"][0])),
        min(float(a["max"][1]), float(b["max"][1])),
        min(float(a["max"][2]), float(b["max"][2])),
    ]
    dx = max_corner[0] - min_corner[0]
    dy = max_corner[1] - min_corner[1]
    dz = max_corner[2] - min_corner[2]
    if dx <= 0.0 or dy <= 0.0 or dz <= 0.0:
        return 0.0, None
    return float(dx * dy * dz), {"min": min_corner, "max": max_corner}


def _group_match(name: str, group_key: str) -> bool:
    lower_name = name.lower()
    if group_key == "slat_":
        return lower_name.startswith("slat_")
    if group_key == "back_slat_":
        return lower_name.startswith("back_slat_")
    if group_key == "arm_":
        return (
            lower_name.startswith("arm_")
            or lower_name.startswith("left_arm")
            or lower_name.startswith("right_arm")
            or "_arm_" in lower_name
        )
    if group_key == "frame_":
        return (
            lower_name.startswith("frame_")
            or lower_name.startswith("beam_")
            or lower_name.startswith("rail_")
            or lower_name.startswith("back_rail_")
            or lower_name in {"seat_support", "back_frame", "back_panel"}
        )
    if group_key == "leg_":
        return lower_name.startswith("leg_")
    return False


def _object_base_bbox_world(obj: Any) -> dict[str, list[float]] | None:
    from mathutils import Vector  # type: ignore

    if obj.type == "MESH" and getattr(obj, "data", None) and len(obj.data.vertices) > 0:
        points = []
        for vertex in obj.data.vertices:
            world = obj.matrix_world @ vertex.co
            points.append((float(world.x), float(world.y), float(world.z)))
        return _bbox_from_points(points)

    if hasattr(obj, "bound_box") and obj.bound_box:
        points = []
        for corner in obj.bound_box:
            world = obj.matrix_world @ Vector(corner)
            points.append((float(world.x), float(world.y), float(world.z)))
        return _bbox_from_points(points)

    location = getattr(obj, "location", None)
    if location is None:
        return None
    return {
        "min": [float(location.x), float(location.y), float(location.z)],
        "max": [float(location.x), float(location.y), float(location.z)],
    }


def _mesh_bbox_world(mesh: Any, matrix_world: Any) -> dict[str, list[float]] | None:
    if not mesh or len(mesh.vertices) == 0:
        return None
    points = []
    for vertex in mesh.vertices:
        world = matrix_world @ vertex.co
        points.append((float(world.x), float(world.y), float(world.z)))
    return _bbox_from_points(points)


def _modifier_info(modifier: Any) -> dict[str, Any]:
    payload: dict[str, Any] = {
        "name": str(getattr(modifier, "name", "")),
        "type": str(getattr(modifier, "type", "")),
    }
    if payload["type"] == "SIMPLE_DEFORM":
        payload["deform_method"] = str(getattr(modifier, "deform_method", ""))
        payload["axis"] = str(getattr(modifier, "deform_axis", ""))
        try:
            payload["angle"] = float(getattr(modifier, "angle", 0.0))
        except (TypeError, ValueError):
            payload["angle"] = 0.0
        origin_obj = getattr(modifier, "origin", None)
        payload["origin"] = origin_obj.name if origin_obj is not None else None
    return payload


def _collect_object_metrics(obj: Any, depsgraph: Any) -> dict[str, Any]:
    base_bbox = _object_base_bbox_world(obj)
    eval_bbox = base_bbox
    vertices = 0
    polygons = 0

    if obj.type == "MESH":
        eval_obj = obj.evaluated_get(depsgraph)
        eval_mesh = eval_obj.to_mesh()
        try:
            vertices = int(len(eval_mesh.vertices))
            polygons = int(len(eval_mesh.polygons))
            eval_bbox = _mesh_bbox_world(eval_mesh, eval_obj.matrix_world) or base_bbox
        finally:
            eval_obj.to_mesh_clear()

    base_spans = _bbox_spans(base_bbox)
    eval_spans = _bbox_spans(eval_bbox)
    bbox_delta = {
        "x": float(eval_spans["x"] - base_spans["x"]),
        "y": float(eval_spans["y"] - base_spans["y"]),
        "z": float(eval_spans["z"] - base_spans["z"]),
    }

    return {
        "name": str(obj.name),
        "type": str(obj.type),
        "verts": vertices,
        "polys": polygons,
        "modifiers": [_modifier_info(mod) for mod in obj.modifiers],
        "bbox_world": eval_bbox,
        "bbox_world_base": base_bbox,
        "bbox_spans": eval_spans,
        "bbox_spans_base": base_spans,
        "bbox_delta": bbox_delta,
    }


def _collect_groups(objects: list[dict[str, Any]]) -> dict[str, dict[str, Any]]:
    groups: dict[str, dict[str, Any]] = {}
    for key in GROUP_KEYS:
        members = [obj for obj in objects if _group_match(str(obj.get("name", "")), key)]
        groups[key] = {
            "count": len(members),
            "objects": [str(obj.get("name", "")) for obj in members],
            "bbox_world": _bbox_union(obj.get("bbox_world") for obj in members),
        }
    return groups


def _collect_overlap_pairs(
    left_names: Iterable[str],
    right_names: Iterable[str],
    object_index: dict[str, dict[str, Any]],
) -> dict[str, Any]:
    pairs: list[dict[str, Any]] = []
    total = 0.0
    for left_name in left_names:
        left_bbox = object_index.get(left_name, {}).get("bbox_world")
        if not left_bbox:
            continue
        for right_name in right_names:
            right_bbox = object_index.get(right_name, {}).get("bbox_world")
            if not right_bbox:
                continue
            volume, bbox = _bbox_overlap(left_bbox, right_bbox)
            if volume <= 0.0:
                continue
            total += volume
            pairs.append(
                {
                    "left": left_name,
                    "right": right_name,
                    "volume": float(volume),
                    "bbox_world": bbox,
                }
            )
    return {"total_volume": float(total), "pairs": pairs}


def collect_scene_metrics() -> dict[str, Any]:
    """Collect object-level and group-level Blender scene metrics."""
    import bpy  # type: ignore

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()
    try:
        depsgraph.update()
    except Exception:
        pass

    scene_objects = sorted(bpy.data.objects, key=lambda item: item.name.lower())
    objects = [_collect_object_metrics(obj, depsgraph) for obj in scene_objects]
    groups = _collect_groups(objects)
    object_index = {str(obj.get("name", "")): obj for obj in objects}

    overlaps = {
        "slats_vs_arms": _collect_overlap_pairs(
            groups["slat_"]["objects"],
            groups["arm_"]["objects"],
            object_index,
        ),
        "slats_vs_frame": _collect_overlap_pairs(
            groups["slat_"]["objects"],
            groups["frame_"]["objects"],
            object_index,
        ),
        "back_slats_vs_frame": _collect_overlap_pairs(
            groups["back_slat_"]["objects"],
            groups["frame_"]["objects"],
            object_index,
        ),
    }

    return {
        "timestamp_utc": datetime.now(timezone.utc).isoformat(),
        "units": {"length": "m", "volume": "m3"},
        "object_count": len(objects),
        "objects": objects,
        "groups": groups,
        "overlaps": overlaps,
    }



===== FILE: tools/blender/debug/validators.py =====
"""Validation rules and scoring for Blender debug metrics."""

from __future__ import annotations

import json
import os
import sys
from typing import Any


DEFAULT_OVERLAP_EPS = 1e-8
BEND_MOD_ANGLE_EPS = 1e-6


def _read_env_float(name: str, default: float) -> float:
    raw = os.getenv(name, str(default))
    try:
        return float(raw)
    except (TypeError, ValueError):
        return float(default)


def _read_env_int(name: str, default: int) -> int:
    raw = os.getenv(name, str(default))
    try:
        return int(raw)
    except (TypeError, ValueError):
        return int(default)


BEND_EPS_M = _read_env_float("DEBUG_BEND_EPS_M", 0.002)
CLEARANCE_EPS_M = _read_env_float("DEBUG_CLEARANCE_EPS_M", 0.003)
JOINT_OVERLAP_ALLOWANCE_MM = _read_env_float("DEBUG_JOINT_OVERLAP_ALLOWANCE_MM", 2.0)
MOD_EFFECT_EPS_M = _read_env_float("DEBUG_MOD_EFFECT_EPS_M", 0.001)
MOD_EFFECT_VERTS_EPS = _read_env_int("DEBUG_MOD_EFFECT_VERTS_EPS", 4)


def _as_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _as_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return int(default)


def _looks_like_metrics(payload: Any) -> bool:
    return isinstance(payload, dict) and any(k in payload for k in ("objects", "groups", "overlaps"))


def _looks_like_ir(payload: Any) -> bool:
    return isinstance(payload, dict) and any(k in payload for k in ("slats", "back_support", "seat_width_mm"))


def _normalize_validate_args(first: dict[str, Any], second: dict[str, Any]) -> tuple[dict[str, Any], dict[str, Any]]:
    """Allow both validate(ir, metrics) and legacy validate(metrics, ir)."""
    if _looks_like_metrics(first) and _looks_like_ir(second):
        return second, first
    return first, second


def _objects_by_prefix(metrics: dict[str, Any], prefix: str) -> list[dict[str, Any]]:
    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return []
    lowered = prefix.lower()
    return [
        obj
        for obj in objects
        if isinstance(obj, dict) and str(obj.get("name", "")).lower().startswith(lowered)
    ]


def _mesh_objects_by_prefix(metrics: dict[str, Any], prefix: str) -> list[dict[str, Any]]:
    return [
        obj
        for obj in _objects_by_prefix(metrics, prefix)
        if str(obj.get("type", "")).strip().upper() == "MESH"
    ]


def _bend_mod_summary(obj: dict[str, Any]) -> tuple[bool, float]:
    """Return (has_bend_modifier, max_abs_bend_angle)."""
    max_abs_angle = 0.0
    has_bend_modifier = False
    modifiers = obj.get("modifiers", [])
    if not isinstance(modifiers, list):
        return has_bend_modifier, max_abs_angle
    for modifier in modifiers:
        if not isinstance(modifier, dict):
            continue
        if str(modifier.get("type", "")).upper() != "SIMPLE_DEFORM":
            continue
        if str(modifier.get("deform_method", "")).upper() == "BEND":
            has_bend_modifier = True
            angle = abs(_as_float(modifier.get("angle", 0.0), 0.0))
            if angle > max_abs_angle:
                max_abs_angle = angle
    return has_bend_modifier, float(max_abs_angle)


def _bbox_delta_axis(obj: dict[str, Any], axis: str) -> float:
    bbox_delta = obj.get("bbox_delta", {})
    if not isinstance(bbox_delta, dict):
        return 0.0
    return abs(_as_float(bbox_delta.get(axis, 0.0), 0.0))


def _bbox_delta_abs_xyz(obj: dict[str, Any]) -> dict[str, float]:
    return {
        "x": _bbox_delta_axis(obj, "x"),
        "y": _bbox_delta_axis(obj, "y"),
        "z": _bbox_delta_axis(obj, "z"),
    }


def _bbox_delta_xyz(obj: dict[str, Any]) -> dict[str, float]:
    bbox_delta = obj.get("bbox_delta", {})
    if not isinstance(bbox_delta, dict):
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    return {
        "x": _as_float(bbox_delta.get("x", 0.0), 0.0),
        "y": _as_float(bbox_delta.get("y", 0.0), 0.0),
        "z": _as_float(bbox_delta.get("z", 0.0), 0.0),
    }


def _max_bbox_delta_abs(obj: dict[str, Any]) -> float:
    deltas = _bbox_delta_abs_xyz(obj)
    return max(deltas["x"], deltas["y"], deltas["z"])


def _bent_stats_for_prefix(
    metrics: dict[str, Any],
    prefix: str,
    bend_eps_m: float,
) -> dict[str, Any]:
    diagnostics: list[dict[str, Any]] = []
    count_bent = 0
    for obj in _objects_by_prefix(metrics, prefix):
        bbox_delta = _bbox_delta_xyz(obj)
        deltas = _bbox_delta_abs_xyz(obj)
        max_delta = _max_bbox_delta_abs(obj)
        has_bend_mod, bend_angle = _bend_mod_summary(obj)
        bent = (max_delta >= bend_eps_m) or (has_bend_mod and bend_angle > BEND_MOD_ANGLE_EPS)
        if bent:
            count_bent += 1
        diagnostics.append(
            {
                "name": str(obj.get("name", "")),
                "bbox_delta": bbox_delta,
                "max_delta": float(max_delta),
                "has_bend_mod": bool(has_bend_mod),
                "bend_angle": float(bend_angle),
            }
        )
    top5 = sorted(diagnostics, key=lambda item: float(item.get("max_delta", 0.0)), reverse=True)[:5]
    return {
        "count_total": len(diagnostics),
        "count_bent": int(count_bent),
        "eps_m": float(bend_eps_m),
        "top5": top5,
    }


def _overlap_total(metrics: dict[str, Any], key: str) -> float:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return 0.0
    overlap = overlaps.get(key, {})
    if not isinstance(overlap, dict):
        return 0.0
    return _as_float(overlap.get("total_volume", 0.0), 0.0)


def _group_count(metrics: dict[str, Any], key: str) -> int:
    groups = metrics.get("groups", {})
    if not isinstance(groups, dict):
        return 0
    payload = groups.get(key, {})
    if not isinstance(payload, dict):
        return 0
    return _as_int(payload.get("count", 0), 0)


def _overlap_entry(metrics: dict[str, Any], key: str) -> dict[str, Any]:
    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return {}
    entry = overlaps.get(key, {})
    if not isinstance(entry, dict):
        return {}
    return entry


def _overlap_pairs(metrics: dict[str, Any], key: str) -> list[dict[str, Any]]:
    entry = _overlap_entry(metrics, key)
    pairs = entry.get("pairs", [])
    if not isinstance(pairs, list):
        return []
    return [pair for pair in pairs if isinstance(pair, dict)]


def _pair_spans(pair: dict[str, Any]) -> dict[str, float]:
    bbox = pair.get("bbox_world", {})
    if not isinstance(bbox, dict):
        return {"x": 0.0, "y": 0.0, "z": 0.0}

    min_corner = bbox.get("min", [])
    max_corner = bbox.get("max", [])
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return {"x": 0.0, "y": 0.0, "z": 0.0}
    if len(min_corner) < 3 or len(max_corner) < 3:
        return {"x": 0.0, "y": 0.0, "z": 0.0}

    return {
        "x": max(0.0, _as_float(max_corner[0], 0.0) - _as_float(min_corner[0], 0.0)),
        "y": max(0.0, _as_float(max_corner[1], 0.0) - _as_float(min_corner[1], 0.0)),
        "z": max(0.0, _as_float(max_corner[2], 0.0) - _as_float(min_corner[2], 0.0)),
    }


def _pair_min_span(pair: dict[str, Any]) -> float:
    spans = _pair_spans(pair)
    return min(float(spans["x"]), float(spans["y"]), float(spans["z"]))


def _is_expected_slats_frame_joint_overlap(ir: dict[str, Any], pair: dict[str, Any]) -> bool:
    right_name = str(pair.get("right", "")).strip().lower()
    if not right_name:
        return False

    if right_name.startswith("rail_") or right_name.startswith("beam_cross_"):
        slats = ir.get("slats", {})
        if not isinstance(slats, dict):
            return False
        allowance_mm = (
            _as_float(slats.get("clearance_mm", 0.0), 0.0)
            + _as_float(slats.get("mount_offset_mm", 0.0), 0.0)
            + JOINT_OVERLAP_ALLOWANCE_MM
        )
        allowance_m = max(0.0, allowance_mm / 1000.0)
        return _pair_min_span(pair) <= allowance_m
    return False


def _is_expected_back_slats_frame_joint_overlap(ir: dict[str, Any], pair: dict[str, Any]) -> bool:
    right_name = str(pair.get("right", "")).strip().lower()
    if right_name not in {"back_rail_left", "back_rail_right"}:
        return False

    back_support = ir.get("back_support", {})
    frame = ir.get("frame", {})
    if not isinstance(back_support, dict) or not isinstance(frame, dict):
        return False

    back_depth_mm = _as_float(back_support.get("thickness_mm", 0.0), 0.0)
    frame_depth_mm = _as_float(frame.get("thickness_mm", 0.0), 0.0)
    allowance_mm = max(0.0, back_depth_mm - frame_depth_mm) + JOINT_OVERLAP_ALLOWANCE_MM
    allowance_m = max(0.0, allowance_mm / 1000.0)
    return _pair_min_span(pair) <= allowance_m


def _split_overlap_pairs(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    key: str,
) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
    all_pairs = _overlap_pairs(metrics, key)
    hard_pairs: list[dict[str, Any]] = []
    allowed_joint_pairs: list[dict[str, Any]] = []

    for pair in all_pairs:
        if key == "slats_vs_frame" and _is_expected_slats_frame_joint_overlap(ir, pair):
            allowed_joint_pairs.append(pair)
            continue
        if key == "back_slats_vs_frame" and _is_expected_back_slats_frame_joint_overlap(ir, pair):
            allowed_joint_pairs.append(pair)
            continue
        hard_pairs.append(pair)

    return hard_pairs, allowed_joint_pairs


def _pairs_total_volume(pairs: list[dict[str, Any]]) -> float:
    total = 0.0
    for pair in pairs:
        total += _as_float(pair.get("volume", 0.0), 0.0)
    return float(total)


def _overlap_pairs_top(metrics: dict[str, Any], key: str, limit: int = 10) -> list[dict[str, Any]]:
    pairs = _overlap_pairs(metrics, key)
    return _pairs_top_from_list(pairs, limit=limit)


def _pairs_top_from_list(pairs: list[dict[str, Any]], limit: int = 10) -> list[dict[str, Any]]:
    typed_pairs = [pair for pair in pairs if isinstance(pair, dict)]

    def _pair_volume(pair: dict[str, Any]) -> float:
        return _as_float(pair.get("volume", 0.0), 0.0)

    sorted_pairs = sorted(typed_pairs, key=_pair_volume, reverse=True)[: max(0, int(limit))]
    result: list[dict[str, Any]] = []
    for pair in sorted_pairs:
        result.append(
            {
                "left": str(pair.get("left", "")),
                "right": str(pair.get("right", "")),
                "volume": float(_as_float(pair.get("volume", 0.0), 0.0)),
                "bbox_world": pair.get("bbox_world"),
            }
        )
    return result


def _offenders_from_pairs_top(pairs_top: list[dict[str, Any]]) -> list[dict[str, Any]]:
    names: set[str] = set()
    for pair in pairs_top:
        if not isinstance(pair, dict):
            continue
        left_name = str(pair.get("left", "")).strip()
        right_name = str(pair.get("right", "")).strip()
        if left_name:
            names.add(left_name)
        if right_name:
            names.add(right_name)
    return [{"name": name} for name in sorted(names)]


def _overlap_unique_counts(metrics: dict[str, Any], key: str) -> tuple[int, int]:
    pairs = _overlap_pairs(metrics, key)
    left_names = {str(pair.get("left", "")) for pair in pairs if str(pair.get("left", "")).strip()}
    right_names = {str(pair.get("right", "")) for pair in pairs if str(pair.get("right", "")).strip()}
    return len(left_names), len(right_names)


def _overlap_problem_details(metrics: dict[str, Any], key: str, total_volume: float, overlap_eps: float) -> dict[str, Any]:
    unique_left_count, unique_right_count = _overlap_unique_counts(metrics, key)
    pairs_top = _overlap_pairs_top(metrics, key, limit=10)
    return {
        "total_volume_m3": float(total_volume),
        "eps_m3": float(overlap_eps),
        "pairs_top": pairs_top,
        "offenders": _offenders_from_pairs_top(pairs_top),
        "unique_left_count": int(unique_left_count),
        "unique_right_count": int(unique_right_count),
    }


def _overlap_problem_details_from_pairs(
    metrics: dict[str, Any],
    key: str,
    *,
    overlap_eps: float,
    hard_pairs: list[dict[str, Any]],
    joint_pairs: list[dict[str, Any]],
) -> dict[str, Any]:
    hard_pairs_top = _pairs_top_from_list(hard_pairs, limit=10)
    joint_pairs_top = _pairs_top_from_list(joint_pairs, limit=10)
    offender_pairs_top = hard_pairs_top if hard_pairs_top else joint_pairs_top

    hard_left = {str(pair.get("left", "")) for pair in hard_pairs if str(pair.get("left", "")).strip()}
    hard_right = {str(pair.get("right", "")) for pair in hard_pairs if str(pair.get("right", "")).strip()}

    return {
        "total_volume_m3": float(_overlap_total(metrics, key)),
        "effective_total_volume_m3": float(_pairs_total_volume(hard_pairs)),
        "joint_only_volume_m3": float(_pairs_total_volume(joint_pairs)),
        "eps_m3": float(overlap_eps),
        "pairs_top": hard_pairs_top,
        "joint_pairs_top": joint_pairs_top,
        "offenders": _offenders_from_pairs_top(offender_pairs_top),
        "unique_left_count": int(len(hard_left)),
        "unique_right_count": int(len(hard_right)),
        "joint_pairs_count": int(len(joint_pairs)),
        "joint_allowance_mm": float(JOINT_OVERLAP_ALLOWANCE_MM),
    }


def _group_bbox_world(metrics: dict[str, Any], group_key: str) -> dict[str, Any] | None:
    groups = metrics.get("groups", {})
    if not isinstance(groups, dict):
        return None
    group_payload = groups.get(group_key, {})
    if not isinstance(group_payload, dict):
        return None
    bbox = group_payload.get("bbox_world")
    if not isinstance(bbox, dict):
        return None
    min_corner = bbox.get("min")
    max_corner = bbox.get("max")
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return None
    if len(min_corner) < 3 or len(max_corner) < 3:
        return None
    return bbox


def _z_clearance_between_bboxes(
    first_bbox: dict[str, Any] | None,
    second_bbox: dict[str, Any] | None,
) -> float | None:
    if not first_bbox or not second_bbox:
        return None
    first_min = _as_float(first_bbox.get("min", [0.0, 0.0, 0.0])[2], 0.0)
    first_max = _as_float(first_bbox.get("max", [0.0, 0.0, 0.0])[2], 0.0)
    second_min = _as_float(second_bbox.get("min", [0.0, 0.0, 0.0])[2], 0.0)
    second_max = _as_float(second_bbox.get("max", [0.0, 0.0, 0.0])[2], 0.0)

    if first_max < second_min:
        return float(second_min - first_max)
    if second_max < first_min:
        return float(first_min - second_max)
    return 0.0


def _problem(code: str, severity: int, message: str, details: dict[str, Any]) -> dict[str, Any]:
    return {
        "code": code,
        "severity": int(severity),
        "message": message,
        "details": details,
    }


def _should_check_slats_overlap(ir: dict[str, Any], metrics: dict[str, Any]) -> bool:
    slats = ir.get("slats", {})
    if isinstance(slats, dict) and "enabled" in slats:
        return bool(slats.get("enabled", False))
    return _group_count(metrics, "slat_") > 0


def _should_check_back_slats_overlap(ir: dict[str, Any], metrics: dict[str, Any]) -> bool:
    back_support = ir.get("back_support", {})
    if isinstance(back_support, dict) and "mode" in back_support:
        return str(back_support.get("mode", "")).strip().lower() == "slats"
    return _group_count(metrics, "back_slat_") > 0


def _normalize_modifier_key(key: Any) -> str:
    raw = str(key).strip().upper()
    if not raw:
        return ""
    raw = raw.replace(" ", "")
    if ":" in raw:
        left, right = raw.split(":", 1)
        if right:
            return f"{left}:{right}"
        return left
    return raw


def _expected_modifiers_map(ir: dict[str, Any]) -> dict[str, list[str]]:
    debug_payload = ir.get("debug", {})
    if not isinstance(debug_payload, dict):
        return {}
    expected_payload = debug_payload.get("expect_modifiers", {})
    if not isinstance(expected_payload, dict):
        return {}

    result: dict[str, list[str]] = {}
    for group_key, expected in expected_payload.items():
        if not isinstance(expected, list):
            continue
        normalized: list[str] = []
        for item in expected:
            key = _normalize_modifier_key(item)
            if key and key not in normalized:
                normalized.append(key)
        if normalized:
            result[str(group_key)] = normalized
    return result


def _modifier_key_from_payload(modifier: dict[str, Any]) -> str:
    mod_type = _normalize_modifier_key(modifier.get("type", ""))
    if mod_type != "SIMPLE_DEFORM":
        return mod_type
    deform_method = _normalize_modifier_key(modifier.get("deform_method", ""))
    if deform_method:
        return f"SIMPLE_DEFORM:{deform_method}"
    return "SIMPLE_DEFORM"


def _object_modifier_keys(obj: dict[str, Any]) -> set[str]:
    keys: set[str] = set()
    raw_keys = obj.get("modifier_keys", [])
    if isinstance(raw_keys, list):
        for item in raw_keys:
            key = _normalize_modifier_key(item)
            if key:
                keys.add(key)

    if keys:
        return keys

    modifiers = obj.get("modifiers", [])
    if not isinstance(modifiers, list):
        return keys
    for modifier in modifiers:
        if not isinstance(modifier, dict):
            continue
        key = _modifier_key_from_payload(modifier)
        if key:
            keys.add(key)
    return keys


def _has_expected_modifier(present_keys: set[str], expected_key: str) -> bool:
    normalized_expected = _normalize_modifier_key(expected_key)
    if not normalized_expected:
        return False
    if normalized_expected in present_keys:
        return True

    if ":" in normalized_expected:
        mod_type = normalized_expected.split(":", 1)[0]
        return mod_type in present_keys

    prefix = f"{normalized_expected}:"
    if normalized_expected in present_keys:
        return True
    return any(key.startswith(prefix) for key in present_keys)


def _object_counts(obj: dict[str, Any]) -> tuple[int, int | None, int, int | None]:
    verts = _as_int(obj.get("verts", 0), 0)
    polys = _as_int(obj.get("polys", 0), 0)

    verts_base_raw = obj.get("verts_base")
    verts_base = _as_int(verts_base_raw, 0) if isinstance(verts_base_raw, (int, float)) else None
    polys_base_raw = obj.get("polys_base")
    polys_base = _as_int(polys_base_raw, 0) if isinstance(polys_base_raw, (int, float)) else None
    return verts, verts_base, polys, polys_base


def _verts_delta_abs(obj: dict[str, Any]) -> int | None:
    verts, verts_base, _, _ = _object_counts(obj)
    if verts_base is None:
        return None
    return abs(int(verts - verts_base))


def _modifier_no_effect_for_object(
    obj: dict[str, Any],
    expected_modifier: str,
    *,
    eps_m: float,
    verts_eps: int,
) -> tuple[bool, int, str, float]:
    mod_key = _normalize_modifier_key(expected_modifier)
    mod_type = mod_key.split(":", 1)[0]
    max_delta = _max_bbox_delta_abs(obj)
    verts_delta = _verts_delta_abs(obj)
    has_geom_delta = max_delta >= eps_m
    has_verts_delta = (verts_delta is not None) and (verts_delta > int(verts_eps))

    if mod_key == "SIMPLE_DEFORM:BEND":
        has_bend_mod, bend_angle = _bend_mod_summary(obj)
        if has_geom_delta or (has_bend_mod and bend_angle > BEND_MOD_ANGLE_EPS):
            return False, 0, "", float(bend_angle)
        if bend_angle > BEND_MOD_ANGLE_EPS:
            return False, 0, "", float(bend_angle)
        return True, 2, "bbox_delta too small", float(bend_angle)

    if mod_type == "ARRAY":
        if has_geom_delta or has_verts_delta:
            return False, 0, "", 0.0
        if verts_delta is None:
            return True, 2, "bbox_delta too small", 0.0
        return True, 2, "bbox_delta and verts delta too small", 0.0

    if mod_type == "MIRROR":
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if verts_delta > int(verts_eps):
            return False, 0, "", 0.0
        return True, 2, "verts did not increase versus base mesh", 0.0

    if mod_type == "SOLIDIFY":
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if (max_delta < eps_m) and (verts_delta <= int(verts_eps)):
            return True, 2, "bbox_delta and verts delta too small", 0.0
        return False, 0, "", 0.0

    warn_types = {"BEVEL", "SUBSURF", "WEIGHTED_NORMAL", "BOOLEAN", "SHRINKWRAP", "CURVE", "LATTICE"}
    if mod_type in warn_types:
        if verts_delta is None:
            return False, 0, "verts_base unavailable", 0.0
        if (max_delta < eps_m) and (verts_delta <= int(verts_eps)):
            return True, 1, "bbox_delta and verts delta too small", 0.0
        return False, 0, "", 0.0

    if has_geom_delta or has_verts_delta:
        return False, 0, "", 0.0
    return True, 1, "bbox_delta and verts delta too small", 0.0


def _validate_modifier_expectation_missing(ir: dict[str, Any], metrics: dict[str, Any]) -> list[dict[str, Any]]:
    expected_map = _expected_modifiers_map(ir)
    if not expected_map:
        return []

    problems: list[dict[str, Any]] = []
    for group_key, expected in expected_map.items():
        objects = _mesh_objects_by_prefix(metrics, group_key)
        if not objects:
            continue

        missing_by_object: list[dict[str, Any]] = []
        for obj in objects:
            present_keys = _object_modifier_keys(obj)
            missing = [key for key in expected if not _has_expected_modifier(present_keys, key)]
            if missing:
                missing_by_object.append(
                    {
                        "name": str(obj.get("name", "")),
                        "missing": missing,
                    }
                )

        if not missing_by_object:
            continue

        problems.append(
            _problem(
                code="MOD_EXPECTATION_MISSING",
                severity=2,
                message=f"Expected modifiers are missing for group '{group_key}'.",
                details={
                    "group_key": group_key,
                    "expected": expected,
                    "missing_by_object": missing_by_object,
                    "counts": {
                        "objects": len(objects),
                        "objects_with_missing": len(missing_by_object),
                    },
                },
            )
        )
    return problems


def _validate_modifier_expectation_no_effect(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    *,
    effect_eps_m: float,
    effect_verts_eps: int,
) -> list[dict[str, Any]]:
    expected_map = _expected_modifiers_map(ir)
    if not expected_map:
        return []

    problems: list[dict[str, Any]] = []
    for group_key, expected in expected_map.items():
        objects = _mesh_objects_by_prefix(metrics, group_key)
        for obj in objects:
            present_keys = _object_modifier_keys(obj)
            if not present_keys:
                continue

            for expected_key in expected:
                if not _has_expected_modifier(present_keys, expected_key):
                    continue

                no_effect, severity, reason, bend_angle = _modifier_no_effect_for_object(
                    obj,
                    expected_modifier=expected_key,
                    eps_m=effect_eps_m,
                    verts_eps=effect_verts_eps,
                )
                if not no_effect or severity <= 0:
                    continue

                verts, verts_base, polys, polys_base = _object_counts(obj)
                details: dict[str, Any] = {
                    "group_key": group_key,
                    "name": str(obj.get("name", "")),
                    "modifier": _normalize_modifier_key(expected_key),
                    "reason": reason,
                    "bbox_delta": _bbox_delta_xyz(obj),
                    "verts": int(verts),
                    "verts_base": verts_base,
                    "polys": int(polys),
                    "polys_base": polys_base,
                    "eps_m": float(effect_eps_m),
                    "verts_eps": int(effect_verts_eps),
                }
                if _normalize_modifier_key(expected_key) == "SIMPLE_DEFORM:BEND":
                    details["bend_angle"] = float(bend_angle)

                problems.append(
                    _problem(
                        code="MOD_EXPECTATION_NO_EFFECT",
                        severity=int(severity),
                        message=f"Modifier {_normalize_modifier_key(expected_key)} has no observable effect.",
                        details=details,
                    )
                )
    return problems


def _validate_slats_not_bent(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    bend_eps_m: float,
) -> list[dict[str, Any]]:
    slats = ir.get("slats", {})
    if not isinstance(slats, dict):
        return []
    if not bool(slats.get("enabled", False)):
        return []
    if _as_float(slats.get("arc_height_mm", 0.0), 0.0) <= 0.0:
        return []

    stats = _bent_stats_for_prefix(metrics, "slat_", bend_eps_m=bend_eps_m)
    if int(stats.get("count_bent", 0)) > 0:
        return []

    details = {
        "count_total": int(stats.get("count_total", 0)),
        "count_bent": int(stats.get("count_bent", 0)),
        "eps_m": float(stats.get("eps_m", bend_eps_m)),
        "top5": stats.get("top5", []),
    }
    if int(stats.get("count_total", 0)) == 0:
        details["note"] = "no objects found"

    return [
        _problem(
            code="SLATS_NOT_BENT",
            severity=2,
            message="Seat slats are expected to be bent but bend evidence is missing.",
            details=details,
        )
    ]


def _validate_back_slats_not_bent(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    bend_eps_m: float,
) -> list[dict[str, Any]]:
    back_support = ir.get("back_support", {})
    if not isinstance(back_support, dict):
        return []
    mode = str(back_support.get("mode", "")).strip().lower()
    if mode != "slats":
        return []
    back_slats = back_support.get("slats", {})
    if not isinstance(back_slats, dict):
        return []
    if _as_float(back_slats.get("arc_height_mm", 0.0), 0.0) <= 0.0:
        return []

    stats = _bent_stats_for_prefix(metrics, "back_slat_", bend_eps_m=bend_eps_m)
    if int(stats.get("count_bent", 0)) > 0:
        return []

    details = {
        "count_total": int(stats.get("count_total", 0)),
        "count_bent": int(stats.get("count_bent", 0)),
        "eps_m": float(stats.get("eps_m", bend_eps_m)),
        "top5": stats.get("top5", []),
    }
    if int(stats.get("count_total", 0)) == 0:
        details["note"] = "no objects found"

    return [
        _problem(
            code="BACK_SLATS_NOT_BENT",
            severity=2,
            message="Back slats are expected to be bent but bend evidence is missing.",
            details=details,
        )
    ]


def _validate_overlap_slats_frame(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_slats_overlap(ir, metrics):
        return []

    hard_pairs, joint_pairs = _split_overlap_pairs(ir, metrics, "slats_vs_frame")
    effective_volume = _pairs_total_volume(hard_pairs)
    total_volume = _overlap_total(metrics, "slats_vs_frame")

    if effective_volume <= overlap_eps:
        if total_volume <= overlap_eps or len(joint_pairs) == 0:
            return []
        details = _overlap_problem_details_from_pairs(
            metrics,
            "slats_vs_frame",
            overlap_eps=overlap_eps,
            hard_pairs=hard_pairs,
            joint_pairs=joint_pairs,
        )
        return [
            _problem(
                code="OVERLAP_SLATS_FRAME",
                severity=1,
                message="Seat slats have only expected joint-contact overlaps with frame.",
                details=details,
            )
        ]

    details = _overlap_problem_details_from_pairs(
        metrics,
        "slats_vs_frame",
        overlap_eps=overlap_eps,
        hard_pairs=hard_pairs,
        joint_pairs=joint_pairs,
    )
    if details.get("unique_left_count", 0) == 0:
        unique_left_count, unique_right_count = _overlap_unique_counts(metrics, "slats_vs_frame")
        details["unique_left_count"] = int(unique_left_count)
        details["unique_right_count"] = int(unique_right_count)

    return [
        _problem(
            code="OVERLAP_SLATS_FRAME",
            severity=2,
            message="Seat slats overlap frame geometry.",
            details=details,
        )
    ]


def _validate_overlap_slats_arms(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_slats_overlap(ir, metrics):
        return []
    volume = _overlap_total(metrics, "slats_vs_arms")
    if volume <= overlap_eps:
        return []

    return [
        _problem(
            code="OVERLAP_SLATS_ARMS",
            severity=2,
            message="Seat slats overlap arm geometry.",
            details=_overlap_problem_details(metrics, "slats_vs_arms", volume, overlap_eps),
        )
    ]


def _validate_overlap_back_slats_frame(ir: dict[str, Any], metrics: dict[str, Any], overlap_eps: float) -> list[dict[str, Any]]:
    if not _should_check_back_slats_overlap(ir, metrics):
        return []

    hard_pairs, joint_pairs = _split_overlap_pairs(ir, metrics, "back_slats_vs_frame")
    effective_volume = _pairs_total_volume(hard_pairs)
    total_volume = _overlap_total(metrics, "back_slats_vs_frame")

    if effective_volume <= overlap_eps:
        if total_volume <= overlap_eps or len(joint_pairs) == 0:
            return []
        details = _overlap_problem_details_from_pairs(
            metrics,
            "back_slats_vs_frame",
            overlap_eps=overlap_eps,
            hard_pairs=hard_pairs,
            joint_pairs=joint_pairs,
        )
        return [
            _problem(
                code="OVERLAP_BACK_SLATS_FRAME",
                severity=1,
                message="Back slats have only expected joint-contact overlaps with frame.",
                details=details,
            )
        ]

    details = _overlap_problem_details_from_pairs(
        metrics,
        "back_slats_vs_frame",
        overlap_eps=overlap_eps,
        hard_pairs=hard_pairs,
        joint_pairs=joint_pairs,
    )
    if details.get("unique_left_count", 0) == 0:
        unique_left_count, unique_right_count = _overlap_unique_counts(metrics, "back_slats_vs_frame")
        details["unique_left_count"] = int(unique_left_count)
        details["unique_right_count"] = int(unique_right_count)

    return [
        _problem(
            code="OVERLAP_BACK_SLATS_FRAME",
            severity=2,
            message="Back slats overlap frame geometry.",
            details=details,
        )
    ]


def _validate_low_clearance_slats_frame(metrics: dict[str, Any], clearance_eps: float) -> list[dict[str, Any]]:
    overlap_volume = _overlap_total(metrics, "slats_vs_frame")
    if overlap_volume > 0.0:
        return []

    slat_bbox = _group_bbox_world(metrics, "slat_")
    frame_bbox = _group_bbox_world(metrics, "frame_")
    min_clearance_z = _z_clearance_between_bboxes(slat_bbox, frame_bbox)
    if min_clearance_z is None:
        return []
    if min_clearance_z >= clearance_eps:
        return []

    return [
        _problem(
            code="LOW_CLEARANCE_SLATS_FRAME",
            severity=1,
            message="Seat slats and frame have very low Z clearance.",
            details={
                "min_clearance_z_m": float(min_clearance_z),
                "eps_m": float(clearance_eps),
            },
        )
    ]


def validate(
    ir: dict[str, Any],
    metrics: dict[str, Any],
    overlap_eps: float = DEFAULT_OVERLAP_EPS,
    bend_delta_eps: float | None = None,
    clearance_eps_m: float | None = None,
) -> dict[str, Any]:
    """Validate IR against metrics and return score payload."""
    ir, metrics = _normalize_validate_args(ir, metrics)
    overlap_eps = float(_read_env_float("DEBUG_OVERLAP_EPS_M3", overlap_eps))
    bent_eps = float(BEND_EPS_M if bend_delta_eps is None else bend_delta_eps)
    clearance_eps = float(CLEARANCE_EPS_M if clearance_eps_m is None else clearance_eps_m)
    mod_effect_eps_m = float(_read_env_float("DEBUG_MOD_EFFECT_EPS_M", MOD_EFFECT_EPS_M))
    mod_effect_verts_eps = int(_read_env_int("DEBUG_MOD_EFFECT_VERTS_EPS", MOD_EFFECT_VERTS_EPS))

    problems: list[dict[str, Any]] = []
    problems.extend(_validate_modifier_expectation_missing(ir, metrics))
    problems.extend(
        _validate_modifier_expectation_no_effect(
            ir,
            metrics,
            effect_eps_m=mod_effect_eps_m,
            effect_verts_eps=mod_effect_verts_eps,
        )
    )
    problems.extend(_validate_slats_not_bent(ir, metrics, bend_eps_m=bent_eps))
    problems.extend(_validate_back_slats_not_bent(ir, metrics, bend_eps_m=bent_eps))
    problems.extend(_validate_overlap_slats_frame(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_overlap_slats_arms(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_overlap_back_slats_frame(ir, metrics, overlap_eps=overlap_eps))
    problems.extend(_validate_low_clearance_slats_frame(metrics, clearance_eps=clearance_eps))

    def _severity_weight(severity: int) -> float:
        if severity >= 3:
            return 0.30
        if severity == 2:
            return 0.10
        if severity == 1:
            return 0.02
        return 0.0

    severity_sum = sum(_as_int(problem.get("severity", 0), 0) for problem in problems)
    severity_max = max((_as_int(problem.get("severity", 0), 0) for problem in problems), default=0)
    penalty = min(1.0, sum(_severity_weight(_as_int(problem.get("severity", 0), 0)) for problem in problems))
    score = max(0.0, 1.0 - penalty)

    return {
        "score": float(round(score, 6)),
        "problems": problems,
        "problem_count": len(problems),
        "severity_max": int(severity_max),
        "penalty": float(round(penalty, 6)),
    }


def _load_json_object(path: str) -> dict[str, Any]:
    with open(path, "r", encoding="utf-8") as handle:
        payload = json.load(handle)
    if not isinstance(payload, dict):
        raise ValueError(f"Expected JSON object in {path}, got {type(payload).__name__}")
    return payload


def _resolve_input_path(base_path: str, candidate: str) -> str:
    if not candidate:
        return ""
    if os.path.isabs(candidate):
        return candidate
    return os.path.abspath(os.path.join(os.path.dirname(base_path), candidate))


def _infer_payload_kind(payload: dict[str, Any]) -> tuple[str, str]:
    kind_raw = str(payload.get("kind", "")).strip().lower()
    if kind_raw == "run":
        return "run", "kind_run"
    if kind_raw == "metrics":
        return "metrics", "kind_metrics"

    if (
        "validation" in payload
        or "patches_applied" in payload
        or "ir_in_path" in payload
        or ("metrics" in payload and ("status" in payload or "run_id" in payload))
    ):
        return "run", "heuristic_run"

    if (
        "validation" not in payload
        and "objects" in payload
        and "groups" in payload
        and "overlaps" in payload
    ):
        return "metrics", "heuristic_metrics"

    return "metrics", "heuristic_fallback_metrics"


def _extract_metrics_from_metrics_payload(payload: dict[str, Any]) -> dict[str, Any]:
    nested_metrics = payload.get("metrics")
    if isinstance(nested_metrics, dict) and not _looks_like_metrics(payload):
        return nested_metrics
    return payload


def _extract_ir_from_payload(payload: dict[str, Any]) -> dict[str, Any]:
    embedded_ir = payload.get("ir")
    if isinstance(embedded_ir, dict):
        return embedded_ir
    kind, _ = _infer_payload_kind(payload)
    if kind == "run":
        return {}
    return payload


def load_debug_payload(path: str) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any]]:
    """Load debug input payload and return (ir, metrics, meta)."""
    input_path = os.path.abspath(path)
    payload = _load_json_object(input_path)
    kind, payload_format = _infer_payload_kind(payload)

    meta: dict[str, Any] = {
        "kind": kind,
        "format": payload_format,
        "input_path": input_path,
        "metrics_source": "none",
        "ir_source": "none",
        "metrics_error": None,
    }

    metrics_payload: dict[str, Any] = {}
    ir_payload: dict[str, Any] = {}

    if kind == "run":
        embedded_metrics = payload.get("metrics")
        if isinstance(embedded_metrics, dict):
            metrics_payload = embedded_metrics
            meta["metrics_source"] = "embedded"
        else:
            metrics_path_raw = str(payload.get("metrics_path", "")).strip()
            if metrics_path_raw:
                metrics_path = _resolve_input_path(input_path, metrics_path_raw)
                try:
                    loaded_metrics_payload = _load_json_object(metrics_path)
                    metrics_payload = _extract_metrics_from_metrics_payload(loaded_metrics_payload)
                    meta["metrics_source"] = "metrics_path"
                    meta["metrics_path"] = metrics_path
                except Exception as exc:
                    meta["metrics_error"] = f"failed to load metrics_path: {exc}"
            else:
                meta["metrics_error"] = "run payload has no embedded metrics and no metrics_path"

        env_ir_path = str(os.getenv("DEBUG_IR_JSON", "")).strip()
        if env_ir_path:
            loaded_ir_payload = _load_json_object(env_ir_path)
            ir_payload = _extract_ir_from_payload(loaded_ir_payload)
            meta["ir_source"] = "env_debug_ir_json"
        elif isinstance(payload.get("ir"), dict):
            ir_payload = payload["ir"]
            meta["ir_source"] = "embedded_ir"
        else:
            ir_in_path_raw = str(payload.get("ir_in_path", "")).strip()
            if ir_in_path_raw:
                ir_in_path = _resolve_input_path(input_path, ir_in_path_raw)
                if os.path.exists(ir_in_path):
                    try:
                        ir_payload = _load_json_object(ir_in_path)
                        meta["ir_source"] = "ir_in_path"
                        meta["ir_in_path"] = ir_in_path
                    except Exception:
                        ir_payload = {}
                        meta["ir_source"] = "ir_in_path_unreadable"
    else:
        metrics_payload = _extract_metrics_from_metrics_payload(payload)
        meta["metrics_source"] = "input_file"

        env_ir_path = str(os.getenv("DEBUG_IR_JSON", "")).strip()
        if env_ir_path:
            loaded_ir_payload = _load_json_object(env_ir_path)
            ir_payload = _extract_ir_from_payload(loaded_ir_payload)
            meta["ir_source"] = "env_debug_ir_json"

    return ir_payload, metrics_payload, meta


def _self_check_joint_only_overlap_payload() -> tuple[dict[str, Any], dict[str, Any]]:
    ir_payload: dict[str, Any] = {
        "back_support": {
            "mode": "slats",
            "thickness_mm": 60.0,
        },
        "frame": {
            "thickness_mm": 58.0,
        },
    }
    metrics_payload: dict[str, Any] = {
        "kind": "metrics",
        "groups": {
            "back_slat_": {"count": 1},
            "frame_": {"count": 1},
        },
        "overlaps": {
            "back_slats_vs_frame": {
                "total_volume": 3.2e-5,
                "pairs": [
                    {
                        "left": "back_slat_1",
                        "right": "back_rail_left",
                        "volume": 3.2e-5,
                        "bbox_world": {
                            "min": [0.0, 0.0, 0.0],
                            "max": [0.0015, 0.0010, 0.0040],
                        },
                    }
                ],
            },
            "slats_vs_frame": {"total_volume": 0.0, "pairs": []},
            "slats_vs_arms": {"total_volume": 0.0, "pairs": []},
        },
    }
    return ir_payload, metrics_payload


if __name__ == "__main__":
    input_path = str(os.getenv("DEBUG_INPUT_JSON", "")).strip()
    if not input_path:
        input_path = str(os.getenv("DEBUG_METRICS_JSON", "")).strip()

    if not input_path:
        print("validators: running built-in joint-only overlap self-check", file=sys.stderr)
        ir_payload, metrics_payload = _self_check_joint_only_overlap_payload()
        result = validate(ir_payload, metrics_payload)
        print(json.dumps(result, ensure_ascii=False, indent=2))

        joint_top_found = False
        joint_top_len = 0
        hard_top_len = 0
        offenders_len = 0
        problems = result.get("problems", [])
        if isinstance(problems, list):
            for problem in problems:
                if not isinstance(problem, dict):
                    continue
                code = str(problem.get("code", "")).strip().upper()
                if code != "OVERLAP_BACK_SLATS_FRAME":
                    continue
                details = problem.get("details", {})
                if not isinstance(details, dict):
                    continue
                joint_pairs_top = details.get("joint_pairs_top", [])
                pairs_top = details.get("pairs_top", [])
                offenders = details.get("offenders", [])
                joint_top_found = isinstance(joint_pairs_top, list) and len(joint_pairs_top) > 0
                joint_top_len = len(joint_pairs_top) if isinstance(joint_pairs_top, list) else 0
                hard_top_len = len(pairs_top) if isinstance(pairs_top, list) else 0
                offenders_len = len(offenders) if isinstance(offenders, list) else 0
                break
        print(
            f"validators: self_check joint_pairs_top_found={joint_top_found} "
            f"joint_pairs_top_len={joint_top_len} hard_pairs_top_len={hard_top_len} "
            f"offenders_len={offenders_len}",
            file=sys.stderr,
        )
        raise SystemExit(0)

    try:
        ir_payload, metrics_payload, meta = load_debug_payload(input_path)
    except Exception as exc:
        print(f"validators: failed to load input: {exc}", file=sys.stderr)
        raise SystemExit(2)

    print(
        f"validators: loaded input kind={meta.get('kind')} format={meta.get('format')}",
        file=sys.stderr,
    )

    if meta.get("kind") == "run" and (not _looks_like_metrics(metrics_payload)):
        error_text = str(meta.get("metrics_error") or "run input metrics not found or unreadable")
        print(f"validators: {error_text}", file=sys.stderr)
        raise SystemExit(2)

    result = validate(ir_payload, metrics_payload)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print(
        f"validators: kind={meta.get('kind')} problems={int(result.get('problem_count', 0))}",
        file=sys.stderr,
    )



===== FILE: tools/blender/debug/visualize.py =====
"""Blender-only visualization helpers for debug overlap offenders."""

from __future__ import annotations

import os
from typing import Any


TARGET_GROUPS = ("frame_", "slat_", "back_slat_", "arm_", "leg_")


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _valid_bbox(bbox: Any) -> bool:
    if not isinstance(bbox, dict):
        return False
    min_corner = bbox.get("min")
    max_corner = bbox.get("max")
    if not isinstance(min_corner, list) or not isinstance(max_corner, list):
        return False
    return len(min_corner) >= 3 and len(max_corner) >= 3


def _bbox_union(a: dict[str, list[float]] | None, b: dict[str, list[float]] | None) -> dict[str, list[float]] | None:
    if not a:
        return b
    if not b:
        return a
    return {
        "min": [
            min(_safe_float(a["min"][0]), _safe_float(b["min"][0])),
            min(_safe_float(a["min"][1]), _safe_float(b["min"][1])),
            min(_safe_float(a["min"][2]), _safe_float(b["min"][2])),
        ],
        "max": [
            max(_safe_float(a["max"][0]), _safe_float(b["max"][0])),
            max(_safe_float(a["max"][1]), _safe_float(b["max"][1])),
            max(_safe_float(a["max"][2]), _safe_float(b["max"][2])),
        ],
    }


def _scene_bbox_from_metrics(metrics: dict[str, Any] | None) -> dict[str, list[float]] | None:
    if not isinstance(metrics, dict):
        return None

    groups = metrics.get("groups", {})
    bbox: dict[str, list[float]] | None = None
    if isinstance(groups, dict):
        for group_key in TARGET_GROUPS:
            payload = groups.get(group_key, {})
            if not isinstance(payload, dict):
                continue
            group_bbox = payload.get("bbox_world")
            if _valid_bbox(group_bbox):
                bbox = _bbox_union(bbox, group_bbox)

    if bbox:
        return bbox

    objects = metrics.get("objects", [])
    if not isinstance(objects, list):
        return None
    for obj in objects:
        if not isinstance(obj, dict):
            continue
        if str(obj.get("type", "")).upper() != "MESH":
            continue
        obj_bbox = obj.get("bbox_world")
        if _valid_bbox(obj_bbox):
            bbox = _bbox_union(bbox, obj_bbox)
    return bbox


def _material(name: str, rgba: tuple[float, float, float, float]) -> Any:
    import bpy  # type: ignore

    mat = bpy.data.materials.get(name)
    if mat is None:
        mat = bpy.data.materials.new(name=name)

    if hasattr(mat, "use_nodes"):
        mat.use_nodes = True
        node_tree = getattr(mat, "node_tree", None)
        if node_tree and node_tree.nodes:
            principled = node_tree.nodes.get("Principled BSDF")
            if principled is not None:
                principled.inputs[0].default_value = rgba
                principled.inputs[7].default_value = 0.35

    if hasattr(mat, "diffuse_color"):
        mat.diffuse_color = rgba
    return mat


def _details(problem: dict[str, Any]) -> dict[str, Any]:
    details = problem.get("details", {})
    if isinstance(details, dict):
        return details
    return {}


def _add_name(target: set[str], value: Any) -> None:
    name = str(value).strip()
    if name:
        target.add(name)


def _names_from_pairs_field(details: dict[str, Any], field_name: str) -> set[str]:
    names: set[str] = set()
    pairs = details.get(field_name, [])
    if not isinstance(pairs, list):
        return names
    for pair in pairs:
        if not isinstance(pair, dict):
            continue
        _add_name(names, pair.get("left", ""))
        _add_name(names, pair.get("right", ""))
    return names


def _names_from_pairs_top(details: dict[str, Any]) -> set[str]:
    return _names_from_pairs_field(details, "pairs_top")


def _names_from_joint_pairs_top(details: dict[str, Any]) -> set[str]:
    return _names_from_pairs_field(details, "joint_pairs_top")


def _names_from_offenders(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    offenders = details.get("offenders")
    if isinstance(offenders, dict):
        _add_name(names, offenders.get("name", ""))
        _add_name(names, offenders.get("left", ""))
        _add_name(names, offenders.get("right", ""))
        return names
    if not isinstance(offenders, list):
        return names
    for item in offenders:
        if isinstance(item, dict):
            _add_name(names, item.get("name", ""))
            _add_name(names, item.get("left", ""))
            _add_name(names, item.get("right", ""))
        else:
            _add_name(names, item)
    return names


def _names_from_top_offender_pair(metrics: dict[str, Any] | None) -> set[str]:
    names: set[str] = set()
    if not isinstance(metrics, dict):
        return names
    pair = metrics.get("top_offender_pair")
    if not isinstance(pair, dict):
        return names
    _add_name(names, pair.get("left", ""))
    _add_name(names, pair.get("right", ""))
    return names


def _names_from_top5(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    top5 = details.get("top5", [])
    if not isinstance(top5, list):
        return names
    for item in top5:
        if not isinstance(item, dict):
            continue
        _add_name(names, item.get("name", ""))
    return names


def _names_from_missing_details(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    missing_by_object = details.get("missing_by_object", [])
    if isinstance(missing_by_object, list):
        for item in missing_by_object:
            if not isinstance(item, dict):
                continue
            _add_name(names, item.get("name", ""))
    elif isinstance(missing_by_object, dict):
        for key in missing_by_object.keys():
            _add_name(names, key)
    return names


def _names_from_no_effect_details(details: dict[str, Any]) -> set[str]:
    names: set[str] = set()
    _add_name(names, details.get("name", ""))

    by_object = details.get("by_object")
    if isinstance(by_object, list):
        for item in by_object:
            if not isinstance(item, dict):
                continue
            _add_name(names, item.get("name", ""))
    elif isinstance(by_object, dict):
        for key in by_object.keys():
            _add_name(names, key)

    offenders = details.get("offenders")
    if isinstance(offenders, list):
        for item in offenders:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)

    top = details.get("top")
    if isinstance(top, list):
        for item in top:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)

    top5 = details.get("top5")
    if isinstance(top5, list):
        for item in top5:
            if isinstance(item, dict):
                _add_name(names, item.get("name", ""))
            else:
                _add_name(names, item)
    return names


def _collect_offenders_by_priority(
    validation: dict[str, Any],
    metrics: dict[str, Any] | None = None,
) -> tuple[set[str], set[str], set[str], set[str], set[str], set[str]]:
    red: set[str] = set()
    blue: set[str] = set()
    orange: set[str] = set()
    offender_codes: set[str] = set()
    hard_overlap_offenders: set[str] = set()
    joint_overlap_offenders: set[str] = set()

    problems = validation.get("problems", [])
    if not isinstance(problems, list):
        return red, blue, orange, offender_codes, hard_overlap_offenders, joint_overlap_offenders

    for problem in problems:
        if not isinstance(problem, dict):
            continue
        code = str(problem.get("code", "")).strip().upper()
        details = _details(problem)

        names: set[str] = set()
        if code.startswith("OVERLAP_"):
            hard_names = _names_from_pairs_top(details)
            offender_names = _names_from_offenders(details)
            joint_names = _names_from_joint_pairs_top(details)
            if hard_names:
                names = hard_names
                hard_overlap_offenders.update(hard_names)
            elif offender_names:
                names = offender_names
                if joint_names and not hard_names:
                    joint_overlap_offenders.update(offender_names)
                else:
                    hard_overlap_offenders.update(offender_names)
            elif joint_names:
                names = joint_names
                joint_overlap_offenders.update(joint_names)
            else:
                fallback_names = _names_from_top_offender_pair(metrics)
                if fallback_names:
                    names = fallback_names
                    hard_overlap_offenders.update(fallback_names)
            red.update(names)
        elif code in {"SLATS_NOT_BENT", "BACK_SLATS_NOT_BENT"}:
            names = _names_from_top5(details)
            blue.update(names)
        elif code == "MOD_EXPECTATION_MISSING":
            names = _names_from_missing_details(details)
            blue.update(names)
        elif code == "MOD_EXPECTATION_NO_EFFECT":
            names = _names_from_no_effect_details(details)
            orange.update(names)

        if names:
            offender_codes.add(code)

    return red, blue, orange, offender_codes, hard_overlap_offenders, joint_overlap_offenders


def _look_at_rotation(camera_obj: Any, target_xyz: tuple[float, float, float]) -> None:
    from mathutils import Vector  # type: ignore

    target_vec = Vector((target_xyz[0], target_xyz[1], target_xyz[2]))
    direction = target_vec - camera_obj.location
    if direction.length <= 1e-9:
        return
    camera_obj.rotation_euler = direction.to_track_quat("-Z", "Y").to_euler()


def _ensure_camera_and_light(
    scene_bbox: dict[str, list[float]] | None,
    lens_mm: float = 50.0,
) -> tuple[Any, Any]:
    import bpy  # type: ignore

    center_x = 0.0
    center_y = 0.0
    center_z = 0.0
    extent_x = 2.0
    extent_y = 2.0
    extent_z = 1.5
    if scene_bbox:
        min_corner = scene_bbox["min"]
        max_corner = scene_bbox["max"]
        center_x = 0.5 * (_safe_float(min_corner[0]) + _safe_float(max_corner[0]))
        center_y = 0.5 * (_safe_float(min_corner[1]) + _safe_float(max_corner[1]))
        center_z = 0.5 * (_safe_float(min_corner[2]) + _safe_float(max_corner[2]))
        extent_x = max(0.1, _safe_float(max_corner[0]) - _safe_float(min_corner[0]))
        extent_y = max(0.1, _safe_float(max_corner[1]) - _safe_float(min_corner[1]))
        extent_z = max(0.1, _safe_float(max_corner[2]) - _safe_float(min_corner[2]))

    extent = max(extent_x, extent_y, extent_z)
    cam_distance = max(2.5, extent * 2.4)

    camera_obj = bpy.data.objects.get("DEBUG_CAMERA")
    if camera_obj is None:
        camera_data = bpy.data.cameras.new(name="DEBUG_CAMERA")
        camera_obj = bpy.data.objects.new("DEBUG_CAMERA", camera_data)
        bpy.context.scene.collection.objects.link(camera_obj)
    if getattr(camera_obj, "data", None) is not None:
        camera_obj.data.lens = float(lens_mm)
        camera_obj.data.clip_end = max(200.0, cam_distance * 20.0)

    camera_obj.location.x = center_x + cam_distance
    camera_obj.location.y = center_y - cam_distance
    camera_obj.location.z = center_z + cam_distance * 0.75
    _look_at_rotation(camera_obj, (center_x, center_y, center_z))
    bpy.context.scene.camera = camera_obj

    light_obj = bpy.data.objects.get("DEBUG_LIGHT")
    if light_obj is None:
        light_data = bpy.data.lights.new(name="DEBUG_LIGHT", type="SUN")
        light_obj = bpy.data.objects.new(name="DEBUG_LIGHT", object_data=light_data)
        bpy.context.scene.collection.objects.link(light_obj)
    if getattr(light_obj, "data", None) is not None:
        light_obj.data.energy = 3.0

    light_obj.location.x = center_x + cam_distance * 0.4
    light_obj.location.y = center_y - cam_distance * 0.2
    light_obj.location.z = center_z + cam_distance * 1.2
    _look_at_rotation(light_obj, (center_x, center_y, center_z))
    return camera_obj, light_obj


def apply_debug_visualization(
    validation: dict[str, Any],
    metrics: dict[str, Any] | None = None,
    snapshot_blend_path: str | None = None,
    snapshot_png_path: str | None = None,
    camera_lens_mm: float = 50.0,
) -> dict[str, Any]:
    """Highlight offenders and optionally save .blend and PNG snapshots."""
    try:
        import bpy  # type: ignore
    except Exception:
        return {
            "offender_count": 0,
            "painted_red": 0,
            "painted_gray": 0,
            "snapshot_blend_path": "",
            "snapshot_png_path": "",
            "error": "bpy unavailable",
        }

    (
        red_offenders,
        blue_offenders,
        orange_offenders,
        offender_codes,
        hard_overlap_offenders,
        joint_overlap_offenders,
    ) = _collect_offenders_by_priority(validation, metrics=metrics)
    all_offenders = set(red_offenders) | set(blue_offenders) | set(orange_offenders)

    offender_mat = _material("MAT_DEBUG_OFFENDER", (0.92, 0.16, 0.16, 1.0))
    bent_mat = _material("MAT_DEBUG_BENT", (0.18, 0.42, 0.95, 1.0))
    orange_mat = _material("MAT_DEBUG_ORANGE", (0.95, 0.52, 0.14, 1.0))
    other_mat = _material("MAT_DEBUG_OTHER", (0.58, 0.58, 0.58, 1.0))

    painted_red = 0
    painted_blue = 0
    painted_orange = 0
    painted_gray = 0
    for obj in bpy.data.objects:
        if str(getattr(obj, "type", "")) != "MESH":
            continue
        mesh = getattr(obj, "data", None)
        if mesh is None or not hasattr(mesh, "materials"):
            continue

        if obj.name in red_offenders:
            target_material = offender_mat
            painted_red += 1
        elif obj.name in blue_offenders:
            target_material = bent_mat
            painted_blue += 1
        elif obj.name in orange_offenders:
            target_material = orange_mat
            painted_orange += 1
        else:
            target_material = other_mat
            painted_gray += 1

        if len(mesh.materials) == 0:
            mesh.materials.append(target_material)
        else:
            mesh.materials[0] = target_material

    scene_bbox = _scene_bbox_from_metrics(metrics)
    _ensure_camera_and_light(scene_bbox, lens_mm=camera_lens_mm)

    saved_blend_path = ""
    if snapshot_blend_path:
        blend_path = os.path.abspath(str(snapshot_blend_path).strip())
        if blend_path:
            parent_dir = os.path.dirname(blend_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)
            bpy.ops.wm.save_as_mainfile(filepath=blend_path)
            saved_blend_path = blend_path

    saved_png_path = ""
    if snapshot_png_path:
        png_path = os.path.abspath(str(snapshot_png_path).strip())
        if png_path:
            parent_dir = os.path.dirname(png_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)
            scene = bpy.context.scene
            scene.render.image_settings.file_format = "PNG"
            scene.render.filepath = png_path
            bpy.ops.render.render(write_still=True)
            saved_png_path = png_path

    codes_csv = ",".join(sorted(offender_codes))
    print(f"DEBUG_OFFENDERS_COUNT:{len(all_offenders)}")
    print(f"DEBUG_OFFENDER_CODES:{codes_csv}")

    return {
        "offender_count": len(all_offenders),
        "overlap_offender_count": len(red_offenders),
        "bent_offender_count": len(blue_offenders),
        "mod_offender_count": len(orange_offenders),
        "hard_offender_count": len(hard_overlap_offenders),
        "joint_offender_count": len(joint_overlap_offenders),
        "offender_codes": sorted(offender_codes),
        "painted_red": painted_red,
        "painted_blue": painted_blue,
        "painted_orange": painted_orange,
        "painted_gray": painted_gray,
        "snapshot_blend_path": saved_blend_path,
        "snapshot_png_path": saved_png_path,
    }



===== FILE: tools/blender/debug_run.py =====
"""Blender-level debug run orchestrator for sofa IR.

Usage:
  blender --background --python tools/blender/debug_run.py -- path/to/sofa_ir.json
"""

from __future__ import annotations

import json
import os
import sys
from copy import deepcopy
from typing import Any


REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.builders.blender.builder_v01 import build_plan_from_ir  # noqa: E402
from tools.blender.debug.autofix import fix_ir  # noqa: E402
from tools.blender.debug.io import (  # noqa: E402
    ensure_dir,
    make_run_id,
    make_run_tag,
    save_json,
    sha256_file,
    sha256_json,
)
from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
from tools.blender.debug.validators import validate  # noqa: E402
from tools.blender.run_builder_v01 import (  # noqa: E402
    _clear_scene,
    _create_anchor,
    _create_primitive,
    _ensure_mm_units,
)


def _read_ir_path() -> str:
    """Resolve IR path from argv after '--', then from IR_PATH env."""
    if "--" in sys.argv:
        idx = sys.argv.index("--")
        if len(sys.argv) > idx + 1:
            candidate = str(sys.argv[idx + 1]).strip()
            if candidate:
                return candidate

    env_candidate = str(os.environ.get("IR_PATH", "")).strip()
    if env_candidate:
        return env_candidate

    if len(sys.argv) > 1:
        fallback = str(sys.argv[-1]).strip()
        if fallback and fallback != "--":
            return fallback
    return ""


def _env_int(name: str, default: int, min_value: int = 1) -> int:
    raw = os.environ.get(name, str(default))
    try:
        value = int(raw)
    except (TypeError, ValueError):
        value = int(default)
    return max(int(min_value), value)


def _env_flag(name: str, default: bool = False) -> bool:
    raw = str(os.environ.get(name, "1" if default else "0")).strip().lower()
    return raw in {"1", "true", "yes", "on"}


def _resolve_out_dir(path: str) -> str:
    if os.path.isabs(path):
        return path
    return os.path.abspath(os.path.join(REPO_ROOT, path))


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _problem_count(validation: dict[str, Any]) -> int:
    problems = validation.get("problems", [])
    if isinstance(problems, list):
        return len(problems)
    return 0


def _top_overlap_offender_pair(validation: dict[str, Any], metrics: dict[str, Any]) -> dict[str, Any] | None:
    best: dict[str, Any] | None = None
    best_volume = -1.0

    problems = validation.get("problems", [])
    if isinstance(problems, list):
        for problem in problems:
            if not isinstance(problem, dict):
                continue
            code = str(problem.get("code", "")).strip().upper()
            if not code.startswith("OVERLAP_"):
                continue
            details = problem.get("details", {})
            if not isinstance(details, dict):
                continue
            pairs = details.get("pairs_top", [])
            if not isinstance(pairs, list) or len(pairs) == 0:
                pairs = details.get("joint_pairs_top", [])
            if not isinstance(pairs, list):
                continue
            for pair in pairs:
                if not isinstance(pair, dict):
                    continue
                volume = _safe_float(pair.get("volume", 0.0), 0.0)
                if volume > best_volume:
                    best_volume = volume
                    best = {
                        "source": code,
                        "left": str(pair.get("left", "")),
                        "right": str(pair.get("right", "")),
                        "volume": float(volume),
                    }

    if best is not None:
        return best

    overlaps = metrics.get("overlaps", {})
    if not isinstance(overlaps, dict):
        return None

    for overlap_key, payload in overlaps.items():
        if not isinstance(payload, dict):
            continue
        pairs = payload.get("pairs", [])
        if not isinstance(pairs, list):
            continue
        for pair in pairs:
            if not isinstance(pair, dict):
                continue
            volume = _safe_float(pair.get("volume", 0.0), 0.0)
            if volume > best_volume:
                best_volume = volume
                best = {
                    "source": str(overlap_key),
                    "left": str(pair.get("left", "")),
                    "right": str(pair.get("right", "")),
                    "volume": float(volume),
                }
    return best


def _top_fixes_payload(patches_applied: list[dict[str, Any]], limit: int = 5) -> list[dict[str, Any]]:
    payload: list[dict[str, Any]] = []
    for patch in patches_applied[: max(0, int(limit))]:
        if not isinstance(patch, dict):
            continue
        payload.append(
            {
                "path": str(patch.get("path", "")),
                "new": patch.get("new"),
            }
        )
    return payload


def _has_severity_ge3(validation: dict[str, Any]) -> bool:
    problems = validation.get("problems", [])
    if not isinstance(problems, list):
        return False
    for problem in problems:
        if not isinstance(problem, dict):
            continue
        if int(_safe_float(problem.get("severity", 0), 0.0)) >= 3:
            return True
    return False


def _extract_build_counts(metrics: dict[str, Any]) -> dict[str, Any]:
    object_count = 0
    if isinstance(metrics.get("object_count"), int):
        object_count = int(metrics["object_count"])
    elif isinstance(metrics.get("objects"), list):
        object_count = len(metrics["objects"])

    group_counts: dict[str, int] = {}
    top_group_counts = metrics.get("group_counts", {})
    if isinstance(top_group_counts, dict):
        for key, value in top_group_counts.items():
            group_counts[str(key)] = int(_safe_float(value, 0.0))
    else:
        groups = metrics.get("groups", {})
        if isinstance(groups, dict):
            for key, value in groups.items():
                if isinstance(value, dict):
                    group_counts[str(key)] = int(_safe_float(value.get("count", 0), 0.0))

    return {
        "object_count": int(object_count),
        "group_counts": group_counts,
    }


def _build_scene_from_ir(ir: dict[str, Any]) -> dict[str, int]:
    """Build scene from IR using the existing builder primitive functions."""
    import bpy  # type: ignore

    _clear_scene()
    _ensure_mm_units()

    plan = build_plan_from_ir(ir)
    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_params = legs.get("params", {}) if isinstance(legs.get("params"), dict) else None

    for primitive in plan.primitives:
        _create_primitive(primitive, legs_params=legs_params)

    for anchor in plan.anchors:
        _create_anchor(anchor.name, anchor.location_mm)

    bpy.context.view_layer.update()
    return {"primitives": len(plan.primitives), "anchors": len(plan.anchors)}


def main() -> int:
    run_id = make_run_id()
    run_tag = make_run_tag(run_id=run_id)
    out_dir = _resolve_out_dir(os.environ.get("DEBUG_OUT_DIR", "out/logs/runs"))
    ensure_dir(out_dir)

    debug_iters = _env_int("DEBUG_ITERS", 1, min_value=1)
    debug_autofix = _env_flag("DEBUG_AUTOFIX", default=False)
    debug_visualize = _env_flag("DEBUG_VISUALIZE", default=False)

    ir_source_path = ""
    ir_in_path = ""
    ir_out_path = ""
    ir_sha256_in = ""
    ir_sha256_out = ""
    metrics_log_path = ""
    metrics_sha256 = ""
    validation_log_path = ""

    source_ir: dict[str, Any] = {}
    current_ir: dict[str, Any] = {}
    iter_index = 0
    iterations: list[dict[str, Any]] = []
    patches_applied: list[dict[str, Any]] = []

    final_metrics: dict[str, Any] = {}
    final_validation: dict[str, Any] = {
        "score": 0.0,
        "penalty": 1.0,
        "problem_count": 0,
        "problems": [],
    }
    final_build_counts: dict[str, Any] = {"object_count": 0, "group_counts": {}}
    final_top_offender_pair: dict[str, Any] | None = None
    prev_metrics: dict[str, Any] | None = None
    autofix_context: dict[str, Any] = {}

    status = "error"
    error_text: str | None = None
    snapshot_blend_saved = "N/A"
    snapshot_png_saved = "N/A"
    debug_offenders_count = 0
    hard_offenders_count = 0
    joint_offenders_count = 0

    try:
        ir_path = _read_ir_path()
        if not ir_path:
            raise RuntimeError("IR path is required. Pass it after '--' or set IR_PATH.")

        ir_source_path = os.path.abspath(ir_path)
        with open(ir_source_path, "r", encoding="utf-8") as handle:
            loaded_ir = json.load(handle)
        if not isinstance(loaded_ir, dict):
            raise RuntimeError(f"Expected IR JSON object, got {type(loaded_ir).__name__}")

        source_ir = loaded_ir
        current_ir = deepcopy(source_ir)

        ir_in_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_in.json"), source_ir)
        ir_sha256_in = sha256_json(source_ir)

        try:
            import bpy  # type: ignore  # noqa: F401
        except Exception as exc:
            raise RuntimeError("Blender Python runtime is required (module bpy is unavailable).") from exc

        for idx in range(1, debug_iters + 1):
            iter_index = idx
            plan_counts = _build_scene_from_ir(current_ir)
            metrics = collect_scene_metrics()
            validation_payload = validate(current_ir, metrics)
            build_counts = _extract_build_counts(metrics)

            iteration_patches: list[dict[str, Any]] = []
            if debug_autofix and idx < debug_iters:
                problems = validation_payload.get("problems", [])
                if not isinstance(problems, list):
                    problems = []
                updated_ir, iteration_patches = fix_ir(
                    current_ir,
                    problems,
                    metrics=metrics,
                    validation=validation_payload,
                    prev_metrics=prev_metrics,
                    context=autofix_context,
                )
                current_ir = updated_ir
                patches_applied.extend(iteration_patches)

            iterations.append(
                {
                    "iter_index": idx,
                    "plan_counts": plan_counts,
                    "build_counts": build_counts,
                    "validation": validation_payload,
                    "patches_applied": iteration_patches,
                }
            )
            final_metrics = metrics
            final_validation = validation_payload
            final_build_counts = build_counts
            prev_metrics = metrics

        final_top_offender_pair = _top_overlap_offender_pair(final_validation, final_metrics)
        if final_top_offender_pair and isinstance(final_metrics, dict):
            final_metrics["top_offender_pair"] = final_top_offender_pair

        if debug_visualize:
            try:
                from tools.blender.debug.visualize import apply_debug_visualization  # noqa: E402

                vis_payload = apply_debug_visualization(
                    validation=final_validation,
                    metrics=final_metrics,
                    snapshot_blend_path=str(os.environ.get("DEBUG_SNAPSHOT_BLEND", "")).strip() or None,
                    snapshot_png_path=str(os.environ.get("DEBUG_SNAPSHOT_PNG", "")).strip() or None,
                    camera_lens_mm=_safe_float(os.environ.get("DEBUG_SNAPSHOT_LENS_MM", "50"), 50.0),
                )
                debug_offenders_count = int(_safe_float(vis_payload.get("offender_count", 0), 0.0))
                hard_offenders_count = int(_safe_float(vis_payload.get("hard_offender_count", 0), 0.0))
                joint_offenders_count = int(_safe_float(vis_payload.get("joint_offender_count", 0), 0.0))
                snapshot_blend_saved = str(vis_payload.get("snapshot_blend_path", "")).strip() or "N/A"
                snapshot_png_saved = str(vis_payload.get("snapshot_png_path", "")).strip() or "N/A"
            except Exception as exc:
                print(f"DEBUG_VISUALIZE_ERROR:{exc}")

        score = _safe_float(final_validation.get("score", 0.0), 0.0)
        pass_result = score >= 0.95 and (not _has_severity_ge3(final_validation))
        status = "ok" if pass_result else "fail"

    except Exception as exc:
        status = "error"
        error_text = str(exc)

    ir_in_payload = source_ir if isinstance(source_ir, dict) else {}
    if not ir_in_path:
        ir_in_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_in.json"), ir_in_payload)
    if not ir_sha256_in:
        ir_sha256_in = sha256_json(ir_in_payload)

    if not current_ir and isinstance(source_ir, dict):
        current_ir = deepcopy(source_ir)
    ir_out_payload = current_ir if isinstance(current_ir, dict) else {}
    ir_out_path = save_json(os.path.join(out_dir, f"{run_tag}.ir_out.json"), ir_out_payload)
    ir_sha256_out = sha256_json(ir_out_payload)

    metrics_log_payload: dict[str, Any] = {"kind": "metrics"}
    if isinstance(final_metrics, dict):
        metrics_log_payload.update(final_metrics)
    else:
        metrics_log_payload["metrics"] = final_metrics
    metrics_log_path = os.path.abspath(save_json(os.path.join(out_dir, f"{run_tag}.metrics.json"), metrics_log_payload))
    metrics_sha256 = sha256_file(metrics_log_path)
    validation_log_path = os.path.abspath(
        save_json(os.path.join(out_dir, f"{run_tag}.validation.json"), final_validation)
    )

    log_payload: dict[str, Any] = {
        "kind": "run",
        "status": status,
        "error": error_text,
        "run_id": run_id,
        "iter_index": int(iter_index),
        "ir_source_path": ir_source_path,
        "ir_in_path": ir_in_path,
        "ir_out_path": ir_out_path,
        "ir_sha256_in": ir_sha256_in,
        "ir_sha256_out": ir_sha256_out,
        "metrics_path": metrics_log_path,
        "metrics_sha256": metrics_sha256,
        "validation_path": validation_log_path,
        "build_counts": final_build_counts,
        "metrics": final_metrics,
        "validation": final_validation,
        "patches_applied": patches_applied,
        "iterations": iterations,
        "debug_autofix": bool(debug_autofix),
        "debug_iters": int(debug_iters),
        "debug_offenders_count": int(debug_offenders_count),
        "hard_offenders_count": int(hard_offenders_count),
        "joint_offenders_count": int(joint_offenders_count),
    }

    log_path = os.path.abspath(save_json(os.path.join(out_dir, f"{run_tag}.json"), log_payload))

    score = _safe_float(final_validation.get("score", 0.0), 0.0)
    problems = _problem_count(final_validation)
    top_pair = final_top_offender_pair or _top_overlap_offender_pair(final_validation, final_metrics)
    top_fixes = _top_fixes_payload(patches_applied, limit=5)
    ir_in_debug = os.path.abspath(ir_in_path) if ir_in_path else "N/A"
    ir_out_debug = os.path.abspath(ir_out_path) if ir_out_path else "N/A"
    metrics_debug = metrics_log_path if metrics_log_path else "N/A"

    print(f"status: {status}")
    print(f"iterations: {iter_index}")
    if top_pair:
        print(
            "top_offender_pair: "
            f"{top_pair.get('left')} vs {top_pair.get('right')} "
            f"volume_m3={_safe_float(top_pair.get('volume', 0.0), 0.0):.6g} "
            f"source={top_pair.get('source')}"
        )
    else:
        print("top_offender_pair: none")

    print(f"DEBUG_RUN_ID:{run_id}")
    print(f"DEBUG_RUN_LOG:{log_path}")
    print(f"DEBUG_RUN_METRICS:{metrics_debug}")
    print(f"DEBUG_IR_IN:{ir_in_debug}")
    print(f"DEBUG_IR_OUT:{ir_out_debug}")
    print(f"DEBUG_SCORE:{score:.6f}")
    print(f"DEBUG_PROBLEMS:{problems}")
    print(f"DEBUG_TOP_FIXES:{json.dumps(top_fixes, ensure_ascii=False)}")
    print(f"DEBUG_SNAPSHOT_BLEND_SAVED:{snapshot_blend_saved}")
    print(f"DEBUG_SNAPSHOT_PNG_SAVED:{snapshot_png_saved}")
    print(f"DEBUG_OFFENDERS_COUNT:{debug_offenders_count}")
    print(f"DEBUG_HARD_OFFENDERS_COUNT:{hard_offenders_count}")
    print(f"DEBUG_JOINT_OFFENDERS_COUNT:{joint_offenders_count}")

    if status == "error":
        return 3
    if score >= 0.95 and (not _has_severity_ge3(final_validation)):
        return 0
    return 2


if __name__ == "__main__":
    raise SystemExit(main())



===== FILE: tools/blender/DEBUG_USAGE.md =====
# Blender Debug Usage

Optional IR block for modifier expectations:

```json
"debug": {
  "expect_modifiers": {
    "slat_": ["SIMPLE_DEFORM:BEND", "SOLIDIFY", "BEVEL"],
    "back_slat_": ["SIMPLE_DEFORM:BEND"],
    "arm_": ["MIRROR"],
    "frame_": ["BEVEL"],
    "leg_": ["BEVEL"]
  }
}
```

## Color Legend

| Class | Color | Source problem codes |
|---|---|---|
| Overlap offenders | Red | `OVERLAP_*` |
| Missing expected modifiers | Blue | `MOD_EXPECTATION_MISSING` |
| Modifier no-effect offenders | Orange | `MOD_EXPECTATION_NO_EFFECT` |
| Non-offenders / other meshes | Gray | fallback |

Paint priority is fixed: `RED > BLUE > ORANGE > GRAY`.

## Highlight-Only (No Autofix)

```powershell
$env:DEBUG_VISUALIZE="1"
$env:DEBUG_AUTOFIX="0"
$env:DEBUG_ITERS="1"
$env:DEBUG_SNAPSHOT_BLEND="out/snapshots/sofa_highlight_only.blend"
$env:DEBUG_SNAPSHOT_PNG="out/snapshots/sofa_highlight_only.png"
& $env:BLENDER_EXE --background --python tools/blender/debug_run.py -- data/examples/sofa_ir.json
```

## Highlight + Autofix (Iterative)

```powershell
$env:DEBUG_VISUALIZE="1"
$env:DEBUG_AUTOFIX="1"
$env:DEBUG_ITERS="2"
$env:DEBUG_AUTOFIX_VERBOSE="1"
$env:DEBUG_AUTOFIX_SAFETY_MM="3"
$env:DEBUG_SNAPSHOT_BLEND="out/snapshots/sofa_autofix.blend"
$env:DEBUG_SNAPSHOT_PNG="out/snapshots/sofa_autofix.png"
& $env:BLENDER_EXE --background --python tools/blender/debug_run.py -- data/examples/sofa_ir.json
```

Autofix overlap safety margin:
- `DEBUG_AUTOFIX_SAFETY_MM` (default `2`) adds extra millimeters on top of bbox-derived penetration delta.

## Batch Run For Folder Of IR Files

Generates per-IR debug outputs and `summary.csv` with:
- `file_name`
- `debug_score`
- `problems_count`
- `overlaps_slats_m3`
- `overlaps_back_m3`
- `fixes_applied_count`

```powershell
$env:DEBUG_AUTOFIX="1"
$env:DEBUG_ITERS="2"
$env:DEBUG_SNAPSHOT_BLEND_DIR="out/snapshots/batch_blend"
& $env:BLENDER_EXE --background --python tools/blender/batch_debug_run.py -- data/examples out/logs/batch

Get-Item out/logs/batch/summary.csv
```



===== FILE: tools/blender/run_builder_v01.py =====
"""Run builder_v01 inside Blender.

Usage (called by export_blender.py):
blender --background --python tools/blender/run_builder_v01.py -- path/to/sofa_ir.json

This version FIXES slat bending by doing vertex-level bending (bmesh),
instead of relying on SimpleDeform (which can appear "flat" in some pipeline cases).

Env vars:
- IR_PATH: override IR path
- BLEND_PATH: if set, saves .blend to that path
- DEBUG_SLAT=1: adds an extra DEBUG_SLAT
- APPLY_DEBUG_SLAT=1: bakes modifiers for DEBUG_SLAT
- APPLY_ALL_SLATS=1: bakes modifiers for ALL slats (optional)
- DEBUG_JSON=1: writes debug JSON metrics/validation log
"""

import json
import math
import os
import sys
from typing import Optional, Tuple

# --- ensure repo root in sys.path so "src.*" imports work ---
REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.builders.blender import builder_v01 as builder_module  # noqa: E402
from src.builders.blender.builder_v01 import build_plan_from_ir  # noqa: E402


# -------------------------
# small helpers
# -------------------------

def _read_ir_path() -> str:
    """Resolve IR path from env or argv (after '--')."""
    if os.environ.get("IR_PATH"):
        return os.environ["IR_PATH"]

    if "--" in sys.argv:
        i = sys.argv.index("--")
        if len(sys.argv) > i + 1:
            return sys.argv[i + 1]

    # fallback: last arg
    if len(sys.argv) > 1:
        return sys.argv[-1]

    return ""


def _clear_scene() -> None:
    """Start from an empty scene."""
    import bpy  # type: ignore
    bpy.ops.wm.read_factory_settings(use_empty=True)


def _ensure_mm_units() -> None:
    """Configure the scene for millimeter units.

    Blender units: meters. So 1 mm = 0.001 m.
    """
    import bpy  # type: ignore
    scene = bpy.context.scene
    scene.unit_settings.system = "METRIC"
    scene.unit_settings.scale_length = 1.0


def _mm_to_m(v):
    return tuple(float(x) / 1000.0 for x in v)


def _apply_rotation_deg(obj, rotation_deg) -> None:
    if not rotation_deg:
        return
    try:
        rx, ry, rz = rotation_deg
    except (TypeError, ValueError):
        return
    if rx == 0 and ry == 0 and rz == 0:
        return
    obj.rotation_euler = (math.radians(rx), math.radians(ry), math.radians(rz))


def _bake_object_modifiers(obj) -> None:
    """Bake evaluated mesh into obj.data and clear modifiers."""
    import bpy  # type: ignore

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()
    try:
        depsgraph.update()
    except Exception:
        pass

    eval_obj = obj.evaluated_get(depsgraph)
    new_mesh = bpy.data.meshes.new_from_object(
        eval_obj,
        depsgraph=depsgraph,
        preserve_all_data_layers=True,
    )
    obj.data = new_mesh
    obj.modifiers.clear()


# -------------------------
# primitives
# -------------------------

def _create_cube(name, dimensions_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cube_add(size=1.0, location=_mm_to_m(location_mm))
    obj = bpy.context.active_object
    obj.name = name
    obj.dimensions = _mm_to_m(dimensions_mm)
    bpy.context.view_layer.update()
    return obj


def _create_cylinder(name, radius_mm, height_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cylinder_add(
        radius=float(radius_mm) / 1000.0,
        depth=float(height_mm) / 1000.0,
        location=_mm_to_m(location_mm),
    )
    obj = bpy.context.active_object
    obj.name = name
    return obj


def _create_cone(name, r_top_mm, r_bottom_mm, height_mm, location_mm):
    import bpy  # type: ignore
    bpy.ops.mesh.primitive_cone_add(
        radius1=float(r_bottom_mm) / 1000.0,
        radius2=float(r_top_mm) / 1000.0,
        depth=float(height_mm) / 1000.0,
        location=_mm_to_m(location_mm),
    )
    obj = bpy.context.active_object
    obj.name = name
    return obj


def _create_anchor(name, location_mm):
    import bpy  # type: ignore
    empty = bpy.data.objects.new(name, None)
    empty.empty_display_type = "PLAIN_AXES"
    empty.location = _mm_to_m(location_mm)
    bpy.context.scene.collection.objects.link(empty)
    return empty


# -------------------------
# slats: mesh + vertex bend
# -------------------------

def _create_slat_mesh(
    name: str,
    width_mm: float,
    length_mm: float,
    location_mm,
    rotation_deg,
    segments_len: int,
    segments_w: int,
    orientation: str,
):
    """Creates a grid plane:
    - horizontal: plane in XY (length along +Y), normal ~ +Z
    - vertical:   plane in XZ (length along +Z), normal ~ +Y (or -Y)
    """
    import bpy  # type: ignore
    import bmesh  # type: ignore

    segments_len = max(1, int(segments_len))
    segments_w = max(1, int(segments_w))

    width_m = float(width_mm) / 1000.0
    length_m = float(length_mm) / 1000.0

    bm = bmesh.new()

    # Start with unit grid in XY centered at origin
    bmesh.ops.create_grid(bm, x_segments=segments_w, y_segments=segments_len, size=1.0)

    # Normalize to target width/length in local space
    if bm.verts:
        xs = [v.co.x for v in bm.verts]
        ys = [v.co.y for v in bm.verts]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        cx = (min_x + max_x) / 2.0
        cy = (min_y + max_y) / 2.0
        ext_x = max_x - min_x
        ext_y = max_y - min_y
        sx = (width_m / ext_x) if ext_x != 0.0 else 1.0
        sy = (length_m / ext_y) if ext_y != 0.0 else 1.0

        for v in bm.verts:
            v.co.x = (v.co.x - cx) * sx
            v.co.y = (v.co.y - cy) * sy
            v.co.z = 0.0

    # If vertical: rotate XY plane into XZ (so length becomes Z)
    if orientation == "vertical":
        from mathutils import Matrix  # type: ignore
        rot_m = Matrix.Rotation(math.radians(90.0), 4, "X")  # Y -> Z
        for v in bm.verts:
            v.co = rot_m @ v.co

    mesh = bpy.data.meshes.new(name)
    bm.to_mesh(mesh)
    bm.free()
    mesh.update()

    for poly in mesh.polygons:
        poly.use_smooth = True

    obj = bpy.data.objects.new(name, mesh)
    obj.location = _mm_to_m(location_mm)
    _apply_rotation_deg(obj, rotation_deg)
    bpy.context.scene.collection.objects.link(obj)
    bpy.context.view_layer.update()
    return obj


def _bend_vertices_arc(
    obj,
    orientation: str,
    length_mm: float,
    arc_height_mm: float,
    arc_sign: float,
) -> Tuple[float, float]:
    """Bend vertices into a circular arc (sagitta).
    Returns (radius_m, angle_rad).
    - horizontal: length along local Y, sag applied to local Z
    - vertical:   length along local Z, sag applied to local Y  (back curvature)
    """
    import bmesh  # type: ignore

    if arc_height_mm <= 0.0 or length_mm <= 0.0:
        return (0.0, 0.0)

    L = float(length_mm) / 1000.0
    h = float(arc_height_mm) / 1000.0
    sign = -1.0 if arc_sign < 0 else 1.0

    # radius from sagitta
    # R = L^2/(8h) + h/2
    R = (L * L) / (8.0 * h) + (h / 2.0)
    if not math.isfinite(R) or R <= 0:
        return (0.0, 0.0)

    angle = L / R
    angle = max(-math.pi, min(math.pi, angle))

    half = L / 2.0

    bm = bmesh.new()
    bm.from_mesh(obj.data)

    for v in bm.verts:
        if orientation == "vertical":
            t = v.co.z  # along length
        else:
            t = v.co.y

        t = max(-half, min(half, t))

        # sag = R - sqrt(R^2 - t^2)
        under = max(0.0, (R * R - t * t))
        sag = R - math.sqrt(under)

        if orientation == "vertical":
            v.co.y += sag * sign
        else:
            v.co.z += sag * sign

    bm.to_mesh(obj.data)
    bm.free()
    obj.data.update()

    return (R, angle)


def _axis_ranges_world(mesh, matrix_world):
    if not mesh or len(mesh.vertices) == 0:
        return None
    xs, ys, zs = [], [], []
    for v in mesh.vertices:
        w = matrix_world @ v.co
        xs.append(w.x)
        ys.append(w.y)
        zs.append(w.z)
    return (min(xs), max(xs)), (min(ys), max(ys)), (min(zs), max(zs))


# -------------------------
# plan primitive creator
# -------------------------

def _create_primitive(p, legs_params=None):
    """Create geometry for a Primitive from builder_v01 plan."""
    import bpy  # type: ignore

    shape = getattr(p, "shape", "cube")
    dims = getattr(p, "dimensions_mm", (100, 100, 100))
    loc = getattr(p, "location_mm", (0, 0, 0))
    rot = getattr(p, "rotation_deg", (0.0, 0.0, 0.0))

    if shape in {"cube", "beam", "board"}:
        obj = _create_cube(p.name, dims, loc)
        _apply_rotation_deg(obj, rot)
        return obj

    if shape == "slat":
        # defaults
        arc_height_mm = 0.0
        arc_sign = -1.0
        orientation = "horizontal"
        subdiv_cuts = 64
        edge_radius_mm = 1.0
        solidify_offset = 1.0

        params = getattr(p, "params", None)
        if isinstance(params, dict):
            try:
                arc_height_mm = float(params.get("arc_height_mm", 0.0))
            except (TypeError, ValueError):
                arc_height_mm = 0.0
            try:
                arc_sign = float(params.get("arc_sign", -1.0))
            except (TypeError, ValueError):
                arc_sign = -1.0
            try:
                orientation = str(params.get("orientation", "horizontal")).strip().lower()
            except (TypeError, ValueError):
                orientation = "horizontal"
            try:
                subdiv_cuts = int(params.get("subdiv_cuts", 64))
            except (TypeError, ValueError):
                subdiv_cuts = 64
            try:
                edge_radius_mm = float(params.get("edge_radius_mm", 1.0))
            except (TypeError, ValueError):
                edge_radius_mm = 1.0
            try:
                solidify_offset = float(params.get("solidify_offset", 1.0))
            except (TypeError, ValueError):
                solidify_offset = 1.0

        if orientation in {"seat"}:
            orientation = "horizontal"
        if orientation not in {"horizontal", "vertical"}:
            orientation = "horizontal"

        arc_sign = -1.0 if arc_sign < 0 else 1.0
        solidify_offset = max(-1.0, min(1.0, solidify_offset))

        # dims mapping
        if orientation == "vertical":
            # width X, thickness Y, length Z  (like your older logic)
            width_mm = float(dims[0])
            thickness_mm = float(dims[1])
            length_mm = float(dims[2])
        else:
            # width X, length Y, thickness Z
            width_mm = float(dims[0])
            length_mm = float(dims[1])
            thickness_mm = float(dims[2])

        # mesh density: must be high along length for nice arc
        subdiv_cuts = max(8, min(200, int(subdiv_cuts)))
        segments_len = max(40, min(240, subdiv_cuts * 2))
        segments_w = 4

        obj = _create_slat_mesh(
            name=p.name,
            width_mm=width_mm,
            length_mm=length_mm,
            location_mm=loc,
            rotation_deg=rot,
            segments_len=segments_len,
            segments_w=segments_w,
            orientation=orientation,
        )

        # do vertex bending (the fix)
        radius_m, angle_rad = (0.0, 0.0)
        if arc_height_mm > 0.0 and length_mm > 0.0:
            radius_m, angle_rad = _bend_vertices_arc(
                obj=obj,
                orientation=orientation,
                length_mm=length_mm,
                arc_height_mm=arc_height_mm,
                arc_sign=arc_sign,
            )

        # solidify thickness (works from normals of the plane)
        if thickness_mm > 0.0:
            solid = obj.modifiers.new(name="Solidify", type="SOLIDIFY")
            solid.thickness = float(thickness_mm) / 1000.0
            solid.offset = solidify_offset
            solid.use_even_offset = True

        # bevel edges
        if edge_radius_mm > 0.0:
            bevel = obj.modifiers.new(name="Bevel", type="BEVEL")
            bevel.width = float(edge_radius_mm) / 1000.0
            bevel.segments = 2
            bevel.limit_method = "ANGLE"
            bevel.angle_limit = math.radians(40.0)
            if hasattr(bevel, "harden_normals"):
                bevel.harden_normals = True

        # normals
        wn = obj.modifiers.new(name="WeightedNormal", type="WEIGHTED_NORMAL")
        wn.keep_sharp = True
        wn.weight = 50
        if hasattr(obj.data, "use_auto_smooth"):
            obj.data.use_auto_smooth = True
        if hasattr(obj.data, "auto_smooth_angle"):
            obj.data.auto_smooth_angle = math.radians(40.0)

        # optional baking
        if os.environ.get("APPLY_ALL_SLATS") == "1":
            _bake_object_modifiers(obj)

        # debug ranges (base/eval)
        if obj.name in {"DEBUG_SLAT", "slat_1"} or os.environ.get("DEBUG_SLAT") == "1":
            bpy.context.view_layer.update()
            depsgraph = bpy.context.evaluated_depsgraph_get()
            eval_obj = obj.evaluated_get(depsgraph)
            eval_mesh = eval_obj.to_mesh()

            base_ranges = _axis_ranges_world(obj.data, obj.matrix_world)
            eval_ranges = _axis_ranges_world(eval_mesh, eval_obj.matrix_world)

            print(
                f"[slat] name={obj.name} orientation={orientation} arc_height_mm={arc_height_mm} "
                f"radius_m={radius_m:.6f} angle_rad={angle_rad:.6f} "
                f"verts={len(obj.data.vertices)} mods={[m.type for m in obj.modifiers]}"
            )
            if base_ranges and eval_ranges:
                base_spans = (
                    base_ranges[0][1] - base_ranges[0][0],
                    base_ranges[1][1] - base_ranges[1][0],
                    base_ranges[2][1] - base_ranges[2][0],
                )
                eval_spans = (
                    eval_ranges[0][1] - eval_ranges[0][0],
                    eval_ranges[1][1] - eval_ranges[1][0],
                    eval_ranges[2][1] - eval_ranges[2][0],
                )
                dx = abs(eval_spans[0] - base_spans[0])
                dy = abs(eval_spans[1] - base_spans[1])
                dz = abs(eval_spans[2] - base_spans[2])
                print(
                    f"SLAT_RANGES_BASE x=({base_ranges[0][0]:.6f},{base_ranges[0][1]:.6f}) "
                    f"y=({base_ranges[1][0]:.6f},{base_ranges[1][1]:.6f}) "
                    f"z=({base_ranges[2][0]:.6f},{base_ranges[2][1]:.6f})"
                )
                print(
                    f"SLAT_RANGES_EVAL x=({eval_ranges[0][0]:.6f},{eval_ranges[0][1]:.6f}) "
                    f"y=({eval_ranges[1][0]:.6f},{eval_ranges[1][1]:.6f}) "
                    f"z=({eval_ranges[2][0]:.6f},{eval_ranges[2][1]:.6f})"
                )
                print(f"SLAT_RANGE_DELTAS dx={dx:.6f} dy={dy:.6f} dz={dz:.6f}")

            eval_obj.to_mesh_clear()

        return obj

    if shape == "cylindrical":
        obj = _create_cylinder(p.name, radius_mm=float(dims[0]) / 2.0, height_mm=float(dims[2]), location_mm=loc)
        _apply_rotation_deg(obj, rot)
        return obj

    if shape == "tapered_cone":
        r_top = None
        r_bottom = None
        if isinstance(legs_params, dict):
            try:
                if legs_params.get("r_top") is not None:
                    r_top = float(legs_params["r_top"])
                if legs_params.get("r_bottom") is not None:
                    r_bottom = float(legs_params["r_bottom"])
            except (TypeError, ValueError):
                r_top = None
                r_bottom = None
        if r_top is None or r_bottom is None:
            r_top = max(6.0, float(dims[0]) * 0.35)
            r_bottom = max(r_top + 2.0, float(dims[0]) * 0.6)
        obj = _create_cone(p.name, r_top_mm=r_top, r_bottom_mm=r_bottom, height_mm=float(dims[2]), location_mm=loc)
        _apply_rotation_deg(obj, rot)
        return obj

    # fallback -> cube
    obj = _create_cube(p.name, dims, loc)
    _apply_rotation_deg(obj, rot)
    return obj


# -------------------------
# main
# -------------------------

def main():
    import bpy  # type: ignore

    ir_path = _read_ir_path()
    if not ir_path:
        raise SystemExit("IR path is required. Pass it after '--' or set IR_PATH env var.")

    print(f"RUN_BUILDER_V01:{__file__}")
    print(f"REPO_ROOT:{REPO_ROOT}")
    print(f"BUILDER_MODULE:{builder_module.__file__}")

    _clear_scene()
    _ensure_mm_units()

    blend_path = os.environ.get("BLEND_PATH", "")
    print(f"IR_PATH:{ir_path}")
    print(f"BLEND_PATH:{blend_path}")

    with open(ir_path, "r", encoding="utf-8") as f:
        ir = json.load(f)

    plan = build_plan_from_ir(ir)
    legs = ir.get("legs", {}) if isinstance(ir.get("legs"), dict) else {}
    legs_params = legs.get("params", {}) if isinstance(legs.get("params"), dict) else None

    # build primitives
    for prim in plan.primitives:
        _create_primitive(prim, legs_params=legs_params)

    # optional debug slat
    if os.environ.get("DEBUG_SLAT") == "1":
        try:
            debug_slat = _create_primitive(
                builder_module.Primitive(
                    name="DEBUG_SLAT",
                    shape="slat",
                    dimensions_mm=(60.0, 600.0, 12.0),  # width, length, thickness (horizontal)
                    location_mm=(0.0, 900.0, 300.0),
                    rotation_deg=(0.0, 0.0, 0.0),
                    params={
                        "arc_height_mm": 35.0,
                        "arc_sign": -1.0,
                        "orientation": "horizontal",
                        "subdiv_cuts": 64,
                        "edge_radius_mm": 1.0,
                        "solidify_offset": 1.0,
                    },
                ),
                legs_params=legs_params,
            )
            print(f"DEBUG_SLAT_CREATED:{debug_slat.name} verts={len(debug_slat.data.vertices)}")
            if os.environ.get("APPLY_DEBUG_SLAT") == "1":
                _bake_object_modifiers(debug_slat)
                print("DEBUG_SLAT_BAKED:1")
        except Exception as exc:
            print(f"DEBUG_SLAT_CREATED:error={exc}")

    # anchors as empties
    for a in plan.anchors:
        _create_anchor(a.name, a.location_mm)

    object_names = sorted(obj.name for obj in bpy.data.objects)
    print(f"OBJECTS_TOTAL:{len(object_names)} FIRST:{object_names[:10]}")
    slat_count = sum(1 for name in object_names if name.startswith("slat_"))
    beam_count = sum(1 for name in object_names if name.startswith("beam_"))
    rail_count = sum(1 for name in object_names if name.startswith("rail_"))
    print(f"OBJECT_PREFIX_COUNTS slat_={slat_count} beam_={beam_count} rail_={rail_count}")

    if os.environ.get("DEBUG_JSON") == "1":
        try:
            from tools.blender.debug.io import ir_sha256, make_run_id, save_run_log  # noqa: E402
            from tools.blender.debug.metrics import collect_scene_metrics  # noqa: E402
            from tools.blender.debug.validators import validate  # noqa: E402

            debug_run_id = make_run_id()
            metrics = collect_scene_metrics()
            validation = validate(metrics, ir)
            debug_payload = {
                "run_id": debug_run_id,
                "source": "run_builder_v01",
                "ir_path": os.path.abspath(ir_path),
                "ir_sha256": ir_sha256(ir),
                "build": {
                    "primitives": len(plan.primitives),
                    "anchors": len(plan.anchors),
                },
                "metrics": metrics,
                "validation": validation,
            }
            debug_log_path = save_run_log(
                debug_payload,
                out_dir=os.path.join(REPO_ROOT, "out", "logs", "runs"),
                run_id=debug_run_id,
            )
            print(f"DEBUG_JSON_LOG:{debug_log_path}")
        except Exception as exc:
            print(f"DEBUG_JSON_ERROR:{exc}")

    # optionally save .blend
    if blend_path:
        os.makedirs(os.path.dirname(blend_path), exist_ok=True)
        bpy.ops.wm.save_as_mainfile(filepath=blend_path)

    return {"status": "built", "primitives": len(plan.primitives), "anchors": len(plan.anchors)}


if __name__ == "__main__":
    main()



===== FILE: tools/blender/run_export_glb.py =====
"""Export GLB from Blender scene."""

import os
import sys

import bpy  # type: ignore  # Blender-only


def _read_glb_path() -> str:
    """Resolve GLB path from env or argv."""
    if os.environ.get("GLB_PATH"):
        return os.environ["GLB_PATH"]
    if "--" in sys.argv:
        index = sys.argv.index("--")
        if len(sys.argv) > index + 1:
            return sys.argv[index + 1]
    if len(sys.argv) > 1:
        return sys.argv[-1]
    return "out/glb/sofa.glb"


def _export_apply_kwargs():
    props = bpy.ops.export_scene.gltf.get_rna_type().properties
    if "export_apply" in props:
        return {"export_apply": True}
    if "export_apply_modifiers" in props:
        return {"export_apply_modifiers": True}
    return {}


def _is_exportable_mesh(obj) -> bool:
    if obj.type != "MESH":
        return False
    if obj.name.endswith("_bend_origin"):
        return False
    for col in obj.users_collection:
        if col.name == "_helpers":
            return False
    if obj.hide_get() or obj.hide_viewport or obj.hide_render:
        return False
    if not obj.visible_get():
        return False
    return True


def main():
    """Entry point for Blender execution."""
    glb_path = _read_glb_path()
    glb_path = os.path.abspath(glb_path)
    os.makedirs(os.path.dirname(glb_path), exist_ok=True)

    print(f"RUN_EXPORT_GLB:{__file__}")
    print(f"BLEND_PATH:{bpy.data.filepath}")
    print(f"GLB_PATH:{glb_path}")

    if os.path.exists(glb_path):
        try:
            os.remove(glb_path)
        except OSError as exc:
            print(f"WARNING: failed to remove existing GLB {glb_path}: {exc}")

    bpy.context.view_layer.update()
    depsgraph = bpy.context.evaluated_depsgraph_get()

    helpers = bpy.data.collections.get("_helpers")
    if helpers is not None:
        helpers.hide_viewport = True
        helpers.hide_render = True

    export_objs = [obj for obj in bpy.data.objects if _is_exportable_mesh(obj)]
    tmp_coll = bpy.data.collections.get("_export_tmp")
    if tmp_coll is None:
        tmp_coll = bpy.data.collections.new("_export_tmp")
        bpy.context.scene.collection.children.link(tmp_coll)
    tmp_coll.hide_viewport = False
    tmp_coll.hide_render = False

    tmp_objects = []
    tmp_meshes = []
    for obj in export_objs:
        eval_obj = obj.evaluated_get(depsgraph)
        try:
            mesh = bpy.data.meshes.new_from_object(eval_obj, depsgraph=depsgraph)
            used_new_from_object = True
        except Exception:
            used_new_from_object = False
            mesh_eval = eval_obj.to_mesh()
            mesh = mesh_eval.copy()
            eval_obj.to_mesh_clear()
        tmp = bpy.data.objects.new(obj.name, mesh)
        tmp.matrix_world = obj.matrix_world
        tmp_coll.objects.link(tmp)
        tmp_objects.append(tmp)
        tmp_meshes.append(mesh)

    print(f"EXPORT_MESH_OBJECTS:{len(tmp_objects)}")

    bpy.ops.object.select_all(action="DESELECT")
    for obj in tmp_objects:
        obj.select_set(True)
    if tmp_objects:
        bpy.context.view_layer.objects.active = tmp_objects[0]

    export_kwargs = {
        "filepath": glb_path,
        "export_format": "GLB",
        "use_selection": True,
    }
    export_kwargs.update(_export_apply_kwargs())

    result = bpy.ops.export_scene.gltf(**export_kwargs)
    print(f"GLTF_EXPORT_RESULT:{result}")
    bpy.context.view_layer.update()

    size = os.path.getsize(glb_path) if os.path.exists(glb_path) else 0
    print(f"GLB_SIZE_BYTES:{size}")
    if size <= 0:
        raise SystemExit(2)

    for obj in tmp_objects:
        bpy.data.objects.remove(obj, do_unlink=True)
    for mesh in tmp_meshes:
        if mesh.users == 0:
            bpy.data.meshes.remove(mesh)

    return {
        "status": "exported",
        "path": glb_path,
    }


if __name__ == "__main__":
    main()



===== FILE: tools/blender/slat_lab.py =====
"""Isolated slat deformation lab for Blender 4.4.

Run:
  blender --background --factory-startup --python tools/blender/slat_lab.py -- [options]

Options (after "--"):
  --out_blend <path>   Save .blend (optional)
  --apply              Bake modifiers for variant C
  --arc_mm <float>     Sagitta height in mm (default 35)
  --length_mm <float>  Slat length in mm (default 600)
  --width_mm <float>   Slat width in mm (default 60)
  --thick_mm <float>   Slat thickness in mm (default 12)
  --segments <int>     Grid segments along length (default 80)
"""

from __future__ import annotations

import math
import os
import sys
from dataclasses import dataclass


def _mm_to_m(x_mm: float) -> float:
    return float(x_mm) / 1000.0


def _clamp(v, lo, hi):
    return max(lo, min(hi, v))


@dataclass
class Opts:
    out_blend: str = ""
    apply: bool = False
    arc_mm: float = 35.0
    length_mm: float = 600.0
    width_mm: float = 60.0
    thick_mm: float = 12.0
    segments: int = 80


def _parse_opts(argv: list[str]) -> Opts:
    opts = Opts()

    if "--" in argv:
        args = argv[argv.index("--") + 1 :]
    else:
        args = []

    i = 0
    while i < len(args):
        a = args[i]
        if a == "--apply":
            opts.apply = True
            i += 1
            continue
        if a == "--out_blend" and i + 1 < len(args):
            opts.out_blend = str(args[i + 1])
            i += 2
            continue
        if a == "--arc_mm" and i + 1 < len(args):
            try:
                opts.arc_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--length_mm" and i + 1 < len(args):
            try:
                opts.length_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--width_mm" and i + 1 < len(args):
            try:
                opts.width_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--thick_mm" and i + 1 < len(args):
            try:
                opts.thick_mm = float(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue
        if a == "--segments" and i + 1 < len(args):
            try:
                opts.segments = int(args[i + 1])
            except (TypeError, ValueError):
                pass
            i += 2
            continue

        i += 1

    opts.segments = int(_clamp(opts.segments, 1, 500))
    return opts


def _bend_angle_from_sagitta(length_mm: float, arc_mm: float) -> tuple[float, float]:
    """Return (angle_rad, radius_mm)."""
    if length_mm <= 0.0 or arc_mm <= 0.0:
        return 0.0, 0.0
    arc_mm = min(max(0.0, arc_mm), length_mm / 2.0)
    radius_mm = (length_mm * length_mm) / (8.0 * arc_mm) + (arc_mm / 2.0)
    if radius_mm <= 0.0 or not math.isfinite(radius_mm):
        return 0.0, radius_mm
    angle_rad = length_mm / radius_mm
    angle_rad = max(-math.pi, min(math.pi, angle_rad))
    return angle_rad, radius_mm


def _ensure_child_collection(scene_coll, name: str, hide: bool) -> "bpy.types.Collection":
    import bpy  # type: ignore

    coll = bpy.data.collections.get(name)
    if coll is None:
        coll = bpy.data.collections.new(name)
    if coll.name not in scene_coll.children:
        scene_coll.children.link(coll)
    coll.hide_viewport = bool(hide)
    coll.hide_render = bool(hide)
    return coll


def _move_obj_to_collection(obj, dst_coll) -> None:
    # Ensure object is only linked to dst_coll.
    for c in list(obj.users_collection):
        if c != dst_coll:
            c.objects.unlink(obj)
    if obj not in dst_coll.objects:
        dst_coll.objects.link(obj)


def _create_origin_empty(name: str, location, rotation_euler, helpers_coll):
    import bpy  # type: ignore

    empty = bpy.data.objects.new(name, None)
    empty.empty_display_type = "PLAIN_AXES"
    empty.location = location
    if rotation_euler is not None:
        empty.rotation_euler = rotation_euler
    empty.hide_viewport = True
    empty.hide_render = True
    helpers_coll.objects.link(empty)
    return empty


def _mesh_bbox_world(mesh, matrix_world):
    from mathutils import Vector  # type: ignore

    if not mesh.vertices:
        zero = Vector((0.0, 0.0, 0.0))
        return zero, zero
    min_v = None
    max_v = None
    for v in mesh.vertices:
        co = matrix_world @ v.co
        if min_v is None:
            min_v = co.copy()
            max_v = co.copy()
        else:
            min_v.x = min(min_v.x, co.x)
            min_v.y = min(min_v.y, co.y)
            min_v.z = min(min_v.z, co.z)
            max_v.x = max(max_v.x, co.x)
            max_v.y = max(max_v.y, co.y)
            max_v.z = max(max_v.z, co.z)
    return min_v, max_v


def _print_obj_stats(obj, label: str) -> None:
    mesh = obj.data
    mods = [f"{m.name}:{m.type}" for m in obj.modifiers]
    bb_min, bb_max = _mesh_bbox_world(mesh, obj.matrix_world)
    print(
        f"OBJ {label} name={obj.name} verts={len(mesh.vertices)} polys={len(mesh.polygons)} "
        f"bbox_min=({bb_min.x:.6f},{bb_min.y:.6f},{bb_min.z:.6f}) "
        f"bbox_max=({bb_max.x:.6f},{bb_max.y:.6f},{bb_max.z:.6f}) mods={mods}"
    )


def _print_obj_eval_stats(obj, label: str) -> tuple[float, float]:
    import bpy  # type: ignore

    depsgraph = bpy.context.evaluated_depsgraph_get()
    eval_obj = obj.evaluated_get(depsgraph)
    eval_mesh = eval_obj.to_mesh()
    try:
        bb_min, bb_max = _mesh_bbox_world(eval_mesh, eval_obj.matrix_world)
        mods = [f"{m.name}:{m.type}" for m in obj.modifiers]
        print(
            f"OBJ_EVAL {label} name={obj.name} verts={len(eval_mesh.vertices)} polys={len(eval_mesh.polygons)} "
            f"bbox_min=({bb_min.x:.6f},{bb_min.y:.6f},{bb_min.z:.6f}) "
            f"bbox_max=({bb_max.x:.6f},{bb_max.y:.6f},{bb_max.z:.6f}) mods={mods}"
        )
        return bb_min.z, bb_max.z
    finally:
        eval_obj.to_mesh_clear()


def _create_grid_slat_object(name: str, width_m: float, length_m: float, segments_len: int, segments_w: int):
    import bpy  # type: ignore
    import bmesh  # type: ignore

    bm = bmesh.new()
    bmesh.ops.create_grid(bm, x_segments=segments_w, y_segments=segments_len, size=1.0)

    if bm.verts:
        xs = [v.co.x for v in bm.verts]
        ys = [v.co.y for v in bm.verts]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        cx = (min_x + max_x) / 2.0
        cy = (min_y + max_y) / 2.0
        ext_x = max_x - min_x
        ext_y = max_y - min_y
        sx = (width_m / ext_x) if ext_x != 0.0 else 1.0
        sy = (length_m / ext_y) if ext_y != 0.0 else 1.0
        for v in bm.verts:
            v.co.x = (v.co.x - cx) * sx
            v.co.y = (v.co.y - cy) * sy
            v.co.z = 0.0

    mesh = bpy.data.meshes.new(name)
    bm.to_mesh(mesh)
    bm.free()
    mesh.update()
    for poly in mesh.polygons:
        poly.use_smooth = True

    obj = bpy.data.objects.new(name, mesh)
    return obj


def _add_bend_modifier(obj, origin, axis: str, angle_rad: float) -> None:
    mod = obj.modifiers.new(name="Bend", type="SIMPLE_DEFORM")
    mod.deform_method = "BEND"
    mod.deform_axis = axis
    mod.angle = angle_rad
    mod.origin = origin
    if hasattr(mod, "show_viewport"):
        mod.show_viewport = True
    if hasattr(mod, "show_render"):
        mod.show_render = True
    if hasattr(mod, "show_in_editmode"):
        mod.show_in_editmode = True
    if hasattr(mod, "show_on_cage"):
        mod.show_on_cage = True


def main() -> None:
    import bpy  # type: ignore
    from mathutils import Vector  # type: ignore

    opts = _parse_opts(sys.argv)

    print(f"BLENDER_VERSION:{bpy.app.version_string}")
    print(f"FILEPATH:{bpy.data.filepath}")
    print(
        "OPTS "
        f"out_blend={opts.out_blend!r} apply={opts.apply} arc_mm={opts.arc_mm} "
        f"length_mm={opts.length_mm} width_mm={opts.width_mm} thick_mm={opts.thick_mm} segments={opts.segments}"
    )

    bpy.ops.wm.read_factory_settings(use_empty=True)
    scene = bpy.context.scene

    lab_coll = _ensure_child_collection(scene.collection, "_lab", hide=False)
    helpers_coll = _ensure_child_collection(scene.collection, "_helpers", hide=True)

    width_m = _mm_to_m(opts.width_mm)
    length_m = _mm_to_m(opts.length_mm)
    thick_m = _mm_to_m(opts.thick_mm)

    # Use negative angle to bend "upwards" in +Z for axis=Y in typical orientation.
    angle_rad, radius_mm = _bend_angle_from_sagitta(opts.length_mm, opts.arc_mm)
    bend_angle = -angle_rad
    print(f"BEND_CALC arc_mm={opts.arc_mm} length_mm={opts.length_mm} radius_mm={radius_mm} angle_rad={bend_angle}")

    # Layout: three objects spaced in X.
    base_z = 0.30
    loc_a = Vector((-0.45, 0.0, base_z))
    loc_b = Vector((0.00, 0.0, base_z))
    loc_c = Vector((0.45, 0.0, base_z))

    # A) SLAT_CUBE
    bpy.ops.mesh.primitive_cube_add(size=1.0, location=loc_a)
    obj_a = bpy.context.active_object
    obj_a.name = "SLAT_CUBE"
    obj_a.dimensions = (width_m, length_m, thick_m)
    _move_obj_to_collection(obj_a, lab_coll)
    origin_a = _create_origin_empty("SLAT_CUBE_ORIGIN", obj_a.location.copy(), obj_a.rotation_euler, helpers_coll)
    _add_bend_modifier(obj_a, origin_a, axis="Y", angle_rad=bend_angle)

    # B) SLAT_GRID
    obj_b = _create_grid_slat_object("SLAT_GRID", width_m=width_m, length_m=length_m, segments_len=opts.segments, segments_w=2)
    obj_b.location = loc_b
    lab_coll.objects.link(obj_b)
    mod_solid_b = obj_b.modifiers.new(name="Solidify", type="SOLIDIFY")
    mod_solid_b.thickness = thick_m
    mod_solid_b.offset = 0.0
    mod_solid_b.use_even_offset = True
    origin_b = _create_origin_empty(
        "SLAT_GRID_ORIGIN",
        obj_b.matrix_world @ Vector((0.0, -length_m / 2.0, 0.0)),
        obj_b.rotation_euler,
        helpers_coll,
    )
    _add_bend_modifier(obj_b, origin_b, axis="Y", angle_rad=bend_angle)

    # C) SLAT_GRID_APPLIED
    obj_c = obj_b.copy()
    obj_c.data = obj_b.data.copy()
    obj_c.name = "SLAT_GRID_APPLIED"
    obj_c.location = loc_c
    lab_coll.objects.link(obj_c)
    # Replace bend origin to avoid sharing the same empty.
    for m in obj_c.modifiers:
        if m.type == "SIMPLE_DEFORM":
            origin_c = _create_origin_empty(
                "SLAT_GRID_APPLIED_ORIGIN",
                obj_c.matrix_world @ Vector((0.0, -length_m / 2.0, 0.0)),
                obj_c.rotation_euler,
                helpers_coll,
            )
            m.origin = origin_c

    bpy.context.view_layer.update()

    # Logs: base mesh stats.
    _print_obj_stats(obj_a, label="BASE")
    _print_obj_stats(obj_b, label="BASE")
    _print_obj_stats(obj_c, label="BASE")

    # Logs: evaluated stats (show modifier effect).
    _print_obj_eval_stats(obj_a, label="EVAL")
    b_base_minz, b_base_maxz = _mesh_bbox_world(obj_b.data, obj_b.matrix_world)
    b_eval_minz, b_eval_maxz = _print_obj_eval_stats(obj_b, label="EVAL")
    print(f"Z_RANGE SLAT_GRID base=({b_base_minz.z:.6f},{b_base_maxz.z:.6f}) eval=({b_eval_minz:.6f},{b_eval_maxz:.6f})")

    c_base_minz, c_base_maxz = _mesh_bbox_world(obj_c.data, obj_c.matrix_world)
    c_eval_minz, c_eval_maxz = _print_obj_eval_stats(obj_c, label="EVAL")
    print(
        f"Z_RANGE SLAT_GRID_APPLIED base=({c_base_minz.z:.6f},{c_base_maxz.z:.6f}) "
        f"eval=({c_eval_minz:.6f},{c_eval_maxz:.6f})"
    )

    if opts.apply:
        depsgraph = bpy.context.evaluated_depsgraph_get()
        eval_obj = obj_c.evaluated_get(depsgraph)
        new_mesh = bpy.data.meshes.new_from_object(eval_obj, depsgraph=depsgraph)
        old_mesh = obj_c.data
        obj_c.data = new_mesh
        obj_c.modifiers.clear()
        if old_mesh.users == 0:
            bpy.data.meshes.remove(old_mesh)
        bpy.context.view_layer.update()
        _print_obj_stats(obj_c, label="APPLIED")

    if opts.out_blend:
        out_blend = os.path.abspath(opts.out_blend)
        out_dir = os.path.dirname(out_blend)
        if out_dir:
            os.makedirs(out_dir, exist_ok=True)
        bpy.ops.wm.save_as_mainfile(filepath=out_blend)
        print(f"SAVED_BLEND:{out_blend}")


if __name__ == "__main__":
    main()



===== FILE: tools/dump_debug.ps1 =====
param(
  [int]$MaxFileSizeKB = 500,
  [string]$OutDump = "repo_dump_debug.txt",
  [string]$OutIndex = "repo_dump_debug_index.txt"
)

$ErrorActionPreference = "Stop"
$root = (Resolve-Path ".").Path

# Список файлов debug-системы (поддерживаемый минимум)
$paths = @(
  "tools/blender/debug_run.py",
  "tools/blender/batch_debug_run.py",
  "tools/blender/DEBUG_USAGE.md",

  "tools/blender/debug/__init__.py",
  "tools/blender/debug/io.py",
  "tools/blender/debug/metrics.py",
  "tools/blender/debug/validators.py",
  "tools/blender/debug/visualize.py",
  "tools/blender/debug/autofix.py",

  # опционально, но часто нужно рядом
  "tools/blender/run_builder_v01.py",
  "tools/blender/run_export_glb.py",
  "tools/blender/slat_lab.py"
)

# нормализация
$files = @()
foreach ($p in $paths) {
  $abs = Join-Path $root $p
  if (Test-Path $abs) { $files += (Get-Item $abs) }
}

# индекс
$idx = @()
$i = 1
foreach ($f in $files) {
  $sizeKB = [math]::Round(($f.Length / 1KB), 2)
  $note = ""
  if ($sizeKB -gt $MaxFileSizeKB) { $note = "skipped_content_over_limit" }

  $idx += [pscustomobject]@{
    id = $i
    path = (Resolve-Path $f.FullName).Path.Substring($root.Length + 1) -replace "\\","/"
    size_kb = $sizeKB
    note = $note
  }
  $i++
}

$idx | ConvertTo-Json -Depth 6 | Set-Content -Encoding UTF8 $OutIndex

# дамп (в один текстовый файл)
$sb = New-Object System.Text.StringBuilder
$null = $sb.AppendLine("=== DEBUG DUMP (filtered) ===")
$null = $sb.AppendLine("root: $root")
$null = $sb.AppendLine("max_file_size_kb: $MaxFileSizeKB")
$null = $sb.AppendLine("generated_at: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')")
$null = $sb.AppendLine("")

foreach ($item in $idx) {
  $rel = $item.path -replace "/","\"
  $abs = Join-Path $root $rel

  $null = $sb.AppendLine("----- FILE: $($item.path) ($($item.size_kb) KB) -----")

  if ($item.note -eq "skipped_content_over_limit") {
    $null = $sb.AppendLine("[SKIPPED CONTENT: file is larger than MaxFileSizeKB]")
    $null = $sb.AppendLine("")
    continue
  }

  try {
    $content = Get-Content -Raw -Encoding UTF8 $abs
    $null = $sb.AppendLine($content)
  } catch {
    $null = $sb.AppendLine("[FAILED TO READ FILE AS UTF8] $($_.Exception.Message)")
  }

  $null = $sb.AppendLine("")
}

$sb.ToString() | Set-Content -Encoding UTF8 $OutDump

Write-Host "Wrote $OutDump"
Write-Host "Wrote $OutIndex (rows=$($idx.Count))"



===== FILE: tools/dump_repo.ps1 =====
<#
Usage:
  powershell -ExecutionPolicy Bypass -File tools/dump_repo.ps1

Creates in repository root:
  - repo_dump.txt
  - repo_dump_index.txt

Key excluded directories (any level):
  .git, __pycache__, .venv, venv, out, models, data/cache,
  .mypy_cache, .pytest_cache, .ruff_cache, node_modules,
  dist, build, .next, .idea, .vscode, .vs, logs, tmp, temp, .cache
#>

Set-StrictMode -Version Latest
$ErrorActionPreference = 'Stop'

$script:MaxFileSizeBytes = 2MB
$script:IncludedExtensions = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@('.py', '.ps1', '.md', '.txt', '.json', '.yml', '.yaml', '.toml', '.ini') | ForEach-Object {
    [void]$script:IncludedExtensions.Add($_)
}

$script:IncludedExactNames = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@('requirements.txt', 'pyproject.toml', 'README.md') | ForEach-Object {
    [void]$script:IncludedExactNames.Add($_)
}

$script:ExcludedDirNames = New-Object 'System.Collections.Generic.HashSet[string]' ([System.StringComparer]::OrdinalIgnoreCase)
@(
    '.git', '__pycache__', '.venv', 'venv', 'out', 'models',
    '.mypy_cache', '.pytest_cache', '.ruff_cache', 'node_modules',
    'dist', 'build', '.next', '.idea', '.vscode', '.vs',
    'logs', 'tmp', 'temp', '.cache'
) | ForEach-Object {
    [void]$script:ExcludedDirNames.Add($_)
}

$script:Utf8NoBom = New-Object System.Text.UTF8Encoding($false)

function Resolve-RepoRoot {
    param(
        [string]$StartPath = (Get-Location).Path
    )

    $startItem = Get-Item -LiteralPath $StartPath -Force -ErrorAction SilentlyContinue
    if ($null -eq $startItem) {
        return (Get-Location).Path
    }

    $initialDir = if ($startItem.PSIsContainer) {
        $startItem.FullName
    } else {
        Split-Path -LiteralPath $startItem.FullName -Parent
    }
    $currentPath = $initialDir

    while ($true) {
        if (Test-Path -LiteralPath (Join-Path -Path $currentPath -ChildPath '.git')) {
            return $currentPath
        }

        $parent = [System.IO.Directory]::GetParent($currentPath)
        if ($null -eq $parent) {
            return $initialDir
        }

        $currentPath = $parent.FullName
    }
}

function Get-RelativePath {
    param(
        [Parameter(Mandatory = $true)][string]$BasePath,
        [Parameter(Mandatory = $true)][string]$Path
    )

    $baseResolved = [System.IO.Path]::GetFullPath((Resolve-Path -LiteralPath $BasePath -ErrorAction Stop).Path).TrimEnd('\', '/')
    $pathResolved = [System.IO.Path]::GetFullPath((Resolve-Path -LiteralPath $Path -ErrorAction Stop).Path)

    if ($pathResolved.Equals($baseResolved, [System.StringComparison]::OrdinalIgnoreCase)) {
        return '.'
    }

    $basePrefix = $baseResolved + '\'
    if ($pathResolved.StartsWith($basePrefix, [System.StringComparison]::OrdinalIgnoreCase)) {
        return ($pathResolved.Substring($basePrefix.Length) -replace '\\', '/')
    }

    $baseUriText = 'file:///' + (($baseResolved -replace '\\', '/').TrimStart('/')) + '/'
    $pathUriText = 'file:///' + (($pathResolved -replace '\\', '/').TrimStart('/'))
    $baseUri = New-Object System.Uri($baseUriText)
    $pathUri = New-Object System.Uri($pathUriText)
    $relative = [System.Uri]::UnescapeDataString($baseUri.MakeRelativeUri($pathUri).ToString())
    return ($relative -replace '\\', '/')
}

function Is-ExcludedDir {
    param(
        [Parameter(Mandatory = $true)][string]$RepoRoot,
        [Parameter(Mandatory = $true)][string]$DirPath
    )

    $relative = Get-RelativePath -BasePath $RepoRoot -Path $DirPath
    if ($relative -eq '.') {
        return $false
    }

    $parts = @($relative -split '/' | Where-Object { $_ -ne '' })

    foreach ($part in $parts) {
        if ($script:ExcludedDirNames.Contains($part)) {
            return $true
        }
    }

    for ($i = 0; $i -lt ($parts.Count - 1); $i++) {
        if ($parts[$i].Equals('data', [System.StringComparison]::OrdinalIgnoreCase) -and
            $parts[$i + 1].Equals('cache', [System.StringComparison]::OrdinalIgnoreCase)) {
            return $true
        }
    }

    return $false
}

function Is-IncludedFile {
    param(
        [Parameter(Mandatory = $true)][System.IO.FileInfo]$File
    )

    if ($script:IncludedExactNames.Contains($File.Name)) {
        return $true
    }

    if ($script:IncludedExtensions.Contains($File.Extension)) {
        return $true
    }

    return $false
}

function Is-BinaryFile {
    param(
        [Parameter(Mandatory = $true)][string]$Path
    )

    try {
        $stream = [System.IO.File]::Open($Path, [System.IO.FileMode]::Open, [System.IO.FileAccess]::Read, [System.IO.FileShare]::ReadWrite)
        try {
            $buffer = New-Object byte[] 4096
            $bytesRead = $stream.Read($buffer, 0, $buffer.Length)
            for ($i = 0; $i -lt $bytesRead; $i++) {
                if ($buffer[$i] -eq 0) {
                    return $true
                }
            }
            return $false
        } finally {
            $stream.Dispose()
        }
    } catch {
        return $true
    }
}

function Write-Dump {
    param(
        [Parameter(Mandatory = $true)][array]$Entries,
        [Parameter(Mandatory = $true)][string]$DumpPath
    )

    $includedEntries = @($Entries | Where-Object { $_.Included } | Sort-Object RelativePath)

    $filesFound = $Entries.Count
    $filesWritten = @($Entries | Where-Object { $_.Status -eq 'OK' }).Count
    $filesSkippedLarge = @($Entries | Where-Object { $_.Status -eq 'SKIP_LARGE' }).Count
    $filesSkippedBinary = @($Entries | Where-Object { $_.Status -eq 'SKIP_BINARY' }).Count

    $renderDump = {
        param([long]$OutputBytesValue)

        $sb = New-Object System.Text.StringBuilder

        for ($i = 0; $i -lt $includedEntries.Count; $i++) {
            $entry = $includedEntries[$i]

            if ($i -gt 0) {
                [void]$sb.Append("`r`n`r`n`r`n")
            }

            [void]$sb.Append('===== FILE: ').Append($entry.RelativePath).Append(" =====`r`n")

            if ($entry.Status -eq 'OK') {
                if ($null -ne $entry.Content) {
                    [void]$sb.Append($entry.Content)
                }
            } elseif ($entry.Status -eq 'SKIP_LARGE') {
                [void]$sb.Append('[SKIP: file too large ').Append($entry.SizeBytes).Append(' bytes]')
            } elseif ($entry.Status -eq 'SKIP_BINARY') {
                [void]$sb.Append('[SKIP: unreadable or binary]')
            }
        }

        if ($includedEntries.Count -gt 0) {
            [void]$sb.Append("`r`n`r`n")
        }

        [void]$sb.Append("===== SUMMARY =====`r`n")
        [void]$sb.Append('files_found=').Append($filesFound).Append("`r`n")
        [void]$sb.Append('files_written=').Append($filesWritten).Append("`r`n")
        [void]$sb.Append('files_skipped_large=').Append($filesSkippedLarge).Append("`r`n")
        [void]$sb.Append('files_skipped_binary=').Append($filesSkippedBinary).Append("`r`n")
        [void]$sb.Append('output_bytes=').Append($OutputBytesValue)

        return $sb.ToString()
    }

    $outputBytes = 0L
    $content = ''

    for ($i = 0; $i -lt 8; $i++) {
        $content = & $renderDump $outputBytes
        $calculated = $script:Utf8NoBom.GetByteCount($content)
        if ($calculated -eq $outputBytes) {
            break
        }
        $outputBytes = $calculated
    }

    $content = & $renderDump $outputBytes
    [System.IO.File]::WriteAllText($DumpPath, $content, $script:Utf8NoBom)

    return (Get-Item -LiteralPath $DumpPath -ErrorAction Stop).Length
}

function Write-Index {
    param(
        [Parameter(Mandatory = $true)][array]$Entries,
        [Parameter(Mandatory = $true)][string]$IndexPath
    )

    $sb = New-Object System.Text.StringBuilder
    [void]$sb.Append("path`tsize_bytes`tstatus`r`n")

    foreach ($entry in $Entries) {
        [void]$sb.Append($entry.RelativePath).Append("`t").Append($entry.SizeBytes).Append("`t").Append($entry.Status).Append("`r`n")
    }

    [System.IO.File]::WriteAllText($IndexPath, $sb.ToString(), $script:Utf8NoBom)

    return ($Entries.Count + 1)
}

$repoRoot = Resolve-RepoRoot
$dumpPath = Join-Path -Path $repoRoot -ChildPath 'repo_dump.txt'
$indexPath = Join-Path -Path $repoRoot -ChildPath 'repo_dump_index.txt'

$allFiles = New-Object System.Collections.Generic.List[System.IO.FileInfo]
$stack = New-Object 'System.Collections.Generic.Stack[string]'
$stack.Push($repoRoot)

while ($stack.Count -gt 0) {
    $currentDir = $stack.Pop()

    try {
        $children = Get-ChildItem -LiteralPath $currentDir -Force -ErrorAction Stop
    } catch {
        continue
    }

    foreach ($child in $children) {
        if ($child.PSIsContainer) {
            if (($child.Attributes -band [System.IO.FileAttributes]::ReparsePoint) -ne 0) {
                continue
            }

            if (Is-ExcludedDir -RepoRoot $repoRoot -DirPath $child.FullName) {
                continue
            }

            $stack.Push($child.FullName)
            continue
        }

        $allFiles.Add([System.IO.FileInfo]$child)
    }
}

$entries = @(
    foreach ($file in ($allFiles | Sort-Object { Get-RelativePath -BasePath $repoRoot -Path $_.FullName })) {
        $relativePath = Get-RelativePath -BasePath $repoRoot -Path $file.FullName
        $included = Is-IncludedFile -File $file
        $status = 'SKIP_EXT'
        $content = $null

        if ($included) {
            if ($file.Length -gt $script:MaxFileSizeBytes) {
                $status = 'SKIP_LARGE'
            } elseif (Is-BinaryFile -Path $file.FullName) {
                $status = 'SKIP_BINARY'
            } else {
                try {
                    $content = [System.IO.File]::ReadAllText($file.FullName)
                    $status = 'OK'
                } catch {
                    $status = 'SKIP_BINARY'
                    $content = $null
                }
            }
        }

        [pscustomobject]@{
            RelativePath = $relativePath
            SizeBytes = [long]$file.Length
            Status = $status
            Included = $included
            Content = $content
        }
    }
)

$dumpBytes = Write-Dump -Entries $entries -DumpPath $dumpPath
$indexRows = Write-Index -Entries $entries -IndexPath $indexPath

Write-Output ("Wrote repo_dump.txt (bytes={0})" -f $dumpBytes)
Write-Output ("Wrote repo_dump_index.txt (rows={0})" -f $indexRows)



===== FILE: tools/generate_sofa_ner_dataset.py =====
import json
import random
import re
from pathlib import Path

# ----------------------------
# Config
# ----------------------------

TAGS = [
    "TYPE", "STYLE", "LAYOUT", "ORIENTATION",
    "SEAT_HEIGHT_MM", "SEAT_DEPTH_MM", "SEAT_WIDTH_RANGE_MM",
    "SEAT_COUNT", "HAS_CHAISE", "ARMRESTS", "LEG_FAMILY", "TRANSFORMABLE"
]

RANDOM_SEED = 42

# ----------------------------
# Lexicons
# ----------------------------

TYPE_WORDS = ["диван", "софа"]

STYLE_WORDS = {
    "scandi": ["сканди", "скандинавский", "scandi"],
    "loft": ["лофт", "industrial", "индастриал"],
    "modern": ["модерн", "современный", "modern"],
    "minimal": ["минимализм", "минималистичный", "minimal"],
    "classic": ["классика", "классический", "classic"],
}

LAYOUT_WORDS = {
    "straight": ["прямой", "прямолинейный", "обычный"],
    "corner": ["угловой", "Г-образный", "l-образный"],
    "u_shape": ["п-образный", "u-образный"],
    "modular": ["модульный", "секции", "модули"],
}

ORIENTATION_WORDS = {
    "left": ["левый", "слева", "левосторонний"],
    "right": ["правый", "справа", "правосторонний"],
}

LEG_FAMILY_WORDS = {
    "tapered_cone": ["конусные ножки", "конусообразные ножки", "tapered_cone"],
    "tapered_prism": ["призматические ножки", "скошенная пирамида", "tapered_prism"],
    "cylindrical": ["цилиндрические ножки", "круглые ножки", "cylindrical"],
    "block": ["блочные ножки", "квадратные ножки", "block"],
    "hairpin": ["hairpin", "шпильки", "ножки-шпильки"],
    "sled": ["салазки", "sled", "полозья"],
    "frame": ["рамные ножки", "металлическая рама", "frame"],
}

ARMREST_WORDS = {
    "none": ["без подлокотников", "подлокотники не нужны", "no armrests"],
    "both": ["с подлокотниками", "два подлокотника", "с двух сторон"],
    "left": ["подлокотник слева", "левый подлокотник"],
    "right": ["подлокотник справа", "правый подлокотник"],
}

CHAISE_WORDS_TRUE = ["с оттоманкой", "с шезлонгом", "с канапе", "с удлинением"]
CHAISE_WORDS_FALSE = ["без оттоманки", "без шезлонга", "без удлинения"]

TRANSFORM_TRUE = ["раскладной", "трансформер", "с механизмом раскладывания"]
TRANSFORM_FALSE = ["не раскладной", "без механизма", "стационарный"]

# ----------------------------
# Helpers
# ----------------------------

def tokenize_ru(text: str):
    # токенизация как у тебя в примерах (слова/числа/знаки)
    # разделяем числа, точки, запятые
    tokens = re.findall(r"\d+|[A-Za-zА-Яа-яЁё]+|[^\w\s]", text, flags=re.UNICODE)
    return tokens

def tag_span(tokens, start_idx, end_idx, label):
    # end_idx exclusive
    tags = ["O"] * len(tokens)
    tags[start_idx] = f"B-{label}"
    for i in range(start_idx + 1, end_idx):
        tags[i] = f"I-{label}"
    return tags

def merge_tags(base_tags, span_tags):
    # span_tags has O except labeled region; overlay onto base_tags
    out = base_tags[:]
    for i, t in enumerate(span_tags):
        if t != "O":
            out[i] = t
    return out

def mm_or_cm_value(mm_value: int):
    # иногда пишем в мм, иногда в см
    if random.random() < 0.65:
        # см
        cm = round(mm_value / 10)
        return cm, "см"
    return mm_value, "мм"

def format_dim_phrase(kind: str, mm_value: int):
    # kind: высота сиденья / глубина сиденья
    val, unit = mm_or_cm_value(mm_value)
    # варианты формулировок
    templates = [
        f"{kind} {val} {unit}",
        f"{kind} — {val}{unit}",
        f"{kind}: {val} {unit}",
        f"{kind} примерно {val} {unit}",
    ]
    return random.choice(templates)

def format_width_range(min_mm: int, max_mm: int):
    min_val, unit1 = mm_or_cm_value(min_mm)
    # чтобы не было несостыковки единиц в одном диапазоне, делаем одинаковую единицу
    if unit1 == "см":
        max_val = round(max_mm / 10)
        unit = "см"
    else:
        max_val = max_mm
        unit = "мм"
    templates = [
        f"ширина посадки {min_val}–{max_val} {unit}",
        f"ширина сиденья от {min_val} до {max_val} {unit}",
        f"посадочное место {min_val}-{max_val} {unit} по ширине",
    ]
    return random.choice(templates)

def pick_style():
    key = random.choice(list(STYLE_WORDS.keys()))
    return key, random.choice(STYLE_WORDS[key])

def pick_layout():
    key = random.choice(list(LAYOUT_WORDS.keys()))
    return key, random.choice(LAYOUT_WORDS[key])

def pick_orientation():
    key = random.choice(list(ORIENTATION_WORDS.keys()))
    return key, random.choice(ORIENTATION_WORDS[key])

def pick_legs():
    key = random.choice(list(LEG_FAMILY_WORDS.keys()))
    return key, random.choice(LEG_FAMILY_WORDS[key])

def pick_armrests():
    key = random.choice(list(ARMREST_WORDS.keys()))
    return key, random.choice(ARMREST_WORDS[key])

def maybe(include_prob=0.7):
    return random.random() < include_prob

# ----------------------------
# Sample generator
# ----------------------------

def generate_one():
    # Core choices
    type_word = random.choice(TYPE_WORDS)

    style_key, style_word = pick_style()
    layout_key, layout_word = pick_layout()

    # Orientation only for corner/u_shape sometimes mentioned
    orientation_key = None
    orientation_word = None
    if layout_key in ("corner", "u_shape") and maybe(0.85):
        orientation_key, orientation_word = pick_orientation()

    # Dimensions
    seat_height = random.randint(380, 500)   # mm typical
    seat_depth = random.randint(520, 700)    # mm typical

    w_min = random.randint(450, 650)
    w_max = random.randint(max(w_min + 50, 520), min(w_min + 300, 900))

    # Seat count
    seat_count = random.choice([2, 3, 4, 5])

    # Options
    has_chaise = random.random() < 0.35
    leg_key, leg_word = pick_legs()
    arm_key, arm_word = pick_armrests()
    transformable = random.random() < 0.25

    # Text templates (shuffled clauses)
    clauses = []

    # intro
    intro_templates = [
        f"Мне нужен {type_word}",
        f"Хочу {type_word}",
        f"Подберите {type_word}",
        f"Нужен {type_word} для гостиной",
    ]
    clauses.append(random.choice(intro_templates))

    # style + layout
    style_layout_templates = [
        f"в стиле {style_word}",
        f"{style_word} стиль",
        f"стиль {style_word}",
    ]
    clauses.append(random.choice(style_layout_templates))

    layout_templates = [
        f"{layout_word}",
        f"компоновка {layout_word}",
        f"формат {layout_word}",
    ]
    clauses.append(random.choice(layout_templates))

    # orientation clause
    if orientation_word:
        orientation_templates = [
            f"угол {orientation_word}",
            f"ориентация {orientation_word}",
            f"{orientation_word} угол",
        ]
        clauses.append(random.choice(orientation_templates))

    # seat count
    if maybe(0.75):
        seat_templates = [
            f"на {seat_count} места",
            f"{seat_count}-местный",
            f"количество мест {seat_count}",
        ]
        clauses.append(random.choice(seat_templates))

    # dimensions
    if maybe(0.8):
        clauses.append(format_dim_phrase("высота сиденья", seat_height))
    if maybe(0.8):
        clauses.append(format_dim_phrase("глубина сиденья", seat_depth))
    if maybe(0.7):
        clauses.append(format_width_range(w_min, w_max))

    # legs
    if maybe(0.75):
        legs_templates = [
            f"ножки {leg_word}",
            f"с ножками: {leg_word}",
            f"тип ножек {leg_word}",
        ]
        clauses.append(random.choice(legs_templates))

    # armrests
    if maybe(0.75):
        clauses.append(arm_word)

    # chaise
    if maybe(0.65):
        clauses.append(random.choice(CHAISE_WORDS_TRUE if has_chaise else CHAISE_WORDS_FALSE))

    # transformable
    if maybe(0.6):
        clauses.append(random.choice(TRANSFORM_TRUE if transformable else TRANSFORM_FALSE))

    # Shuffle clauses and join
    random.shuffle(clauses)
    text = ", ".join(clauses) + "."

    tokens = tokenize_ru(text)
    tags = ["O"] * len(tokens)

    # Labeling helper to find token spans of inserted phrases
    def label_phrase(phrase: str, label: str):
        nonlocal tags
        phrase_tokens = tokenize_ru(phrase)
        # find first occurrence
        for i in range(len(tokens) - len(phrase_tokens) + 1):
            if tokens[i:i+len(phrase_tokens)] == phrase_tokens:
                span = tag_span(tokens, i, i+len(phrase_tokens), label)
                tags = merge_tags(tags, span)
                return True
        return False

    # TYPE
    label_phrase(type_word, "TYPE")

    # STYLE (label only the style word/phrase)
    label_phrase(style_word, "STYLE")

    # LAYOUT
    # label the main layout_word if present
    label_phrase(layout_word, "LAYOUT")

    # ORIENTATION
    if orientation_word:
        label_phrase(orientation_word, "ORIENTATION")

    # SEAT_COUNT: label the number token only (simpler and consistent)
    # locate seat_count as token
    for i, tok in enumerate(tokens):
        if tok == str(seat_count):
            tags[i] = "B-SEAT_COUNT"
            break

    # SEAT_HEIGHT_MM / SEAT_DEPTH_MM: label the numeric+unit region where possible
    # we label [число][единица] (e.g. "44", "см")
    def label_number_unit(mm_kind_label: str):
        nonlocal tags
        # look for pattern: number then unit token
        for i in range(len(tokens) - 1):
            if tokens[i].isdigit() and tokens[i+1] in ("см", "мм"):
                # Heuristic: check previous token context in window
                window = " ".join(tokens[max(0, i-4):i])
                if mm_kind_label == "SEAT_HEIGHT_MM" and ("высота" in window and "сиденья" in window):
                    tags[i] = f"B-{mm_kind_label}"
                    tags[i+1] = f"I-{mm_kind_label}"
                    return
                if mm_kind_label == "SEAT_DEPTH_MM" and ("глубина" in window and "сиденья" in window):
                    tags[i] = f"B-{mm_kind_label}"
                    tags[i+1] = f"I-{mm_kind_label}"
                    return

    label_number_unit("SEAT_HEIGHT_MM")
    label_number_unit("SEAT_DEPTH_MM")

    # SEAT_WIDTH_RANGE_MM: label the min–max + unit
    # patterns: number, "–"/"-", number, unit  OR  "от", number, "до", number, unit
    def label_width_range():
        nonlocal tags
        # pattern 1: N – N unit
        for i in range(len(tokens) - 3):
            if tokens[i].isdigit() and tokens[i+1] in ("–", "-") and tokens[i+2].isdigit() and tokens[i+3] in ("см", "мм"):
                tags[i] = "B-SEAT_WIDTH_RANGE_MM"
                tags[i+1] = "I-SEAT_WIDTH_RANGE_MM"
                tags[i+2] = "I-SEAT_WIDTH_RANGE_MM"
                tags[i+3] = "I-SEAT_WIDTH_RANGE_MM"
                return
        # pattern 2: от N до N unit
        for i in range(len(tokens) - 4):
            if tokens[i].lower() == "от" and tokens[i+1].isdigit() and tokens[i+2].lower() == "до" and tokens[i+3].isdigit() and tokens[i+4] in ("см", "мм"):
                tags[i] = "B-SEAT_WIDTH_RANGE_MM"
                for j in range(i+1, i+5):
                    tags[j] = "I-SEAT_WIDTH_RANGE_MM"
                return

    label_width_range()

    # HAS_CHAISE: label whole phrase (simple)
    chaise_phrase = random.choice(CHAISE_WORDS_TRUE if has_chaise else CHAISE_WORDS_FALSE)
    # but note: we used random choice when building clauses; we must find which one ended up in text
    for ph in CHAISE_WORDS_TRUE + CHAISE_WORDS_FALSE:
        if ph in text:
            label_phrase(ph, "HAS_CHAISE")
            break

    # ARMRESTS: label phrase
    for ph in sum(ARMREST_WORDS.values(), []):
        if ph in text:
            label_phrase(ph, "ARMRESTS")
            break

    # LEG_FAMILY: label phrase
    for ph in sum(LEG_FAMILY_WORDS.values(), []):
        if ph in text:
            label_phrase(ph, "LEG_FAMILY")
            break

    # TRANSFORMABLE: label phrase
    for ph in TRANSFORM_TRUE + TRANSFORM_FALSE:
        if ph in text:
            label_phrase(ph, "TRANSFORMABLE")
            break

    return {"tokens": tokens, "tags": tags}


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--n", type=int, default=20000, help="number of samples")
    parser.add_argument("--out", type=str, default="data/sofa_ner_train.jsonl")
    args = parser.parse_args()

    random.seed(RANDOM_SEED)

    out_path = Path(args.out)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with out_path.open("w", encoding="utf-8") as f:
        for _ in range(args.n):
            sample = generate_one()
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")

    print(f"✅ Wrote {args.n} samples to: {out_path.resolve()}")


if __name__ == "__main__":
    main()



===== FILE: tools/inspect_blend.py =====
# tools/inspect_blend.py
# Usage:
#   blender --background out/logs/sofa.blend --python C:\Users\Gigabyte\AMS\tools\inspect_blend.py

print("INSPECT_BLEND_START")

import bpy  # type: ignore


def axis_ranges_world(mesh, matrix_world):
    if not mesh or not getattr(mesh, "vertices", None):
        return None
    if len(mesh.vertices) == 0:
        return None

    xs = []
    ys = []
    zs = []
    for v in mesh.vertices:
        w = matrix_world @ v.co
        xs.append(w.x)
        ys.append(w.y)
        zs.append(w.z)

    return (
        (min(xs), max(xs)),
        (min(ys), max(ys)),
        (min(zs), max(zs)),
    )


def axis_spans(ranges):
    return (
        ranges[0][1] - ranges[0][0],
        ranges[1][1] - ranges[1][0],
        ranges[2][1] - ranges[2][0],
    )


def fmt_axis(ranges):
    return (
        f"x=({ranges[0][0]:.6f},{ranges[0][1]:.6f}) "
        f"y=({ranges[1][0]:.6f},{ranges[1][1]:.6f}) "
        f"z=({ranges[2][0]:.6f},{ranges[2][1]:.6f})"
    )


def mesh_counts(mesh):
    if not mesh:
        return (0, 0)
    verts = len(mesh.vertices) if getattr(mesh, "vertices", None) is not None else 0
    polys = len(mesh.polygons) if getattr(mesh, "polygons", None) is not None else 0
    return (verts, polys)


def fmt_modifiers(obj):
    if len(obj.modifiers) == 0:
        return "[]"

    rows = []
    for mod in obj.modifiers:
        show_viewport = bool(getattr(mod, "show_viewport", False))
        show_render = bool(getattr(mod, "show_render", False))
        show_in_editmode = bool(getattr(mod, "show_in_editmode", False))
        show_on_cage = bool(getattr(mod, "show_on_cage", False))
        rows.append(
            f"{mod.name}:{mod.type} "
            f"viewport={int(show_viewport)} render={int(show_render)} "
            f"edit={int(show_in_editmode)} cage={int(show_on_cage)}"
        )
    return "[" + ", ".join(rows) + "]"


def print_bend_modifiers(obj):
    for mod in obj.modifiers:
        if mod.type == "SIMPLE_DEFORM" and getattr(mod, "deform_method", "") == "BEND":
            origin = mod.origin.name if getattr(mod, "origin", None) else "None"
            print(f"BEND axis={mod.deform_axis} angle={float(mod.angle):.6f} origin={origin}")


def main():
    print("FILE:", bpy.data.filepath)
    print("BLENDER_VERSION:", bpy.app.version_string)
    print("Objects:", len(bpy.data.objects))

    depsgraph = bpy.context.evaluated_depsgraph_get()

    slats = [
        o
        for o in bpy.data.objects
        if o.type == "MESH" and ("slat" in o.name.lower() or o.name == "DEBUG_SLAT")
    ]
    slats = sorted(slats, key=lambda x: x.name)

    print("Slat-like:", len(slats))
    print("--- SLATS DUMP (first 60) ---")

    for obj in slats[:60]:
        eval_obj = obj.evaluated_get(depsgraph)
        eval_mesh = None
        base_verts, base_polys = mesh_counts(obj.data)
        try:
            eval_mesh = eval_obj.to_mesh()
            base_ranges = axis_ranges_world(obj.data, obj.matrix_world)
            eval_ranges = axis_ranges_world(eval_mesh, eval_obj.matrix_world)
        finally:
            if eval_mesh is not None:
                eval_obj.to_mesh_clear()

        print(f"\n- {obj.name}")
        print(f"BASE_MESH verts={base_verts} polys={base_polys}")
        print(f"MODIFIERS {fmt_modifiers(obj)}")
        print_bend_modifiers(obj)

        if base_ranges is None or eval_ranges is None:
            print("AXIS_RANGES_BASE x=(nan,nan) y=(nan,nan) z=(nan,nan)")
            print("AXIS_RANGES_EVAL x=(nan,nan) y=(nan,nan) z=(nan,nan)")
            print("RANGE_DELTAS dx=nan dy=nan dz=nan")
            print("BEND_EFFECT=NO")
            continue

        base_spans = axis_spans(base_ranges)
        eval_spans = axis_spans(eval_ranges)
        dx = abs(eval_spans[0] - base_spans[0])
        dy = abs(eval_spans[1] - base_spans[1])
        dz = abs(eval_spans[2] - base_spans[2])
        bend_effect = "OK" if max(dx, dy, dz) > 1e-5 else "NO"

        print(f"AXIS_RANGES_BASE {fmt_axis(base_ranges)}")
        print(f"AXIS_RANGES_EVAL {fmt_axis(eval_ranges)}")
        print(f"RANGE_DELTAS dx={dx:.6f} dy={dy:.6f} dz={dz:.6f}")
        print(f"BEND_EFFECT={bend_effect}")

    print("\nINSPECT_BLEND_DONE")


if __name__ == "__main__":
    main()



===== FILE: tools/ner_to_schema_demo.py =====
import sys
import re
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(ROOT))

from src.ner_infer import predict
from src.schema import SofaRequest, resolve_sofa

MODEL_DIR = "models/sofa_ner_rubert"


def parse_length_to_mm(s: str) -> int:
    t = s.lower().replace(",", ".")
    m = re.search(r"(\d+(?:\.\d+)?)", t)
    if not m:
        raise ValueError(f"Cannot parse length: {s}")
    value = float(m.group(1))

    if "мм" in t:
        mm = value
    elif "см" in t:
        mm = value * 10
    elif "м" in t:
        mm = value * 1000
    else:
        mm = value  # по умолчанию считаем мм

    return int(round(mm))


def parse_int(s: str) -> int:
    m = re.search(r"\d+", s)
    if not m:
        raise ValueError(f"Cannot parse int: {s}")
    return int(m.group(0))


def normalize_entities(entities: dict) -> dict:
    data: dict = {}

    # простые строковые
    for key in ["type", "style", "layout", "orientation", "leg_family", "armrests"]:
        K = key.upper()
        if K in entities and entities[K]:
            data[key] = entities[K][0].strip()

    # числовые
    if "SEAT_HEIGHT_MM" in entities and entities["SEAT_HEIGHT_MM"]:
        data["seat_height_mm"] = parse_length_to_mm(entities["SEAT_HEIGHT_MM"][0])

    if "SEAT_DEPTH_MM" in entities and entities["SEAT_DEPTH_MM"]:
        data["seat_depth_mm"] = parse_length_to_mm(entities["SEAT_DEPTH_MM"][0])

    if "SEAT_COUNT" in entities and entities["SEAT_COUNT"]:
        data["seat_count"] = parse_int(entities["SEAT_COUNT"][0])

    if "SEAT_WIDTH_RANGE_MM" in entities and entities["SEAT_WIDTH_RANGE_MM"]:
        joined = " ".join(entities["SEAT_WIDTH_RANGE_MM"])
        nums = [int(x) for x in re.findall(r"\d+", joined)]
        if len(nums) >= 2:
            data["seat_width_range_mm"] = (nums[0], nums[1])

    if "TRANSFORMABLE" in entities and entities["TRANSFORMABLE"]:
        t = " ".join(entities["TRANSFORMABLE"]).lower()
        data["transformable"] = not ("без" in t or "нет" in t)

    return data


def main():
    text = (
        "Мне нужен скандинавский угловой диван, "
        "высота сиденья 44 см, глубина 60 см, "
        "на 3 места, без механизма, ножки конусные."
    )

    print("\n=== USER TEXT ===")
    print(text)

    out = predict(text, MODEL_DIR, max_len=128)

    print("\n=== TOKENS ===")
    print(out.tokens)

    print("\n=== TAGS ===")
    print(out.tags)

    print("\n=== NER ENTITIES ===")
    for k, v in out.entities.items():
        print(f"{k}: {v}")

    params = normalize_entities(out.entities)
    print("\n=== NORMALIZED PARAMS ===")
    print(params)

    # 1) validate + aliases (Request)
    req = SofaRequest(**params)

    # 2) deterministic resolve (IR for Builder)
    resolved = resolve_sofa(req)

    print("\n=== SOFA RESOLVED (IR) ===")
    # красиво JSON-ом
    print(resolved.model_dump_json(indent=2, ensure_ascii=False))

    # если нужен dict:
    # print(resolved.model_dump())


if __name__ == "__main__":
    main()



===== FILE: tools/predict_sofa_ner.py =====



===== FILE: tools/train_sofa_ner.py =====
from __future__ import annotations
import json
import random
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    DataCollatorForTokenClassification,
    TrainingArguments,
    Trainer,
)
from seqeval.metrics import f1_score, precision_score, recall_score, classification_report


# ----------------------------
# Config
# ----------------------------
RANDOM_SEED = 42

# стабильная, хорошая стартовая RU-модель для NER
DEFAULT_MODEL_NAME = "DeepPavlov/rubert-base-cased"


def read_jsonl(path: str) -> List[Dict]:
    items = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            items.append(json.loads(line))
    return items


def build_label_list(items: List[Dict]) -> List[str]:
    # собираем список всех тегов, чтобы label2id/id2label были стабильны
    labels = set()
    for it in items:
        for t in it["tags"]:
            labels.add(t)
    # важно: O первым
    labels = sorted(labels)
    if "O" in labels:
        labels.remove("O")
    return ["O"] + labels


def split_items(items: List[Dict], train_ratio=0.9) -> Tuple[List[Dict], List[Dict]]:
    random.shuffle(items)
    n_train = int(len(items) * train_ratio)
    return items[:n_train], items[n_train:]


def align_labels_with_tokens(tokenizer, tokens: List[str], tags: List[str], label2id: Dict[str, int], max_length: int):
    # токенизация по словам + alignment
    enc = tokenizer(
        tokens,
        is_split_into_words=True,
        truncation=True,
        max_length=max_length,
    )
    word_ids = enc.word_ids()
    label_ids = []
    prev_word_id = None

    for word_id in word_ids:
        if word_id is None:
            label_ids.append(-100)
        elif word_id != prev_word_id:
            label_ids.append(label2id[tags[word_id]])
        else:
            # если токен является продолжением слова:
            # B-XXX -> I-XXX, иначе остаётся как есть
            tag = tags[word_id]
            if tag.startswith("B-"):
                tag = "I-" + tag[2:]
                tag = tag if tag in label2id else tags[word_id]
            label_ids.append(label2id[tag])
        prev_word_id = word_id

    enc["labels"] = label_ids
    return enc


def compute_metrics_builder(id2label: Dict[int, str]):
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)

        true_labels = []
        true_preds = []

        for pred_row, label_row in zip(preds, labels):
            seq_true = []
            seq_pred = []
            for p, l in zip(pred_row, label_row):
                if l == -100:
                    continue
                seq_true.append(id2label[int(l)])
                seq_pred.append(id2label[int(p)])
            true_labels.append(seq_true)
            true_preds.append(seq_pred)

        return {
            "precision": precision_score(true_labels, true_preds),
            "recall": recall_score(true_labels, true_preds),
            "f1": f1_score(true_labels, true_preds),
        }
    return compute_metrics


def main():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, default="data/sofa_ner_train.jsonl")
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL_NAME)
    parser.add_argument("--out", type=str, default="models/sofa_ner_rubert")
    parser.add_argument("--max_len", type=int, default=192)
    parser.add_argument("--epochs", type=int, default=5)
    parser.add_argument("--batch", type=int, default=16)
    parser.add_argument("--lr", type=float, default=3e-5)
    args = parser.parse_args()

    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)

    items = read_jsonl(args.data)
    if not items:
        raise RuntimeError("Dataset is empty")

    labels = build_label_list(items)
    label2id = {l: i for i, l in enumerate(labels)}
    id2label = {i: l for l, i in label2id.items()}

    train_items, val_items = split_items(items, train_ratio=0.9)

    tokenizer = AutoTokenizer.from_pretrained(args.model)

    def to_features(item):
        return align_labels_with_tokens(
            tokenizer,
            item["tokens"],
            item["tags"],
            label2id=label2id,
            max_length=args.max_len,
        )

    train_ds = Dataset.from_list(train_items).map(to_features, remove_columns=["tokens", "tags"])
    val_ds = Dataset.from_list(val_items).map(to_features, remove_columns=["tokens", "tags"])

    model = AutoModelForTokenClassification.from_pretrained(
        args.model,
        num_labels=len(labels),
        id2label=id2label,
        label2id=label2id,
    )

    collator = DataCollatorForTokenClassification(tokenizer)

    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    training_args = TrainingArguments(
    output_dir=str(out_dir),
    eval_strategy="epoch",
    save_strategy="epoch",
        learning_rate=args.lr,
        per_device_train_batch_size=args.batch,
        per_device_eval_batch_size=args.batch,
        num_train_epochs=args.epochs,
        weight_decay=0.01,
        logging_steps=100,
        report_to="none",
        fp16=True,  # на RTX 5070 обычно ок
        seed=RANDOM_SEED,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        tokenizer=tokenizer,
        data_collator=collator,
        compute_metrics=compute_metrics_builder(id2label),
    )

    trainer.train()

    # финальная оценка + отчёт
    preds = trainer.predict(val_ds)
    logits, labels_ids = preds.predictions, preds.label_ids
    preds_ids = np.argmax(logits, axis=-1)

    true_labels = []
    true_preds = []
    for pr, lb in zip(preds_ids, labels_ids):
        seq_true = []
        seq_pred = []
        for p, l in zip(pr, lb):
            if l == -100:
                continue
            seq_true.append(id2label[int(l)])
            seq_pred.append(id2label[int(p)])
        true_labels.append(seq_true)
        true_preds.append(seq_pred)

    print("\n=== SeqEval report (VAL) ===")
    print(classification_report(true_labels, true_preds))

    # сохраняем модель
    trainer.save_model(str(out_dir))
    tokenizer.save_pretrained(str(out_dir))
    print(f"\n✅ Saved model to: {out_dir.resolve()}")


if __name__ == "__main__":
    main()



===== FILE: tools/validate_schema.py =====
# tools/validate_schema.py
import json
import sys
from pathlib import Path

from pydantic import ValidationError

ROOT = Path(__file__).resolve().parents[1]  # AMS/
sys.path.insert(0, str(ROOT))

from src.schema import SofaRequest, resolve_sofa  # noqa: E402


def main():
    path = ROOT / "data" / "examples" / "request_scandi.json"
    raw = json.loads(path.read_text(encoding="utf-8"))

    print("INPUT JSON:")
    print(json.dumps(raw, ensure_ascii=False, indent=2))

    try:
        req = SofaRequest.model_validate(raw)
        print("\nSofaRequest OK ✅")
        print(req.model_dump())

        resolved = resolve_sofa(req)
        print("\nSofaResolved OK ✅")
        print(json.dumps(resolved.model_dump(), ensure_ascii=False, indent=2))

    except ValidationError as e:
        print("\nVALIDATION ERROR ❌")
        print(e)


if __name__ == "__main__":
    main()


===== SUMMARY =====
files_found=43
files_written=41
files_skipped_large=0
files_skipped_binary=0
output_bytes=845116